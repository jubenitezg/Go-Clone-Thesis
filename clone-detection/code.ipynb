{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:36.719713Z",
     "start_time": "2024-11-27T05:09:36.706220Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "MAPPED = 'group_repositories_per_topic.json'\n",
    "TOPICS = [\n",
    "    \"topic_0\",\n",
    "    \"topic_1\",\n",
    "    \"topic_2\",\n",
    "    \"topic_3\",\n",
    "    \"topic_4\",\n",
    "]\n",
    "CLASSES = 'classes2.json'\n",
    "METADATA = 'metadata.json'\n",
    "FUNCTIONS = 'go-functions.json'"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:36.940007Z",
     "start_time": "2024-11-27T05:09:36.722709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "BUCKET = os.getenv('BUCKET')\n",
    "s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)"
   ],
   "id": "f6ff06f17deb33f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:36.943189Z",
     "start_time": "2024-11-27T05:09:36.940710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def s3_load(key):\n",
    "  obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "  return json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "def s3_save(key, data):\n",
    "  s3.put_object(Bucket=BUCKET, Key=key, Body=json.dumps(data))"
   ],
   "id": "aa56be4ba99ce83d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:42.125259Z",
     "start_time": "2024-11-27T05:09:36.944867Z"
    }
   },
   "cell_type": "code",
   "source": "classes = s3_load(CLASSES)",
   "id": "d0503f6d5737a09d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:42.131463Z",
     "start_time": "2024-11-27T05:09:42.126574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for topic in classes:\n",
    "  klass_count = 0\n",
    "  for repo in classes[topic]:\n",
    "    klass_count += len(repo['classes'])\n",
    "  print(topic, klass_count/len(classes[topic]))"
   ],
   "id": "a9a9f93b825352a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 2.6337579617834397\n",
      "topic_1 2.4182944259171033\n",
      "topic_2 3.004304160688666\n",
      "topic_3 2.812351543942993\n",
      "topic_4 2.3670320747056435\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:09:42.924363Z",
     "start_time": "2024-11-27T05:09:42.132363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes_f = []\n",
    "repos_topic = {}\n",
    "for topic in TOPICS:\n",
    "  classes_f.append(s3_load(f\"{topic}/classes.json\"))\n",
    "  repos_topic[topic] = sorted(classes[topic], key=lambda repo: repo['stars'], reverse=True)[:10]"
   ],
   "id": "4f53e940e8ec329c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:52:37.888339Z",
     "start_time": "2024-11-29T01:52:37.854153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_function(functions, func_id):\n",
    "  for func in functions:\n",
    "    if func['id'] == func_id:\n",
    "      return func\n",
    "  return None\n",
    "\n",
    "\n",
    "def find_functions(func_ids, topic):\n",
    "  print(func_ids)\n",
    "  f = []\n",
    "  print(\"On topic:\", topic)\n",
    "  for repo in repos_topic[topic]:\n",
    "    functions = s3_load(f\"{repo['key']}/{FUNCTIONS}\")\n",
    "    for func in functions:\n",
    "      if func['id'] in func_ids:\n",
    "        f.append(func)\n",
    "  print(\"Found:\", len(f), topic)\n",
    "  return \n",
    "\n",
    "concurrency = [\"mutex\", \"waitgroup\", \"chan\"]\n",
    "mocks = [\"mock\", \"fake\", \"mockservice\", \"fakeservice\"]\n",
    "types = [\"type\", \"switch\", \"case\"]\n",
    "config = [\"config\", \"env\", \"flag\", \"viper\", \"init\", \"settings\"]\n",
    "\n",
    "def print_classes_code(repo_name, classes):\n",
    "  funcs = s3_load(f\"{repo_name}/{FUNCTIONS}\")\n",
    "  print(len(classes))\n",
    "  for klass in classes:\n",
    "    print(\"CLASS\".center(50, \"=\"))\n",
    "    for id in klass:\n",
    "      func = find_function(funcs, id)\n",
    "      # if any(word in config for word in func['code'].lower().split()):\n",
    "      print(func['code'])\n",
    "\n",
    "def save_classes_code(repo_name, classes):\n",
    "  funcs = s3_load(f\"{repo_name}/{FUNCTIONS}\")\n",
    "  lines = f\"TOTAL CLASSES {len(classes)}\\n\"\n",
    "  for klass in classes:\n",
    "    lines += \"CLASS\".center(20, \"=\") + \"\\n\"\n",
    "    for id in klass:\n",
    "      func = find_function(funcs, id)\n",
    "      lines += func['code'] + \"\\n\"\n",
    "  return lines\n",
    "\n",
    "def json_classes_code(repo_name, classes):\n",
    "  funcs = s3_load(f\"{repo_name}/{FUNCTIONS}\")\n",
    "  codes = []\n",
    "  for klass in classes:\n",
    "    k = []\n",
    "    for id in klass:\n",
    "      func = find_function(funcs, id)\n",
    "      k.append(func['code'])\n",
    "    codes.append(k)\n",
    "  return codes"
   ],
   "id": "6cbb3062a446f5bd",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T00:32:43.706122Z",
     "start_time": "2024-11-29T00:32:43.695825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for topic in repos_topic:\n",
    "  print(topic, len(repos_topic[topic]))\n",
    "  for repo in repos_topic[topic]:\n",
    "    print(repo['key'], len(repo['classes']), repo['stars'])\n",
    "  print(\"\\n\")"
   ],
   "id": "39e03d6b7063df9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 10\n",
      "junegunn/fzf 2 57530\n",
      "wagoodman/dive 2 42548\n",
      "coreybutler/nvm-windows 4 33303\n",
      "spf13/viper 3 25212\n",
      "tsenart/vegeta 5 22484\n",
      "projectdiscovery/nuclei 1 16418\n",
      "charmbracelet/gum 4 15909\n",
      "bcicen/ctop 6 14993\n",
      "FiloSottile/age 1 14855\n",
      "gitleaks/gitleaks 2 14713\n",
      "\n",
      "\n",
      "topic_1 10\n",
      "fatedier/frp 9 77144\n",
      "FiloSottile/mkcert 2 44662\n",
      "ehang-io/nps 3 28567\n",
      "schollz/croc 5 25745\n",
      "inconshreveable/ngrok 1 23632\n",
      "redis/go-redis 3 18715\n",
      "yudai/gotty 2 18326\n",
      "joewalnes/websocketd 6 17028\n",
      "rakyll/hey 2 16914\n",
      "XIU2/CloudflareSpeedTest 2 15319\n",
      "\n",
      "\n",
      "topic_2 10\n",
      "prometheus/prometheus 5 51732\n",
      "rclone/rclone 6 42712\n",
      "hashicorp/terraform 6 40408\n",
      "hashicorp/vault 703 29289\n",
      "hashicorp/consul 11 27562\n",
      "tmrts/go-patterns 1 23606\n",
      "hashicorp/packer 1 14780\n",
      "rqlite/rqlite 3 14605\n",
      "Netflix/chaosmonkey 3 14258\n",
      "CodisLabs/codis 5 13027\n",
      "\n",
      "\n",
      "topic_3 10\n",
      "gohugoio/hugo 6 71281\n",
      "syncthing/syncthing 11 58080\n",
      "etcd-io/etcd 15 45720\n",
      "gogs/gogs 3 43778\n",
      "astaxie/build-web-application-with-golang 13 42697\n",
      "spf13/cobra 1 35174\n",
      "go-gorm/gorm 1 34799\n",
      "unknwon/the-way-to-go_ZH_CN 8 33963\n",
      "docker/compose 1 31817\n",
      "harness/gitness 5 31162\n",
      "\n",
      "\n",
      "topic_4 10\n",
      "avelino/awesome-go 1 116621\n",
      "gin-gonic/gin 2 74189\n",
      "sirupsen/logrus 1 23799\n",
      "charmbracelet/bubbletea 4 22583\n",
      "stretchr/testify 4 21538\n",
      "gorilla/mux 1 19872\n",
      "go-chi/chi 4 16555\n",
      "julienschmidt/httprouter 1 16120\n",
      "go-playground/validator 1 15048\n",
      "jmoiron/sqlx 1 15043\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T00:48:23.708768Z",
     "start_time": "2024-11-29T00:48:03.143636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for topic in repos_topic:\n",
    "  print(topic, len(repos_topic[topic]))\n",
    "  for repo in repos_topic[topic]:\n",
    "    print(repo['key'], len(repo['classes']), repo['stars'])\n",
    "    print_classes_code(repo['key'], repo['classes'])\n",
    "  print(\"\\n\"*3)"
   ],
   "id": "231d0fa9e6a2b8e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 10\n",
      "junegunn/fzf 2 57530\n",
      "2\n",
      "======================CLASS=======================\n",
      "func getEnv(name string, defaultValue int) int {\n",
      "\tenv := os.Getenv(name)\n",
      "\tif len(env) == 0 {\n",
      "\t\treturn defaultValue\n",
      "\t}\n",
      "\treturn atoi(env, defaultValue)\n",
      "}\n",
      "func (t *Terminal) Loop() {\n",
      "\tfitpad := <-t.startChan\n",
      "\tfit := fitpad.fit\n",
      "\tif fit >= 0 {\n",
      "\t\tpad := fitpad.pad\n",
      "\t\tt.tui.Resize(func(termHeight int) int {\n",
      "\t\t\tcontentHeight := fit + t.extraLines()\n",
      "\t\t\tif t.needPreviewWindow() {\n",
      "\t\t\t\tif t.previewOpts.aboveOrBelow() {\n",
      "\t\t\t\t\tif t.previewOpts.size.percent {\n",
      "\t\t\t\t\t\tnewContentHeight := int(float64(contentHeight) * 100. / (100. - t.previewOpts.size.size))\n",
      "\t\t\t\t\t\tcontentHeight = util.Max(contentHeight+1+borderLines(t.previewOpts.border), newContentHeight)\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tcontentHeight += int(t.previewOpts.size.size) + borderLines(t.previewOpts.border)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tcontentHeight = util.Max(contentHeight, 1+borderLines(t.previewOpts.border))\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn util.Min(termHeight, contentHeight+pad)\n",
      "\t\t})\n",
      "\t}\n",
      "\t{\n",
      "\t\tintChan := make(chan os.Signal, 1)\n",
      "\t\tsignal.Notify(intChan, os.Interrupt, syscall.SIGTERM)\n",
      "\t\tgo func() {\n",
      "\t\t\tfor s := range intChan {\n",
      "\t\t\t\tif !(s == os.Interrupt && t.executing.Get()) {\n",
      "\t\t\t\t\tt.reqBox.Set(reqQuit, nil)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tcontChan := make(chan os.Signal, 1)\n",
      "\t\tnotifyOnCont(contChan)\n",
      "\t\tgo func() {\n",
      "\t\t\tfor {\n",
      "\t\t\t\t<-contChan\n",
      "\t\t\t\tt.reqBox.Set(reqReinit, nil)\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tif !t.tui.ShouldEmitResizeEvent() {\n",
      "\t\t\tresizeChan := make(chan os.Signal, 1)\n",
      "\t\t\tnotifyOnResize(resizeChan)\n",
      "\t\t\tgo func() {\n",
      "\t\t\t\tfor {\n",
      "\t\t\t\t\t<-resizeChan\n",
      "\t\t\t\t\tt.reqBox.Set(reqResize, nil)\n",
      "\t\t\t\t}\n",
      "\t\t\t}()\n",
      "\t\t}\n",
      "\t\tt.mutex.Lock()\n",
      "\t\tt.initFunc()\n",
      "\t\tt.termSize = t.tui.Size()\n",
      "\t\tt.resizeWindows(false)\n",
      "\t\tt.printPrompt()\n",
      "\t\tt.printInfo()\n",
      "\t\tt.printHeader()\n",
      "\t\tt.refresh()\n",
      "\t\tt.mutex.Unlock()\n",
      "\t\tgo func() {\n",
      "\t\t\ttimer := time.NewTimer(t.initDelay)\n",
      "\t\t\t<-timer.C\n",
      "\t\t\tt.reqBox.Set(reqRefresh, nil)\n",
      "\t\t}()\n",
      "\t\tgo func() {\n",
      "\t\t\tfor {\n",
      "\t\t\t\tt.mutex.Lock()\n",
      "\t\t\t\treading := t.reading\n",
      "\t\t\t\tt.mutex.Unlock()\n",
      "\t\t\t\ttime.Sleep(spinnerDuration)\n",
      "\t\t\t\tif reading {\n",
      "\t\t\t\t\tt.reqBox.Set(reqInfo, nil)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t}\n",
      "\tif t.hasPreviewer() {\n",
      "\t\tgo func() {\n",
      "\t\t\tvar version int64\n",
      "\t\t\tfor {\n",
      "\t\t\t\tvar items []*Item\n",
      "\t\t\t\tvar commandTemplate string\n",
      "\t\t\t\tvar pwindow tui.Window\n",
      "\t\t\t\tvar pwindowSize tui.TermSize\n",
      "\t\t\t\tinitialOffset := 0\n",
      "\t\t\t\tt.previewBox.Wait(func(events *util.Events) {\n",
      "\t\t\t\t\tfor req, value := range *events {\n",
      "\t\t\t\t\t\tswitch req {\n",
      "\t\t\t\t\t\tcase reqPreviewEnqueue:\n",
      "\t\t\t\t\t\t\trequest := value.(previewRequest)\n",
      "\t\t\t\t\t\t\tcommandTemplate = request.template\n",
      "\t\t\t\t\t\t\tinitialOffset = request.scrollOffset\n",
      "\t\t\t\t\t\t\titems = request.list\n",
      "\t\t\t\t\t\t\tpwindow = request.pwindow\n",
      "\t\t\t\t\t\t\tpwindowSize = request.pwindowSize\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tevents.Clear()\n",
      "\t\t\t\t})\n",
      "\t\t\t\tversion++\n",
      "\t\t\t\tif items[0] != nil {\n",
      "\t\t\t\t\t_, query := t.Input()\n",
      "\t\t\t\t\tcommand := t.replacePlaceholder(commandTemplate, false, string(query), items)\n",
      "\t\t\t\t\tcmd := util.ExecCommand(command, true)\n",
      "\t\t\t\t\tenv := t.environ()\n",
      "\t\t\t\t\tif pwindowSize.Lines > 0 {\n",
      "\t\t\t\t\t\tlines := fmt.Sprintf(\"LINES=%d\", pwindowSize.Lines)\n",
      "\t\t\t\t\t\tcolumns := fmt.Sprintf(\"COLUMNS=%d\", pwindowSize.Columns)\n",
      "\t\t\t\t\t\tenv = append(env, lines)\n",
      "\t\t\t\t\t\tenv = append(env, \"FZF_PREVIEW_\"+lines)\n",
      "\t\t\t\t\t\tenv = append(env, columns)\n",
      "\t\t\t\t\t\tenv = append(env, \"FZF_PREVIEW_\"+columns)\n",
      "\t\t\t\t\t\tenv = append(env, fmt.Sprintf(\"FZF_PREVIEW_TOP=%d\", t.tui.Top()+pwindow.Top()))\n",
      "\t\t\t\t\t\tenv = append(env, fmt.Sprintf(\"FZF_PREVIEW_LEFT=%d\", pwindow.Left()))\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tcmd.Env = env\n",
      "\t\t\t\t\tout, _ := cmd.StdoutPipe()\n",
      "\t\t\t\t\tcmd.Stderr = cmd.Stdout\n",
      "\t\t\t\t\treader := bufio.NewReader(out)\n",
      "\t\t\t\t\teofChan := make(chan bool)\n",
      "\t\t\t\t\tfinishChan := make(chan bool, 1)\n",
      "\t\t\t\t\terr := cmd.Start()\n",
      "\t\t\t\t\tif err == nil {\n",
      "\t\t\t\t\t\treapChan := make(chan bool)\n",
      "\t\t\t\t\t\tlineChan := make(chan eachLine)\n",
      "\t\t\t\t\t\tgo func() {\n",
      "\t\t\t\t\t\t\tfor {\n",
      "\t\t\t\t\t\t\t\tline, err := reader.ReadString('\\n')\n",
      "\t\t\t\t\t\t\t\tlineChan <- eachLine{line, err}\n",
      "\t\t\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\teofChan <- true\n",
      "\t\t\t\t\t\t}()\n",
      "\t\t\t\t\t\trendered := util.NewAtomicBool(false)\n",
      "\t\t\t\t\t\tgo func(version int64) {\n",
      "\t\t\t\t\t\t\tlines := []string{}\n",
      "\t\t\t\t\t\t\tspinner := makeSpinner(t.unicode)\n",
      "\t\t\t\t\t\t\tspinnerIndex := -1\n",
      "\t\t\t\t\t\t\tticker := time.NewTicker(previewChunkDelay)\n",
      "\t\t\t\t\t\t\toffset := initialOffset\n",
      "\t\t\t\t\t\tLoop:\n",
      "\t\t\t\t\t\t\tfor {\n",
      "\t\t\t\t\t\t\t\tselect {\n",
      "\t\t\t\t\t\t\t\tcase <-ticker.C:\n",
      "\t\t\t\t\t\t\t\t\tif len(lines) > 0 && len(lines) >= initialOffset {\n",
      "\t\t\t\t\t\t\t\t\t\tif spinnerIndex >= 0 {\n",
      "\t\t\t\t\t\t\t\t\t\t\tspin := spinner[spinnerIndex%len(spinner)]\n",
      "\t\t\t\t\t\t\t\t\t\t\tt.reqBox.Set(reqPreviewDisplay, previewResult{version, lines, offset, spin})\n",
      "\t\t\t\t\t\t\t\t\t\t\trendered.Set(true)\n",
      "\t\t\t\t\t\t\t\t\t\t\toffset = -1\n",
      "\t\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\t\tspinnerIndex++\n",
      "\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\tcase eachLine := <-lineChan:\n",
      "\t\t\t\t\t\t\t\t\tline := eachLine.line\n",
      "\t\t\t\t\t\t\t\t\terr := eachLine.err\n",
      "\t\t\t\t\t\t\t\t\tif len(line) > 0 {\n",
      "\t\t\t\t\t\t\t\t\t\tclearIndex := strings.Index(line, clearCode)\n",
      "\t\t\t\t\t\t\t\t\t\tif clearIndex >= 0 {\n",
      "\t\t\t\t\t\t\t\t\t\t\tlines = []string{}\n",
      "\t\t\t\t\t\t\t\t\t\t\tline = line[clearIndex+len(clearCode):]\n",
      "\t\t\t\t\t\t\t\t\t\t\tversion--\n",
      "\t\t\t\t\t\t\t\t\t\t\toffset = 0\n",
      "\t\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\t\tlines = append(lines, line)\n",
      "\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\t\t\t\tt.reqBox.Set(reqPreviewDisplay, previewResult{version, lines, offset, \"\"})\n",
      "\t\t\t\t\t\t\t\t\t\trendered.Set(true)\n",
      "\t\t\t\t\t\t\t\t\t\tbreak Loop\n",
      "\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\tticker.Stop()\n",
      "\t\t\t\t\t\t\treapChan <- true\n",
      "\t\t\t\t\t\t}(version)\n",
      "\t\t\t\t\t\tgo func(version int64) {\n",
      "\t\t\t\t\t\t\ttimer := time.NewTimer(previewDelayed)\n",
      "\t\t\t\t\t\tLoop:\n",
      "\t\t\t\t\t\t\tfor {\n",
      "\t\t\t\t\t\t\t\tselect {\n",
      "\t\t\t\t\t\t\t\tcase <-timer.C:\n",
      "\t\t\t\t\t\t\t\t\tt.reqBox.Set(reqPreviewDelayed, version)\n",
      "\t\t\t\t\t\t\t\tcase code := <-t.killChan:\n",
      "\t\t\t\t\t\t\t\t\tif code != exitCancel {\n",
      "\t\t\t\t\t\t\t\t\t\tutil.KillCommand(cmd)\n",
      "\t\t\t\t\t\t\t\t\t\tt.eventBox.Set(EvtQuit, code)\n",
      "\t\t\t\t\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\t\t\t\t\tdelay := previewCancelWait\n",
      "\t\t\t\t\t\t\t\t\t\tif rendered.Get() {\n",
      "\t\t\t\t\t\t\t\t\t\t\tdelay = 0\n",
      "\t\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\t\ttimer := time.NewTimer(delay)\n",
      "\t\t\t\t\t\t\t\t\t\tselect {\n",
      "\t\t\t\t\t\t\t\t\t\tcase <-timer.C:\n",
      "\t\t\t\t\t\t\t\t\t\t\tutil.KillCommand(cmd)\n",
      "\t\t\t\t\t\t\t\t\t\tcase <-finishChan:\n",
      "\t\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\t\ttimer.Stop()\n",
      "\t\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t\t\tbreak Loop\n",
      "\t\t\t\t\t\t\t\tcase <-finishChan:\n",
      "\t\t\t\t\t\t\t\t\tbreak Loop\n",
      "\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\ttimer.Stop()\n",
      "\t\t\t\t\t\t\treapChan <- true\n",
      "\t\t\t\t\t\t}(version)\n",
      "\t\t\t\t\t\t<-eofChan\n",
      "\t\t\t\t\t\tcmd.Wait()\n",
      "\t\t\t\t\t\tfinishChan <- true\n",
      "\t\t\t\t\t\t<-reapChan\n",
      "\t\t\t\t\t\t<-reapChan\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tt.reqBox.Set(reqPreviewDisplay, previewResult{version, []string{err.Error()}, 0, \"\"})\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tcleanTemporaryFiles()\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tt.reqBox.Set(reqPreviewDisplay, previewResult{version, nil, 0, \"\"})\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t}\n",
      "\trefreshPreview := func(command string) {\n",
      "\t\tif len(command) > 0 && t.canPreview() {\n",
      "\t\t\t_, list := t.buildPlusList(command, false)\n",
      "\t\t\tt.cancelPreview()\n",
      "\t\t\tt.previewBox.Set(reqPreviewEnqueue, previewRequest{command, t.pwindow, t.pwindowSize(), t.evaluateScrollOffset(), list})\n",
      "\t\t}\n",
      "\t}\n",
      "\tgo func() {\n",
      "\t\tvar focusedIndex int32 = minItem.Index()\n",
      "\t\tvar version int64 = -1\n",
      "\t\trunning := true\n",
      "\t\tcode := exitError\n",
      "\t\texit := func(getCode func() int) {\n",
      "\t\t\tt.tui.Close()\n",
      "\t\t\tcode = getCode()\n",
      "\t\t\tif code <= exitNoMatch && t.history != nil {\n",
      "\t\t\t\tt.history.append(string(t.input))\n",
      "\t\t\t}\n",
      "\t\t\trunning = false\n",
      "\t\t\tt.mutex.Unlock()\n",
      "\t\t}\n",
      "\t\tfor running {\n",
      "\t\t\tt.reqBox.Wait(func(events *util.Events) {\n",
      "\t\t\t\tdefer events.Clear()\n",
      "\t\t\t\tt.mutex.Lock()\n",
      "\t\t\t\tfor req, value := range *events {\n",
      "\t\t\t\t\tswitch req {\n",
      "\t\t\t\t\tcase reqPrompt:\n",
      "\t\t\t\t\t\tt.printPrompt()\n",
      "\t\t\t\t\t\tif t.noInfoLine() {\n",
      "\t\t\t\t\t\t\tt.printInfo()\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\tcase reqInfo:\n",
      "\t\t\t\t\t\tt.printInfo()\n",
      "\t\t\t\t\tcase reqList:\n",
      "\t\t\t\t\t\tt.printList()\n",
      "\t\t\t\t\t\tcurrentIndex := t.currentIndex()\n",
      "\t\t\t\t\t\tfocusChanged := focusedIndex != currentIndex\n",
      "\t\t\t\t\t\tif focusChanged && t.track == trackCurrent {\n",
      "\t\t\t\t\t\t\tt.track = trackDisabled\n",
      "\t\t\t\t\t\t\tt.printInfo()\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif t.hasFocusActions && focusChanged && currentIndex != t.lastFocus {\n",
      "\t\t\t\t\t\t\tt.lastFocus = currentIndex\n",
      "\t\t\t\t\t\t\tt.eventChan <- tui.Focus.AsEvent()\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif focusChanged || version != t.version {\n",
      "\t\t\t\t\t\t\tversion = t.version\n",
      "\t\t\t\t\t\t\tfocusedIndex = currentIndex\n",
      "\t\t\t\t\t\t\trefreshPreview(t.previewOpts.command)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\tcase reqJump:\n",
      "\t\t\t\t\t\tif t.merger.Length() == 0 {\n",
      "\t\t\t\t\t\t\tt.jumping = jumpDisabled\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tt.printList()\n",
      "\t\t\t\t\tcase reqHeader:\n",
      "\t\t\t\t\t\tt.printHeader()\n",
      "\t\t\t\t\tcase reqRefresh:\n",
      "\t\t\t\t\t\tt.suppress = false\n",
      "\t\t\t\t\tcase reqRedrawBorderLabel:\n",
      "\t\t\t\t\t\tt.printLabel(t.border, t.borderLabel, t.borderLabelOpts, t.borderLabelLen, t.borderShape, true)\n",
      "\t\t\t\t\tcase reqRedrawPreviewLabel:\n",
      "\t\t\t\t\t\tt.printLabel(t.pborder, t.previewLabel, t.previewLabelOpts, t.previewLabelLen, t.previewOpts.border, true)\n",
      "\t\t\t\t\tcase reqReinit:\n",
      "\t\t\t\t\t\tt.tui.Resume(t.fullscreen, t.sigstop)\n",
      "\t\t\t\t\t\tt.redraw()\n",
      "\t\t\t\t\tcase reqResize, reqFullRedraw:\n",
      "\t\t\t\t\t\tif req == reqResize {\n",
      "\t\t\t\t\t\t\tt.termSize = t.tui.Size()\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\twasHidden := t.pwindow == nil\n",
      "\t\t\t\t\t\tt.redraw()\n",
      "\t\t\t\t\t\tif wasHidden && t.hasPreviewWindow() {\n",
      "\t\t\t\t\t\t\trefreshPreview(t.previewOpts.command)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif req == reqResize && t.hasResizeActions {\n",
      "\t\t\t\t\t\t\tt.eventChan <- tui.Resize.AsEvent()\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\tcase reqClose:\n",
      "\t\t\t\t\t\texit(func() int {\n",
      "\t\t\t\t\t\t\tif t.output() {\n",
      "\t\t\t\t\t\t\t\treturn exitOk\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\treturn exitNoMatch\n",
      "\t\t\t\t\t\t})\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\tcase reqPreviewDisplay:\n",
      "\t\t\t\t\t\tresult := value.(previewResult)\n",
      "\t\t\t\t\t\tif t.previewer.version != result.version {\n",
      "\t\t\t\t\t\t\tt.previewer.version = result.version\n",
      "\t\t\t\t\t\t\tt.previewer.following.Force(t.previewOpts.follow)\n",
      "\t\t\t\t\t\t\tif t.previewer.following.Enabled() {\n",
      "\t\t\t\t\t\t\t\tt.previewer.offset = 0\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tt.previewer.lines = result.lines\n",
      "\t\t\t\t\t\tt.previewer.spinner = result.spinner\n",
      "\t\t\t\t\t\tif t.previewer.following.Enabled() {\n",
      "\t\t\t\t\t\t\tt.previewer.offset = util.Max(t.previewer.offset, len(t.previewer.lines)-(t.pwindow.Height()-t.previewOpts.headerLines))\n",
      "\t\t\t\t\t\t} else if result.offset >= 0 {\n",
      "\t\t\t\t\t\t\tt.previewer.offset = util.Constrain(result.offset, t.previewOpts.headerLines, len(t.previewer.lines)-1)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tt.printPreview()\n",
      "\t\t\t\t\tcase reqPreviewRefresh:\n",
      "\t\t\t\t\t\tt.printPreview()\n",
      "\t\t\t\t\tcase reqPreviewDelayed:\n",
      "\t\t\t\t\t\tt.previewer.version = value.(int64)\n",
      "\t\t\t\t\t\tt.printPreviewDelayed()\n",
      "\t\t\t\t\tcase reqPrintQuery:\n",
      "\t\t\t\t\t\texit(func() int {\n",
      "\t\t\t\t\t\t\tt.printer(string(t.input))\n",
      "\t\t\t\t\t\t\treturn exitOk\n",
      "\t\t\t\t\t\t})\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\tcase reqQuit:\n",
      "\t\t\t\t\t\texit(func() int {\n",
      "\t\t\t\t\t\t\treturn exitInterrupt\n",
      "\t\t\t\t\t\t})\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tt.refresh()\n",
      "\t\t\t\tt.mutex.Unlock()\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t\tt.killPreview(code)\n",
      "\t}()\n",
      "\tlooping := true\n",
      "\t_, startEvent := t.keymap[tui.Start.AsEvent()]\n",
      "\tneedBarrier := true\n",
      "\tbarrier := make(chan bool)\n",
      "\tgo func() {\n",
      "\t\tfor {\n",
      "\t\t\t<-barrier\n",
      "\t\t\tt.eventChan <- t.tui.GetChar()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tpreviewDraggingPos := -1\n",
      "\tbarDragging := false\n",
      "\tpbarDragging := false\n",
      "\twasDown := false\n",
      "\tfor looping {\n",
      "\t\tvar newCommand *string\n",
      "\t\tvar reloadSync bool\n",
      "\t\tchanged := false\n",
      "\t\tbeof := false\n",
      "\t\tqueryChanged := false\n",
      "\t\tvar event tui.Event\n",
      "\t\tactions := []*action{}\n",
      "\t\tif startEvent {\n",
      "\t\t\tevent = tui.Start.AsEvent()\n",
      "\t\t\tstartEvent = false\n",
      "\t\t} else {\n",
      "\t\t\tif needBarrier {\n",
      "\t\t\t\tbarrier <- true\n",
      "\t\t\t}\n",
      "\t\t\tselect {\n",
      "\t\t\tcase event = <-t.eventChan:\n",
      "\t\t\t\tif t.tui.ShouldEmitResizeEvent() {\n",
      "\t\t\t\t\tneedBarrier = !event.Is(tui.Load, tui.Result, tui.Focus, tui.One, tui.Zero)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tneedBarrier = !event.Is(tui.Load, tui.Result, tui.Focus, tui.One, tui.Zero, tui.Resize)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase serverActions := <-t.serverInputChan:\n",
      "\t\t\t\tevent = tui.Invalid.AsEvent()\n",
      "\t\t\t\tif t.listenAddr == nil || t.listenAddr.IsLocal() || t.listenUnsafe {\n",
      "\t\t\t\t\tactions = serverActions\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tfor _, action := range serverActions {\n",
      "\t\t\t\t\t\tif !processExecution(action.t) {\n",
      "\t\t\t\t\t\t\tactions = append(actions, action)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tneedBarrier = false\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tt.mutex.Lock()\n",
      "\t\tpreviousInput := t.input\n",
      "\t\tpreviousCx := t.cx\n",
      "\t\tevents := []util.EventType{}\n",
      "\t\treq := func(evts ...util.EventType) {\n",
      "\t\t\tfor _, event := range evts {\n",
      "\t\t\t\tevents = append(events, event)\n",
      "\t\t\t\tif event == reqClose || event == reqQuit {\n",
      "\t\t\t\t\tlooping = false\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tupdatePreviewWindow := func(forcePreview bool) {\n",
      "\t\t\tt.resizeWindows(forcePreview)\n",
      "\t\t\treq(reqPrompt, reqList, reqInfo, reqHeader)\n",
      "\t\t}\n",
      "\t\ttoggle := func() bool {\n",
      "\t\t\tcurrent := t.currentItem()\n",
      "\t\t\tif current != nil && t.toggleItem(current) {\n",
      "\t\t\t\treq(reqInfo)\n",
      "\t\t\t\treturn true\n",
      "\t\t\t}\n",
      "\t\t\treturn false\n",
      "\t\t}\n",
      "\t\tscrollPreviewTo := func(newOffset int) {\n",
      "\t\t\tif !t.previewer.scrollable {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\tnumLines := len(t.previewer.lines)\n",
      "\t\t\theaderLines := t.previewOpts.headerLines\n",
      "\t\t\tif t.previewOpts.cycle {\n",
      "\t\t\t\toffsetRange := numLines - headerLines\n",
      "\t\t\t\tnewOffset = ((newOffset-headerLines)+offsetRange)%offsetRange + headerLines\n",
      "\t\t\t}\n",
      "\t\t\tnewOffset = util.Constrain(newOffset, headerLines, numLines-1)\n",
      "\t\t\tif t.previewer.offset != newOffset {\n",
      "\t\t\t\tt.previewer.offset = newOffset\n",
      "\t\t\t\tt.previewer.following.Set(t.previewer.offset >= numLines-(t.pwindow.Height()-headerLines))\n",
      "\t\t\t\treq(reqPreviewRefresh)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tscrollPreviewBy := func(amount int) {\n",
      "\t\t\tscrollPreviewTo(t.previewer.offset + amount)\n",
      "\t\t}\n",
      "\t\tfor key, ret := range t.expect {\n",
      "\t\t\tif keyMatch(key, event) {\n",
      "\t\t\t\tt.pressed = ret\n",
      "\t\t\t\tt.reqBox.Set(reqClose, nil)\n",
      "\t\t\t\tt.mutex.Unlock()\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tactionsFor := func(eventType tui.EventType) []*action {\n",
      "\t\t\treturn t.keymap[eventType.AsEvent()]\n",
      "\t\t}\n",
      "\t\tvar doAction func(*action) bool\n",
      "\t\tvar doActions func(actions []*action) bool\n",
      "\t\tdoActions = func(actions []*action) bool {\n",
      "\t\t\tcurrentIndex := t.currentIndex()\n",
      "\t\t\tfor _, action := range actions {\n",
      "\t\t\t\tif !doAction(action) {\n",
      "\t\t\t\t\treturn false\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif onFocus, prs := t.keymap[tui.Focus.AsEvent()]; prs {\n",
      "\t\t\t\tif newIndex := t.currentIndex(); newIndex != currentIndex {\n",
      "\t\t\t\t\tt.lastFocus = newIndex\n",
      "\t\t\t\t\treturn doActions(onFocus)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn true\n",
      "\t\t}\n",
      "\t\tdoAction = func(a *action) bool {\n",
      "\t\t\tswitch a.t {\n",
      "\t\t\tcase actIgnore, actStart, actClick:\n",
      "\t\t\tcase actResponse:\n",
      "\t\t\t\tt.serverOutputChan <- t.dumpStatus(parseGetParams(a.a))\n",
      "\t\t\tcase actBecome:\n",
      "\t\t\t\tvalid, list := t.buildPlusList(a.a, false)\n",
      "\t\t\t\tif valid {\n",
      "\t\t\t\t\tcommand := t.replacePlaceholder(a.a, false, string(t.input), list)\n",
      "\t\t\t\t\tshell := os.Getenv(\"SHELL\")\n",
      "\t\t\t\t\tif len(shell) == 0 {\n",
      "\t\t\t\t\t\tshell = \"sh\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tshellPath, err := exec.LookPath(shell)\n",
      "\t\t\t\t\tif err == nil {\n",
      "\t\t\t\t\t\tt.tui.Close()\n",
      "\t\t\t\t\t\tif t.history != nil {\n",
      "\t\t\t\t\t\t\tt.history.append(string(t.input))\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\ttui.TtyIn()\n",
      "\t\t\t\t\t\tutil.SetStdin(tui.TtyIn())\n",
      "\t\t\t\t\t\tsyscall.Exec(shellPath, []string{shell, \"-c\", command}, os.Environ())\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actExecute, actExecuteSilent:\n",
      "\t\t\t\tt.executeCommand(a.a, false, a.t == actExecuteSilent, false, false)\n",
      "\t\t\tcase actExecuteMulti:\n",
      "\t\t\t\tt.executeCommand(a.a, true, false, false, false)\n",
      "\t\t\tcase actInvalid:\n",
      "\t\t\t\tt.mutex.Unlock()\n",
      "\t\t\t\treturn false\n",
      "\t\t\tcase actTogglePreview, actShowPreview, actHidePreview:\n",
      "\t\t\t\tvar act bool\n",
      "\t\t\t\tswitch a.t {\n",
      "\t\t\t\tcase actShowPreview:\n",
      "\t\t\t\t\tact = !t.hasPreviewWindow() && len(t.previewOpts.command) > 0\n",
      "\t\t\t\tcase actHidePreview:\n",
      "\t\t\t\t\tact = t.hasPreviewWindow()\n",
      "\t\t\t\tcase actTogglePreview:\n",
      "\t\t\t\t\tact = t.hasPreviewWindow() || len(t.previewOpts.command) > 0\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif act {\n",
      "\t\t\t\t\tt.activePreviewOpts.Toggle()\n",
      "\t\t\t\t\tupdatePreviewWindow(false)\n",
      "\t\t\t\t\tif t.canPreview() {\n",
      "\t\t\t\t\t\tvalid, list := t.buildPlusList(t.previewOpts.command, false)\n",
      "\t\t\t\t\t\tif valid {\n",
      "\t\t\t\t\t\t\tt.cancelPreview()\n",
      "\t\t\t\t\t\t\tt.previewBox.Set(reqPreviewEnqueue, previewRequest{t.previewOpts.command, t.pwindow, t.pwindowSize(), t.evaluateScrollOffset(), list})\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tt.previewer.lines = nil\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actTogglePreviewWrap:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tt.previewOpts.wrap = !t.previewOpts.wrap\n",
      "\t\t\t\t\tt.previewed.version = 0\n",
      "\t\t\t\t\treq(reqPreviewRefresh)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actTransformPrompt:\n",
      "\t\t\t\tprompt := t.executeCommand(a.a, false, true, true, true)\n",
      "\t\t\t\tt.promptString = prompt\n",
      "\t\t\t\tt.prompt, t.promptLen = t.parsePrompt(prompt)\n",
      "\t\t\t\treq(reqPrompt)\n",
      "\t\t\tcase actTransformQuery:\n",
      "\t\t\t\tquery := t.executeCommand(a.a, false, true, true, true)\n",
      "\t\t\t\tt.input = []rune(query)\n",
      "\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\tcase actToggleSort:\n",
      "\t\t\t\tt.sort = !t.sort\n",
      "\t\t\t\tchanged = true\n",
      "\t\t\tcase actPreviewTop:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewTo(0)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewBottom:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewTo(len(t.previewer.lines) - t.pwindow.Height())\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewUp:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(-1)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewDown:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(1)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewPageUp:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(-t.pwindow.Height())\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewPageDown:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(t.pwindow.Height())\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewHalfPageUp:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(-t.pwindow.Height() / 2)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPreviewHalfPageDown:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tscrollPreviewBy(t.pwindow.Height() / 2)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actBeginningOfLine:\n",
      "\t\t\t\tt.cx = 0\n",
      "\t\t\t\tt.xoffset = 0\n",
      "\t\t\tcase actBackwardChar:\n",
      "\t\t\t\tif t.cx > 0 {\n",
      "\t\t\t\t\tt.cx--\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPrintQuery:\n",
      "\t\t\t\treq(reqPrintQuery)\n",
      "\t\t\tcase actChangeQuery:\n",
      "\t\t\t\tt.input = []rune(a.a)\n",
      "\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\tcase actTransformHeader:\n",
      "\t\t\t\theader := t.executeCommand(a.a, false, true, true, false)\n",
      "\t\t\t\tif t.changeHeader(header) {\n",
      "\t\t\t\t\treq(reqFullRedraw)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treq(reqHeader)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangeHeader:\n",
      "\t\t\t\tif t.changeHeader(a.a) {\n",
      "\t\t\t\t\treq(reqFullRedraw)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treq(reqHeader)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangeBorderLabel:\n",
      "\t\t\t\tif t.border != nil {\n",
      "\t\t\t\t\tt.borderLabel, t.borderLabelLen = t.ansiLabelPrinter(a.a, &tui.ColBorderLabel, false)\n",
      "\t\t\t\t\treq(reqRedrawBorderLabel)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangePreviewLabel:\n",
      "\t\t\t\tif t.pborder != nil {\n",
      "\t\t\t\t\tt.previewLabel, t.previewLabelLen = t.ansiLabelPrinter(a.a, &tui.ColPreviewLabel, false)\n",
      "\t\t\t\t\treq(reqRedrawPreviewLabel)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actTransform:\n",
      "\t\t\t\tbody := t.executeCommand(a.a, false, true, true, false)\n",
      "\t\t\t\tactions := parseSingleActionList(strings.Trim(body, \"\\r\\n\"), func(message string) {\n",
      "\t\t\t\t})\n",
      "\t\t\t\treturn doActions(actions)\n",
      "\t\t\tcase actTransformBorderLabel:\n",
      "\t\t\t\tif t.border != nil {\n",
      "\t\t\t\t\tlabel := t.executeCommand(a.a, false, true, true, true)\n",
      "\t\t\t\t\tt.borderLabel, t.borderLabelLen = t.ansiLabelPrinter(label, &tui.ColBorderLabel, false)\n",
      "\t\t\t\t\treq(reqRedrawBorderLabel)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actTransformPreviewLabel:\n",
      "\t\t\t\tif t.pborder != nil {\n",
      "\t\t\t\t\tlabel := t.executeCommand(a.a, false, true, true, true)\n",
      "\t\t\t\t\tt.previewLabel, t.previewLabelLen = t.ansiLabelPrinter(label, &tui.ColPreviewLabel, false)\n",
      "\t\t\t\t\treq(reqRedrawPreviewLabel)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangePrompt:\n",
      "\t\t\t\tt.promptString = a.a\n",
      "\t\t\t\tt.prompt, t.promptLen = t.parsePrompt(a.a)\n",
      "\t\t\t\treq(reqPrompt)\n",
      "\t\t\tcase actPreview:\n",
      "\t\t\t\tif !t.hasPreviewWindow() {\n",
      "\t\t\t\t\tupdatePreviewWindow(true)\n",
      "\t\t\t\t}\n",
      "\t\t\t\trefreshPreview(a.a)\n",
      "\t\t\tcase actRefreshPreview:\n",
      "\t\t\t\trefreshPreview(t.previewOpts.command)\n",
      "\t\t\tcase actReplaceQuery:\n",
      "\t\t\t\tcurrent := t.currentItem()\n",
      "\t\t\t\tif current != nil {\n",
      "\t\t\t\t\tt.input = current.text.ToRunes()\n",
      "\t\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actAbort:\n",
      "\t\t\t\treq(reqQuit)\n",
      "\t\t\tcase actDeleteChar:\n",
      "\t\t\t\tt.delChar()\n",
      "\t\t\tcase actDeleteCharEof:\n",
      "\t\t\t\tif !t.delChar() && t.cx == 0 {\n",
      "\t\t\t\t\treq(reqQuit)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actEndOfLine:\n",
      "\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\tcase actCancel:\n",
      "\t\t\t\tif len(t.input) == 0 {\n",
      "\t\t\t\t\treq(reqQuit)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tt.yanked = t.input\n",
      "\t\t\t\t\tt.input = []rune{}\n",
      "\t\t\t\t\tt.cx = 0\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actBackwardDeleteCharEof:\n",
      "\t\t\t\tif len(t.input) == 0 {\n",
      "\t\t\t\t\treq(reqQuit)\n",
      "\t\t\t\t} else if t.cx > 0 {\n",
      "\t\t\t\t\tt.input = append(t.input[:t.cx-1], t.input[t.cx:]...)\n",
      "\t\t\t\t\tt.cx--\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actForwardChar:\n",
      "\t\t\t\tif t.cx < len(t.input) {\n",
      "\t\t\t\t\tt.cx++\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actBackwardDeleteChar:\n",
      "\t\t\t\tbeof = len(t.input) == 0\n",
      "\t\t\t\tif t.cx > 0 {\n",
      "\t\t\t\t\tt.input = append(t.input[:t.cx-1], t.input[t.cx:]...)\n",
      "\t\t\t\t\tt.cx--\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actSelectAll:\n",
      "\t\t\t\tif t.multi > 0 {\n",
      "\t\t\t\t\tfor i := 0; i < t.merger.Length(); i++ {\n",
      "\t\t\t\t\t\tif !t.selectItem(t.merger.Get(i).item) {\n",
      "\t\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actDeselectAll:\n",
      "\t\t\t\tif t.multi > 0 {\n",
      "\t\t\t\t\tfor i := 0; i < t.merger.Length() && len(t.selected) > 0; i++ {\n",
      "\t\t\t\t\t\tt.deselectItem(t.merger.Get(i).item)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actClose:\n",
      "\t\t\t\tif t.hasPreviewWindow() {\n",
      "\t\t\t\t\tt.activePreviewOpts.Toggle()\n",
      "\t\t\t\t\tupdatePreviewWindow(false)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treq(reqQuit)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actSelect:\n",
      "\t\t\t\tcurrent := t.currentItem()\n",
      "\t\t\t\tif t.multi > 0 && current != nil && t.selectItemChanged(current) {\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actDeselect:\n",
      "\t\t\t\tcurrent := t.currentItem()\n",
      "\t\t\t\tif t.multi > 0 && current != nil && t.deselectItemChanged(current) {\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actToggle:\n",
      "\t\t\t\tif t.multi > 0 && t.merger.Length() > 0 && toggle() {\n",
      "\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actToggleAll:\n",
      "\t\t\t\tif t.multi > 0 {\n",
      "\t\t\t\t\tprevIndexes := make(map[int]struct{})\n",
      "\t\t\t\t\tfor i := 0; i < t.merger.Length() && len(t.selected) > 0; i++ {\n",
      "\t\t\t\t\t\titem := t.merger.Get(i).item\n",
      "\t\t\t\t\t\tif _, found := t.selected[item.Index()]; found {\n",
      "\t\t\t\t\t\t\tprevIndexes[i] = struct{}{}\n",
      "\t\t\t\t\t\t\tt.deselectItem(item)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tfor i := 0; i < t.merger.Length(); i++ {\n",
      "\t\t\t\t\t\tif _, found := prevIndexes[i]; !found {\n",
      "\t\t\t\t\t\t\titem := t.merger.Get(i).item\n",
      "\t\t\t\t\t\t\tif !t.selectItem(item) {\n",
      "\t\t\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actToggleIn:\n",
      "\t\t\t\tif t.layout != layoutDefault {\n",
      "\t\t\t\t\treturn doAction(&action{t: actToggleUp})\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn doAction(&action{t: actToggleDown})\n",
      "\t\t\tcase actToggleOut:\n",
      "\t\t\t\tif t.layout != layoutDefault {\n",
      "\t\t\t\t\treturn doAction(&action{t: actToggleDown})\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn doAction(&action{t: actToggleUp})\n",
      "\t\t\tcase actToggleDown:\n",
      "\t\t\t\tif t.multi > 0 && t.merger.Length() > 0 && toggle() {\n",
      "\t\t\t\t\tt.vmove(-1, true)\n",
      "\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actToggleUp:\n",
      "\t\t\t\tif t.multi > 0 && t.merger.Length() > 0 && toggle() {\n",
      "\t\t\t\t\tt.vmove(1, true)\n",
      "\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actDown:\n",
      "\t\t\t\tt.vmove(-1, true)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actUp:\n",
      "\t\t\t\tt.vmove(1, true)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actAccept:\n",
      "\t\t\t\treq(reqClose)\n",
      "\t\t\tcase actAcceptNonEmpty:\n",
      "\t\t\t\tif len(t.selected) > 0 || t.merger.Length() > 0 || !t.reading && t.count == 0 {\n",
      "\t\t\t\t\treq(reqClose)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actAcceptOrPrintQuery:\n",
      "\t\t\t\tif len(t.selected) > 0 || t.merger.Length() > 0 {\n",
      "\t\t\t\t\treq(reqClose)\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treq(reqPrintQuery)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actClearScreen:\n",
      "\t\t\t\treq(reqFullRedraw)\n",
      "\t\t\tcase actClearQuery:\n",
      "\t\t\t\tt.input = []rune{}\n",
      "\t\t\t\tt.cx = 0\n",
      "\t\t\tcase actClearSelection:\n",
      "\t\t\t\tif t.multi > 0 {\n",
      "\t\t\t\t\tt.selected = make(map[int32]selectedItem)\n",
      "\t\t\t\t\tt.version++\n",
      "\t\t\t\t\treq(reqList, reqInfo)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actFirst:\n",
      "\t\t\t\tt.vset(0)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actLast:\n",
      "\t\t\t\tt.vset(t.merger.Length() - 1)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actPosition:\n",
      "\t\t\t\tif n, e := strconv.Atoi(a.a); e == nil {\n",
      "\t\t\t\t\tif n > 0 {\n",
      "\t\t\t\t\t\tn--\n",
      "\t\t\t\t\t} else if n < 0 {\n",
      "\t\t\t\t\t\tn += t.merger.Length()\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tt.vset(n)\n",
      "\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actPut:\n",
      "\t\t\t\tstr := []rune(a.a)\n",
      "\t\t\t\tsuffix := copySlice(t.input[t.cx:])\n",
      "\t\t\t\tt.input = append(append(t.input[:t.cx], str...), suffix...)\n",
      "\t\t\t\tt.cx += len(str)\n",
      "\t\t\tcase actUnixLineDiscard:\n",
      "\t\t\t\tbeof = len(t.input) == 0\n",
      "\t\t\t\tif t.cx > 0 {\n",
      "\t\t\t\t\tt.yanked = copySlice(t.input[:t.cx])\n",
      "\t\t\t\t\tt.input = t.input[t.cx:]\n",
      "\t\t\t\t\tt.cx = 0\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actUnixWordRubout:\n",
      "\t\t\t\tbeof = len(t.input) == 0\n",
      "\t\t\t\tif t.cx > 0 {\n",
      "\t\t\t\t\tt.rubout(\"\\\\s\\\\S\")\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actBackwardKillWord:\n",
      "\t\t\t\tbeof = len(t.input) == 0\n",
      "\t\t\t\tif t.cx > 0 {\n",
      "\t\t\t\t\tt.rubout(t.wordRubout)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actYank:\n",
      "\t\t\t\tsuffix := copySlice(t.input[t.cx:])\n",
      "\t\t\t\tt.input = append(append(t.input[:t.cx], t.yanked...), suffix...)\n",
      "\t\t\t\tt.cx += len(t.yanked)\n",
      "\t\t\tcase actPageUp:\n",
      "\t\t\t\tt.vmove(t.maxItems()-1, false)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actPageDown:\n",
      "\t\t\t\tt.vmove(-(t.maxItems() - 1), false)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actHalfPageUp:\n",
      "\t\t\t\tt.vmove(t.maxItems()/2, false)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actHalfPageDown:\n",
      "\t\t\t\tt.vmove(-(t.maxItems() / 2), false)\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actOffsetUp, actOffsetDown:\n",
      "\t\t\t\tdiff := 1\n",
      "\t\t\t\tif a.t == actOffsetDown {\n",
      "\t\t\t\t\tdiff = -1\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif t.layout == layoutReverse {\n",
      "\t\t\t\t\tdiff *= -1\n",
      "\t\t\t\t}\n",
      "\t\t\t\tt.offset += diff\n",
      "\t\t\t\tbefore := t.offset\n",
      "\t\t\t\tt.constrain()\n",
      "\t\t\t\tif before != t.offset {\n",
      "\t\t\t\t\tt.offset = before\n",
      "\t\t\t\t\tif t.layout == layoutReverse {\n",
      "\t\t\t\t\t\tdiff *= -1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tt.vmove(diff, false)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\tcase actJump:\n",
      "\t\t\t\tt.jumping = jumpEnabled\n",
      "\t\t\t\treq(reqJump)\n",
      "\t\t\tcase actJumpAccept:\n",
      "\t\t\t\tt.jumping = jumpAcceptEnabled\n",
      "\t\t\t\treq(reqJump)\n",
      "\t\t\tcase actBackwardWord:\n",
      "\t\t\t\tt.cx = findLastMatch(t.wordRubout, string(t.input[:t.cx])) + 1\n",
      "\t\t\tcase actForwardWord:\n",
      "\t\t\t\tt.cx += findFirstMatch(t.wordNext, string(t.input[t.cx:])) + 1\n",
      "\t\t\tcase actKillWord:\n",
      "\t\t\t\tncx := t.cx + findFirstMatch(t.wordNext, string(t.input[t.cx:])) + 1\n",
      "\t\t\t\tif ncx > t.cx {\n",
      "\t\t\t\t\tt.yanked = copySlice(t.input[t.cx:ncx])\n",
      "\t\t\t\t\tt.input = append(t.input[:t.cx], t.input[ncx:]...)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actKillLine:\n",
      "\t\t\t\tif t.cx < len(t.input) {\n",
      "\t\t\t\t\tt.yanked = copySlice(t.input[t.cx:])\n",
      "\t\t\t\t\tt.input = t.input[:t.cx]\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChar:\n",
      "\t\t\t\tprefix := copySlice(t.input[:t.cx])\n",
      "\t\t\t\tt.input = append(append(prefix, event.Char), t.input[t.cx:]...)\n",
      "\t\t\t\tt.cx++\n",
      "\t\t\tcase actPrevHistory:\n",
      "\t\t\t\tif t.history != nil {\n",
      "\t\t\t\t\tt.history.override(string(t.input))\n",
      "\t\t\t\t\tt.input = trimQuery(t.history.previous())\n",
      "\t\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actNextHistory:\n",
      "\t\t\t\tif t.history != nil {\n",
      "\t\t\t\t\tt.history.override(string(t.input))\n",
      "\t\t\t\t\tt.input = trimQuery(t.history.next())\n",
      "\t\t\t\t\tt.cx = len(t.input)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actToggleSearch:\n",
      "\t\t\t\tt.paused = !t.paused\n",
      "\t\t\t\tchanged = !t.paused\n",
      "\t\t\t\treq(reqPrompt)\n",
      "\t\t\tcase actToggleTrack:\n",
      "\t\t\t\tswitch t.track {\n",
      "\t\t\t\tcase trackEnabled:\n",
      "\t\t\t\t\tt.track = trackDisabled\n",
      "\t\t\t\tcase trackDisabled:\n",
      "\t\t\t\t\tt.track = trackEnabled\n",
      "\t\t\t\t}\n",
      "\t\t\t\treq(reqInfo)\n",
      "\t\t\tcase actShowHeader:\n",
      "\t\t\t\tt.headerVisible = true\n",
      "\t\t\t\treq(reqList, reqInfo, reqPrompt, reqHeader)\n",
      "\t\t\tcase actHideHeader:\n",
      "\t\t\t\tt.headerVisible = false\n",
      "\t\t\t\treq(reqList, reqInfo, reqPrompt, reqHeader)\n",
      "\t\t\tcase actToggleHeader:\n",
      "\t\t\t\tt.headerVisible = !t.headerVisible\n",
      "\t\t\t\treq(reqList, reqInfo, reqPrompt, reqHeader)\n",
      "\t\t\tcase actTrack:\n",
      "\t\t\t\tif t.track == trackDisabled {\n",
      "\t\t\t\t\tt.track = trackCurrent\n",
      "\t\t\t\t}\n",
      "\t\t\t\treq(reqInfo)\n",
      "\t\t\tcase actEnableSearch:\n",
      "\t\t\t\tt.paused = false\n",
      "\t\t\t\tchanged = true\n",
      "\t\t\t\treq(reqPrompt)\n",
      "\t\t\tcase actDisableSearch:\n",
      "\t\t\t\tt.paused = true\n",
      "\t\t\t\treq(reqPrompt)\n",
      "\t\t\tcase actSigStop:\n",
      "\t\t\t\tp, err := os.FindProcess(os.Getpid())\n",
      "\t\t\t\tif err == nil {\n",
      "\t\t\t\t\tt.sigstop = true\n",
      "\t\t\t\t\tt.tui.Clear()\n",
      "\t\t\t\t\tt.tui.Pause(t.fullscreen)\n",
      "\t\t\t\t\tnotifyStop(p)\n",
      "\t\t\t\t\tt.mutex.Unlock()\n",
      "\t\t\t\t\treturn false\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actMouse:\n",
      "\t\t\t\tme := event.MouseEvent\n",
      "\t\t\t\tmx, my := me.X, me.Y\n",
      "\t\t\t\tclicked := !wasDown && me.Down\n",
      "\t\t\t\twasDown = me.Down\n",
      "\t\t\t\tif !me.Down {\n",
      "\t\t\t\t\tbarDragging = false\n",
      "\t\t\t\t\tpbarDragging = false\n",
      "\t\t\t\t\tpreviewDraggingPos = -1\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif me.S != 0 {\n",
      "\t\t\t\t\tif t.window.Enclose(my, mx) && t.merger.Length() > 0 {\n",
      "\t\t\t\t\t\tevt := tui.ScrollUp\n",
      "\t\t\t\t\t\tif me.Mod {\n",
      "\t\t\t\t\t\t\tevt = tui.SScrollUp\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif me.S < 0 {\n",
      "\t\t\t\t\t\t\tevt = tui.ScrollDown\n",
      "\t\t\t\t\t\t\tif me.Mod {\n",
      "\t\t\t\t\t\t\t\tevt = tui.SScrollDown\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\treturn doActions(actionsFor(evt))\n",
      "\t\t\t\t\t} else if t.hasPreviewWindow() && t.pwindow.Enclose(my, mx) {\n",
      "\t\t\t\t\t\tevt := tui.PreviewScrollUp\n",
      "\t\t\t\t\t\tif me.S < 0 {\n",
      "\t\t\t\t\t\t\tevt = tui.PreviewScrollDown\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\treturn doActions(actionsFor(evt))\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif me.Down && (previewDraggingPos >= 0 || clicked && t.hasPreviewWindow() && t.pwindow.Enclose(my, mx)) {\n",
      "\t\t\t\t\tif previewDraggingPos > 0 {\n",
      "\t\t\t\t\t\tscrollPreviewBy(previewDraggingPos - my)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tpreviewDraggingPos = my\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\theaderLines := t.previewOpts.headerLines\n",
      "\t\t\t\tpbarDragging = me.Down && (pbarDragging || clicked && t.hasPreviewWindow() && my >= t.pwindow.Top()+headerLines && my < t.pwindow.Top()+t.pwindow.Height() && mx == t.pwindow.Left()+t.pwindow.Width())\n",
      "\t\t\t\tif pbarDragging {\n",
      "\t\t\t\t\teffectiveHeight := t.pwindow.Height() - headerLines\n",
      "\t\t\t\t\tnumLines := len(t.previewer.lines) - headerLines\n",
      "\t\t\t\t\tbarLength, _ := getScrollbar(numLines, effectiveHeight, util.Min(numLines-effectiveHeight, t.previewer.offset-headerLines))\n",
      "\t\t\t\t\tif barLength > 0 {\n",
      "\t\t\t\t\t\ty := my - t.pwindow.Top() - headerLines - barLength/2\n",
      "\t\t\t\t\t\ty = util.Constrain(y, 0, effectiveHeight-barLength)\n",
      "\t\t\t\t\t\tt.previewer.offset = headerLines + int(math.Ceil(float64(y)*float64(numLines-effectiveHeight)/float64(effectiveHeight-barLength)))\n",
      "\t\t\t\t\t\tt.previewer.following.Set(t.previewer.offset >= numLines-effectiveHeight)\n",
      "\t\t\t\t\t\treq(reqPreviewRefresh)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif !t.window.Enclose(my, mx) && !barDragging {\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tmx -= t.window.Left()\n",
      "\t\t\t\tmy -= t.window.Top()\n",
      "\t\t\t\tmin := 2 + t.visibleHeaderLines()\n",
      "\t\t\t\tif t.noInfoLine() {\n",
      "\t\t\t\t\tmin--\n",
      "\t\t\t\t}\n",
      "\t\t\t\th := t.window.Height()\n",
      "\t\t\t\tswitch t.layout {\n",
      "\t\t\t\tcase layoutDefault:\n",
      "\t\t\t\t\tmy = h - my - 1\n",
      "\t\t\t\tcase layoutReverseList:\n",
      "\t\t\t\t\tif my < h-min {\n",
      "\t\t\t\t\t\tmy += min\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tmy = h - my - 1\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbarDragging = me.Down && (barDragging || clicked && my >= min && mx == t.window.Width()-1)\n",
      "\t\t\t\tif barDragging {\n",
      "\t\t\t\t\tbarLength, barStart := t.getScrollbar()\n",
      "\t\t\t\t\tif barLength > 0 {\n",
      "\t\t\t\t\t\tmaxItems := t.maxItems()\n",
      "\t\t\t\t\t\tif newBarStart := util.Constrain(my-min-barLength/2, 0, maxItems-barLength); newBarStart != barStart {\n",
      "\t\t\t\t\t\t\ttotal := t.merger.Length()\n",
      "\t\t\t\t\t\t\tprevOffset := t.offset\n",
      "\t\t\t\t\t\t\tt.offset = int(math.Ceil(float64(newBarStart) * float64(total-maxItems) / float64(maxItems-barLength)))\n",
      "\t\t\t\t\t\t\tt.cy = t.offset + t.cy - prevOffset\n",
      "\t\t\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif me.Double && mx < t.window.Width()-1 {\n",
      "\t\t\t\t\tif my >= min {\n",
      "\t\t\t\t\t\tif t.vset(t.offset+my-min) && t.cy < t.merger.Length() {\n",
      "\t\t\t\t\t\t\treturn doActions(actionsFor(tui.DoubleClick))\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif me.Down {\n",
      "\t\t\t\t\tmx = util.Constrain(mx-t.promptLen, 0, len(t.input))\n",
      "\t\t\t\t\tif my == t.promptLine() && mx >= 0 {\n",
      "\t\t\t\t\t\tt.cx = mx + t.xoffset\n",
      "\t\t\t\t\t} else if my >= min {\n",
      "\t\t\t\t\t\tt.vset(t.offset + my - min)\n",
      "\t\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t\t\tevt := tui.RightClick\n",
      "\t\t\t\t\t\tif me.Mod {\n",
      "\t\t\t\t\t\t\tevt = tui.SRightClick\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif me.Left {\n",
      "\t\t\t\t\t\t\tevt = tui.LeftClick\n",
      "\t\t\t\t\t\t\tif me.Mod {\n",
      "\t\t\t\t\t\t\t\tevt = tui.SLeftClick\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\treturn doActions(actionsFor(evt))\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actReload, actReloadSync:\n",
      "\t\t\t\tt.failed = nil\n",
      "\t\t\t\tvalid, list := t.buildPlusList(a.a, false)\n",
      "\t\t\t\tif !valid {\n",
      "\t\t\t\t\tslot, _, forceUpdate := hasPreviewFlags(a.a)\n",
      "\t\t\t\t\tvalid = !slot || forceUpdate\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif valid {\n",
      "\t\t\t\t\tcommand := t.replacePlaceholder(a.a, false, string(t.input), list)\n",
      "\t\t\t\t\tnewCommand = &command\n",
      "\t\t\t\t\treloadSync = a.t == actReloadSync\n",
      "\t\t\t\t\tt.reading = true\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actUnbind:\n",
      "\t\t\t\tkeys := parseKeyChords(a.a, \"PANIC\")\n",
      "\t\t\t\tfor key := range keys {\n",
      "\t\t\t\t\tdelete(t.keymap, key)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actRebind:\n",
      "\t\t\t\tkeys := parseKeyChords(a.a, \"PANIC\")\n",
      "\t\t\t\tfor key := range keys {\n",
      "\t\t\t\t\tif originalAction, found := t.keymapOrg[key]; found {\n",
      "\t\t\t\t\t\tt.keymap[key] = originalAction\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangePreview:\n",
      "\t\t\t\tif t.previewOpts.command != a.a {\n",
      "\t\t\t\t\tt.previewOpts.command = a.a\n",
      "\t\t\t\t\tupdatePreviewWindow(false)\n",
      "\t\t\t\t\trefreshPreview(t.previewOpts.command)\n",
      "\t\t\t\t}\n",
      "\t\t\tcase actChangePreviewWindow:\n",
      "\t\t\t\tcurrentPreviewOpts := t.previewOpts\n",
      "\t\t\t\tt.previewOpts = t.initialPreviewOpts\n",
      "\t\t\t\ttokens := strings.Split(a.a, \"|\")\n",
      "\t\t\t\tif len(tokens[0]) > 0 && t.initialPreviewOpts.hidden {\n",
      "\t\t\t\t\tt.previewOpts.hidden = false\n",
      "\t\t\t\t}\n",
      "\t\t\t\tparsePreviewWindow(&t.previewOpts, tokens[0])\n",
      "\t\t\t\tif len(tokens) > 1 {\n",
      "\t\t\t\t\ta.a = strings.Join(append(tokens[1:], tokens[0]), \"|\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif !currentPreviewOpts.sameLayout(t.previewOpts) {\n",
      "\t\t\t\t\twasHidden := t.pwindow == nil\n",
      "\t\t\t\t\tupdatePreviewWindow(false)\n",
      "\t\t\t\t\tif wasHidden && t.hasPreviewWindow() {\n",
      "\t\t\t\t\t\trefreshPreview(t.previewOpts.command)\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\treq(reqPreviewRefresh)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else if !currentPreviewOpts.sameContentLayout(t.previewOpts) {\n",
      "\t\t\t\t\tt.previewed.version = 0\n",
      "\t\t\t\t\treq(reqPreviewRefresh)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif t.hasPreviewWindow() && currentPreviewOpts.scroll != t.previewOpts.scroll {\n",
      "\t\t\t\t\tscrollPreviewTo(t.evaluateScrollOffset())\n",
      "\t\t\t\t}\n",
      "\t\t\t\tt.previewer.following.Force(t.previewOpts.follow)\n",
      "\t\t\tcase actNextSelected, actPrevSelected:\n",
      "\t\t\t\tif len(t.selected) > 0 {\n",
      "\t\t\t\t\ttotal := t.merger.Length()\n",
      "\t\t\t\t\tfor i := 1; i < total; i++ {\n",
      "\t\t\t\t\t\ty := (t.cy + i) % total\n",
      "\t\t\t\t\t\tif t.layout == layoutDefault && a.t == actNextSelected || t.layout != layoutDefault && a.t == actPrevSelected {\n",
      "\t\t\t\t\t\t\ty = (t.cy - i + total) % total\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif _, found := t.selected[t.merger.Get(y).item.Index()]; found {\n",
      "\t\t\t\t\t\t\tt.vset(y)\n",
      "\t\t\t\t\t\t\treq(reqList)\n",
      "\t\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif !processExecution(a.t) {\n",
      "\t\t\t\tt.lastAction = a.t\n",
      "\t\t\t}\n",
      "\t\t\treturn true\n",
      "\t\t}\n",
      "\t\tif t.jumping == jumpDisabled || len(actions) > 0 {\n",
      "\t\t\tif t.jumping != jumpDisabled {\n",
      "\t\t\t\tt.jumping = jumpDisabled\n",
      "\t\t\t\treq(reqList)\n",
      "\t\t\t}\n",
      "\t\t\tif len(actions) == 0 {\n",
      "\t\t\t\tactions = t.keymap[event.Comparable()]\n",
      "\t\t\t}\n",
      "\t\t\tif len(actions) == 0 && event.Type == tui.Rune {\n",
      "\t\t\t\tdoAction(&action{t: actChar})\n",
      "\t\t\t} else if !doActions(actions) {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tt.truncateQuery()\n",
      "\t\t\tqueryChanged = string(previousInput) != string(t.input)\n",
      "\t\t\tchanged = changed || queryChanged\n",
      "\t\t\tif onChanges, prs := t.keymap[tui.Change.AsEvent()]; queryChanged && prs {\n",
      "\t\t\t\tif !doActions(onChanges) {\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif onEOFs, prs := t.keymap[tui.BackwardEOF.AsEvent()]; beof && prs {\n",
      "\t\t\t\tif !doActions(onEOFs) {\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tif event.Type == tui.Rune {\n",
      "\t\t\t\tif idx := strings.IndexRune(t.jumpLabels, event.Char); idx >= 0 && idx < t.maxItems() && idx < t.merger.Length() {\n",
      "\t\t\t\t\tt.cy = idx + t.offset\n",
      "\t\t\t\t\tif t.jumping == jumpAcceptEnabled {\n",
      "\t\t\t\t\t\treq(reqClose)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tt.jumping = jumpDisabled\n",
      "\t\t\treq(reqList)\n",
      "\t\t}\n",
      "\t\tif queryChanged && t.canPreview() && len(t.previewOpts.command) > 0 {\n",
      "\t\t\t_, _, forceUpdate := hasPreviewFlags(t.previewOpts.command)\n",
      "\t\t\tif forceUpdate {\n",
      "\t\t\t\tt.version++\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif queryChanged || t.cx != previousCx {\n",
      "\t\t\treq(reqPrompt)\n",
      "\t\t}\n",
      "\t\treload := changed || newCommand != nil\n",
      "\t\tvar reloadRequest *searchRequest\n",
      "\t\tif reload {\n",
      "\t\t\treloadRequest = &searchRequest{sort: t.sort, sync: reloadSync, command: newCommand, environ: t.environ(), changed: changed}\n",
      "\t\t}\n",
      "\t\tt.mutex.Unlock()\n",
      "\t\tif reload {\n",
      "\t\t\tt.eventBox.Set(EvtSearchNew, *reloadRequest)\n",
      "\t\t}\n",
      "\t\tfor _, event := range events {\n",
      "\t\t\tt.reqBox.Set(event, nil)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (t *Terminal) environ() []string {\n",
      "\tenv := os.Environ()\n",
      "\tif t.listenPort != nil {\n",
      "\t\tenv = append(env, fmt.Sprintf(\"FZF_PORT=%d\", *t.listenPort))\n",
      "\t}\n",
      "\tenv = append(env, \"FZF_QUERY=\"+string(t.input))\n",
      "\tenv = append(env, \"FZF_ACTION=\"+t.lastAction.Name())\n",
      "\tenv = append(env, \"FZF_PROMPT=\"+string(t.promptString))\n",
      "\tenv = append(env, fmt.Sprintf(\"FZF_TOTAL_COUNT=%d\", t.count))\n",
      "\tenv = append(env, fmt.Sprintf(\"FZF_MATCH_COUNT=%d\", t.merger.Length()))\n",
      "\tenv = append(env, fmt.Sprintf(\"FZF_SELECT_COUNT=%d\", len(t.selected)))\n",
      "\tenv = append(env, fmt.Sprintf(\"FZF_LINES=%d\", t.areaLines))\n",
      "\tenv = append(env, fmt.Sprintf(\"FZF_COLUMNS=%d\", t.areaColumns))\n",
      "\treturn env\n",
      "}\n",
      "func (s *resumableState) Set(flag bool) {\n",
      "\tif *s == disabledState {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif flag {\n",
      "\t\t*s = enabledState\n",
      "\t} else {\n",
      "\t\t*s = pausedState\n",
      "\t}\n",
      "}\n",
      "======================CLASS=======================\n",
      "wagoodman/dive 2 42548\n",
      "2\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func loadCiRules(config *viper.Viper) []CiRule {\n",
      "\tvar rules = make([]CiRule, 0)\n",
      "\tvar ruleKey = \"lowestEfficiency\"\n",
      "\trules = append(rules, newGenericCiRule(ruleKey, config.GetString(fmt.Sprintf(\"rules.%s\", ruleKey)), func(value string) error {\n",
      "\t\tlowestEfficiency, err := strconv.ParseFloat(value, 64)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\tif lowestEfficiency < 0 || lowestEfficiency > 1 {\n",
      "\t\t\treturn fmt.Errorf(\"lowestEfficiency config value is outside allowed range (0-1), given '%s'\", value)\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}, func(analysis *image.AnalysisResult, value string) (RuleStatus, string) {\n",
      "\t\tlowestEfficiency, err := strconv.ParseFloat(value, 64)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\tif lowestEfficiency > analysis.Efficiency {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"image efficiency is too low (efficiency=%v < threshold=%v)\", analysis.Efficiency, lowestEfficiency)\n",
      "\t\t}\n",
      "\t\treturn RulePassed, \"\"\n",
      "\t}))\n",
      "\truleKey = \"highestWastedBytes\"\n",
      "\trules = append(rules, newGenericCiRule(ruleKey, config.GetString(fmt.Sprintf(\"rules.%s\", ruleKey)), func(value string) error {\n",
      "\t\t_, err := humanize.ParseBytes(value)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}, func(analysis *image.AnalysisResult, value string) (RuleStatus, string) {\n",
      "\t\thighestWastedBytes, err := humanize.ParseBytes(value)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\tif analysis.WastedBytes > highestWastedBytes {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"too many bytes wasted (wasted-bytes=%v > threshold=%v)\", analysis.WastedBytes, highestWastedBytes)\n",
      "\t\t}\n",
      "\t\treturn RulePassed, \"\"\n",
      "\t}))\n",
      "\truleKey = \"highestUserWastedPercent\"\n",
      "\trules = append(rules, newGenericCiRule(ruleKey, config.GetString(fmt.Sprintf(\"rules.%s\", ruleKey)), func(value string) error {\n",
      "\t\thighestUserWastedPercent, err := strconv.ParseFloat(value, 64)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\tif highestUserWastedPercent < 0 || highestUserWastedPercent > 1 {\n",
      "\t\t\treturn fmt.Errorf(\"highestUserWastedPercent config value is outside allowed range (0-1), given '%s'\", value)\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}, func(analysis *image.AnalysisResult, value string) (RuleStatus, string) {\n",
      "\t\thighestUserWastedPercent, err := strconv.ParseFloat(value, 64)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"invalid config value ('%v'): %v\", value, err)\n",
      "\t\t}\n",
      "\t\tif highestUserWastedPercent < analysis.WastedUserPercent {\n",
      "\t\t\treturn RuleFailed, fmt.Sprintf(\"too many bytes wasted, relative to the user bytes added (%%-user-wasted-bytes=%v > threshold=%v)\", analysis.WastedUserPercent, highestUserWastedPercent)\n",
      "\t\t}\n",
      "\t\treturn RulePassed, \"\"\n",
      "\t}))\n",
      "\treturn rules\n",
      "}\n",
      "func newFileTreeView(gui *gocui.Gui, tree *filetree.FileTree, refTrees []*filetree.FileTree, cache filetree.Comparer) (controller *FileTree, err error) {\n",
      "\tcontroller = new(FileTree)\n",
      "\tcontroller.listeners = make([]ViewOptionChangeListener, 0)\n",
      "\tcontroller.name = \"filetree\"\n",
      "\tcontroller.gui = gui\n",
      "\tcontroller.vm, err = viewmodel.NewFileTreeViewModel(tree, refTrees, cache)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\trequestedWidthRatio := viper.GetFloat64(\"filetree.pane-width\")\n",
      "\tif requestedWidthRatio >= 1 || requestedWidthRatio <= 0 {\n",
      "\t\tlogrus.Errorf(\"invalid config value: 'filetree.pane-width' should be 0 < value < 1, given '%v'\", requestedWidthRatio)\n",
      "\t\trequestedWidthRatio = 0.5\n",
      "\t}\n",
      "\tcontroller.requestedWidthRatio = requestedWidthRatio\n",
      "\treturn controller, err\n",
      "}\n",
      "func newConfig(configBytes []byte) config {\n",
      "\tvar imageConfig config\n",
      "\terr := json.Unmarshal(configBytes, &imageConfig)\n",
      "\tif err != nil {\n",
      "\t\tlogrus.Panic(err)\n",
      "\t}\n",
      "\tlayerIdx := 0\n",
      "\tfor idx := range imageConfig.History {\n",
      "\t\tif imageConfig.History[idx].EmptyLayer {\n",
      "\t\t\timageConfig.History[idx].ID = \"<missing>\"\n",
      "\t\t} else {\n",
      "\t\t\timageConfig.History[idx].ID = imageConfig.RootFs.DiffIds[layerIdx]\n",
      "\t\t\tlayerIdx++\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn imageConfig\n",
      "}\n",
      "func initConfig() {\n",
      "\tvar err error\n",
      "\tviper.SetDefault(\"log.level\", log.InfoLevel.String())\n",
      "\tviper.SetDefault(\"log.path\", \"./dive.log\")\n",
      "\tviper.SetDefault(\"log.enabled\", false)\n",
      "\tviper.SetDefault(\"keybinding.quit\", \"ctrl+c,q\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-view\", \"tab\")\n",
      "\tviper.SetDefault(\"keybinding.filter-files\", \"ctrl+f, ctrl+slash\")\n",
      "\tviper.SetDefault(\"keybinding.compare-all\", \"ctrl+a\")\n",
      "\tviper.SetDefault(\"keybinding.compare-layer\", \"ctrl+l\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-collapse-dir\", \"space\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-collapse-all-dir\", \"ctrl+space\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-sort-order\", \"ctrl+o\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-filetree-attributes\", \"ctrl+b\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-added-files\", \"ctrl+a\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-removed-files\", \"ctrl+r\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-modified-files\", \"ctrl+m\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-unmodified-files\", \"ctrl+u\")\n",
      "\tviper.SetDefault(\"keybinding.toggle-wrap-tree\", \"ctrl+p\")\n",
      "\tviper.SetDefault(\"keybinding.page-up\", \"pgup\")\n",
      "\tviper.SetDefault(\"keybinding.page-down\", \"pgdn\")\n",
      "\tviper.SetDefault(\"diff.hide\", \"\")\n",
      "\tviper.SetDefault(\"layer.show-aggregated-changes\", false)\n",
      "\tviper.SetDefault(\"filetree.collapse-dir\", false)\n",
      "\tviper.SetDefault(\"filetree.pane-width\", 0.5)\n",
      "\tviper.SetDefault(\"filetree.show-attributes\", true)\n",
      "\tviper.SetDefault(\"container-engine\", \"docker\")\n",
      "\tviper.SetDefault(\"ignore-errors\", false)\n",
      "\terr = viper.BindPFlag(\"source\", rootCmd.PersistentFlags().Lookup(\"source\"))\n",
      "\tif err != nil {\n",
      "\t\tfmt.Println(err)\n",
      "\t\tos.Exit(1)\n",
      "\t}\n",
      "\tviper.SetEnvPrefix(\"DIVE\")\n",
      "\tviper.SetEnvKeyReplacer(strings.NewReplacer(\"-\", \"_\"))\n",
      "\tviper.AutomaticEnv()\n",
      "\tif cfgFile == \"\" {\n",
      "\t\tfilepathToCfg := getDefaultCfgFile()\n",
      "\t\tviper.SetConfigFile(filepathToCfg)\n",
      "\t} else {\n",
      "\t\tviper.SetConfigFile(cfgFile)\n",
      "\t}\n",
      "\terr = viper.ReadInConfig()\n",
      "\tif err == nil {\n",
      "\t\tfmt.Println(\"Using config file:\", viper.ConfigFileUsed())\n",
      "\t} else if cfgFile != \"\" {\n",
      "\t\tfmt.Println(err)\n",
      "\t\tos.Exit(0)\n",
      "\t}\n",
      "\tfiletree.GlobalFileTreeCollapse = viper.GetBool(\"filetree.collapse-dir\")\n",
      "}\n",
      "func initCli() {\n",
      "\trootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.dive.yaml, ~/.config/dive/*.yaml, or $XDG_CONFIG_HOME/dive.yaml)\")\n",
      "\trootCmd.PersistentFlags().String(\"source\", \"docker\", \"The container engine to fetch the image from. Allowed values: \"+strings.Join(dive.ImageSources, \", \"))\n",
      "\trootCmd.PersistentFlags().BoolP(\"version\", \"v\", false, \"display version number\")\n",
      "\trootCmd.PersistentFlags().BoolP(\"ignore-errors\", \"i\", false, \"ignore image parsing errors and run the analysis anyway\")\n",
      "\trootCmd.Flags().BoolVar(&isCi, \"ci\", false, \"Skip the interactive TUI and validate against CI rules (same as env var CI=true)\")\n",
      "\trootCmd.Flags().StringVarP(&exportFile, \"json\", \"j\", \"\", \"Skip the interactive TUI and write the layer analysis statistics to a given file.\")\n",
      "\trootCmd.Flags().StringVar(&ciConfigFile, \"ci-config\", \".dive-ci\", \"If CI=true in the environment, use the given yaml to drive validation rules.\")\n",
      "\trootCmd.Flags().String(\"lowestEfficiency\", \"0.9\", \"(only valid with --ci given) lowest allowable image efficiency (as a ratio between 0-1), otherwise CI validation will fail.\")\n",
      "\trootCmd.Flags().String(\"highestWastedBytes\", \"disabled\", \"(only valid with --ci given) highest allowable bytes wasted, otherwise CI validation will fail.\")\n",
      "\trootCmd.Flags().String(\"highestUserWastedPercent\", \"0.1\", \"(only valid with --ci given) highest allowable percentage of bytes wasted (as a ratio between 0-1), otherwise CI validation will fail.\")\n",
      "\tfor _, key := range []string{\"lowestEfficiency\", \"highestWastedBytes\", \"highestUserWastedPercent\"} {\n",
      "\t\tif err := ciConfig.BindPFlag(fmt.Sprintf(\"rules.%s\", key), rootCmd.Flags().Lookup(key)); err != nil {\n",
      "\t\t\tlog.Fatalf(\"Unable to bind '%s' flag: %v\", key, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := ciConfig.BindPFlag(\"ignore-errors\", rootCmd.PersistentFlags().Lookup(\"ignore-errors\")); err != nil {\n",
      "\t\tlog.Fatalf(\"Unable to bind 'ignore-errors' flag: %v\", err)\n",
      "\t}\n",
      "}\n",
      "coreybutler/nvm-windows 4 33303\n",
      "4\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "spf13/viper 3 25212\n",
      "3\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func BindFlagValue(key string, flag FlagValue) error {\n",
      "\treturn v.BindFlagValue(key, flag)\n",
      "}\n",
      "func (v *Viper) UnmarshalExact(rawVal any, opts ...DecoderConfigOption) error {\n",
      "\tconfig := defaultDecoderConfig(rawVal, opts...)\n",
      "\tconfig.ErrorUnused = true\n",
      "\tkeys := v.AllKeys()\n",
      "\tif features.BindStruct {\n",
      "\t\tstructKeys, err := v.decodeStructKeys(rawVal, opts...)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tkeys = append(keys, structKeys...)\n",
      "\t}\n",
      "\treturn decode(v.getSettings(keys), config)\n",
      "}\n",
      "func (v *Viper) searchInPath(in string) (filename string) {\n",
      "\tv.logger.Debug(\"searching for config in path\", \"path\", in)\n",
      "\tfor _, ext := range SupportedExts {\n",
      "\t\tv.logger.Debug(\"checking if file exists\", \"file\", filepath.Join(in, v.configName+\".\"+ext))\n",
      "\t\tif b, _ := exists(v.fs, filepath.Join(in, v.configName+\".\"+ext)); b {\n",
      "\t\t\tv.logger.Debug(\"found file\", \"file\", filepath.Join(in, v.configName+\".\"+ext))\n",
      "\t\t\treturn filepath.Join(in, v.configName+\".\"+ext)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif v.configType != \"\" {\n",
      "\t\tif b, _ := exists(v.fs, filepath.Join(in, v.configName)); b {\n",
      "\t\t\treturn filepath.Join(in, v.configName)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn \"\"\n",
      "}\n",
      "func (v *Viper) findConfigFile() (string, error) {\n",
      "\tv.logger.Info(\"searching for config in paths\", \"paths\", v.configPaths)\n",
      "\tfor _, cp := range v.configPaths {\n",
      "\t\tfile := v.searchInPath(cp)\n",
      "\t\tif file != \"\" {\n",
      "\t\t\treturn file, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn \"\", ConfigFileNotFoundError{v.configName, fmt.Sprintf(\"%s\", v.configPaths)}\n",
      "}\n",
      "func BindPFlag(key string, flag *pflag.Flag) error {\n",
      "\treturn v.BindPFlag(key, flag)\n",
      "}\n",
      "func (str UnsupportedConfigError) Error() string {\n",
      "\treturn fmt.Sprintf(\"Unsupported Config Type %q\", string(str))\n",
      "}\n",
      "func decode(input any, config *mapstructure.DecoderConfig) error {\n",
      "\tdecoder, err := mapstructure.NewDecoder(config)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\treturn decoder.Decode(input)\n",
      "}\n",
      "func (v *Viper) WatchConfig() {\n",
      "\tinitWG := sync.WaitGroup{}\n",
      "\tinitWG.Add(1)\n",
      "\tgo func() {\n",
      "\t\twatcher, err := fsnotify.NewWatcher()\n",
      "\t\tif err != nil {\n",
      "\t\t\tv.logger.Error(fmt.Sprintf(\"failed to create watcher: %s\", err))\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t\tdefer watcher.Close()\n",
      "\t\tfilename, err := v.getConfigFile()\n",
      "\t\tif err != nil {\n",
      "\t\t\tv.logger.Error(fmt.Sprintf(\"get config file: %s\", err))\n",
      "\t\t\tinitWG.Done()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tconfigFile := filepath.Clean(filename)\n",
      "\t\tconfigDir, _ := filepath.Split(configFile)\n",
      "\t\trealConfigFile, _ := filepath.EvalSymlinks(filename)\n",
      "\t\teventsWG := sync.WaitGroup{}\n",
      "\t\teventsWG.Add(1)\n",
      "\t\tgo func() {\n",
      "\t\t\tfor {\n",
      "\t\t\t\tselect {\n",
      "\t\t\t\tcase event, ok := <-watcher.Events:\n",
      "\t\t\t\t\tif !ok {\n",
      "\t\t\t\t\t\teventsWG.Done()\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tcurrentConfigFile, _ := filepath.EvalSymlinks(filename)\n",
      "\t\t\t\t\tif (filepath.Clean(event.Name) == configFile && (event.Has(fsnotify.Write) || event.Has(fsnotify.Create))) || (currentConfigFile != \"\" && currentConfigFile != realConfigFile) {\n",
      "\t\t\t\t\t\trealConfigFile = currentConfigFile\n",
      "\t\t\t\t\t\terr := v.ReadInConfig()\n",
      "\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\tv.logger.Error(fmt.Sprintf(\"read config file: %s\", err))\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif v.onConfigChange != nil {\n",
      "\t\t\t\t\t\t\tv.onConfigChange(event)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t} else if filepath.Clean(event.Name) == configFile && event.Has(fsnotify.Remove) {\n",
      "\t\t\t\t\t\teventsWG.Done()\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\tcase err, ok := <-watcher.Errors:\n",
      "\t\t\t\t\tif ok {\n",
      "\t\t\t\t\t\tv.logger.Error(fmt.Sprintf(\"watcher error: %s\", err))\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\teventsWG.Done()\n",
      "\t\t\t\t\treturn\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\twatcher.Add(configDir)\n",
      "\t\tinitWG.Done()\n",
      "\t\teventsWG.Wait()\n",
      "\t}()\n",
      "\tinitWG.Wait()\n",
      "}\n",
      "func (v *Viper) BindPFlag(key string, flag *pflag.Flag) error {\n",
      "\tif flag == nil {\n",
      "\t\treturn fmt.Errorf(\"flag for %q is nil\", key)\n",
      "\t}\n",
      "\treturn v.BindFlagValue(key, pflagValue{flag})\n",
      "}\n",
      "func (v *Viper) ReadInConfig() error {\n",
      "\tv.logger.Info(\"attempting to read in config file\")\n",
      "\tfilename, err := v.getConfigFile()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif !stringInSlice(v.getConfigType(), SupportedExts) {\n",
      "\t\treturn UnsupportedConfigError(v.getConfigType())\n",
      "\t}\n",
      "\tv.logger.Debug(\"reading file\", \"file\", filename)\n",
      "\tfile, err := afero.ReadFile(v.fs, filename)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tconfig := make(map[string]any)\n",
      "\terr = v.unmarshalReader(bytes.NewReader(file), config)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tv.config = config\n",
      "\treturn nil\n",
      "}\n",
      "func (v *Viper) BindFlagValue(key string, flag FlagValue) error {\n",
      "\tif flag == nil {\n",
      "\t\treturn fmt.Errorf(\"flag for %q is nil\", key)\n",
      "\t}\n",
      "\tv.pflags[strings.ToLower(key)] = flag\n",
      "\treturn nil\n",
      "}\n",
      "func (v *Viper) MergeInConfig() error {\n",
      "\tv.logger.Info(\"attempting to merge in config file\")\n",
      "\tfilename, err := v.getConfigFile()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif !stringInSlice(v.getConfigType(), SupportedExts) {\n",
      "\t\treturn UnsupportedConfigError(v.getConfigType())\n",
      "\t}\n",
      "\tfile, err := afero.ReadFile(v.fs, filename)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\treturn v.MergeConfig(bytes.NewReader(file))\n",
      "}\n",
      "======================CLASS=======================\n",
      "tsenart/vegeta 5 22484\n",
      "5\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "projectdiscovery/nuclei 1 16418\n",
      "1\n",
      "======================CLASS=======================\n",
      "func printVersion() {\n",
      "\tgologger.Info().Msgf(\"Nuclei Engine Version: %s\", config.Version)\n",
      "\tgologger.Info().Msgf(\"Nuclei Config Directory: %s\", config.DefaultConfig.GetConfigDir())\n",
      "\tgologger.Info().Msgf(\"Nuclei Cache Directory: %s\", config.DefaultConfig.GetCacheDir())\n",
      "\tgologger.Info().Msgf(\"PDCP Directory: %s\", pdcp.PDCPDir)\n",
      "\tos.Exit(0)\n",
      "}\n",
      "func init() {\n",
      "\tgoflags.AttemptConfigMigration()\n",
      "\tConfigDir := folderutil.AppConfigDirOrDefault(FallbackConfigFolderName, BinaryName)\n",
      "\tif cfgDir := os.Getenv(NucleiConfigDirEnv); cfgDir != \"\" {\n",
      "\t\tConfigDir = cfgDir\n",
      "\t}\n",
      "\tif !fileutil.FolderExists(ConfigDir) {\n",
      "\t\tif err := fileutil.CreateFolder(ConfigDir); err != nil {\n",
      "\t\t\tgologger.Error().Msgf(\"failed to create config directory at %v got: %s\", ConfigDir, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tDefaultConfig = &Config{homeDir: folderutil.HomeDirOrDefault(\"\"), configDir: ConfigDir}\n",
      "\tif value := env.GetEnvOrDefault(\"NUCLEI_LOG_ALL\", false); value {\n",
      "\t\tDefaultConfig.LogAllEvents = true\n",
      "\t}\n",
      "\tif value := env.GetEnvOrDefault(\"HIDE_TEMPLATE_SIG_WARNING\", false); value {\n",
      "\t\tDefaultConfig.HideTemplateSigWarning = true\n",
      "\t}\n",
      "\tif err := DefaultConfig.ReadTemplatesConfig(); err != nil {\n",
      "\t\tgologger.Verbose().Msgf(\"config file not found, creating new config file at %s\", DefaultConfig.getTemplatesConfigFilePath())\n",
      "\t\tapplyDefaultConfig()\n",
      "\t\tif err := DefaultConfig.WriteTemplatesConfig(); err != nil {\n",
      "\t\t\tgologger.Error().Msgf(\"failed to write config file at %s got: %s\", DefaultConfig.getTemplatesConfigFilePath(), err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tmigrateResumeFiles()\n",
      "\tDefaultConfig.SetTemplatesDir(DefaultConfig.TemplatesDirectory)\n",
      "}\n",
      "func parseWorkflowTemplate(workflow *workflows.WorkflowTemplate, preprocessor Preprocessor, options *protocols.ExecutorOptions, loader model.WorkflowLoader, noValidate bool) error {\n",
      "\tvar paths []string\n",
      "\tsubTemplateTags := workflow.Tags\n",
      "\tif !subTemplateTags.IsEmpty() {\n",
      "\t\tpaths = loader.GetTemplatePathsByTags(subTemplateTags.ToSlice())\n",
      "\t} else {\n",
      "\t\tpaths = loader.GetTemplatePaths([]string{workflow.Template}, noValidate)\n",
      "\t}\n",
      "\tif len(paths) == 0 {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tvar workflowTemplates []*Template\n",
      "\tfor _, path := range paths {\n",
      "\t\ttemplate, err := Parse(path, preprocessor, options.Copy())\n",
      "\t\tif err != nil {\n",
      "\t\t\tgologger.Warning().Msgf(\"Could not parse workflow template %s: %v\\n\", path, err)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif template.Executer == nil {\n",
      "\t\t\tgologger.Warning().Msgf(\"Could not parse workflow template %s: no executer found\\n\", path)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif len(template.RequestsCode) > 0 {\n",
      "\t\t\tif !options.Options.EnableCodeTemplates {\n",
      "\t\t\t\tgologger.Warning().Msgf(\"`-code` flag not found, skipping code template from workflow: %v\\n\", path)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t} else if !template.Verified {\n",
      "\t\t\t\tgologger.Warning().Msgf(\"skipping unverified code template from workflow: %v\\n\", path)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tworkflowTemplates = append(workflowTemplates, template)\n",
      "\t}\n",
      "\tfinalTemplates, _ := ClusterTemplates(workflowTemplates, options.Copy())\n",
      "\tfor _, template := range finalTemplates {\n",
      "\t\tworkflow.Executers = append(workflow.Executers, &workflows.ProtocolExecuterPair{Executer: template.Executer, Options: options, TemplateType: template.Type()})\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (store *Store) LoadTemplatesWithTags(templatesList, tags []string) []*templates.Template {\n",
      "\tincludedTemplates, errs := store.config.Catalog.GetTemplatesPath(templatesList)\n",
      "\tstore.logErroredTemplates(errs)\n",
      "\ttemplatePathMap := store.pathFilter.Match(includedTemplates)\n",
      "\tloadedTemplates := make([]*templates.Template, 0, len(templatePathMap))\n",
      "\tfor templatePath := range templatePathMap {\n",
      "\t\tloaded, err := parsers.LoadTemplate(templatePath, store.tagFilter, tags, store.config.Catalog)\n",
      "\t\tif loaded || store.pathFilter.MatchIncluded(templatePath) {\n",
      "\t\t\tparsed, err := templates.Parse(templatePath, store.preprocessor, store.config.ExecutorOptions)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tif !errors.Is(err, templates.ErrIncompatibleWithOfflineMatching) {\n",
      "\t\t\t\t\tstats.Increment(parsers.RuntimeWarningsStats)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tgologger.Warning().Msgf(\"Could not parse template %s: %s\\n\", templatePath, err)\n",
      "\t\t\t} else if parsed != nil {\n",
      "\t\t\t\tif len(parsed.RequestsHeadless) > 0 && !store.config.ExecutorOptions.Options.Headless {\n",
      "\t\t\t\t\tstats.Increment(parsers.HeadlessFlagWarningStats)\n",
      "\t\t\t\t\tif config.DefaultConfig.LogAllEvents {\n",
      "\t\t\t\t\t\tgologger.Print().Msgf(\"[%v] Headless flag is required for headless template '%s'.\\n\", aurora.Yellow(\"WRN\").String(), templatePath)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else if len(parsed.RequestsCode) > 0 && !store.config.ExecutorOptions.Options.EnableCodeTemplates {\n",
      "\t\t\t\t\tstats.Increment(parsers.CodeFlagWarningStats)\n",
      "\t\t\t\t\tif config.DefaultConfig.LogAllEvents {\n",
      "\t\t\t\t\t\tgologger.Print().Msgf(\"[%v] Code flag is required for code protocol template '%s'.\\n\", aurora.Yellow(\"WRN\").String(), templatePath)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else if len(parsed.RequestsCode) > 0 && !parsed.Verified && len(parsed.Workflows) == 0 {\n",
      "\t\t\t\t\tstats.Increment(parsers.UnsignedWarning)\n",
      "\t\t\t\t\tif config.DefaultConfig.LogAllEvents {\n",
      "\t\t\t\t\t\tgologger.Print().Msgf(\"[%v] Tampered/Unsigned template at %v.\\n\", aurora.Yellow(\"WRN\").String(), templatePath)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tloadedTemplates = append(loadedTemplates, parsed)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err != nil {\n",
      "\t\t\tif strings.Contains(err.Error(), filter.ErrExcluded.Error()) {\n",
      "\t\t\t\tstats.Increment(parsers.TemplatesExecutedStats)\n",
      "\t\t\t\tif config.DefaultConfig.LogAllEvents {\n",
      "\t\t\t\t\tgologger.Print().Msgf(\"[%v] %v\\n\", aurora.Yellow(\"WRN\").String(), err.Error())\n",
      "\t\t\t\t}\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tgologger.Warning().Msg(err.Error())\n",
      "\t\t}\n",
      "\t}\n",
      "\tsort.SliceStable(loadedTemplates, func(i, j int) bool {\n",
      "\t\treturn loadedTemplates[i].Path < loadedTemplates[j].Path\n",
      "\t})\n",
      "\treturn loadedTemplates\n",
      "}\n",
      "func OpenTLS(protocol, address string) (*NetConn, error) {\n",
      "\tconfig := &tls.Config{InsecureSkipVerify: true, MinVersion: tls.VersionTLS10}\n",
      "\thost, _, _ := net.SplitHostPort(address)\n",
      "\tif host != \"\" {\n",
      "\t\tc := config.Clone()\n",
      "\t\tc.ServerName = host\n",
      "\t\tconfig = c\n",
      "\t}\n",
      "\tconn, err := protocolstate.Dialer.DialTLSWithConfig(context.TODO(), protocol, address, config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn &NetConn{conn: conn, timeout: defaultTimeout}, nil\n",
      "}\n",
      "func readConfig() *goflags.FlagSet {\n",
      "\tvar updateNucleiBinary bool\n",
      "\tvar pdcpauth string\n",
      "\tflagSet := goflags.NewFlagSet()\n",
      "\tflagSet.CaseSensitive = true\n",
      "\tflagSet.SetDescription(`Nuclei is a fast, template based vulnerability scanner focusing\n",
      "on extensive configurability, massive extensibility and ease of use.`)\n",
      "\tflagSet.CreateGroup(\"input\", \"Target\", flagSet.StringSliceVarP(&options.Targets, \"target\", \"u\", nil, \"target URLs/hosts to scan\", goflags.StringSliceOptions), flagSet.StringVarP(&options.TargetsFilePath, \"list\", \"l\", \"\", \"path to file containing a list of target URLs/hosts to scan (one per line)\"), flagSet.StringSliceVarP(&options.ExcludeTargets, \"exclude-hosts\", \"eh\", nil, \"hosts to exclude to scan from the input list (ip, cidr, hostname)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringVar(&options.Resume, \"resume\", \"\", \"resume scan using resume.cfg (clustering will be disabled)\"), flagSet.BoolVarP(&options.ScanAllIPs, \"scan-all-ips\", \"sa\", false, \"scan all the IP's associated with dns record\"), flagSet.StringSliceVarP(&options.IPVersion, \"ip-version\", \"iv\", nil, \"IP version to scan of hostname (4,6) - (default 4)\", goflags.CommaSeparatedStringSliceOptions))\n",
      "\tflagSet.CreateGroup(\"templates\", \"Templates\", flagSet.BoolVarP(&options.NewTemplates, \"new-templates\", \"nt\", false, \"run only new templates added in latest nuclei-templates release\"), flagSet.StringSliceVarP(&options.NewTemplatesWithVersion, \"new-templates-version\", \"ntv\", nil, \"run new templates added in specific version\", goflags.CommaSeparatedStringSliceOptions), flagSet.BoolVarP(&options.AutomaticScan, \"automatic-scan\", \"as\", false, \"automatic web scan using wappalyzer technology detection to tags mapping\"), flagSet.StringSliceVarP(&options.Templates, \"templates\", \"t\", nil, \"list of template or template directory to run (comma-separated, file)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringSliceVarP(&options.TemplateURLs, \"template-url\", \"turl\", nil, \"template url or list containing template urls to run (comma-separated, file)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringSliceVarP(&options.Workflows, \"workflows\", \"w\", nil, \"list of workflow or workflow directory to run (comma-separated, file)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringSliceVarP(&options.WorkflowURLs, \"workflow-url\", \"wurl\", nil, \"workflow url or list containing workflow urls to run (comma-separated, file)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.BoolVar(&options.Validate, \"validate\", false, \"validate the passed templates to nuclei\"), flagSet.BoolVarP(&options.NoStrictSyntax, \"no-strict-syntax\", \"nss\", false, \"disable strict syntax check on templates\"), flagSet.BoolVarP(&options.TemplateDisplay, \"template-display\", \"td\", false, \"displays the templates content\"), flagSet.BoolVar(&options.TemplateList, \"tl\", false, \"list all available templates\"), flagSet.StringSliceVarConfigOnly(&options.RemoteTemplateDomainList, \"remote-template-domain\", []string{\"cloud.projectdiscovery.io\"}, \"allowed domain list to load remote templates from\"), flagSet.BoolVar(&options.SignTemplates, \"sign\", false, \"signs the templates with the private key defined in NUCLEI_SIGNATURE_PRIVATE_KEY env variable\"), flagSet.BoolVar(&options.EnableCodeTemplates, \"code\", false, \"enable loading code protocol-based templates\"))\n",
      "\tflagSet.CreateGroup(\"filters\", \"Filtering\", flagSet.StringSliceVarP(&options.Authors, \"author\", \"a\", nil, \"templates to run based on authors (comma-separated, file)\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVar(&options.Tags, \"tags\", nil, \"templates to run based on tags (comma-separated, file)\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVarP(&options.ExcludeTags, \"exclude-tags\", \"etags\", nil, \"templates to exclude based on tags (comma-separated, file)\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVarP(&options.IncludeTags, \"include-tags\", \"itags\", nil, \"tags to be executed even if they are excluded either by default or configuration\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVarP(&options.IncludeIds, \"template-id\", \"id\", nil, \"templates to run based on template ids (comma-separated, file, allow-wildcard)\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVarP(&options.ExcludeIds, \"exclude-id\", \"eid\", nil, \"templates to exclude based on template ids (comma-separated, file)\", goflags.FileNormalizedStringSliceOptions), flagSet.StringSliceVarP(&options.IncludeTemplates, \"include-templates\", \"it\", nil, \"templates to be executed even if they are excluded either by default or configuration\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringSliceVarP(&options.ExcludedTemplates, \"exclude-templates\", \"et\", nil, \"template or template directory to exclude (comma-separated, file)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.StringSliceVarP(&options.ExcludeMatchers, \"exclude-matchers\", \"em\", nil, \"template matchers to exclude in result\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.VarP(&options.Severities, \"severity\", \"s\", fmt.Sprintf(\"templates to run based on severity. Possible values: %s\", severity.GetSupportedSeverities().String())), flagSet.VarP(&options.ExcludeSeverities, \"exclude-severity\", \"es\", fmt.Sprintf(\"templates to exclude based on severity. Possible values: %s\", severity.GetSupportedSeverities().String())), flagSet.VarP(&options.Protocols, \"type\", \"pt\", fmt.Sprintf(\"templates to run based on protocol type. Possible values: %s\", templateTypes.GetSupportedProtocolTypes())), flagSet.VarP(&options.ExcludeProtocols, \"exclude-type\", \"ept\", fmt.Sprintf(\"templates to exclude based on protocol type. Possible values: %s\", templateTypes.GetSupportedProtocolTypes())), flagSet.StringSliceVarP(&options.IncludeConditions, \"template-condition\", \"tc\", nil, \"templates to run based on expression condition\", goflags.StringSliceOptions))\n",
      "\tflagSet.CreateGroup(\"output\", \"Output\", flagSet.StringVarP(&options.Output, \"output\", \"o\", \"\", \"output file to write found issues/vulnerabilities\"), flagSet.BoolVarP(&options.StoreResponse, \"store-resp\", \"sresp\", false, \"store all request/response passed through nuclei to output directory\"), flagSet.StringVarP(&options.StoreResponseDir, \"store-resp-dir\", \"srd\", runner.DefaultDumpTrafficOutputFolder, \"store all request/response passed through nuclei to custom directory\"), flagSet.BoolVar(&options.Silent, \"silent\", false, \"display findings only\"), flagSet.BoolVarP(&options.NoColor, \"no-color\", \"nc\", false, \"disable output content coloring (ANSI escape codes)\"), flagSet.BoolVarP(&options.JSONL, \"jsonl\", \"j\", false, \"write output in JSONL(ines) format\"), flagSet.BoolVarP(&options.JSONRequests, \"include-rr\", \"irr\", true, \"include request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only) [DEPRECATED use `-omit-raw`]\"), flagSet.BoolVarP(&options.OmitRawRequests, \"omit-raw\", \"or\", false, \"omit request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only)\"), flagSet.BoolVarP(&options.OmitTemplate, \"omit-template\", \"ot\", false, \"omit encoded template in the JSON, JSONL output\"), flagSet.BoolVarP(&options.NoMeta, \"no-meta\", \"nm\", false, \"disable printing result metadata in cli output\"), flagSet.BoolVarP(&options.Timestamp, \"timestamp\", \"ts\", false, \"enables printing timestamp in cli output\"), flagSet.StringVarP(&options.ReportingDB, \"report-db\", \"rdb\", \"\", \"nuclei reporting database (always use this to persist report data)\"), flagSet.BoolVarP(&options.MatcherStatus, \"matcher-status\", \"ms\", false, \"display match failure status\"), flagSet.StringVarP(&options.MarkdownExportDirectory, \"markdown-export\", \"me\", \"\", \"directory to export results in markdown format\"), flagSet.StringVarP(&options.SarifExport, \"sarif-export\", \"se\", \"\", \"file to export results in SARIF format\"), flagSet.StringVarP(&options.JSONExport, \"json-export\", \"je\", \"\", \"file to export results in JSON format\"), flagSet.StringVarP(&options.JSONLExport, \"jsonl-export\", \"jle\", \"\", \"file to export results in JSONL(ine) format\"))\n",
      "\tflagSet.CreateGroup(\"configs\", \"Configurations\", flagSet.StringVar(&cfgFile, \"config\", \"\", \"path to the nuclei configuration file\"), flagSet.BoolVarP(&options.FollowRedirects, \"follow-redirects\", \"fr\", false, \"enable following redirects for http templates\"), flagSet.BoolVarP(&options.FollowHostRedirects, \"follow-host-redirects\", \"fhr\", false, \"follow redirects on the same host\"), flagSet.IntVarP(&options.MaxRedirects, \"max-redirects\", \"mr\", 10, \"max number of redirects to follow for http templates\"), flagSet.BoolVarP(&options.DisableRedirects, \"disable-redirects\", \"dr\", false, \"disable redirects for http templates\"), flagSet.StringVarP(&options.ReportingConfig, \"report-config\", \"rc\", \"\", \"nuclei reporting module configuration file\"), flagSet.StringSliceVarP(&options.CustomHeaders, \"header\", \"H\", nil, \"custom header/cookie to include in all http request in header:value format (cli, file)\", goflags.FileStringSliceOptions), flagSet.RuntimeMapVarP(&options.Vars, \"var\", \"V\", nil, \"custom vars in key=value format\"), flagSet.StringVarP(&options.ResolversFile, \"resolvers\", \"r\", \"\", \"file containing resolver list for nuclei\"), flagSet.BoolVarP(&options.SystemResolvers, \"system-resolvers\", \"sr\", false, \"use system DNS resolving as error fallback\"), flagSet.BoolVarP(&options.DisableClustering, \"disable-clustering\", \"dc\", false, \"disable clustering of requests\"), flagSet.BoolVar(&options.OfflineHTTP, \"passive\", false, \"enable passive HTTP response processing mode\"), flagSet.BoolVarP(&options.ForceAttemptHTTP2, \"force-http2\", \"fh2\", false, \"force http2 connection on requests\"), flagSet.BoolVarP(&options.EnvironmentVariables, \"env-vars\", \"ev\", false, \"enable environment variables to be used in template\"), flagSet.StringVarP(&options.ClientCertFile, \"client-cert\", \"cc\", \"\", \"client certificate file (PEM-encoded) used for authenticating against scanned hosts\"), flagSet.StringVarP(&options.ClientKeyFile, \"client-key\", \"ck\", \"\", \"client key file (PEM-encoded) used for authenticating against scanned hosts\"), flagSet.StringVarP(&options.ClientCAFile, \"client-ca\", \"ca\", \"\", \"client certificate authority file (PEM-encoded) used for authenticating against scanned hosts\"), flagSet.BoolVarP(&options.ShowMatchLine, \"show-match-line\", \"sml\", false, \"show match lines for file templates, works with extractors only\"), flagSet.BoolVar(&options.ZTLS, \"ztls\", false, \"use ztls library with autofallback to standard one for tls13 [Deprecated] autofallback to ztls is enabled by default\"), flagSet.StringVar(&options.SNI, \"sni\", \"\", \"tls sni hostname to use (default: input domain name)\"), flagSet.DurationVarP(&options.DialerTimeout, \"dialer-timeout\", \"dt\", 0, \"timeout for network requests.\"), flagSet.DurationVarP(&options.DialerKeepAlive, \"dialer-keep-alive\", \"dka\", 0, \"keep-alive duration for network requests.\"), flagSet.BoolVarP(&options.AllowLocalFileAccess, \"allow-local-file-access\", \"lfa\", false, \"allows file (payload) access anywhere on the system\"), flagSet.BoolVarP(&options.RestrictLocalNetworkAccess, \"restrict-local-network-access\", \"lna\", false, \"blocks connections to the local / private network\"), flagSet.StringVarP(&options.Interface, \"interface\", \"i\", \"\", \"network interface to use for network scan\"), flagSet.StringVarP(&options.AttackType, \"attack-type\", \"at\", \"\", \"type of payload combinations to perform (batteringram,pitchfork,clusterbomb)\"), flagSet.StringVarP(&options.SourceIP, \"source-ip\", \"sip\", \"\", \"source ip address to use for network scan\"), flagSet.IntVarP(&options.ResponseReadSize, \"response-size-read\", \"rsr\", 10*1024*1024, \"max response size to read in bytes\"), flagSet.IntVarP(&options.ResponseSaveSize, \"response-size-save\", \"rss\", 1*1024*1024, \"max response size to read in bytes\"), flagSet.CallbackVar(resetCallback, \"reset\", \"reset removes all nuclei configuration and data files (including nuclei-templates)\"), flagSet.BoolVarP(&options.TlsImpersonate, \"tls-impersonate\", \"tlsi\", false, \"enable experimental client hello (ja3) tls randomization\"))\n",
      "\tflagSet.CreateGroup(\"interactsh\", \"interactsh\", flagSet.StringVarP(&options.InteractshURL, \"interactsh-server\", \"iserver\", \"\", fmt.Sprintf(\"interactsh server url for self-hosted instance (default: %s)\", client.DefaultOptions.ServerURL)), flagSet.StringVarP(&options.InteractshToken, \"interactsh-token\", \"itoken\", \"\", \"authentication token for self-hosted interactsh server\"), flagSet.IntVar(&options.InteractionsCacheSize, \"interactions-cache-size\", 5000, \"number of requests to keep in the interactions cache\"), flagSet.IntVar(&options.InteractionsEviction, \"interactions-eviction\", 60, \"number of seconds to wait before evicting requests from cache\"), flagSet.IntVar(&options.InteractionsPollDuration, \"interactions-poll-duration\", 5, \"number of seconds to wait before each interaction poll request\"), flagSet.IntVar(&options.InteractionsCoolDownPeriod, \"interactions-cooldown-period\", 5, \"extra time for interaction polling before exiting\"), flagSet.BoolVarP(&options.NoInteractsh, \"no-interactsh\", \"ni\", false, \"disable interactsh server for OAST testing, exclude OAST based templates\"))\n",
      "\tflagSet.CreateGroup(\"fuzzing\", \"Fuzzing\", flagSet.StringVarP(&options.FuzzingType, \"fuzzing-type\", \"ft\", \"\", \"overrides fuzzing type set in template (replace, prefix, postfix, infix)\"), flagSet.StringVarP(&options.FuzzingMode, \"fuzzing-mode\", \"fm\", \"\", \"overrides fuzzing mode set in template (multiple, single)\"))\n",
      "\tflagSet.CreateGroup(\"uncover\", \"Uncover\", flagSet.BoolVarP(&options.Uncover, \"uncover\", \"uc\", false, \"enable uncover engine\"), flagSet.StringSliceVarP(&options.UncoverQuery, \"uncover-query\", \"uq\", nil, \"uncover search query\", goflags.FileStringSliceOptions), flagSet.StringSliceVarP(&options.UncoverEngine, \"uncover-engine\", \"ue\", nil, fmt.Sprintf(\"uncover search engine (%s) (default shodan)\", uncover.GetUncoverSupportedAgents()), goflags.FileStringSliceOptions), flagSet.StringVarP(&options.UncoverField, \"uncover-field\", \"uf\", \"ip:port\", \"uncover fields to return (ip,port,host)\"), flagSet.IntVarP(&options.UncoverLimit, \"uncover-limit\", \"ul\", 100, \"uncover results to return\"), flagSet.IntVarP(&options.UncoverRateLimit, \"uncover-ratelimit\", \"ur\", 60, \"override ratelimit of engines with unknown ratelimit (default 60 req/min)\"))\n",
      "\tflagSet.CreateGroup(\"rate-limit\", \"Rate-Limit\", flagSet.IntVarP(&options.RateLimit, \"rate-limit\", \"rl\", 150, \"maximum number of requests to send per second\"), flagSet.IntVarP(&options.RateLimitMinute, \"rate-limit-minute\", \"rlm\", 0, \"maximum number of requests to send per minute\"), flagSet.IntVarP(&options.BulkSize, \"bulk-size\", \"bs\", 25, \"maximum number of hosts to be analyzed in parallel per template\"), flagSet.IntVarP(&options.TemplateThreads, \"concurrency\", \"c\", 25, \"maximum number of templates to be executed in parallel\"), flagSet.IntVarP(&options.HeadlessBulkSize, \"headless-bulk-size\", \"hbs\", 10, \"maximum number of headless hosts to be analyzed in parallel per template\"), flagSet.IntVarP(&options.HeadlessTemplateThreads, \"headless-concurrency\", \"headc\", 10, \"maximum number of headless templates to be executed in parallel\"), flagSet.IntVarP(&options.JsConcurrency, \"js-concurrency\", \"jsc\", 120, \"maximum number of javascript runtimes to be executed in parallel\"))\n",
      "\tflagSet.CreateGroup(\"optimization\", \"Optimizations\", flagSet.IntVar(&options.Timeout, \"timeout\", 10, \"time to wait in seconds before timeout\"), flagSet.IntVar(&options.Retries, \"retries\", 1, \"number of times to retry a failed request\"), flagSet.BoolVarP(&options.LeaveDefaultPorts, \"leave-default-ports\", \"ldp\", false, \"leave default HTTP/HTTPS ports (eg. host:80,host:443)\"), flagSet.IntVarP(&options.MaxHostError, \"max-host-error\", \"mhe\", 30, \"max errors for a host before skipping from scan\"), flagSet.StringSliceVarP(&options.TrackError, \"track-error\", \"te\", nil, \"adds given error to max-host-error watchlist (standard, file)\", goflags.FileStringSliceOptions), flagSet.BoolVarP(&options.NoHostErrors, \"no-mhe\", \"nmhe\", false, \"disable skipping host from scan based on errors\"), flagSet.BoolVar(&options.Project, \"project\", false, \"use a project folder to avoid sending same request multiple times\"), flagSet.StringVar(&options.ProjectPath, \"project-path\", os.TempDir(), \"set a specific project path\"), flagSet.BoolVarP(&options.StopAtFirstMatch, \"stop-at-first-match\", \"spm\", false, \"stop processing HTTP requests after the first match (may break template/workflow logic)\"), flagSet.BoolVar(&options.Stream, \"stream\", false, \"stream mode - start elaborating without sorting the input\"), flagSet.EnumVarP(&options.ScanStrategy, \"scan-strategy\", \"ss\", goflags.EnumVariable(0), \"strategy to use while scanning(auto/host-spray/template-spray)\", goflags.AllowdTypes{scanstrategy.Auto.String(): goflags.EnumVariable(0), scanstrategy.HostSpray.String(): goflags.EnumVariable(1), scanstrategy.TemplateSpray.String(): goflags.EnumVariable(2)}), flagSet.DurationVarP(&options.InputReadTimeout, \"input-read-timeout\", \"irt\", time.Duration(3*time.Minute), \"timeout on input read\"), flagSet.BoolVarP(&options.DisableHTTPProbe, \"no-httpx\", \"nh\", false, \"disable httpx probing for non-url input\"), flagSet.BoolVar(&options.DisableStdin, \"no-stdin\", false, \"disable stdin processing\"))\n",
      "\tflagSet.CreateGroup(\"headless\", \"Headless\", flagSet.BoolVar(&options.Headless, \"headless\", false, \"enable templates that require headless browser support (root user on Linux will disable sandbox)\"), flagSet.IntVar(&options.PageTimeout, \"page-timeout\", 20, \"seconds to wait for each page in headless mode\"), flagSet.BoolVarP(&options.ShowBrowser, \"show-browser\", \"sb\", false, \"show the browser on the screen when running templates with headless mode\"), flagSet.StringSliceVarP(&options.HeadlessOptionalArguments, \"headless-options\", \"ho\", nil, \"start headless chrome with additional options\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.BoolVarP(&options.UseInstalledChrome, \"system-chrome\", \"sc\", false, \"use local installed Chrome browser instead of nuclei installed\"), flagSet.BoolVarP(&options.ShowActions, \"list-headless-action\", \"lha\", false, \"list available headless actions\"))\n",
      "\tflagSet.CreateGroup(\"debug\", \"Debug\", flagSet.BoolVar(&options.Debug, \"debug\", false, \"show all requests and responses\"), flagSet.BoolVarP(&options.DebugRequests, \"debug-req\", \"dreq\", false, \"show all sent requests\"), flagSet.BoolVarP(&options.DebugResponse, \"debug-resp\", \"dresp\", false, \"show all received responses\"), flagSet.StringSliceVarP(&options.Proxy, \"proxy\", \"p\", nil, \"list of http/socks5 proxy to use (comma separated or file input)\", goflags.FileCommaSeparatedStringSliceOptions), flagSet.BoolVarP(&options.ProxyInternal, \"proxy-internal\", \"pi\", false, \"proxy all internal requests\"), flagSet.BoolVarP(&options.ListDslSignatures, \"list-dsl-function\", \"ldf\", false, \"list all supported DSL function signatures\"), flagSet.StringVarP(&options.TraceLogFile, \"trace-log\", \"tlog\", \"\", \"file to write sent requests trace log\"), flagSet.StringVarP(&options.ErrorLogFile, \"error-log\", \"elog\", \"\", \"file to write sent requests error log\"), flagSet.CallbackVar(printVersion, \"version\", \"show nuclei version\"), flagSet.BoolVarP(&options.HangMonitor, \"hang-monitor\", \"hm\", false, \"enable nuclei hang monitoring\"), flagSet.BoolVarP(&options.Verbose, \"verbose\", \"v\", false, \"show verbose output\"), flagSet.StringVar(&memProfile, \"profile-mem\", \"\", \"optional nuclei memory profile dump file\"), flagSet.BoolVar(&options.VerboseVerbose, \"vv\", false, \"display templates loaded for scan\"), flagSet.BoolVarP(&options.ShowVarDump, \"show-var-dump\", \"svd\", false, \"show variables dump for debugging\"), flagSet.BoolVarP(&options.EnablePprof, \"enable-pprof\", \"ep\", false, \"enable pprof debugging server\"), flagSet.CallbackVarP(printTemplateVersion, \"templates-version\", \"tv\", \"shows the version of the installed nuclei-templates\"), flagSet.BoolVarP(&options.HealthCheck, \"health-check\", \"hc\", false, \"run diagnostic check up\"))\n",
      "\tflagSet.CreateGroup(\"update\", \"Update\", flagSet.BoolVarP(&updateNucleiBinary, \"update\", \"up\", false, \"update nuclei engine to the latest released version\"), flagSet.BoolVarP(&options.UpdateTemplates, \"update-templates\", \"ut\", false, \"update nuclei-templates to latest released version\"), flagSet.StringVarP(&options.NewTemplatesDirectory, \"update-template-dir\", \"ud\", \"\", \"custom directory to install / update nuclei-templates\"), flagSet.CallbackVarP(disableUpdatesCallback, \"disable-update-check\", \"duc\", \"disable automatic nuclei/templates update check\"))\n",
      "\tflagSet.CreateGroup(\"stats\", \"Statistics\", flagSet.BoolVar(&options.EnableProgressBar, \"stats\", false, \"display statistics about the running scan\"), flagSet.BoolVarP(&options.StatsJSON, \"stats-json\", \"sj\", false, \"display statistics in JSONL(ines) format\"), flagSet.IntVarP(&options.StatsInterval, \"stats-interval\", \"si\", 5, \"number of seconds to wait between showing a statistics update\"), flagSet.IntVarP(&options.MetricsPort, \"metrics-port\", \"mp\", 9092, \"port to expose nuclei metrics on\"))\n",
      "\tflagSet.CreateGroup(\"cloud\", \"Cloud\", flagSet.DynamicVar(&pdcpauth, \"auth\", \"true\", \"configure projectdiscovery cloud (pdcp) api key\"), flagSet.BoolVarP(&options.EnableCloudUpload, \"cloud-upload\", \"cup\", false, \"upload scan results to pdcp dashboard\"), flagSet.StringVarP(&options.ScanID, \"scan-id\", \"sid\", \"\", \"upload scan results to given scan id\"))\n",
      "\tflagSet.SetCustomHelpText(`EXAMPLES:\n",
      "Run nuclei on single host:\n",
      "\t$ nuclei -target example.com\n",
      "\n",
      "Run nuclei with specific template directories:\n",
      "\t$ nuclei -target example.com -t http/cves/ -t ssl\n",
      "\n",
      "Run nuclei against a list of hosts:\n",
      "\t$ nuclei -list hosts.txt\n",
      "\n",
      "Run nuclei with a JSON output:\n",
      "\t$ nuclei -target example.com -json-export output.json\n",
      "\n",
      "Run nuclei with sorted Markdown outputs (with environment variables):\n",
      "\t$ MARKDOWN_EXPORT_SORT_MODE=template nuclei -target example.com -markdown-export nuclei_report/\n",
      "\n",
      "Additional documentation is available at: https://docs.nuclei.sh/getting-started/running\n",
      "\t`)\n",
      "\tgoflags.DisableAutoConfigMigration = true\n",
      "\t_ = flagSet.Parse()\n",
      "\tif pdcpauth == \"true\" {\n",
      "\t\trunner.AuthWithPDCP()\n",
      "\t} else if len(pdcpauth) == 36 {\n",
      "\t\tph := pdcp.PDCPCredHandler{}\n",
      "\t\tif _, err := ph.GetCreds(); err == pdcp.ErrNoCreds {\n",
      "\t\t\tapiServer := env.GetEnvOrDefault(\"PDCP_API_SERVER\", pdcp.DefaultApiServer)\n",
      "\t\t\tif validatedCreds, err := ph.ValidateAPIKey(pdcpauth, apiServer, config.BinaryName); err == nil {\n",
      "\t\t\t\t_ = ph.SaveCreds(validatedCreds)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tgologger.DefaultLogger.SetTimestamp(options.Timestamp, levels.LevelDebug)\n",
      "\tif options.VerboseVerbose {\n",
      "\t\tinstaller.HideReleaseNotes = false\n",
      "\t}\n",
      "\tif options.Timeout > 30 {\n",
      "\t\tupdateutils.DownloadUpdateTimeout = time.Duration(options.Timeout) * time.Second\n",
      "\t}\n",
      "\tif updateNucleiBinary {\n",
      "\t\trunner.NucleiToolUpdateCallback()\n",
      "\t}\n",
      "\tif options.LeaveDefaultPorts {\n",
      "\t\thttp.LeaveDefaultPorts = true\n",
      "\t}\n",
      "\tif customConfigDir := os.Getenv(config.NucleiConfigDirEnv); customConfigDir != \"\" {\n",
      "\t\tconfig.DefaultConfig.SetConfigDir(customConfigDir)\n",
      "\t\treadFlagsConfig(flagSet)\n",
      "\t}\n",
      "\tif cfgFile != \"\" {\n",
      "\t\tif !fileutil.FileExists(cfgFile) {\n",
      "\t\t\tgologger.Fatal().Msgf(\"given config file '%s' does not exist\", cfgFile)\n",
      "\t\t}\n",
      "\t\tif err := flagSet.MergeConfigFile(cfgFile); err != nil {\n",
      "\t\t\tgologger.Fatal().Msgf(\"Could not read config: %s\\n\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif options.NewTemplatesDirectory != \"\" {\n",
      "\t\tconfig.DefaultConfig.SetTemplatesDir(options.NewTemplatesDirectory)\n",
      "\t}\n",
      "\tcleanupOldResumeFiles()\n",
      "\treturn flagSet\n",
      "}\n",
      "func createReportingOptions(options *types.Options) (*reporting.Options, error) {\n",
      "\tvar reportingOptions = &reporting.Options{}\n",
      "\tif options.ReportingConfig != \"\" {\n",
      "\t\tfile, err := os.Open(options.ReportingConfig)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, errors.Wrap(err, \"could not open reporting config file\")\n",
      "\t\t}\n",
      "\t\tdefer file.Close()\n",
      "\t\tif err := yaml.DecodeAndValidate(file, reportingOptions); err != nil {\n",
      "\t\t\treturn nil, errors.Wrap(err, \"could not parse reporting config file\")\n",
      "\t\t}\n",
      "\t\tWalk(reportingOptions, expandEndVars)\n",
      "\t}\n",
      "\tif options.MarkdownExportDirectory != \"\" {\n",
      "\t\treportingOptions.MarkdownExporter = &markdown.Options{Directory: options.MarkdownExportDirectory, OmitRaw: options.OmitRawRequests, SortMode: options.MarkdownExportSortMode}\n",
      "\t}\n",
      "\tif options.SarifExport != \"\" {\n",
      "\t\treportingOptions.SarifExporter = &sarif.Options{File: options.SarifExport}\n",
      "\t}\n",
      "\tif options.JSONExport != \"\" {\n",
      "\t\treportingOptions.JSONExporter = &jsonexporter.Options{File: options.JSONExport, OmitRaw: options.OmitRawRequests}\n",
      "\t}\n",
      "\tif options.JSONLExport != \"\" {\n",
      "\t\treportingOptions.JSONLExporter = &jsonl.Options{File: options.JSONLExport, OmitRaw: options.OmitRawRequests}\n",
      "\t}\n",
      "\treportingOptions.OmitRaw = options.OmitRawRequests\n",
      "\treturn reportingOptions, nil\n",
      "}\n",
      "func expandEndVars(f reflect.Value, fieldType reflect.StructField) {\n",
      "\tif _, ok := fieldType.Tag.Lookup(\"yaml\"); !ok {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif f.Kind() == reflect.String {\n",
      "\t\tstr := f.String()\n",
      "\t\tif strings.HasPrefix(str, \"$\") {\n",
      "\t\t\tenv := strings.TrimPrefix(str, \"$\")\n",
      "\t\t\tretrievedEnv := os.Getenv(env)\n",
      "\t\t\tif retrievedEnv != \"\" {\n",
      "\t\t\t\tf.SetString(os.Getenv(env))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func CreateTemplateData(directory string, packagePrefix string) (*TemplateData, error) {\n",
      "\tfmt.Println(directory)\n",
      "\tfset := token.NewFileSet()\n",
      "\tpkgs, err := parser.ParseDir(fset, directory, nil, parser.ParseComments)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errors.Wrap(err, \"could not parse directory\")\n",
      "\t}\n",
      "\tif len(pkgs) != 1 {\n",
      "\t\treturn nil, fmt.Errorf(\"expected 1 package, got %d\", len(pkgs))\n",
      "\t}\n",
      "\tconfig := &types.Config{Importer: importer.ForCompiler(fset, \"source\", nil)}\n",
      "\tvar packageName string\n",
      "\tvar files []*ast.File\n",
      "\tfor k, v := range pkgs {\n",
      "\t\tpackageName = k\n",
      "\t\tfor _, f := range v.Files {\n",
      "\t\t\tfiles = append(files, f)\n",
      "\t\t}\n",
      "\t\tbreak\n",
      "\t}\n",
      "\tpkg, err := config.Check(packageName, fset, files, nil)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errors.Wrap(err, \"could not check package\")\n",
      "\t}\n",
      "\tvar pkgMain *ast.Package\n",
      "\tfor _, p := range pkgs {\n",
      "\t\tpkgMain = p\n",
      "\t\tbreak\n",
      "\t}\n",
      "\tlog.Printf(\"[create] [discover] Package: %s\\n\", pkgMain.Name)\n",
      "\tdata := newTemplateData(packagePrefix, pkgMain.Name)\n",
      "\tdata.typesPackage = pkg\n",
      "\tdata.gatherPackageData(pkgMain, data)\n",
      "\tfor item, v := range data.PackageFuncsExtra {\n",
      "\t\tif len(v.Items) == 0 {\n",
      "\t\t\tdelete(data.PackageFuncsExtra, item)\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor constructor := range data.PackageDefinedConstructor {\n",
      "\tobject:\n",
      "\t\tfor k := range data.PackageTypes {\n",
      "\t\t\tif strings.Contains(constructor, k) {\n",
      "\t\t\t\tdata.PackageTypes[k] = constructor\n",
      "\t\t\t\tbreak object\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor k, v := range data.PackageTypes {\n",
      "\t\tif k == v || v == \"\" {\n",
      "\t\t\tdata.HasObjects = true\n",
      "\t\t\tdata.PackageTypes[k] = \"\"\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn data, nil\n",
      "}\n",
      "func (c *Config) copyIgnoreFile() {\n",
      "\tif err := c.createConfigDirIfNotExists(); err != nil {\n",
      "\t\tgologger.Error().Msgf(\"Could not create nuclei config directory at %s: %s\", c.configDir, err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tignoreFilePath := c.GetIgnoreFilePath()\n",
      "\tif !fileutil.FileExists(ignoreFilePath) {\n",
      "\t\tif err := fileutil.CopyFile(filepath.Join(folderutil.AppConfigDirOrDefault(FallbackConfigFolderName, BinaryName), NucleiIgnoreFileName), ignoreFilePath); err != nil {\n",
      "\t\t\tgologger.Error().Msgf(\"Could not copy nuclei ignore file at %s: %s\", ignoreFilePath, err)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (c *Config) WriteTemplatesConfig() error {\n",
      "\tif err := c.createConfigDirIfNotExists(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tbin, err := json.Marshal(c)\n",
      "\tif err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"failed to marshal nuclei config\")\n",
      "\t}\n",
      "\tif err = os.WriteFile(c.getTemplatesConfigFilePath(), bin, 0600); err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"failed to write nuclei config file at %s\", c.getTemplatesConfigFilePath())\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func readFlagsConfig(flagset *goflags.FlagSet) {\n",
      "\tdefaultCfgFile, err := flagset.GetConfigFilePath()\n",
      "\tif err != nil {\n",
      "\t\tgologger.Warning().Msgf(\"Could not read config file: %s\\n\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tcfgFile := config.DefaultConfig.GetFlagsConfigFilePath()\n",
      "\tif !fileutil.FileExists(cfgFile) {\n",
      "\t\tif !fileutil.FileExists(defaultCfgFile) {\n",
      "\t\t\tgologger.Warning().Msgf(\"missing default config file : %s\", defaultCfgFile)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif err = fileutil.CopyFile(defaultCfgFile, cfgFile); err != nil {\n",
      "\t\t\tgologger.Warning().Msgf(\"Could not copy config file: %s\\n\", err)\n",
      "\t\t}\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif err = flagset.MergeConfigFile(cfgFile); err != nil {\n",
      "\t\tgologger.Warning().Msgf(\"failed to merge configfile with flags got: %s\\n\", err)\n",
      "\t}\n",
      "}\n",
      "func (request *Request) Compile(options *protocols.ExecutorOptions) error {\n",
      "\trequest.options = options\n",
      "\tvar err error\n",
      "\tif len(request.Payloads) > 0 {\n",
      "\t\trequest.generator, err = generators.New(request.Payloads, request.AttackType.Value, request.options.TemplatePath, options.Catalog, options.Options.AttackType, options.Options)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Wrap(err, \"could not parse payloads\")\n",
      "\t\t}\n",
      "\t\trequest.Threads = options.GetThreadsForNPayloadRequests(request.Requests(), request.Threads)\n",
      "\t}\n",
      "\tif len(request.Matchers) > 0 || len(request.Extractors) > 0 {\n",
      "\t\tcompiled := &request.Operators\n",
      "\t\tcompiled.ExcludeMatchers = options.ExcludeMatchers\n",
      "\t\tcompiled.TemplateID = options.TemplateID\n",
      "\t\tfor _, matcher := range compiled.Matchers {\n",
      "\t\t\tif matcher.Part == \"\" && matcher.Type.MatcherType != matchers.DSLMatcher {\n",
      "\t\t\t\tmatcher.Part = \"response\"\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor _, extractor := range compiled.Extractors {\n",
      "\t\t\tif extractor.Part == \"\" {\n",
      "\t\t\t\textractor.Part = \"response\"\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err := compiled.Compile(); err != nil {\n",
      "\t\t\treturn errorutil.NewWithTag(request.TemplateID, \"could not compile operators got %v\", err)\n",
      "\t\t}\n",
      "\t\trequest.CompiledOperators = compiled\n",
      "\t}\n",
      "\tif strings.Contains(request.getPort(), \"{{\") {\n",
      "\t\treturn errorutil.NewWithTag(request.TemplateID, \"'Port' variable cannot contain any dsl expressions\")\n",
      "\t}\n",
      "\tif request.Init != \"\" {\n",
      "\t\tif request.options.Options.Debug || request.options.Options.DebugRequests {\n",
      "\t\t\tgologger.Debug().Msgf(\"[%s] Executing Template Init\\n\", request.TemplateID)\n",
      "\t\t\tvar highlightFormatter = \"terminal256\"\n",
      "\t\t\tif request.options.Options.NoColor {\n",
      "\t\t\t\thighlightFormatter = \"text\"\n",
      "\t\t\t}\n",
      "\t\t\tvar buff bytes.Buffer\n",
      "\t\t\t_ = quick.Highlight(&buff, beautifyJavascript(request.Init), \"javascript\", highlightFormatter, \"monokai\")\n",
      "\t\t\tprettyPrint(request.TemplateID, buff.String())\n",
      "\t\t}\n",
      "\t\topts := &compiler.ExecuteOptions{Timeout: request.Timeout, Source: &request.Init}\n",
      "\t\topts.Callback = func(runtime *goja.Runtime) error {\n",
      "\t\t\terr := gojs.RegisterFuncWithSignature(runtime, gojs.FuncOpts{Name: \"set\", Signatures: []string{\"set(string, interface{})\"}, Description: \"set variable from init code. this function is available in init code block only\", FuncDecl: func(varname string, value any) error {\n",
      "\t\t\t\tif varname == \"\" {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"variable name cannot be empty\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif value == nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"variable value cannot be empty\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif request.Args == nil {\n",
      "\t\t\t\t\trequest.Args = make(map[string]interface{})\n",
      "\t\t\t\t}\n",
      "\t\t\t\trequest.Args[varname] = value\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t}})\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\treturn gojs.RegisterFuncWithSignature(runtime, gojs.FuncOpts{Name: \"updatePayload\", Signatures: []string{\"updatePayload(string, interface{})\"}, Description: \"update/override any payload from init code. this function is available in init code block only\", FuncDecl: func(varname string, Value any) error {\n",
      "\t\t\t\tif request.Payloads == nil {\n",
      "\t\t\t\t\trequest.Payloads = make(map[string]interface{})\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif request.generator != nil {\n",
      "\t\t\t\t\trequest.Payloads[varname] = Value\n",
      "\t\t\t\t\trequest.generator, err = generators.New(request.Payloads, request.AttackType.Value, request.options.TemplatePath, options.Catalog, options.Options.AttackType, options.Options)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\treturn err\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"payloads not defined and cannot be updated\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t}})\n",
      "\t\t}\n",
      "\t\topts.Cleanup = func(runtime *goja.Runtime) {\n",
      "\t\t\t_ = runtime.GlobalObject().Delete(\"set\")\n",
      "\t\t\t_ = runtime.GlobalObject().Delete(\"updatePayload\")\n",
      "\t\t}\n",
      "\t\targs := compiler.NewExecuteArgs()\n",
      "\t\tallVars := generators.MergeMaps(options.Variables.GetAll(), options.Options.Vars.AsMap(), request.options.Constants)\n",
      "\t\targs.Args, _ = request.evaluateArgs(allVars, options, true)\n",
      "\t\tinitCompiled, err := compiler.WrapScriptNCompile(request.Init, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errorutil.NewWithTag(request.TemplateID, \"could not compile init code: %s\", err)\n",
      "\t\t}\n",
      "\t\tresult, err := request.options.JsCompiler.ExecuteWithOptions(initCompiled, args, opts)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errorutil.NewWithTag(request.TemplateID, \"could not execute pre-condition: %s\", err)\n",
      "\t\t}\n",
      "\t\tif types.ToString(result[\"error\"]) != \"\" {\n",
      "\t\t\tgologger.Warning().Msgf(\"[%s] Init failed with error %v\\n\", request.TemplateID, result[\"error\"])\n",
      "\t\t\treturn nil\n",
      "\t\t} else {\n",
      "\t\t\tif request.options.Options.Debug || request.options.Options.DebugResponse {\n",
      "\t\t\t\tgologger.Debug().Msgf(\"[%s] Init executed successfully\\n\", request.TemplateID)\n",
      "\t\t\t\tgologger.Debug().Msgf(\"[%s] Init result: %v\\n\", request.TemplateID, result[\"response\"])\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif request.PreCondition != \"\" {\n",
      "\t\tpreConditionCompiled, err := compiler.WrapScriptNCompile(request.PreCondition, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errorutil.NewWithTag(request.TemplateID, \"could not compile pre-condition: %s\", err)\n",
      "\t\t}\n",
      "\t\trequest.preConditionCompiled = preConditionCompiled\n",
      "\t}\n",
      "\tif request.Code != \"\" {\n",
      "\t\tscriptCompiled, err := compiler.WrapScriptNCompile(request.Code, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errorutil.NewWithTag(request.TemplateID, \"could not compile javascript code: %s\", err)\n",
      "\t\t}\n",
      "\t\trequest.scriptCompiled = scriptCompiled\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *Config) SetTemplatesVersion(version string) error {\n",
      "\tc.TemplateVersion = version\n",
      "\tif err := c.WriteTemplatesConfig(); err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"could not write nuclei config file at %s\", c.getTemplatesConfigFilePath())\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (e *Extractor) CompileExtractors() error {\n",
      "\tcomputedType, err := toExtractorTypes(e.GetType().String())\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"unknown extractor type specified: %s\", e.Type)\n",
      "\t}\n",
      "\te.extractorType = computedType\n",
      "\tfor _, regex := range e.Regex {\n",
      "\t\tcompiled, err := regexp.Compile(regex)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not compile regex: %s\", regex)\n",
      "\t\t}\n",
      "\t\te.regexCompiled = append(e.regexCompiled, compiled)\n",
      "\t}\n",
      "\tfor i, kval := range e.KVal {\n",
      "\t\te.KVal[i] = strings.ToLower(kval)\n",
      "\t}\n",
      "\tfor _, query := range e.JSON {\n",
      "\t\tquery, err := gojq.Parse(query)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not parse json: %s\", query)\n",
      "\t\t}\n",
      "\t\tcompiled, err := gojq.Compile(query)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not compile json: %s\", query)\n",
      "\t\t}\n",
      "\t\te.jsonCompiled = append(e.jsonCompiled, compiled)\n",
      "\t}\n",
      "\tfor _, dslExp := range e.DSL {\n",
      "\t\tcompiled, err := govaluate.NewEvaluableExpressionWithFunctions(dslExp, dsl.HelperFunctions)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn &dsl.CompilationError{DslSignature: dslExp, WrappedError: err}\n",
      "\t\t}\n",
      "\t\te.dslCompiled = append(e.dslCompiled, compiled)\n",
      "\t}\n",
      "\tif e.CaseInsensitive {\n",
      "\t\tif e.GetType() != KValExtractor {\n",
      "\t\t\treturn fmt.Errorf(\"case-insensitive flag is supported only for 'kval' extractors (not '%s')\", e.Type)\n",
      "\t\t}\n",
      "\t\tfor i := range e.KVal {\n",
      "\t\t\te.KVal[i] = strings.ToLower(e.KVal[i])\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *Config) SetConfigDir(dir string) {\n",
      "\tc.configDir = dir\n",
      "\tif err := c.createConfigDirIfNotExists(); err != nil {\n",
      "\t\tgologger.Fatal().Msgf(\"Could not create nuclei config directory at %s: %s\", c.configDir, err)\n",
      "\t}\n",
      "\tif err := c.ReadTemplatesConfig(); err != nil {\n",
      "\t\tapplyDefaultConfig()\n",
      "\t\tif err2 := c.WriteTemplatesConfig(); err2 != nil {\n",
      "\t\t\tgologger.Fatal().Msgf(\"Could not create nuclei config file at %s: %s\", c.getTemplatesConfigFilePath(), err2)\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.copyIgnoreFile()\n",
      "}\n",
      "func CreateConfigIfNotExists() error {\n",
      "\treportingConfig := config.DefaultConfig.GetReportingConfigFilePath()\n",
      "\tif fileutil.FileExists(reportingConfig) {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tvalues := stringslice.StringSlice{Value: []string{}}\n",
      "\toptions := &Options{AllowList: &filters.Filter{Tags: values}, DenyList: &filters.Filter{Tags: values}, GitHub: &github.Options{}, GitLab: &gitlab.Options{}, Gitea: &gitea.Options{}, Jira: &jira.Options{}, MarkdownExporter: &markdown.Options{}, SarifExporter: &sarif.Options{}, ElasticsearchExporter: &es.Options{}, SplunkExporter: &splunk.Options{}, JSONExporter: &json_exporter.Options{}, JSONLExporter: &jsonl.Options{}}\n",
      "\treportingFile, err := os.Create(reportingConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"could not create config file\")\n",
      "\t}\n",
      "\tdefer reportingFile.Close()\n",
      "\terr = yaml.NewEncoder(reportingFile).Encode(options)\n",
      "\treturn err\n",
      "}\n",
      "func ParseOptions(options *types.Options) {\n",
      "\toptions.Stdin = !options.DisableStdin && fileutil.HasStdin()\n",
      "\treadEnvInputVars(options)\n",
      "\tconfigureOutput(options)\n",
      "\tshowBanner()\n",
      "\tif options.ShowVarDump {\n",
      "\t\tvardump.EnableVarDump = true\n",
      "\t}\n",
      "\tif options.ShowActions {\n",
      "\t\tgologger.Info().Msgf(\"Showing available headless actions: \")\n",
      "\t\tfor action := range engine.ActionStringToAction {\n",
      "\t\t\tgologger.Print().Msgf(\"\\t%s\", action)\n",
      "\t\t}\n",
      "\t\tos.Exit(0)\n",
      "\t}\n",
      "\tif options.StoreResponseDir != DefaultDumpTrafficOutputFolder && !options.StoreResponse {\n",
      "\t\tgologger.Debug().Msgf(\"Store response directory specified, enabling \\\"store-resp\\\" flag automatically\\n\")\n",
      "\t\toptions.StoreResponse = true\n",
      "\t}\n",
      "\tif err := ValidateOptions(options); err != nil {\n",
      "\t\tgologger.Fatal().Msgf(\"Program exiting: %s\\n\", err)\n",
      "\t}\n",
      "\tloadResolvers(options)\n",
      "\terr := protocolinit.Init(options)\n",
      "\tif err != nil {\n",
      "\t\tgologger.Fatal().Msgf(\"Could not initialize protocols: %s\\n\", err)\n",
      "\t}\n",
      "\tif options.GitHubToken != \"\" && os.Getenv(\"GITHUB_TOKEN\") != options.GitHubToken {\n",
      "\t\tos.Setenv(\"GITHUB_TOKEN\", options.GitHubToken)\n",
      "\t}\n",
      "\tif options.UncoverQuery != nil {\n",
      "\t\toptions.Uncover = true\n",
      "\t\tif len(options.UncoverEngine) == 0 {\n",
      "\t\t\toptions.UncoverEngine = append(options.UncoverEngine, \"shodan\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif options.OfflineHTTP {\n",
      "\t\toptions.DisableHTTPProbe = true\n",
      "\t}\n",
      "}\n",
      "func (c *Config) ReadTemplatesConfig() error {\n",
      "\tif !fileutil.FileExists(c.getTemplatesConfigFilePath()) {\n",
      "\t\treturn errorutil.NewWithTag(\"config\", \"nuclei config file at %s does not exist\", c.getTemplatesConfigFilePath())\n",
      "\t}\n",
      "\tvar cfg *Config\n",
      "\tbin, err := os.ReadFile(c.getTemplatesConfigFilePath())\n",
      "\tif err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"could not read nuclei config file at %s\", c.getTemplatesConfigFilePath())\n",
      "\t}\n",
      "\tif err := json.Unmarshal(bin, &cfg); err != nil {\n",
      "\t\treturn errorutil.NewWithErr(err).Msgf(\"could not unmarshal nuclei config file at %s\", c.getTemplatesConfigFilePath())\n",
      "\t}\n",
      "\tc.TemplatesDirectory = cfg.TemplatesDirectory\n",
      "\tc.TemplateVersion = cfg.TemplateVersion\n",
      "\tc.NucleiIgnoreHash = cfg.NucleiIgnoreHash\n",
      "\tc.LatestNucleiIgnoreHash = cfg.LatestNucleiIgnoreHash\n",
      "\tc.LatestNucleiTemplatesVersion = cfg.LatestNucleiTemplatesVersion\n",
      "\treturn nil\n",
      "}\n",
      "func (c *Config) createConfigDirIfNotExists() error {\n",
      "\tif !fileutil.FolderExists(c.configDir) {\n",
      "\t\tif err := fileutil.CreateFolder(c.configDir); err != nil {\n",
      "\t\t\treturn errorutil.NewWithErr(err).Msgf(\"could not create nuclei config directory at %s\", c.configDir)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (matcher *Matcher) CompileMatchers() error {\n",
      "\tvar ok bool\n",
      "\tif matcher.Encoding == \"hex\" {\n",
      "\t\tfor i, word := range matcher.Words {\n",
      "\t\t\tif decoded, err := hex.DecodeString(word); err == nil && len(decoded) > 0 {\n",
      "\t\t\t\tmatcher.Words[i] = string(decoded)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tcomputedType, err := toMatcherTypes(matcher.GetType().String())\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"unknown matcher type specified: %s\", matcher.Type)\n",
      "\t}\n",
      "\tmatcher.matcherType = computedType\n",
      "\tif err := matcher.Validate(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif matcher.Part == \"\" && matcher.GetType() != DSLMatcher {\n",
      "\t\tmatcher.Part = \"body\"\n",
      "\t}\n",
      "\tfor _, regex := range matcher.Regex {\n",
      "\t\tcompiled, err := regexp.Compile(regex)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not compile regex: %s\", regex)\n",
      "\t\t}\n",
      "\t\tmatcher.regexCompiled = append(matcher.regexCompiled, compiled)\n",
      "\t}\n",
      "\tfor _, value := range matcher.Binary {\n",
      "\t\tif decoded, err := hex.DecodeString(value); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not hex decode binary: %s\", value)\n",
      "\t\t} else {\n",
      "\t\t\tmatcher.binaryDecoded = append(matcher.binaryDecoded, string(decoded))\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor _, dslExpression := range matcher.DSL {\n",
      "\t\tcompiledExpression, err := govaluate.NewEvaluableExpressionWithFunctions(dslExpression, dsl.HelperFunctions)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn &dsl.CompilationError{DslSignature: dslExpression, WrappedError: err}\n",
      "\t\t}\n",
      "\t\tmatcher.dslCompiled = append(matcher.dslCompiled, compiledExpression)\n",
      "\t}\n",
      "\tif matcher.Condition != \"\" {\n",
      "\t\tmatcher.condition, ok = ConditionTypes[matcher.Condition]\n",
      "\t\tif !ok {\n",
      "\t\t\treturn fmt.Errorf(\"unknown condition specified: %s\", matcher.Condition)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tmatcher.condition = ORCondition\n",
      "\t}\n",
      "\tif matcher.CaseInsensitive {\n",
      "\t\tif matcher.GetType() != WordsMatcher {\n",
      "\t\t\treturn fmt.Errorf(\"case-insensitive flag is supported only for 'word' matchers (not '%s')\", matcher.Type)\n",
      "\t\t}\n",
      "\t\tfor i := range matcher.Words {\n",
      "\t\t\tmatcher.Words[i] = strings.ToLower(matcher.Words[i])\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "charmbracelet/gum 4 15909\n",
      "4\n",
      "======================CLASS=======================\n",
      "func writeFlags(buf io.StringWriter, cmd *kong.Node) {\n",
      "\twriteString(buf, `    flags=()\n",
      "    two_word_flags=()\n",
      "    local_nonpersistent_flags=()\n",
      "    flags_with_completion=()\n",
      "    flags_completion=()\n",
      "\n",
      "`)\n",
      "\tfor _, flag := range cmd.Flags {\n",
      "\t\tif nonCompletableFlag(flag) {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\twriteFlag(buf, flag, cmd)\n",
      "\t\tif flag.Short != 0 {\n",
      "\t\t\twriteShortFlag(buf, flag, cmd)\n",
      "\t\t}\n",
      "\t}\n",
      "\twriteString(buf, \"\\n\")\n",
      "}\n",
      "func writeLocalNonPersistentFlag(buf io.StringWriter, flag *kong.Flag) {\n",
      "\tname := flag.Name\n",
      "\tformat := \"    local_nonpersistent_flags+=(\\\"--%[1]s\" + cbn\n",
      "\tif len(flag.DefaultValue.String()) == 0 {\n",
      "\t\tformat += \"    local_nonpersistent_flags+=(\\\"--%[1]s=\" + cbn\n",
      "\t}\n",
      "\twriteString(buf, fmt.Sprintf(format, name))\n",
      "\tif flag.Short > 0 {\n",
      "\t\twriteString(buf, fmt.Sprintf(\"    local_nonpersistent_flags+=(\\\"-%c\\\")\\n\", flag.Short))\n",
      "\t}\n",
      "}\n",
      "func writeFlag(buf io.StringWriter, flag *kong.Flag, cmd *kong.Node) {\n",
      "\tname := flag.Name\n",
      "\tformat := \"    flags+=(\\\"--%s\"\n",
      "\tif len(flag.DefaultValue.String()) == 0 {\n",
      "\t\tformat += \"=\"\n",
      "\t}\n",
      "\tformat += cbn\n",
      "\twriteString(buf, fmt.Sprintf(format, name))\n",
      "\tif len(flag.DefaultValue.String()) == 0 {\n",
      "\t\tformat = \"    two_word_flags+=(\\\"--%s\" + cbn\n",
      "\t\twriteString(buf, fmt.Sprintf(format, name))\n",
      "\t}\n",
      "\twriteFlagHandler(buf, \"--\"+name, map[string][]string{}, cmd)\n",
      "}\n",
      "func writeShortFlag(buf io.StringWriter, flag *kong.Flag, cmd *kong.Node) {\n",
      "\tname := fmt.Sprintf(\"%c\", flag.Short)\n",
      "\tformat := \"    \"\n",
      "\tif len(flag.DefaultValue.String()) == 0 {\n",
      "\t\tformat += \"two_word_\"\n",
      "\t}\n",
      "\tformat += \"flags+=(\\\"-%s\" + cbn\n",
      "\twriteString(buf, fmt.Sprintf(format, name))\n",
      "\twriteFlagHandler(buf, \"-\"+name, map[string][]string{}, cmd)\n",
      "}\n",
      "func writePreamble(buf io.StringWriter, name string) {\n",
      "\twriteString(buf, fmt.Sprintf(\"# bash completion for %-36s -*- shell-script -*-\\n\", name))\n",
      "\twriteString(buf, fmt.Sprintf(`\n",
      "__%[1]s_debug()\n",
      "{\n",
      "    if [[ -n ${BASH_COMP_DEBUG_FILE:-} ]]; then\n",
      "        echo \"$*\" >> \"${BASH_COMP_DEBUG_FILE}\"\n",
      "    fi\n",
      "}\n",
      "\n",
      "# Homebrew on Macs have version 1.3 of bash-completion which doesn't include\n",
      "# _init_completion. This is a very minimal version of that function.\n",
      "__%[1]s_init_completion()\n",
      "{\n",
      "    COMPREPLY=()\n",
      "    _get_comp_words_by_ref \"$@\" cur prev words cword\n",
      "}\n",
      "\n",
      "__%[1]s_index_of_word()\n",
      "{\n",
      "    local w word=$1\n",
      "    shift\n",
      "    index=0\n",
      "    for w in \"$@\"; do\n",
      "        [[ $w = \"$word\" ]] && return\n",
      "        index=$((index+1))\n",
      "    done\n",
      "    index=-1\n",
      "}\n",
      "\n",
      "__%[1]s_contains_word()\n",
      "{\n",
      "    local w word=$1; shift\n",
      "    for w in \"$@\"; do\n",
      "        [[ $w = \"$word\" ]] && return\n",
      "    done\n",
      "    return 1\n",
      "}\n",
      "\n",
      "__%[1]s_handle_go_custom_completion()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: cur is ${cur}, words[*] is ${words[*]}, #words[@] is ${#words[@]}\"\n",
      "\n",
      "    local shellCompDirectiveError=%[3]d\n",
      "    local shellCompDirectiveNoSpace=%[4]d\n",
      "    local shellCompDirectiveNoFileComp=%[5]d\n",
      "    local shellCompDirectiveFilterFileExt=%[6]d\n",
      "    local shellCompDirectiveFilterDirs=%[7]d\n",
      "\n",
      "    local out requestComp lastParam lastChar comp directive args\n",
      "\n",
      "    # Prepare the command to request completions for the program.\n",
      "    # Calling ${words[0]} instead of directly %[1]s allows to handle aliases\n",
      "    args=(\"${words[@]:1}\")\n",
      "    # Disable ActiveHelp which is not supported for bash completion v1\n",
      "    requestComp=\"%[8]s=0 ${words[0]} %[2]s ${args[*]}\"\n",
      "\n",
      "    lastParam=${words[$((${#words[@]}-1))]}\n",
      "    lastChar=${lastParam:$((${#lastParam}-1)):1}\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: lastParam ${lastParam}, lastChar ${lastChar}\"\n",
      "\n",
      "    if [ -z \"${cur}\" ] && [ \"${lastChar}\" != \"=\" ]; then\n",
      "        # If the last parameter is complete (there is a space following it)\n",
      "        # We add an extra empty parameter so we can indicate this to the go method.\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: Adding extra empty parameter\"\n",
      "        requestComp=\"${requestComp} \\\"\\\"\"\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: calling ${requestComp}\"\n",
      "    # Use eval to handle any environment variables and such\n",
      "    out=$(eval \"${requestComp}\" 2>/dev/null)\n",
      "\n",
      "    # Extract the directive integer at the very end of the output following a colon (:)\n",
      "    directive=${out##*:}\n",
      "    # Remove the directive\n",
      "    out=${out%%:*}\n",
      "    if [ \"${directive}\" = \"${out}\" ]; then\n",
      "        # There is not directive specified\n",
      "        directive=0\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: the completion directive is: ${directive}\"\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: the completions are: ${out}\"\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveError)) -ne 0 ]; then\n",
      "        # Error code.  No completion.\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: received error from custom completion go code\"\n",
      "        return\n",
      "    else\n",
      "        if [ $((directive & shellCompDirectiveNoSpace)) -ne 0 ]; then\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                __%[1]s_debug \"${FUNCNAME[0]}: activating no space\"\n",
      "                compopt -o nospace\n",
      "            fi\n",
      "        fi\n",
      "        if [ $((directive & shellCompDirectiveNoFileComp)) -ne 0 ]; then\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                __%[1]s_debug \"${FUNCNAME[0]}: activating no file completion\"\n",
      "                compopt +o default\n",
      "            fi\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveFilterFileExt)) -ne 0 ]; then\n",
      "        # File extension filtering\n",
      "        local fullFilter filter filteringCmd\n",
      "        # Do not use quotes around the $out variable or else newline\n",
      "        # characters will be kept.\n",
      "        for filter in ${out}; do\n",
      "            fullFilter+=\"$filter|\"\n",
      "        done\n",
      "\n",
      "        filteringCmd=\"_filedir $fullFilter\"\n",
      "        __%[1]s_debug \"File filtering command: $filteringCmd\"\n",
      "        $filteringCmd\n",
      "    elif [ $((directive & shellCompDirectiveFilterDirs)) -ne 0 ]; then\n",
      "        # File completion for directories only\n",
      "        local subdir\n",
      "        # Use printf to strip any trailing newline\n",
      "        subdir=$(printf \"%%s\" \"${out}\")\n",
      "        if [ -n \"$subdir\" ]; then\n",
      "            __%[1]s_debug \"Listing directories in $subdir\"\n",
      "            __%[1]s_handle_subdirs_in_dir_flag \"$subdir\"\n",
      "        else\n",
      "            __%[1]s_debug \"Listing directories in .\"\n",
      "            _filedir -d\n",
      "        fi\n",
      "    else\n",
      "        while IFS='' read -r comp; do\n",
      "            COMPREPLY+=(\"$comp\")\n",
      "        done < <(compgen -W \"${out}\" -- \"$cur\")\n",
      "    fi\n",
      "}\n",
      "\n",
      "__%[1]s_handle_reply()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}\"\n",
      "    local comp\n",
      "    case $cur in\n",
      "        -*)\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                compopt -o nospace\n",
      "            fi\n",
      "            local allflags\n",
      "            if [ ${#must_have_one_flag[@]} -ne 0 ]; then\n",
      "                allflags=(\"${must_have_one_flag[@]}\")\n",
      "            else\n",
      "                allflags=(\"${flags[*]} ${two_word_flags[*]}\")\n",
      "            fi\n",
      "            while IFS='' read -r comp; do\n",
      "                COMPREPLY+=(\"$comp\")\n",
      "            done < <(compgen -W \"${allflags[*]}\" -- \"$cur\")\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                [[ \"${COMPREPLY[0]}\" == *= ]] || compopt +o nospace\n",
      "            fi\n",
      "\n",
      "            # complete after --flag=abc\n",
      "            if [[ $cur == *=* ]]; then\n",
      "                if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                    compopt +o nospace\n",
      "                fi\n",
      "\n",
      "                local index flag\n",
      "                flag=\"${cur%%=*}\"\n",
      "                __%[1]s_index_of_word \"${flag}\" \"${flags_with_completion[@]}\"\n",
      "                COMPREPLY=()\n",
      "                if [[ ${index} -ge 0 ]]; then\n",
      "                    PREFIX=\"\"\n",
      "                    cur=\"${cur#*=}\"\n",
      "                    ${flags_completion[${index}]}\n",
      "                    if [ -n \"${ZSH_VERSION:-}\" ]; then\n",
      "                        # zsh completion needs --flag= prefix\n",
      "                        eval \"COMPREPLY=( \\\"\\${COMPREPLY[@]/#/${flag}=}\\\" )\"\n",
      "                    fi\n",
      "                fi\n",
      "            fi\n",
      "\n",
      "            if [[ -z \"${flag_parsing_disabled}\" ]]; then\n",
      "                # If flag parsing is enabled, we have completed the flags and can return.\n",
      "                # If flag parsing is disabled, we may not know all (or any) of the flags, so we fallthrough\n",
      "                # to possibly call handle_go_custom_completion.\n",
      "                return 0;\n",
      "            fi\n",
      "            ;;\n",
      "    esac\n",
      "\n",
      "    # check if we are handling a flag with special work handling\n",
      "    local index\n",
      "    __%[1]s_index_of_word \"${prev}\" \"${flags_with_completion[@]}\"\n",
      "    if [[ ${index} -ge 0 ]]; then\n",
      "        ${flags_completion[${index}]}\n",
      "        return\n",
      "    fi\n",
      "\n",
      "    # we are parsing a flag and don't have a special handler, no completion\n",
      "    if [[ ${cur} != \"${words[cword]}\" ]]; then\n",
      "        return\n",
      "    fi\n",
      "\n",
      "    local completions\n",
      "    completions=(\"${commands[@]}\")\n",
      "    if [[ ${#must_have_one_noun[@]} -ne 0 ]]; then\n",
      "        completions+=(\"${must_have_one_noun[@]}\")\n",
      "    elif [[ -n \"${has_completion_function}\" ]]; then\n",
      "        # if a go completion function is provided, defer to that function\n",
      "        __%[1]s_handle_go_custom_completion\n",
      "    fi\n",
      "    if [[ ${#must_have_one_flag[@]} -ne 0 ]]; then\n",
      "        completions+=(\"${must_have_one_flag[@]}\")\n",
      "    fi\n",
      "    while IFS='' read -r comp; do\n",
      "        COMPREPLY+=(\"$comp\")\n",
      "    done < <(compgen -W \"${completions[*]}\" -- \"$cur\")\n",
      "\n",
      "    if [[ ${#COMPREPLY[@]} -eq 0 && ${#noun_aliases[@]} -gt 0 && ${#must_have_one_noun[@]} -ne 0 ]]; then\n",
      "        while IFS='' read -r comp; do\n",
      "            COMPREPLY+=(\"$comp\")\n",
      "        done < <(compgen -W \"${noun_aliases[*]}\" -- \"$cur\")\n",
      "    fi\n",
      "\n",
      "    if [[ ${#COMPREPLY[@]} -eq 0 ]]; then\n",
      "        if declare -F __%[1]s_custom_func >/dev/null; then\n",
      "            # try command name qualified custom func\n",
      "            __%[1]s_custom_func\n",
      "        else\n",
      "            # otherwise fall back to unqualified for compatibility\n",
      "            declare -F __custom_func >/dev/null && __custom_func\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    # available in bash-completion >= 2, not always present on macOS\n",
      "    if declare -F __ltrim_colon_completions >/dev/null; then\n",
      "        __ltrim_colon_completions \"$cur\"\n",
      "    fi\n",
      "\n",
      "    # If there is only 1 completion and it is a flag with an = it will be completed\n",
      "    # but we don't want a space after the =\n",
      "    if [[ \"${#COMPREPLY[@]}\" -eq \"1\" ]] && [[ $(type -t compopt) = \"builtin\" ]] && [[ \"${COMPREPLY[0]}\" == --*= ]]; then\n",
      "       compopt -o nospace\n",
      "    fi\n",
      "}\n",
      "\n",
      "# The arguments should be in the form \"ext1|ext2|extn\"\n",
      "__%[1]s_handle_filename_extension_flag()\n",
      "{\n",
      "    local ext=\"$1\"\n",
      "    _filedir \"@(${ext})\"\n",
      "}\n",
      "\n",
      "__%[1]s_handle_subdirs_in_dir_flag()\n",
      "{\n",
      "    local dir=\"$1\"\n",
      "    pushd \"${dir}\" >/dev/null 2>&1 && _filedir -d && popd >/dev/null 2>&1 || return\n",
      "}\n",
      "\n",
      "__%[1]s_handle_flag()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    # if a command required a flag, and we found it, unset must_have_one_flag()\n",
      "    local flagname=${words[c]}\n",
      "    local flagvalue=\"\"\n",
      "    # if the word contained an =\n",
      "    if [[ ${words[c]} == *\"=\"* ]]; then\n",
      "        flagvalue=${flagname#*=} # take in as flagvalue after the =\n",
      "        flagname=${flagname%%=*} # strip everything after the =\n",
      "        flagname=\"${flagname}=\" # but put the = back\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: looking for ${flagname}\"\n",
      "    if __%[1]s_contains_word \"${flagname}\" \"${must_have_one_flag[@]}\"; then\n",
      "        must_have_one_flag=()\n",
      "    fi\n",
      "\n",
      "    # if you set a flag which only applies to this command, don't show subcommands\n",
      "    if __%[1]s_contains_word \"${flagname}\" \"${local_nonpersistent_flags[@]}\"; then\n",
      "      commands=()\n",
      "    fi\n",
      "\n",
      "    # keep flag value with flagname as flaghash\n",
      "    # flaghash variable is an associative array which is only supported in bash > 3.\n",
      "    if [[ -z \"${BASH_VERSION:-}\" || \"${BASH_VERSINFO[0]:-}\" -gt 3 ]]; then\n",
      "        if [ -n \"${flagvalue}\" ] ; then\n",
      "            flaghash[${flagname}]=${flagvalue}\n",
      "        elif [ -n \"${words[ $((c+1)) ]}\" ] ; then\n",
      "            flaghash[${flagname}]=${words[ $((c+1)) ]}\n",
      "        else\n",
      "            flaghash[${flagname}]=\"true\" # pad \"true\" for bool flag\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    # skip the argument to a two word flag\n",
      "    if [[ ${words[c]} != *\"=\"* ]] && __%[1]s_contains_word \"${words[c]}\" \"${two_word_flags[@]}\"; then\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: found a flag ${words[c]}, skip the next argument\"\n",
      "        c=$((c+1))\n",
      "        # if we are looking for a flags value, don't show commands\n",
      "        if [[ $c -eq $cword ]]; then\n",
      "            commands=()\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    c=$((c+1))\n",
      "\n",
      "}\n",
      "\n",
      "__%[1]s_handle_noun()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    if __%[1]s_contains_word \"${words[c]}\" \"${must_have_one_noun[@]}\"; then\n",
      "        must_have_one_noun=()\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${noun_aliases[@]}\"; then\n",
      "        must_have_one_noun=()\n",
      "    fi\n",
      "\n",
      "    nouns+=(\"${words[c]}\")\n",
      "    c=$((c+1))\n",
      "}\n",
      "\n",
      "__%[1]s_handle_command()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    local next_command\n",
      "    if [[ -n ${last_command} ]]; then\n",
      "        next_command=\"_${last_command}_${words[c]//:/__}\"\n",
      "    else\n",
      "        if [[ $c -eq 0 ]]; then\n",
      "            next_command=\"_%[1]s_root_command\"\n",
      "        else\n",
      "            next_command=\"_${words[c]//:/__}\"\n",
      "        fi\n",
      "    fi\n",
      "    c=$((c+1))\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: looking for ${next_command}\"\n",
      "    declare -F \"$next_command\" >/dev/null && $next_command\n",
      "}\n",
      "\n",
      "__%[1]s_handle_word()\n",
      "{\n",
      "    if [[ $c -ge $cword ]]; then\n",
      "        __%[1]s_handle_reply\n",
      "        return\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "    if [[ \"${words[c]}\" == -* ]]; then\n",
      "        __%[1]s_handle_flag\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${commands[@]}\"; then\n",
      "        __%[1]s_handle_command\n",
      "    elif [[ $c -eq 0 ]]; then\n",
      "        __%[1]s_handle_command\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${command_aliases[@]}\"; then\n",
      "        # aliashash variable is an associative array which is only supported in bash > 3.\n",
      "        if [[ -z \"${BASH_VERSION:-}\" || \"${BASH_VERSINFO[0]:-}\" -gt 3 ]]; then\n",
      "            words[c]=${aliashash[${words[c]}]}\n",
      "            __%[1]s_handle_command\n",
      "        else\n",
      "            __%[1]s_handle_noun\n",
      "        fi\n",
      "    else\n",
      "        __%[1]s_handle_noun\n",
      "    fi\n",
      "    __%[1]s_handle_word\n",
      "}\n",
      "\n",
      "`, name, ShellCompNoDescRequestCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, activeHelpEnvVar(name)))\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "bcicen/ctop 6 14993\n",
      "6\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func Init() {\n",
      "\tfor _, p := range defaultParams {\n",
      "\t\tGlobalParams = append(GlobalParams, p)\n",
      "\t\tlog.Infof(\"loaded default config param [%s]: %s\", quote(p.Key), quote(p.Val))\n",
      "\t}\n",
      "\tfor _, s := range defaultSwitches {\n",
      "\t\tGlobalSwitches = append(GlobalSwitches, s)\n",
      "\t\tlog.Infof(\"loaded default config switch [%s]: %t\", quote(s.Key), s.Val)\n",
      "\t}\n",
      "\tfor _, c := range defaultColumns {\n",
      "\t\tx := c\n",
      "\t\tGlobalColumns = append(GlobalColumns, &x)\n",
      "\t\tlog.Infof(\"loaded default widget config [%s]: %t\", quote(x.Name), x.Enabled)\n",
      "\t}\n",
      "}\n",
      "func Write() (path string, err error) {\n",
      "\tpath, err = getConfigPath()\n",
      "\tif err != nil {\n",
      "\t\treturn path, err\n",
      "\t}\n",
      "\tcfgdir := filepath.Dir(path)\n",
      "\tif _, err := os.Stat(cfgdir); err != nil {\n",
      "\t\terr = os.MkdirAll(cfgdir, 0755)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn path, fmt.Errorf(\"failed to create config dir [%s]: %s\", cfgdir, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := os.Remove(path); err != nil {\n",
      "\t\tif !os.IsNotExist(err) {\n",
      "\t\t\treturn path, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tfile, err := os.OpenFile(path, os.O_RDWR|os.O_CREATE, 0644)\n",
      "\tif err != nil {\n",
      "\t\treturn path, fmt.Errorf(\"failed to open config for writing: %s\", err)\n",
      "\t}\n",
      "\twriter := toml.NewEncoder(file)\n",
      "\terr = writer.Encode(exportConfig())\n",
      "\tif err != nil {\n",
      "\t\treturn path, fmt.Errorf(\"failed to write config: %s\", err)\n",
      "\t}\n",
      "\treturn path, nil\n",
      "}\n",
      "func (w *Env) Set(allEnvs string) {\n",
      "\tenvs := strings.Split(allEnvs, \";\")\n",
      "\tw.Rows = [][]string{}\n",
      "\tfor _, env := range envs {\n",
      "\t\tmatch := envPattern.FindStringSubmatch(env)\n",
      "\t\tif len(match) == 3 {\n",
      "\t\t\tkey := match[1]\n",
      "\t\t\tvalue := match[2]\n",
      "\t\t\tw.data[key] = value\n",
      "\t\t\tw.Rows = append(w.Rows, mkInfoRows(key, value)...)\n",
      "\t\t}\n",
      "\t}\n",
      "\tw.Height = len(w.Rows) + 2\n",
      "}\n",
      "func Display() bool {\n",
      "\tvar menu MenuFn\n",
      "\tvar connErr error\n",
      "\tcGrid.SetWidth(ui.TermWidth())\n",
      "\tui.DefaultEvtStream.Hook(logEvent)\n",
      "\theader.Align()\n",
      "\tstatus.Align()\n",
      "\tcursor.RefreshContainers()\n",
      "\tRedrawRows(true)\n",
      "\tHandleKeys(\"up\", cursor.Up)\n",
      "\tHandleKeys(\"down\", cursor.Down)\n",
      "\tHandleKeys(\"pgup\", cursor.PgUp)\n",
      "\tHandleKeys(\"pgdown\", cursor.PgDown)\n",
      "\tHandleKeys(\"exit\", ui.StopLoop)\n",
      "\tHandleKeys(\"help\", func() {\n",
      "\t\tmenu = HelpMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/<enter>\", func(ui.Event) {\n",
      "\t\tmenu = ContainerMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/<left>\", func(ui.Event) {\n",
      "\t\tmenu = LogMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/<right>\", func(ui.Event) {\n",
      "\t\tmenu = SingleView\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/l\", func(ui.Event) {\n",
      "\t\tmenu = LogMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/e\", func(ui.Event) {\n",
      "\t\tmenu = ExecShell\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/w\", func(ui.Event) {\n",
      "\t\tmenu = OpenInBrowser()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/o\", func(ui.Event) {\n",
      "\t\tmenu = SingleView\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/a\", func(ui.Event) {\n",
      "\t\tconfig.Toggle(\"allContainers\")\n",
      "\t\tconnErr = RefreshDisplay()\n",
      "\t\tif connErr != nil {\n",
      "\t\t\tui.StopLoop()\n",
      "\t\t}\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/D\", func(ui.Event) {\n",
      "\t\tdumpContainer(cursor.Selected())\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/f\", func(ui.Event) {\n",
      "\t\tmenu = FilterMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/H\", func(ui.Event) {\n",
      "\t\tconfig.Toggle(\"enableHeader\")\n",
      "\t\tRedrawRows(true)\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/r\", func(e ui.Event) {\n",
      "\t\tconfig.Toggle(\"sortReversed\")\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/s\", func(ui.Event) {\n",
      "\t\tmenu = SortMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/c\", func(ui.Event) {\n",
      "\t\tmenu = ColumnsMenu\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/sys/kbd/S\", func(ui.Event) {\n",
      "\t\tpath, err := config.Write()\n",
      "\t\tif err == nil {\n",
      "\t\t\tlog.Statusf(\"wrote config to %s\", path)\n",
      "\t\t} else {\n",
      "\t\t\tlog.StatusErr(err)\n",
      "\t\t}\n",
      "\t\tui.StopLoop()\n",
      "\t})\n",
      "\tui.Handle(\"/timer/1s\", func(e ui.Event) {\n",
      "\t\tif log.StatusQueued() {\n",
      "\t\t\tui.StopLoop()\n",
      "\t\t}\n",
      "\t\tconnErr = RefreshDisplay()\n",
      "\t\tif connErr != nil {\n",
      "\t\t\tui.StopLoop()\n",
      "\t\t}\n",
      "\t})\n",
      "\tui.Handle(\"/sys/wnd/resize\", func(e ui.Event) {\n",
      "\t\theader.Align()\n",
      "\t\tstatus.Align()\n",
      "\t\tcursor.ScrollPage()\n",
      "\t\tcGrid.SetWidth(ui.TermWidth())\n",
      "\t\tlog.Infof(\"resize: width=%v max-rows=%v\", cGrid.Width, cGrid.MaxRows())\n",
      "\t\tRedrawRows(true)\n",
      "\t})\n",
      "\tui.Loop()\n",
      "\tif connErr != nil {\n",
      "\t\treturn ShowConnError(connErr)\n",
      "\t}\n",
      "\tif log.StatusQueued() {\n",
      "\t\tfor sm := range log.FlushStatus() {\n",
      "\t\t\tif sm.IsError {\n",
      "\t\t\t\tstatus.ShowErr(sm.Text)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tstatus.Show(sm.Text)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tif menu != nil {\n",
      "\t\tfor menu != nil {\n",
      "\t\t\tmenu = menu()\n",
      "\t\t}\n",
      "\t\treturn false\n",
      "\t}\n",
      "\treturn true\n",
      "}\n",
      "func Read() error {\n",
      "\tvar config File\n",
      "\tpath, err := getConfigPath()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif _, err := toml.DecodeFile(path, &config); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tfor k, v := range config.Options {\n",
      "\t\tUpdate(k, v)\n",
      "\t}\n",
      "\tfor k, v := range config.Toggles {\n",
      "\t\tUpdateSwitch(k, v)\n",
      "\t}\n",
      "\tcolStr := GetVal(\"columns\")\n",
      "\tif len(colStr) > 0 {\n",
      "\t\tvar colNames []string\n",
      "\t\tfor _, s := range strings.Split(colStr, \",\") {\n",
      "\t\t\ts = strings.TrimSpace(s)\n",
      "\t\t\tif s != \"\" {\n",
      "\t\t\t\tcolNames = append(colNames, s)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tSetColumns(colNames)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "FiloSottile/age 1 14855\n",
      "1\n",
      "======================CLASS=======================\n",
      "gitleaks/gitleaks 2 14713\n",
      "2\n",
      "======================CLASS=======================\n",
      "func (c *Config) extendPath() {\n",
      "\textendDepth++\n",
      "\tviper.SetConfigFile(c.Extend.Path)\n",
      "\tif err := viper.ReadInConfig(); err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\textensionViperConfig := ViperConfig{}\n",
      "\tif err := viper.Unmarshal(&extensionViperConfig); err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tcfg, err := extensionViperConfig.Translate()\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlog.Debug().Msgf(\"extending config with %s\", c.Extend.Path)\n",
      "\tc.extend(cfg)\n",
      "}\n",
      "func (vc *ViperConfig) Translate() (Config, error) {\n",
      "\tvar (\n",
      "\t\tkeywords\t[]string\n",
      "\t\torderedRules\t[]string\n",
      "\t)\n",
      "\trulesMap := make(map[string]Rule)\n",
      "\tfor _, r := range vc.Rules {\n",
      "\t\tvar allowlistRegexes []*regexp.Regexp\n",
      "\t\tfor _, a := range r.Allowlist.Regexes {\n",
      "\t\t\tallowlistRegexes = append(allowlistRegexes, regexp.MustCompile(a))\n",
      "\t\t}\n",
      "\t\tvar allowlistPaths []*regexp.Regexp\n",
      "\t\tfor _, a := range r.Allowlist.Paths {\n",
      "\t\t\tallowlistPaths = append(allowlistPaths, regexp.MustCompile(a))\n",
      "\t\t}\n",
      "\t\tif r.Keywords == nil {\n",
      "\t\t\tr.Keywords = []string{}\n",
      "\t\t} else {\n",
      "\t\t\tfor _, k := range r.Keywords {\n",
      "\t\t\t\tkeywords = append(keywords, strings.ToLower(k))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif r.Tags == nil {\n",
      "\t\t\tr.Tags = []string{}\n",
      "\t\t}\n",
      "\t\tvar configRegex *regexp.Regexp\n",
      "\t\tvar configPathRegex *regexp.Regexp\n",
      "\t\tif r.Regex == \"\" {\n",
      "\t\t\tconfigRegex = nil\n",
      "\t\t} else {\n",
      "\t\t\tconfigRegex = regexp.MustCompile(r.Regex)\n",
      "\t\t}\n",
      "\t\tif r.Path == \"\" {\n",
      "\t\t\tconfigPathRegex = nil\n",
      "\t\t} else {\n",
      "\t\t\tconfigPathRegex = regexp.MustCompile(r.Path)\n",
      "\t\t}\n",
      "\t\tr := Rule{Description: r.Description, RuleID: r.ID, Regex: configRegex, Path: configPathRegex, SecretGroup: r.SecretGroup, Entropy: r.Entropy, Tags: r.Tags, Keywords: r.Keywords, Allowlist: Allowlist{RegexTarget: r.Allowlist.RegexTarget, Regexes: allowlistRegexes, Paths: allowlistPaths, Commits: r.Allowlist.Commits, StopWords: r.Allowlist.StopWords}}\n",
      "\t\torderedRules = append(orderedRules, r.RuleID)\n",
      "\t\tif r.Regex != nil && r.SecretGroup > r.Regex.NumSubexp() {\n",
      "\t\t\treturn Config{}, fmt.Errorf(\"%s invalid regex secret group %d, max regex secret group %d\", r.Description, r.SecretGroup, r.Regex.NumSubexp())\n",
      "\t\t}\n",
      "\t\trulesMap[r.RuleID] = r\n",
      "\t}\n",
      "\tvar allowlistRegexes []*regexp.Regexp\n",
      "\tfor _, a := range vc.Allowlist.Regexes {\n",
      "\t\tallowlistRegexes = append(allowlistRegexes, regexp.MustCompile(a))\n",
      "\t}\n",
      "\tvar allowlistPaths []*regexp.Regexp\n",
      "\tfor _, a := range vc.Allowlist.Paths {\n",
      "\t\tallowlistPaths = append(allowlistPaths, regexp.MustCompile(a))\n",
      "\t}\n",
      "\tc := Config{Description: vc.Description, Extend: vc.Extend, Rules: rulesMap, Allowlist: Allowlist{RegexTarget: vc.Allowlist.RegexTarget, Regexes: allowlistRegexes, Paths: allowlistPaths, Commits: vc.Allowlist.Commits, StopWords: vc.Allowlist.StopWords}, Keywords: keywords, orderedRules: orderedRules}\n",
      "\tif maxExtendDepth != extendDepth {\n",
      "\t\tif c.Extend.Path != \"\" && c.Extend.UseDefault {\n",
      "\t\t\tlog.Fatal().Msg(\"unable to load config due to extend.path and extend.useDefault being set\")\n",
      "\t\t}\n",
      "\t\tif c.Extend.UseDefault {\n",
      "\t\t\tc.extendDefault()\n",
      "\t\t} else if c.Extend.Path != \"\" {\n",
      "\t\t\tc.extendPath()\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn c, nil\n",
      "}\n",
      "func (c *Config) extendDefault() {\n",
      "\textendDepth++\n",
      "\tviper.SetConfigType(\"toml\")\n",
      "\tif err := viper.ReadConfig(strings.NewReader(DefaultConfig)); err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tdefaultViperConfig := ViperConfig{}\n",
      "\tif err := viper.Unmarshal(&defaultViperConfig); err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tcfg, err := defaultViperConfig.Translate()\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"failed to load extended config, err: %s\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlog.Debug().Msg(\"extending config with default config\")\n",
      "\tc.extend(cfg)\n",
      "}\n",
      "func LaunchDarklyAccessToken() *config.Rule {\n",
      "\tr := config.Rule{RuleID: \"launchdarkly-access-token\", Description: \"Uncovered a Launchdarkly Access Token, potentially compromising feature flag management and application functionality.\", Regex: generateSemiGenericRegex([]string{\"launchdarkly\"}, alphaNumericExtended(\"40\"), true), Keywords: []string{\"launchdarkly\"}}\n",
      "\ttps := []string{generateSampleSecret(\"launchdarkly\", secrets.NewSecret(alphaNumericExtended(\"40\")))}\n",
      "\treturn validate(r, tps, nil)\n",
      "}\n",
      "func initConfig() {\n",
      "\thideBanner, err := rootCmd.Flags().GetBool(\"no-banner\")\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal().Msg(err.Error())\n",
      "\t}\n",
      "\tif !hideBanner {\n",
      "\t\t_, _ = fmt.Fprint(os.Stderr, banner)\n",
      "\t}\n",
      "\tcfgPath, err := rootCmd.Flags().GetString(\"config\")\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal().Msg(err.Error())\n",
      "\t}\n",
      "\tif cfgPath != \"\" {\n",
      "\t\tviper.SetConfigFile(cfgPath)\n",
      "\t\tlog.Debug().Msgf(\"using gitleaks config %s from `--config`\", cfgPath)\n",
      "\t} else if os.Getenv(\"GITLEAKS_CONFIG\") != \"\" {\n",
      "\t\tenvPath := os.Getenv(\"GITLEAKS_CONFIG\")\n",
      "\t\tviper.SetConfigFile(envPath)\n",
      "\t\tlog.Debug().Msgf(\"using gitleaks config from GITLEAKS_CONFIG env var: %s\", envPath)\n",
      "\t} else {\n",
      "\t\tsource, err := rootCmd.Flags().GetString(\"source\")\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Fatal().Msg(err.Error())\n",
      "\t\t}\n",
      "\t\tfileInfo, err := os.Stat(source)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Fatal().Msg(err.Error())\n",
      "\t\t}\n",
      "\t\tif !fileInfo.IsDir() {\n",
      "\t\t\tlog.Debug().Msgf(\"unable to load gitleaks config from %s since --source=%s is a file, using default config\", filepath.Join(source, \".gitleaks.toml\"), source)\n",
      "\t\t\tviper.SetConfigType(\"toml\")\n",
      "\t\t\tif err = viper.ReadConfig(strings.NewReader(config.DefaultConfig)); err != nil {\n",
      "\t\t\t\tlog.Fatal().Msgf(\"err reading toml %s\", err.Error())\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif _, err := os.Stat(filepath.Join(source, \".gitleaks.toml\")); os.IsNotExist(err) {\n",
      "\t\t\tlog.Debug().Msgf(\"no gitleaks config found in path %s, using default gitleaks config\", filepath.Join(source, \".gitleaks.toml\"))\n",
      "\t\t\tviper.SetConfigType(\"toml\")\n",
      "\t\t\tif err = viper.ReadConfig(strings.NewReader(config.DefaultConfig)); err != nil {\n",
      "\t\t\t\tlog.Fatal().Msgf(\"err reading default config toml %s\", err.Error())\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\t} else {\n",
      "\t\t\tlog.Debug().Msgf(\"using existing gitleaks config %s from `(--source)/.gitleaks.toml`\", filepath.Join(source, \".gitleaks.toml\"))\n",
      "\t\t}\n",
      "\t\tviper.AddConfigPath(source)\n",
      "\t\tviper.SetConfigName(\".gitleaks\")\n",
      "\t\tviper.SetConfigType(\"toml\")\n",
      "\t}\n",
      "\tif err := viper.ReadInConfig(); err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"unable to load gitleaks config, err: %s\", err)\n",
      "\t}\n",
      "}\n",
      "func init() {\n",
      "\tcobra.OnInitialize(initLog)\n",
      "\trootCmd.PersistentFlags().StringP(\"config\", \"c\", \"\", configDescription)\n",
      "\trootCmd.PersistentFlags().Int(\"exit-code\", 1, \"exit code when leaks have been encountered\")\n",
      "\trootCmd.PersistentFlags().StringP(\"source\", \"s\", \".\", \"path to source\")\n",
      "\trootCmd.PersistentFlags().StringP(\"report-path\", \"r\", \"\", \"report file\")\n",
      "\trootCmd.PersistentFlags().StringP(\"report-format\", \"f\", \"json\", \"output format (json, csv, junit, sarif)\")\n",
      "\trootCmd.PersistentFlags().StringP(\"baseline-path\", \"b\", \"\", \"path to baseline with issues that can be ignored\")\n",
      "\trootCmd.PersistentFlags().StringP(\"log-level\", \"l\", \"info\", \"log level (trace, debug, info, warn, error, fatal)\")\n",
      "\trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"show verbose output from scan\")\n",
      "\trootCmd.PersistentFlags().BoolP(\"no-color\", \"\", false, \"turn off color for verbose output\")\n",
      "\trootCmd.PersistentFlags().Int(\"max-target-megabytes\", 0, \"files larger than this will be skipped\")\n",
      "\trootCmd.PersistentFlags().BoolP(\"ignore-gitleaks-allow\", \"\", false, \"ignore gitleaks:allow comments\")\n",
      "\trootCmd.PersistentFlags().Uint(\"redact\", 0, \"redact secrets from logs and stdout. To redact only parts of the secret just apply a percent value from 0..100. For example --redact=20 (default 100%)\")\n",
      "\trootCmd.Flag(\"redact\").NoOptDefVal = \"100\"\n",
      "\trootCmd.PersistentFlags().Bool(\"no-banner\", false, \"suppress banner\")\n",
      "\trootCmd.PersistentFlags().String(\"log-opts\", \"\", \"git log options\")\n",
      "\trootCmd.PersistentFlags().StringSlice(\"enable-rule\", []string{}, \"only enable specific rules by id, ex: `gitleaks detect --enable-rule=atlassian-api-token --enable-rule=slack-access-token`\")\n",
      "\trootCmd.PersistentFlags().StringP(\"gitleaks-ignore-path\", \"i\", \".\", \"path to .gitleaksignore file or folder containing one\")\n",
      "\trootCmd.PersistentFlags().Bool(\"follow-symlinks\", false, \"scan files that are symlinks to other files\")\n",
      "\terr := viper.BindPFlag(\"config\", rootCmd.PersistentFlags().Lookup(\"config\"))\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal().Msgf(\"err binding config %s\", err.Error())\n",
      "\t}\n",
      "}\n",
      "======================CLASS=======================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "topic_1 10\n",
      "fatedier/frp 9 77144\n",
      "9\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewHTTPS2HTTPSPlugin(options v1.ClientPluginOptions) (Plugin, error) {\n",
      "\topts := options.(*v1.HTTPS2HTTPSPluginOptions)\n",
      "\tlistener := NewProxyListener()\n",
      "\tp := &HTTPS2HTTPSPlugin{opts: opts, l: listener}\n",
      "\ttr := &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: true}}\n",
      "\trp := &httputil.ReverseProxy{Rewrite: func(r *httputil.ProxyRequest) {\n",
      "\t\treq := r.Out\n",
      "\t\treq.URL.Scheme = \"https\"\n",
      "\t\treq.URL.Host = p.opts.LocalAddr\n",
      "\t\tif p.opts.HostHeaderRewrite != \"\" {\n",
      "\t\t\treq.Host = p.opts.HostHeaderRewrite\n",
      "\t\t}\n",
      "\t\tfor k, v := range p.opts.RequestHeaders.Set {\n",
      "\t\t\treq.Header.Set(k, v)\n",
      "\t\t}\n",
      "\t}, Transport: tr}\n",
      "\tp.s = &http.Server{Handler: rp}\n",
      "\tvar (\n",
      "\t\ttlsConfig\t*tls.Config\n",
      "\t\terr\t\terror\n",
      "\t)\n",
      "\tif opts.CrtPath != \"\" || opts.KeyPath != \"\" {\n",
      "\t\ttlsConfig, err = p.genTLSConfig()\n",
      "\t} else {\n",
      "\t\ttlsConfig, err = transport.NewServerTLSConfig(\"\", \"\", \"\")\n",
      "\t\ttlsConfig.InsecureSkipVerify = true\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"gen TLS config error: %v\", err)\n",
      "\t}\n",
      "\tln := tls.NewListener(listener, tlsConfig)\n",
      "\tgo func() {\n",
      "\t\t_ = p.s.Serve(ln)\n",
      "\t}()\n",
      "\treturn p, nil\n",
      "}\n",
      "func (p *HTTPS2HTTPPlugin) genTLSConfig() (*tls.Config, error) {\n",
      "\tcert, err := tls.LoadX509KeyPair(p.opts.CrtPath, p.opts.KeyPath)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfig := &tls.Config{Certificates: []tls.Certificate{cert}}\n",
      "\treturn config, nil\n",
      "}\n",
      "func (svr *Service) apiGetConfig(w http.ResponseWriter, _ *http.Request) {\n",
      "\tres := GeneralResponse{Code: 200}\n",
      "\tlog.Info(\"Http get request [/api/config]\")\n",
      "\tdefer func() {\n",
      "\t\tlog.Info(\"Http get response [/api/config], code [%d]\", res.Code)\n",
      "\t\tw.WriteHeader(res.Code)\n",
      "\t\tif len(res.Msg) > 0 {\n",
      "\t\t\t_, _ = w.Write([]byte(res.Msg))\n",
      "\t\t}\n",
      "\t}()\n",
      "\tif svr.configFilePath == \"\" {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = \"frpc has no config file path\"\n",
      "\t\tlog.Warn(\"%s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tcontent, err := os.ReadFile(svr.configFilePath)\n",
      "\tif err != nil {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = err.Error()\n",
      "\t\tlog.Warn(\"load frpc config file error: %s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tres.Msg = string(content)\n",
      "}\n",
      "func init() {\n",
      "\trootCmd.PersistentFlags().StringVarP(&cfgFile, \"config\", \"c\", \"./frpc.ini\", \"config file of frpc\")\n",
      "\trootCmd.PersistentFlags().StringVarP(&cfgDir, \"config_dir\", \"\", \"\", \"config directory, run one frpc service for each file in config directory\")\n",
      "\trootCmd.PersistentFlags().BoolVarP(&showVersion, \"version\", \"v\", false, \"version of frpc\")\n",
      "\trootCmd.PersistentFlags().BoolVarP(&strictConfigMode, \"strict_config\", \"\", false, \"strict config parsing mode, unknown fields will cause an error\")\n",
      "}\n",
      "func runMultipleClients(cfgDir string) error {\n",
      "\tvar wg sync.WaitGroup\n",
      "\terr := filepath.WalkDir(cfgDir, func(path string, d fs.DirEntry, err error) error {\n",
      "\t\tif err != nil || d.IsDir() {\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\twg.Add(1)\n",
      "\t\ttime.Sleep(time.Millisecond)\n",
      "\t\tgo func() {\n",
      "\t\t\tdefer wg.Done()\n",
      "\t\t\terr := runClient(path)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tfmt.Printf(\"frpc service error for config file [%s]\\n\", path)\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\twg.Wait()\n",
      "\treturn err\n",
      "}\n",
      "func (pxy *XTCPProxy) listenByQUIC(listenConn *net.UDPConn, _ *net.UDPAddr, startWorkConnMsg *msg.StartWorkConn) {\n",
      "\txl := pxy.xl\n",
      "\tdefer listenConn.Close()\n",
      "\ttlsConfig, err := transport.NewServerTLSConfig(\"\", \"\", \"\")\n",
      "\tif err != nil {\n",
      "\t\txl.Warn(\"create tls config error: %v\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\ttlsConfig.NextProtos = []string{\"frp\"}\n",
      "\tquicListener, err := quic.Listen(listenConn, tlsConfig, &quic.Config{MaxIdleTimeout: time.Duration(pxy.clientCfg.Transport.QUIC.MaxIdleTimeout) * time.Second, MaxIncomingStreams: int64(pxy.clientCfg.Transport.QUIC.MaxIncomingStreams), KeepAlivePeriod: time.Duration(pxy.clientCfg.Transport.QUIC.KeepalivePeriod) * time.Second})\n",
      "\tif err != nil {\n",
      "\t\txl.Warn(\"dial quic error: %v\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tc, err := quicListener.Accept(pxy.ctx)\n",
      "\tif err != nil {\n",
      "\t\txl.Error(\"quic accept connection error: %v\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tfor {\n",
      "\t\tstream, err := c.AcceptStream(pxy.ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\txl.Debug(\"quic accept stream error: %v\", err)\n",
      "\t\t\t_ = c.CloseWithError(0, \"\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tgo pxy.HandleTCPWorkConnection(netpkg.QuicStreamToNetConn(stream, c), startWorkConnMsg, []byte(pxy.cfg.Secretkey))\n",
      "\t}\n",
      "}\n",
      "func (svr *Service) apiPutConfig(w http.ResponseWriter, r *http.Request) {\n",
      "\tres := GeneralResponse{Code: 200}\n",
      "\tlog.Info(\"Http put request [/api/config]\")\n",
      "\tdefer func() {\n",
      "\t\tlog.Info(\"Http put response [/api/config], code [%d]\", res.Code)\n",
      "\t\tw.WriteHeader(res.Code)\n",
      "\t\tif len(res.Msg) > 0 {\n",
      "\t\t\t_, _ = w.Write([]byte(res.Msg))\n",
      "\t\t}\n",
      "\t}()\n",
      "\tbody, err := io.ReadAll(r.Body)\n",
      "\tif err != nil {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = fmt.Sprintf(\"read request body error: %v\", err)\n",
      "\t\tlog.Warn(\"%s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif len(body) == 0 {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = \"body can't be empty\"\n",
      "\t\tlog.Warn(\"%s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif err := os.WriteFile(svr.configFilePath, body, 0o644); err != nil {\n",
      "\t\tres.Code = 500\n",
      "\t\tres.Msg = fmt.Sprintf(\"write content to frpc config file error: %v\", err)\n",
      "\t\tlog.Warn(\"%s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "}\n",
      "func LoadAdditionalClientConfigs(paths []string, isLegacyFormat bool, strict bool) ([]v1.ProxyConfigurer, []v1.VisitorConfigurer, error) {\n",
      "\tproxyCfgs := make([]v1.ProxyConfigurer, 0)\n",
      "\tvisitorCfgs := make([]v1.VisitorConfigurer, 0)\n",
      "\tfor _, path := range paths {\n",
      "\t\tabsDir, err := filepath.Abs(filepath.Dir(path))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tif _, err := os.Stat(absDir); os.IsNotExist(err) {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tfiles, err := os.ReadDir(absDir)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tfor _, fi := range files {\n",
      "\t\t\tif fi.IsDir() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tabsFile := filepath.Join(absDir, fi.Name())\n",
      "\t\t\tif matched, _ := filepath.Match(filepath.Join(absDir, filepath.Base(path)), absFile); matched {\n",
      "\t\t\t\tcfg := v1.ClientConfig{}\n",
      "\t\t\t\tif err := LoadConfigureFromFile(absFile, &cfg, strict); err != nil {\n",
      "\t\t\t\t\treturn nil, nil, fmt.Errorf(\"load additional config from %s error: %v\", absFile, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfor _, c := range cfg.Proxies {\n",
      "\t\t\t\t\tproxyCfgs = append(proxyCfgs, c.ProxyConfigurer)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfor _, c := range cfg.Visitors {\n",
      "\t\t\t\t\tvisitorCfgs = append(visitorCfgs, c.VisitorConfigurer)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn proxyCfgs, visitorCfgs, nil\n",
      "}\n",
      "func startService(cfg *v1.ClientCommonConfig, proxyCfgs []v1.ProxyConfigurer, visitorCfgs []v1.VisitorConfigurer, cfgFile string) error {\n",
      "\tlog.InitLog(cfg.Log.To, cfg.Log.Level, cfg.Log.MaxDays, cfg.Log.DisablePrintColor)\n",
      "\tif cfgFile != \"\" {\n",
      "\t\tlog.Info(\"start frpc service for config file [%s]\", cfgFile)\n",
      "\t\tdefer log.Info(\"frpc service for config file [%s] stopped\", cfgFile)\n",
      "\t}\n",
      "\tsvr, err := client.NewService(client.ServiceOptions{Common: cfg, ProxyCfgs: proxyCfgs, VisitorCfgs: visitorCfgs, ConfigFilePath: cfgFile})\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tshouldGracefulClose := cfg.Transport.Protocol == \"kcp\" || cfg.Transport.Protocol == \"quic\"\n",
      "\tif shouldGracefulClose {\n",
      "\t\tgo handleTermSignal(svr)\n",
      "\t}\n",
      "\treturn svr.Run(context.Background())\n",
      "}\n",
      "func (p *HTTPS2HTTPSPlugin) genTLSConfig() (*tls.Config, error) {\n",
      "\tcert, err := tls.LoadX509KeyPair(p.opts.CrtPath, p.opts.KeyPath)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfig := &tls.Config{Certificates: []tls.Certificate{cert}}\n",
      "\treturn config, nil\n",
      "}\n",
      "func ParseClientConfig(filePath string) (cfg ClientCommonConf, proxyCfgs map[string]ProxyConf, visitorCfgs map[string]VisitorConf, err error) {\n",
      "\tvar content []byte\n",
      "\tcontent, err = GetRenderedConfFromFile(filePath)\n",
      "\tif err != nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tconfigBuffer := bytes.NewBuffer(nil)\n",
      "\tconfigBuffer.Write(content)\n",
      "\tcfg, err = UnmarshalClientConfFromIni(content)\n",
      "\tif err != nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif err = cfg.Validate(); err != nil {\n",
      "\t\terr = fmt.Errorf(\"parse config error: %v\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tvar buf []byte\n",
      "\tbuf, err = getIncludeContents(cfg.IncludeConfigFiles)\n",
      "\tif err != nil {\n",
      "\t\terr = fmt.Errorf(\"getIncludeContents error: %v\", err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tconfigBuffer.WriteString(\"\\n\")\n",
      "\tconfigBuffer.Write(buf)\n",
      "\tproxyCfgs, visitorCfgs, err = LoadAllProxyConfsFromIni(cfg.User, configBuffer.Bytes(), cfg.Start)\n",
      "\tif err != nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func ValidateProxyConfigurerForClient(c v1.ProxyConfigurer) error {\n",
      "\tbase := c.GetBaseConfig()\n",
      "\tif err := validateProxyBaseConfigForClient(base); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tswitch v := c.(type) {\n",
      "\tcase *v1.TCPProxyConfig:\n",
      "\t\treturn validateTCPProxyConfigForClient(v)\n",
      "\tcase *v1.UDPProxyConfig:\n",
      "\t\treturn validateUDPProxyConfigForClient(v)\n",
      "\tcase *v1.TCPMuxProxyConfig:\n",
      "\t\treturn validateTCPMuxProxyConfigForClient(v)\n",
      "\tcase *v1.HTTPProxyConfig:\n",
      "\t\treturn validateHTTPProxyConfigForClient(v)\n",
      "\tcase *v1.HTTPSProxyConfig:\n",
      "\t\treturn validateHTTPSProxyConfigForClient(v)\n",
      "\tcase *v1.STCPProxyConfig:\n",
      "\t\treturn validateSTCPProxyConfigForClient(v)\n",
      "\tcase *v1.XTCPProxyConfig:\n",
      "\t\treturn validateXTCPProxyConfigForClient(v)\n",
      "\tcase *v1.SUDPProxyConfig:\n",
      "\t\treturn validateSUDPProxyConfigForClient(v)\n",
      "\t}\n",
      "\treturn errors.New(\"unknown proxy config type\")\n",
      "}\n",
      "func NewHTTPS2HTTPPlugin(options v1.ClientPluginOptions) (Plugin, error) {\n",
      "\topts := options.(*v1.HTTPS2HTTPPluginOptions)\n",
      "\tlistener := NewProxyListener()\n",
      "\tp := &HTTPS2HTTPPlugin{opts: opts, l: listener}\n",
      "\trp := &httputil.ReverseProxy{Rewrite: func(r *httputil.ProxyRequest) {\n",
      "\t\treq := r.Out\n",
      "\t\treq.URL.Scheme = \"http\"\n",
      "\t\treq.URL.Host = p.opts.LocalAddr\n",
      "\t\tif p.opts.HostHeaderRewrite != \"\" {\n",
      "\t\t\treq.Host = p.opts.HostHeaderRewrite\n",
      "\t\t}\n",
      "\t\tfor k, v := range p.opts.RequestHeaders.Set {\n",
      "\t\t\treq.Header.Set(k, v)\n",
      "\t\t}\n",
      "\t}}\n",
      "\tp.s = &http.Server{Handler: rp}\n",
      "\tvar (\n",
      "\t\ttlsConfig\t*tls.Config\n",
      "\t\terr\t\terror\n",
      "\t)\n",
      "\tif opts.CrtPath != \"\" || opts.KeyPath != \"\" {\n",
      "\t\ttlsConfig, err = p.genTLSConfig()\n",
      "\t} else {\n",
      "\t\ttlsConfig, err = transport.NewServerTLSConfig(\"\", \"\", \"\")\n",
      "\t\ttlsConfig.InsecureSkipVerify = true\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"gen TLS config error: %v\", err)\n",
      "\t}\n",
      "\tln := tls.NewListener(listener, tlsConfig)\n",
      "\tgo func() {\n",
      "\t\t_ = p.s.Serve(ln)\n",
      "\t}()\n",
      "\treturn p, nil\n",
      "}\n",
      "func ValidateProxyConfigurerForServer(c v1.ProxyConfigurer, s *v1.ServerConfig) error {\n",
      "\tbase := c.GetBaseConfig()\n",
      "\tif err := validateProxyBaseConfigForServer(base); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tswitch v := c.(type) {\n",
      "\tcase *v1.TCPProxyConfig:\n",
      "\t\treturn validateTCPProxyConfigForServer(v, s)\n",
      "\tcase *v1.UDPProxyConfig:\n",
      "\t\treturn validateUDPProxyConfigForServer(v, s)\n",
      "\tcase *v1.TCPMuxProxyConfig:\n",
      "\t\treturn validateTCPMuxProxyConfigForServer(v, s)\n",
      "\tcase *v1.HTTPProxyConfig:\n",
      "\t\treturn validateHTTPProxyConfigForServer(v, s)\n",
      "\tcase *v1.HTTPSProxyConfig:\n",
      "\t\treturn validateHTTPSProxyConfigForServer(v, s)\n",
      "\tcase *v1.STCPProxyConfig:\n",
      "\t\treturn validateSTCPProxyConfigForServer(v, s)\n",
      "\tcase *v1.XTCPProxyConfig:\n",
      "\t\treturn validateXTCPProxyConfigForServer(v, s)\n",
      "\tcase *v1.SUDPProxyConfig:\n",
      "\t\treturn validateSUDPProxyConfigForServer(v, s)\n",
      "\tdefault:\n",
      "\t\treturn errors.New(\"unknown proxy config type\")\n",
      "\t}\n",
      "}\n",
      "func (svr *Service) apiReload(w http.ResponseWriter, r *http.Request) {\n",
      "\tres := GeneralResponse{Code: 200}\n",
      "\tstrictConfigMode := false\n",
      "\tstrictStr := r.URL.Query().Get(\"strictConfig\")\n",
      "\tif strictStr != \"\" {\n",
      "\t\tstrictConfigMode, _ = strconv.ParseBool(strictStr)\n",
      "\t}\n",
      "\tlog.Info(\"api request [/api/reload]\")\n",
      "\tdefer func() {\n",
      "\t\tlog.Info(\"api response [/api/reload], code [%d]\", res.Code)\n",
      "\t\tw.WriteHeader(res.Code)\n",
      "\t\tif len(res.Msg) > 0 {\n",
      "\t\t\t_, _ = w.Write([]byte(res.Msg))\n",
      "\t\t}\n",
      "\t}()\n",
      "\tcliCfg, proxyCfgs, visitorCfgs, _, err := config.LoadClientConfig(svr.configFilePath, strictConfigMode)\n",
      "\tif err != nil {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = err.Error()\n",
      "\t\tlog.Warn(\"reload frpc proxy config error: %s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif _, err := validation.ValidateAllClientConfig(cliCfg, proxyCfgs, visitorCfgs); err != nil {\n",
      "\t\tres.Code = 400\n",
      "\t\tres.Msg = err.Error()\n",
      "\t\tlog.Warn(\"reload frpc proxy config error: %s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif err := svr.UpdateAllConfigurer(proxyCfgs, visitorCfgs); err != nil {\n",
      "\t\tres.Code = 500\n",
      "\t\tres.Msg = err.Error()\n",
      "\t\tlog.Warn(\"reload frpc proxy config error: %s\", res.Msg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlog.Info(\"success reload conf\")\n",
      "}\n",
      "func init() {\n",
      "\tglbEnvs = make(map[string]string)\n",
      "\tenvs := os.Environ()\n",
      "\tfor _, env := range envs {\n",
      "\t\tpair := strings.SplitN(env, \"=\", 2)\n",
      "\t\tif len(pair) != 2 {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tglbEnvs[pair[0]] = pair[1]\n",
      "\t}\n",
      "}\n",
      "func init() {\n",
      "\tglbEnvs = make(map[string]string)\n",
      "\tenvs := os.Environ()\n",
      "\tfor _, env := range envs {\n",
      "\t\tpair := strings.SplitN(env, \"=\", 2)\n",
      "\t\tif len(pair) != 2 {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tglbEnvs[pair[0]] = pair[1]\n",
      "\t}\n",
      "}\n",
      "func runServer(cfg *v1.ServerConfig) (err error) {\n",
      "\tlog.InitLog(cfg.Log.To, cfg.Log.Level, cfg.Log.MaxDays, cfg.Log.DisablePrintColor)\n",
      "\tif cfgFile != \"\" {\n",
      "\t\tlog.Info(\"frps uses config file: %s\", cfgFile)\n",
      "\t} else {\n",
      "\t\tlog.Info(\"frps uses command line arguments for config\")\n",
      "\t}\n",
      "\tsvr, err := server.NewService(cfg)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tlog.Info(\"frps started successfully\")\n",
      "\tsvr.Run(context.Background())\n",
      "\treturn\n",
      "}\n",
      "func (qs *QUICTunnelSession) Init(listenConn *net.UDPConn, raddr *net.UDPAddr) error {\n",
      "\ttlsConfig, err := transport.NewClientTLSConfig(\"\", \"\", \"\", raddr.String())\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"create tls config error: %v\", err)\n",
      "\t}\n",
      "\ttlsConfig.NextProtos = []string{\"frp\"}\n",
      "\tquicConn, err := quic.Dial(context.Background(), listenConn, raddr, tlsConfig, &quic.Config{MaxIdleTimeout: time.Duration(qs.clientCfg.Transport.QUIC.MaxIdleTimeout) * time.Second, MaxIncomingStreams: int64(qs.clientCfg.Transport.QUIC.MaxIncomingStreams), KeepAlivePeriod: time.Duration(qs.clientCfg.Transport.QUIC.KeepalivePeriod) * time.Second})\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"dial quic error: %v\", err)\n",
      "\t}\n",
      "\tqs.mu.Lock()\n",
      "\tqs.session = quicConn\n",
      "\tqs.listenConn = listenConn\n",
      "\tqs.mu.Unlock()\n",
      "\treturn nil\n",
      "}\n",
      "func init() {\n",
      "\trootCmd.PersistentFlags().StringVarP(&cfgFile, \"config\", \"c\", \"\", \"config file of frps\")\n",
      "\trootCmd.PersistentFlags().BoolVarP(&showVersion, \"version\", \"v\", false, \"version of frps\")\n",
      "\trootCmd.PersistentFlags().BoolVarP(&strictConfigMode, \"strict_config\", \"\", false, \"strict config parsing mode, unknown fields will cause error\")\n",
      "\tconfig.RegisterServerConfigFlags(rootCmd, &serverCfg)\n",
      "}\n",
      "======================CLASS=======================\n",
      "FiloSottile/mkcert 2 44662\n",
      "2\n",
      "======================CLASS=======================\n",
      "func getCAROOT() string {\n",
      "\tif env := os.Getenv(\"CAROOT\"); env != \"\" {\n",
      "\t\treturn env\n",
      "\t}\n",
      "\tvar dir string\n",
      "\tswitch {\n",
      "\tcase runtime.GOOS == \"windows\":\n",
      "\t\tdir = os.Getenv(\"LocalAppData\")\n",
      "\tcase os.Getenv(\"XDG_DATA_HOME\") != \"\":\n",
      "\t\tdir = os.Getenv(\"XDG_DATA_HOME\")\n",
      "\tcase runtime.GOOS == \"darwin\":\n",
      "\t\tdir = os.Getenv(\"HOME\")\n",
      "\t\tif dir == \"\" {\n",
      "\t\t\treturn \"\"\n",
      "\t\t}\n",
      "\t\tdir = filepath.Join(dir, \"Library\", \"Application Support\")\n",
      "\tdefault:\n",
      "\t\tdir = os.Getenv(\"HOME\")\n",
      "\t\tif dir == \"\" {\n",
      "\t\t\treturn \"\"\n",
      "\t\t}\n",
      "\t\tdir = filepath.Join(dir, \".local\", \"share\")\n",
      "\t}\n",
      "\treturn filepath.Join(dir, \"mkcert\")\n",
      "}\n",
      "func (m *mkcert) installPlatform() bool {\n",
      "\tcmd := commandWithSudo(\"security\", \"add-trusted-cert\", \"-d\", \"-k\", \"/Library/Keychains/System.keychain\", filepath.Join(m.CAROOT, rootName))\n",
      "\tout, err := cmd.CombinedOutput()\n",
      "\tfatalIfCmdErr(err, \"security add-trusted-cert\", out)\n",
      "\tplistFile, err := ioutil.TempFile(\"\", \"trust-settings\")\n",
      "\tfatalIfErr(err, \"failed to create temp file\")\n",
      "\tdefer os.Remove(plistFile.Name())\n",
      "\tcmd = commandWithSudo(\"security\", \"trust-settings-export\", \"-d\", plistFile.Name())\n",
      "\tout, err = cmd.CombinedOutput()\n",
      "\tfatalIfCmdErr(err, \"security trust-settings-export\", out)\n",
      "\tplistData, err := ioutil.ReadFile(plistFile.Name())\n",
      "\tfatalIfErr(err, \"failed to read trust settings\")\n",
      "\tvar plistRoot map[string]interface{}\n",
      "\t_, err = plist.Unmarshal(plistData, &plistRoot)\n",
      "\tfatalIfErr(err, \"failed to parse trust settings\")\n",
      "\trootSubjectASN1, _ := asn1.Marshal(m.caCert.Subject.ToRDNSequence())\n",
      "\tif plistRoot[\"trustVersion\"].(uint64) != 1 {\n",
      "\t\tlog.Fatalln(\"ERROR: unsupported trust settings version:\", plistRoot[\"trustVersion\"])\n",
      "\t}\n",
      "\ttrustList := plistRoot[\"trustList\"].(map[string]interface{})\n",
      "\tfor key := range trustList {\n",
      "\t\tentry := trustList[key].(map[string]interface{})\n",
      "\t\tif _, ok := entry[\"issuerName\"]; !ok {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tissuerName := entry[\"issuerName\"].([]byte)\n",
      "\t\tif !bytes.Equal(rootSubjectASN1, issuerName) {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tentry[\"trustSettings\"] = trustSettings\n",
      "\t\tbreak\n",
      "\t}\n",
      "\tplistData, err = plist.MarshalIndent(plistRoot, plist.XMLFormat, \"\\t\")\n",
      "\tfatalIfErr(err, \"failed to serialize trust settings\")\n",
      "\terr = ioutil.WriteFile(plistFile.Name(), plistData, 0600)\n",
      "\tfatalIfErr(err, \"failed to write trust settings\")\n",
      "\tcmd = commandWithSudo(\"security\", \"trust-settings-import\", \"-d\", plistFile.Name())\n",
      "\tout, err = cmd.CombinedOutput()\n",
      "\tfatalIfCmdErr(err, \"security trust-settings-import\", out)\n",
      "\treturn true\n",
      "}\n",
      "func (m *mkcert) Run(args []string) {\n",
      "\tm.CAROOT = getCAROOT()\n",
      "\tif m.CAROOT == \"\" {\n",
      "\t\tlog.Fatalln(\"ERROR: failed to find the default CA location, set one as the CAROOT env var\")\n",
      "\t}\n",
      "\tfatalIfErr(os.MkdirAll(m.CAROOT, 0755), \"failed to create the CAROOT\")\n",
      "\tm.loadCA()\n",
      "\tif m.installMode {\n",
      "\t\tm.install()\n",
      "\t\tif len(args) == 0 {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t} else if m.uninstallMode {\n",
      "\t\tm.uninstall()\n",
      "\t\treturn\n",
      "\t} else {\n",
      "\t\tvar warning bool\n",
      "\t\tif storeEnabled(\"system\") && !m.checkPlatform() {\n",
      "\t\t\twarning = true\n",
      "\t\t\tlog.Println(\"Note: the local CA is not installed in the system trust store.\")\n",
      "\t\t}\n",
      "\t\tif storeEnabled(\"nss\") && hasNSS && CertutilInstallHelp != \"\" && !m.checkNSS() {\n",
      "\t\t\twarning = true\n",
      "\t\t\tlog.Printf(\"Note: the local CA is not installed in the %s trust store.\", NSSBrowsers)\n",
      "\t\t}\n",
      "\t\tif storeEnabled(\"java\") && hasJava && !m.checkJava() {\n",
      "\t\t\twarning = true\n",
      "\t\t\tlog.Println(\"Note: the local CA is not installed in the Java trust store.\")\n",
      "\t\t}\n",
      "\t\tif warning {\n",
      "\t\t\tlog.Println(\"Run \\\"mkcert -install\\\" for certificates to be trusted automatically \")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif m.csrPath != \"\" {\n",
      "\t\tm.makeCertFromCSR()\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif len(args) == 0 {\n",
      "\t\tflag.Usage()\n",
      "\t\treturn\n",
      "\t}\n",
      "\thostnameRegexp := regexp.MustCompile(`(?i)^(\\*\\.)?[0-9a-z_-]([0-9a-z._-]*[0-9a-z_-])?$`)\n",
      "\tfor i, name := range args {\n",
      "\t\tif ip := net.ParseIP(name); ip != nil {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif email, err := mail.ParseAddress(name); err == nil && email.Address == name {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif uriName, err := url.Parse(name); err == nil && uriName.Scheme != \"\" && uriName.Host != \"\" {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tpunycode, err := idna.ToASCII(name)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Fatalf(\"ERROR: %q is not a valid hostname, IP, URL or email: %s\", name, err)\n",
      "\t\t}\n",
      "\t\targs[i] = punycode\n",
      "\t\tif !hostnameRegexp.MatchString(punycode) {\n",
      "\t\t\tlog.Fatalf(\"ERROR: %q is not a valid hostname, IP, URL or email\", name)\n",
      "\t\t}\n",
      "\t}\n",
      "\tm.makeCert(args)\n",
      "}\n",
      "======================CLASS=======================\n",
      "ehang-io/nps 3 28567\n",
      "3\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewTlsServerConn(conn net.Conn) net.Conn {\n",
      "\tvar err error\n",
      "\tif err != nil {\n",
      "\t\tlogs.Error(err)\n",
      "\t\tos.Exit(0)\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tconfig := &tls.Config{Certificates: []tls.Certificate{cert}}\n",
      "\treturn tls.Server(conn, config)\n",
      "}\n",
      "func (s *Bridge) getConfig(c *conn.Conn, isPub bool, client *file.Client) {\n",
      "\tvar fail bool\n",
      "loop:\n",
      "\tfor {\n",
      "\t\tflag, err := c.ReadFlag()\n",
      "\t\tif err != nil {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tswitch flag {\n",
      "\t\tcase common.WORK_STATUS:\n",
      "\t\t\tif b, err := c.GetShortContent(32); err != nil {\n",
      "\t\t\t\tbreak loop\n",
      "\t\t\t} else {\n",
      "\t\t\t\tvar str string\n",
      "\t\t\t\tid, err := file.GetDb().GetClientIdByVkey(string(b))\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tbreak loop\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfile.GetDb().JsonDb.Hosts.Range(func(key, value interface{}) bool {\n",
      "\t\t\t\t\tv := value.(*file.Host)\n",
      "\t\t\t\t\tif v.Client.Id == id {\n",
      "\t\t\t\t\t\tstr += v.Remark + common.CONN_DATA_SEQ\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treturn true\n",
      "\t\t\t\t})\n",
      "\t\t\t\tfile.GetDb().JsonDb.Tasks.Range(func(key, value interface{}) bool {\n",
      "\t\t\t\t\tv := value.(*file.Tunnel)\n",
      "\t\t\t\t\tif _, ok := s.runList.Load(v.Id); ok && v.Client.Id == id {\n",
      "\t\t\t\t\t\tstr += v.Remark + common.CONN_DATA_SEQ\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treturn true\n",
      "\t\t\t\t})\n",
      "\t\t\t\tbinary.Write(c, binary.LittleEndian, int32(len([]byte(str))))\n",
      "\t\t\t\tbinary.Write(c, binary.LittleEndian, []byte(str))\n",
      "\t\t\t}\n",
      "\t\tcase common.NEW_CONF:\n",
      "\t\t\tvar err error\n",
      "\t\t\tif client, err = c.GetConfigInfo(); err != nil {\n",
      "\t\t\t\tfail = true\n",
      "\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\tbreak loop\n",
      "\t\t\t} else {\n",
      "\t\t\t\tif err = file.GetDb().NewClient(client); err != nil {\n",
      "\t\t\t\t\tfail = true\n",
      "\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\tbreak loop\n",
      "\t\t\t\t}\n",
      "\t\t\t\tc.WriteAddOk()\n",
      "\t\t\t\tc.Write([]byte(client.VerifyKey))\n",
      "\t\t\t\ts.Client.Store(client.Id, NewClient(nil, nil, nil, \"\"))\n",
      "\t\t\t}\n",
      "\t\tcase common.NEW_HOST:\n",
      "\t\t\th, err := c.GetHostInfo()\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tfail = true\n",
      "\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\tbreak loop\n",
      "\t\t\t}\n",
      "\t\t\th.Client = client\n",
      "\t\t\tif h.Location == \"\" {\n",
      "\t\t\t\th.Location = \"/\"\n",
      "\t\t\t}\n",
      "\t\t\tif !client.HasHost(h) {\n",
      "\t\t\t\tif file.GetDb().IsHostExist(h) {\n",
      "\t\t\t\t\tfail = true\n",
      "\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\tbreak loop\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tfile.GetDb().NewHost(h)\n",
      "\t\t\t\t\tc.WriteAddOk()\n",
      "\t\t\t\t}\n",
      "\t\t\t} else {\n",
      "\t\t\t\tc.WriteAddOk()\n",
      "\t\t\t}\n",
      "\t\tcase common.NEW_TASK:\n",
      "\t\t\tif t, err := c.GetTaskInfo(); err != nil {\n",
      "\t\t\t\tfail = true\n",
      "\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\tbreak loop\n",
      "\t\t\t} else {\n",
      "\t\t\t\tports := common.GetPorts(t.Ports)\n",
      "\t\t\t\ttargets := common.GetPorts(t.Target.TargetStr)\n",
      "\t\t\t\tif len(ports) > 1 && (t.Mode == \"tcp\" || t.Mode == \"udp\") && (len(ports) != len(targets)) {\n",
      "\t\t\t\t\tfail = true\n",
      "\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\tbreak loop\n",
      "\t\t\t\t} else if t.Mode == \"secret\" || t.Mode == \"p2p\" {\n",
      "\t\t\t\t\tports = append(ports, 0)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif len(ports) == 0 {\n",
      "\t\t\t\t\tfail = true\n",
      "\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\tbreak loop\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfor i := 0; i < len(ports); i++ {\n",
      "\t\t\t\t\ttl := new(file.Tunnel)\n",
      "\t\t\t\t\ttl.Mode = t.Mode\n",
      "\t\t\t\t\ttl.Port = ports[i]\n",
      "\t\t\t\t\ttl.ServerIp = t.ServerIp\n",
      "\t\t\t\t\tif len(ports) == 1 {\n",
      "\t\t\t\t\t\ttl.Target = t.Target\n",
      "\t\t\t\t\t\ttl.Remark = t.Remark\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\ttl.Remark = t.Remark + \"_\" + strconv.Itoa(tl.Port)\n",
      "\t\t\t\t\t\ttl.Target = new(file.Target)\n",
      "\t\t\t\t\t\tif t.TargetAddr != \"\" {\n",
      "\t\t\t\t\t\t\ttl.Target.TargetStr = t.TargetAddr + \":\" + strconv.Itoa(targets[i])\n",
      "\t\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\t\ttl.Target.TargetStr = strconv.Itoa(targets[i])\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\ttl.Id = int(file.GetDb().JsonDb.GetTaskId())\n",
      "\t\t\t\t\ttl.Status = true\n",
      "\t\t\t\t\ttl.Flow = new(file.Flow)\n",
      "\t\t\t\t\ttl.NoStore = true\n",
      "\t\t\t\t\ttl.Client = client\n",
      "\t\t\t\t\ttl.Password = t.Password\n",
      "\t\t\t\t\ttl.LocalPath = t.LocalPath\n",
      "\t\t\t\t\ttl.StripPre = t.StripPre\n",
      "\t\t\t\t\ttl.MultiAccount = t.MultiAccount\n",
      "\t\t\t\t\tif !client.HasTunnel(tl) {\n",
      "\t\t\t\t\t\tif err := file.GetDb().NewTask(tl); err != nil {\n",
      "\t\t\t\t\t\t\tlogs.Notice(\"Add task error \", err.Error())\n",
      "\t\t\t\t\t\t\tfail = true\n",
      "\t\t\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\t\t\tbreak loop\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tif b := tool.TestServerPort(tl.Port, tl.Mode); !b && t.Mode != \"secret\" && t.Mode != \"p2p\" {\n",
      "\t\t\t\t\t\t\tfail = true\n",
      "\t\t\t\t\t\t\tc.WriteAddFail()\n",
      "\t\t\t\t\t\t\tbreak loop\n",
      "\t\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\t\ts.OpenTask <- tl\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tc.WriteAddOk()\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif fail && client != nil {\n",
      "\t\ts.DelClient(client.Id)\n",
      "\t}\n",
      "\tc.Close()\n",
      "}\n",
      "func (s *Conn) SendInfo(t interface{}, flag string) (int, error) {\n",
      "\traw := bytes.NewBuffer([]byte{})\n",
      "\tif flag != \"\" {\n",
      "\t\tbinary.Write(raw, binary.LittleEndian, []byte(flag))\n",
      "\t}\n",
      "\tb, err := json.Marshal(t)\n",
      "\tif err != nil {\n",
      "\t\treturn 0, err\n",
      "\t}\n",
      "\tlenBytes, err := GetLenBytes(b)\n",
      "\tif err != nil {\n",
      "\t\treturn 0, err\n",
      "\t}\n",
      "\tbinary.Write(raw, binary.LittleEndian, lenBytes)\n",
      "\treturn s.Write(raw.Bytes())\n",
      "}\n",
      "func StartLocalServer(l *config.LocalServer, config *config.CommonConfig) error {\n",
      "\tif l.Type != \"secret\" {\n",
      "\t\tgo handleUdpMonitor(config, l)\n",
      "\t}\n",
      "\ttask := &file.Tunnel{Port: l.Port, ServerIp: \"0.0.0.0\", Status: true, Client: &file.Client{Cnf: &file.Config{U: \"\", P: \"\", Compress: config.Client.Cnf.Compress}, Status: true, RateLimit: 0, Flow: &file.Flow{}}, Flow: &file.Flow{}, Target: &file.Target{}}\n",
      "\tswitch l.Type {\n",
      "\tcase \"p2ps\":\n",
      "\t\tlogs.Info(\"successful start-up of local socks5 monitoring, port\", l.Port)\n",
      "\t\treturn proxy.NewSock5ModeServer(p2pNetBridge, task).Start()\n",
      "\tcase \"p2pt\":\n",
      "\t\tlogs.Info(\"successful start-up of local tcp trans monitoring, port\", l.Port)\n",
      "\t\treturn proxy.NewTunnelModeServer(proxy.HandleTrans, p2pNetBridge, task).Start()\n",
      "\tcase \"p2p\", \"secret\":\n",
      "\t\tlistener, err := net.ListenTCP(\"tcp\", &net.TCPAddr{net.ParseIP(\"0.0.0.0\"), l.Port, \"\"})\n",
      "\t\tif err != nil {\n",
      "\t\t\tlogs.Error(\"local listener startup failed port %d, error %s\", l.Port, err.Error())\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tLocalServer = append(LocalServer, listener)\n",
      "\t\tlogs.Info(\"successful start-up of local tcp monitoring, port\", l.Port)\n",
      "\t\tconn.Accept(listener, func(c net.Conn) {\n",
      "\t\t\tlogs.Trace(\"new %s connection\", l.Type)\n",
      "\t\t\tif l.Type == \"secret\" {\n",
      "\t\t\t\thandleSecret(c, config, l)\n",
      "\t\t\t} else if l.Type == \"p2p\" {\n",
      "\t\t\t\thandleP2PVisitor(c, config, l)\n",
      "\t\t\t}\n",
      "\t\t})\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func handleSecret(localTcpConn net.Conn, config *config.CommonConfig, l *config.LocalServer) {\n",
      "\tremoteConn, err := NewConn(config.Tp, config.VKey, config.Server, common.WORK_SECRET, config.ProxyUrl)\n",
      "\tif err != nil {\n",
      "\t\tlogs.Error(\"Local connection server failed \", err.Error())\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif _, err := remoteConn.Write([]byte(crypt.Md5(l.Password))); err != nil {\n",
      "\t\tlogs.Error(\"Local connection server failed \", err.Error())\n",
      "\t\treturn\n",
      "\t}\n",
      "\tconn.CopyWaitGroup(remoteConn.Conn, localTcpConn, false, false, nil, nil, false, nil)\n",
      "}\n",
      "func run() {\n",
      "\tcommon.InitPProfFromArg(*pprofAddr)\n",
      "\tif *password != \"\" {\n",
      "\t\tcommonConfig := new(config.CommonConfig)\n",
      "\t\tcommonConfig.Server = *serverAddr\n",
      "\t\tcommonConfig.VKey = *verifyKey\n",
      "\t\tcommonConfig.Tp = *connType\n",
      "\t\tlocalServer := new(config.LocalServer)\n",
      "\t\tlocalServer.Type = *localType\n",
      "\t\tlocalServer.Password = *password\n",
      "\t\tlocalServer.Target = *target\n",
      "\t\tlocalServer.Port = *localPort\n",
      "\t\tcommonConfig.Client = new(file.Client)\n",
      "\t\tcommonConfig.Client.Cnf = new(file.Config)\n",
      "\t\tgo client.StartLocalServer(localServer, commonConfig)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tenv := common.GetEnvMap()\n",
      "\tif *serverAddr == \"\" {\n",
      "\t\t*serverAddr, _ = env[\"NPC_SERVER_ADDR\"]\n",
      "\t}\n",
      "\tif *verifyKey == \"\" {\n",
      "\t\t*verifyKey, _ = env[\"NPC_SERVER_VKEY\"]\n",
      "\t}\n",
      "\tlogs.Info(\"the version of client is %s, the core version of client is %s\", version.VERSION, version.GetVersion())\n",
      "\tif *verifyKey != \"\" && *serverAddr != \"\" && *configPath == \"\" {\n",
      "\t\tgo func() {\n",
      "\t\t\tfor {\n",
      "\t\t\t\tclient.NewRPClient(*serverAddr, *verifyKey, *connType, *proxyUrl, nil, *disconnectTime).Start()\n",
      "\t\t\t\tlogs.Info(\"Client closed! It will be reconnected in five seconds\")\n",
      "\t\t\t\ttime.Sleep(time.Second * 5)\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t} else {\n",
      "\t\tif *configPath == \"\" {\n",
      "\t\t\t*configPath = common.GetConfigPath()\n",
      "\t\t}\n",
      "\t\tgo client.StartFromFile(*configPath)\n",
      "\t}\n",
      "}\n",
      "func main() {\n",
      "\tflag.Parse()\n",
      "\tif *ver {\n",
      "\t\tcommon.PrintVersion()\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif err := beego.LoadAppConfig(\"ini\", filepath.Join(common.GetRunPath(), \"conf\", \"nps.conf\")); err != nil {\n",
      "\t\tlog.Fatalln(\"load config file error\", err.Error())\n",
      "\t}\n",
      "\tcommon.InitPProfFromFile()\n",
      "\tif level = beego.AppConfig.String(\"log_level\"); level == \"\" {\n",
      "\t\tlevel = \"7\"\n",
      "\t}\n",
      "\tlogs.Reset()\n",
      "\tlogs.EnableFuncCallDepth(true)\n",
      "\tlogs.SetLogFuncCallDepth(3)\n",
      "\tlogPath := beego.AppConfig.String(\"log_path\")\n",
      "\tif logPath == \"\" {\n",
      "\t\tlogPath = common.GetLogPath()\n",
      "\t}\n",
      "\tif common.IsWindows() {\n",
      "\t\tlogPath = strings.Replace(logPath, \"\\\\\", \"\\\\\\\\\", -1)\n",
      "\t}\n",
      "\toptions := make(service.KeyValue)\n",
      "\tsvcConfig := &service.Config{Name: \"Nps\", DisplayName: \"nps\", Description: \"tcpudphttpsocks5snappyheaderweb\", Option: options}\n",
      "\tsvcConfig.Arguments = append(svcConfig.Arguments, \"service\")\n",
      "\tif len(os.Args) > 1 && os.Args[1] == \"service\" {\n",
      "\t\t_ = logs.SetLogger(logs.AdapterFile, `{\"level\":`+level+`,\"filename\":\"`+logPath+`\",\"daily\":false,\"maxlines\":100000,\"color\":true}`)\n",
      "\t} else {\n",
      "\t\t_ = logs.SetLogger(logs.AdapterConsole, `{\"level\":`+level+`,\"color\":true}`)\n",
      "\t}\n",
      "\tif !common.IsWindows() {\n",
      "\t\tsvcConfig.Dependencies = []string{\"Requires=network.target\", \"After=network-online.target syslog.target\"}\n",
      "\t\tsvcConfig.Option[\"SystemdScript\"] = install.SystemdScript\n",
      "\t\tsvcConfig.Option[\"SysvScript\"] = install.SysvScript\n",
      "\t}\n",
      "\tprg := &nps{}\n",
      "\tprg.exit = make(chan struct{})\n",
      "\ts, err := service.New(prg, svcConfig)\n",
      "\tif err != nil {\n",
      "\t\tlogs.Error(err, \"service function disabled\")\n",
      "\t\trun()\n",
      "\t\twg := sync.WaitGroup{}\n",
      "\t\twg.Add(1)\n",
      "\t\twg.Wait()\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif len(os.Args) > 1 && os.Args[1] != \"service\" {\n",
      "\t\tswitch os.Args[1] {\n",
      "\t\tcase \"reload\":\n",
      "\t\t\tdaemon.InitDaemon(\"nps\", common.GetRunPath(), common.GetTmpPath())\n",
      "\t\t\treturn\n",
      "\t\tcase \"install\":\n",
      "\t\t\t_ = service.Control(s, \"stop\")\n",
      "\t\t\t_ = service.Control(s, \"uninstall\")\n",
      "\t\t\tbinPath := install.InstallNps()\n",
      "\t\t\tsvcConfig.Executable = binPath\n",
      "\t\t\ts, err := service.New(prg, svcConfig)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlogs.Error(err)\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\terr = service.Control(s, os.Args[1])\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlogs.Error(\"Valid actions: %q\\n%s\", service.ControlAction, err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif service.Platform() == \"unix-systemv\" {\n",
      "\t\t\t\tlogs.Info(\"unix-systemv service\")\n",
      "\t\t\t\tconfPath := \"/etc/init.d/\" + svcConfig.Name\n",
      "\t\t\t\tos.Symlink(confPath, \"/etc/rc.d/S90\"+svcConfig.Name)\n",
      "\t\t\t\tos.Symlink(confPath, \"/etc/rc.d/K02\"+svcConfig.Name)\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\tcase \"start\", \"restart\", \"stop\":\n",
      "\t\t\tif service.Platform() == \"unix-systemv\" {\n",
      "\t\t\t\tlogs.Info(\"unix-systemv service\")\n",
      "\t\t\t\tcmd := exec.Command(\"/etc/init.d/\"+svcConfig.Name, os.Args[1])\n",
      "\t\t\t\terr := cmd.Run()\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tlogs.Error(err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\terr := service.Control(s, os.Args[1])\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlogs.Error(\"Valid actions: %q\\n%s\", service.ControlAction, err.Error())\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\tcase \"uninstall\":\n",
      "\t\t\terr := service.Control(s, os.Args[1])\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlogs.Error(\"Valid actions: %q\\n%s\", service.ControlAction, err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif service.Platform() == \"unix-systemv\" {\n",
      "\t\t\t\tlogs.Info(\"unix-systemv service\")\n",
      "\t\t\t\tos.Remove(\"/etc/rc.d/S90\" + svcConfig.Name)\n",
      "\t\t\t\tos.Remove(\"/etc/rc.d/K02\" + svcConfig.Name)\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\tcase \"update\":\n",
      "\t\t\tinstall.UpdateNps()\n",
      "\t\t\treturn\n",
      "\t\tdefault:\n",
      "\t\t\tlogs.Error(\"command is not support\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\t_ = s.Run()\n",
      "}\n",
      "func newUdpConn(localAddr string, config *config.CommonConfig, l *config.LocalServer) {\n",
      "\tlock.Lock()\n",
      "\tdefer lock.Unlock()\n",
      "\tremoteConn, err := NewConn(config.Tp, config.VKey, config.Server, common.WORK_P2P, config.ProxyUrl)\n",
      "\tif err != nil {\n",
      "\t\tlogs.Error(\"Local connection server failed \", err.Error())\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif _, err := remoteConn.Write([]byte(crypt.Md5(l.Password))); err != nil {\n",
      "\t\tlogs.Error(\"Local connection server failed \", err.Error())\n",
      "\t\treturn\n",
      "\t}\n",
      "\tvar rAddr []byte\n",
      "\tif rAddr, err = remoteConn.GetShortLenContent(); err != nil {\n",
      "\t\tlogs.Error(err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tvar localConn net.PacketConn\n",
      "\tvar remoteAddress string\n",
      "\tif remoteAddress, localConn, err = handleP2PUdp(localAddr, string(rAddr), crypt.Md5(l.Password), common.WORK_P2P_VISITOR); err != nil {\n",
      "\t\tlogs.Error(err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tudpTunnel, err := kcp.NewConn(remoteAddress, nil, 150, 3, localConn)\n",
      "\tif err != nil || udpTunnel == nil {\n",
      "\t\tlogs.Warn(err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlogs.Trace(\"successful create a connection with server\", remoteAddress)\n",
      "\tconn.SetUdpSession(udpTunnel)\n",
      "\tudpConn = udpTunnel\n",
      "\tmuxSession = nps_mux.NewMux(udpConn, \"kcp\", config.DisconnectTime)\n",
      "\tp2pNetBridge = &p2pBridge{}\n",
      "}\n",
      "func handleP2PVisitor(localTcpConn net.Conn, config *config.CommonConfig, l *config.LocalServer) {\n",
      "\tif udpConn == nil {\n",
      "\t\tlogs.Notice(\"new conn, P2P can not penetrate successfully, traffic will be transferred through the server\")\n",
      "\t\thandleSecret(localTcpConn, config, l)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlogs.Trace(\"start trying to connect with the server\")\n",
      "\tlink := conn.NewLink(common.CONN_TCP, l.Target, false, config.Client.Cnf.Compress, localTcpConn.LocalAddr().String(), false)\n",
      "\tif target, err := p2pNetBridge.SendLinkInfo(0, link, nil); err != nil {\n",
      "\t\tlogs.Error(err)\n",
      "\t\tudpConnStatus = false\n",
      "\t\treturn\n",
      "\t} else {\n",
      "\t\tconn.CopyWaitGroup(target, localTcpConn, false, config.Client.Cnf.Compress, nil, nil, false, nil)\n",
      "\t}\n",
      "}\n",
      "schollz/croc 5 25745\n",
      "5\n",
      "======================CLASS=======================\n",
      "func (c *Client) broadcastOnLocalNetwork(useipv6 bool) {\n",
      "\tvar timeLimit time.Duration\n",
      "\tif c.Options.OnlyLocal {\n",
      "\t\ttimeLimit = -1 * time.Second\n",
      "\t} else {\n",
      "\t\ttimeLimit = 30 * time.Second\n",
      "\t}\n",
      "\tsettings := peerdiscovery.Settings{Limit: -1, Payload: []byte(\"croc\" + c.Options.RelayPorts[0]), Delay: 20 * time.Millisecond, TimeLimit: timeLimit}\n",
      "\tif useipv6 {\n",
      "\t\tsettings.IPVersion = peerdiscovery.IPv6\n",
      "\t}\n",
      "\tdiscoveries, err := peerdiscovery.Discover(settings)\n",
      "\tlog.Debugf(\"discoveries: %+v\", discoveries)\n",
      "\tif err != nil {\n",
      "\t\tlog.Debug(err)\n",
      "\t}\n",
      "}\n",
      "func receive(c *cli.Context) (err error) {\n",
      "\tcomm.Socks5Proxy = c.String(\"socks5\")\n",
      "\tcomm.HttpProxy = c.String(\"connect\")\n",
      "\tcrocOptions := croc.Options{SharedSecret: c.String(\"code\"), IsSender: false, Debug: c.Bool(\"debug\"), NoPrompt: c.Bool(\"yes\"), RelayAddress: c.String(\"relay\"), RelayAddress6: c.String(\"relay6\"), Stdout: c.Bool(\"stdout\"), Ask: c.Bool(\"ask\"), RelayPassword: determinePass(c), OnlyLocal: c.Bool(\"local\"), IP: c.String(\"ip\"), Overwrite: c.Bool(\"overwrite\"), Curve: c.String(\"curve\"), TestFlag: c.Bool(\"testing\")}\n",
      "\tif crocOptions.RelayAddress != models.DEFAULT_RELAY {\n",
      "\t\tcrocOptions.RelayAddress6 = \"\"\n",
      "\t} else if crocOptions.RelayAddress6 != models.DEFAULT_RELAY6 {\n",
      "\t\tcrocOptions.RelayAddress = \"\"\n",
      "\t}\n",
      "\tswitch c.Args().Len() {\n",
      "\tcase 1:\n",
      "\t\tcrocOptions.SharedSecret = c.Args().First()\n",
      "\tcase 3:\n",
      "\t\tvar phrase []string\n",
      "\t\tphrase = append(phrase, c.Args().First())\n",
      "\t\tphrase = append(phrase, c.Args().Tail()...)\n",
      "\t\tcrocOptions.SharedSecret = strings.Join(phrase, \"-\")\n",
      "\t}\n",
      "\tsetDebugLevel(c)\n",
      "\tconfigFile, err := utils.GetConfigDir()\n",
      "\tif err != nil {\n",
      "\t\tlog.Error(err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tconfigFile = path.Join(configFile, \"receive.json\")\n",
      "\tb, errOpen := os.ReadFile(configFile)\n",
      "\tif errOpen == nil && !c.Bool(\"remember\") {\n",
      "\t\tvar rememberedOptions croc.Options\n",
      "\t\terr = json.Unmarshal(b, &rememberedOptions)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"relay\") && rememberedOptions.RelayAddress != \"\" {\n",
      "\t\t\tcrocOptions.RelayAddress = rememberedOptions.RelayAddress\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"yes\") {\n",
      "\t\t\tcrocOptions.NoPrompt = rememberedOptions.NoPrompt\n",
      "\t\t}\n",
      "\t\tif crocOptions.SharedSecret == \"\" {\n",
      "\t\t\tcrocOptions.SharedSecret = rememberedOptions.SharedSecret\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"pass\") && rememberedOptions.RelayPassword != \"\" {\n",
      "\t\t\tcrocOptions.RelayPassword = rememberedOptions.RelayPassword\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"relay6\") && rememberedOptions.RelayAddress6 != \"\" {\n",
      "\t\t\tcrocOptions.RelayAddress6 = rememberedOptions.RelayAddress6\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"overwrite\") {\n",
      "\t\t\tcrocOptions.Overwrite = rememberedOptions.Overwrite\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"curve\") && rememberedOptions.Curve != \"\" {\n",
      "\t\t\tcrocOptions.Curve = rememberedOptions.Curve\n",
      "\t\t}\n",
      "\t\tif !c.IsSet(\"local\") {\n",
      "\t\t\tcrocOptions.OnlyLocal = rememberedOptions.OnlyLocal\n",
      "\t\t}\n",
      "\t}\n",
      "\tif crocOptions.SharedSecret == \"\" {\n",
      "\t\tl, err := readline.NewEx(&readline.Config{Prompt: \"Enter receive code: \", AutoComplete: TabComplete{}})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tcrocOptions.SharedSecret, err = l.Readline()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif c.String(\"out\") != \"\" {\n",
      "\t\tif err = os.Chdir(c.String(\"out\")); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tcr, err := croc.New(crocOptions)\n",
      "\tif err != nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif c.Bool(\"remember\") {\n",
      "\t\tlog.Debug(\"saving config file\")\n",
      "\t\tvar bConfig []byte\n",
      "\t\tbConfig, err = json.MarshalIndent(crocOptions, \"\", \"    \")\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\terr = os.WriteFile(configFile, bConfig, 0o644)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"wrote %s\", configFile)\n",
      "\t}\n",
      "\terr = cr.Receive()\n",
      "\treturn\n",
      "}\n",
      "func (c *Client) Receive() (err error) {\n",
      "\tfmt.Fprintf(os.Stderr, \"connecting...\")\n",
      "\tusingLocal := false\n",
      "\tisIPset := false\n",
      "\tif c.Options.OnlyLocal || c.Options.IP != \"\" {\n",
      "\t\tc.Options.RelayAddress = \"\"\n",
      "\t\tc.Options.RelayAddress6 = \"\"\n",
      "\t}\n",
      "\tif c.Options.IP != \"\" {\n",
      "\t\tif strings.Count(c.Options.IP, \":\") >= 2 {\n",
      "\t\t\tlog.Debug(\"assume ipv6\")\n",
      "\t\t\tc.Options.RelayAddress6 = c.Options.IP\n",
      "\t\t}\n",
      "\t\tif strings.Contains(c.Options.IP, \".\") {\n",
      "\t\t\tlog.Debug(\"assume ipv4\")\n",
      "\t\t\tc.Options.RelayAddress = c.Options.IP\n",
      "\t\t}\n",
      "\t\tisIPset = true\n",
      "\t}\n",
      "\tif !c.Options.DisableLocal && !isIPset {\n",
      "\t\tlog.Debug(\"attempt to discover peers\")\n",
      "\t\tvar discoveries []peerdiscovery.Discovered\n",
      "\t\tvar wgDiscovery sync.WaitGroup\n",
      "\t\tvar dmux sync.Mutex\n",
      "\t\twgDiscovery.Add(2)\n",
      "\t\tgo func() {\n",
      "\t\t\tdefer wgDiscovery.Done()\n",
      "\t\t\tipv4discoveries, err1 := peerdiscovery.Discover(peerdiscovery.Settings{Limit: 1, Payload: []byte(\"ok\"), Delay: 20 * time.Millisecond, TimeLimit: 200 * time.Millisecond})\n",
      "\t\t\tif err1 == nil && len(ipv4discoveries) > 0 {\n",
      "\t\t\t\tdmux.Lock()\n",
      "\t\t\t\terr = err1\n",
      "\t\t\t\tdiscoveries = append(discoveries, ipv4discoveries...)\n",
      "\t\t\t\tdmux.Unlock()\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tgo func() {\n",
      "\t\t\tdefer wgDiscovery.Done()\n",
      "\t\t\tipv6discoveries, err1 := peerdiscovery.Discover(peerdiscovery.Settings{Limit: 1, Payload: []byte(\"ok\"), Delay: 20 * time.Millisecond, TimeLimit: 200 * time.Millisecond, IPVersion: peerdiscovery.IPv6})\n",
      "\t\t\tif err1 == nil && len(ipv6discoveries) > 0 {\n",
      "\t\t\t\tdmux.Lock()\n",
      "\t\t\t\terr = err1\n",
      "\t\t\t\tdiscoveries = append(discoveries, ipv6discoveries...)\n",
      "\t\t\t\tdmux.Unlock()\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\twgDiscovery.Wait()\n",
      "\t\tif err == nil && len(discoveries) > 0 {\n",
      "\t\t\tlog.Debugf(\"all discoveries: %+v\", discoveries)\n",
      "\t\t\tfor i := 0; i < len(discoveries); i++ {\n",
      "\t\t\t\tlog.Debugf(\"discovery %d has payload: %+v\", i, discoveries[i])\n",
      "\t\t\t\tif !bytes.HasPrefix(discoveries[i].Payload, []byte(\"croc\")) {\n",
      "\t\t\t\t\tlog.Debug(\"skipping discovery\")\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tlog.Debug(\"switching to local\")\n",
      "\t\t\t\tportToUse := string(bytes.TrimPrefix(discoveries[i].Payload, []byte(\"croc\")))\n",
      "\t\t\t\tif portToUse == \"\" {\n",
      "\t\t\t\t\tportToUse = models.DEFAULT_PORT\n",
      "\t\t\t\t}\n",
      "\t\t\t\taddress := net.JoinHostPort(discoveries[i].Address, portToUse)\n",
      "\t\t\t\terrPing := tcp.PingServer(address)\n",
      "\t\t\t\tif errPing == nil {\n",
      "\t\t\t\t\tlog.Debugf(\"successfully pinged '%s'\", address)\n",
      "\t\t\t\t\tc.Options.RelayAddress = address\n",
      "\t\t\t\t\tc.ExternalIPConnected = c.Options.RelayAddress\n",
      "\t\t\t\t\tc.Options.RelayAddress6 = \"\"\n",
      "\t\t\t\t\tusingLocal = true\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tlog.Debugf(\"could not ping: %+v\", errPing)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"discoveries: %+v\", discoveries)\n",
      "\t\tlog.Debug(\"establishing connection\")\n",
      "\t}\n",
      "\tvar banner string\n",
      "\tdurations := []time.Duration{200 * time.Millisecond, 5 * time.Second}\n",
      "\terr = fmt.Errorf(\"found no addresses to connect\")\n",
      "\tfor i, address := range []string{c.Options.RelayAddress6, c.Options.RelayAddress} {\n",
      "\t\tif address == \"\" {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tvar host, port string\n",
      "\t\thost, port, _ = net.SplitHostPort(address)\n",
      "\t\tif port == \"\" {\n",
      "\t\t\thost = address\n",
      "\t\t\tport = models.DEFAULT_PORT\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"got host '%v' and port '%v'\", host, port)\n",
      "\t\taddress = net.JoinHostPort(host, port)\n",
      "\t\tlog.Debugf(\"trying connection to %s\", address)\n",
      "\t\tc.conn[0], banner, c.ExternalIP, err = tcp.ConnectToTCPServer(address, c.Options.RelayPassword, c.Options.SharedSecret[:3], durations[i])\n",
      "\t\tif err == nil {\n",
      "\t\t\tc.Options.RelayAddress = address\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"could not establish '%s'\", address)\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\terr = fmt.Errorf(\"could not connect to %s: %w\", c.Options.RelayAddress, err)\n",
      "\t\tlog.Debug(err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tlog.Debugf(\"receiver connection established: %+v\", c.conn[0])\n",
      "\tlog.Debugf(\"banner: %s\", banner)\n",
      "\tif c.Options.TestFlag {\n",
      "\t\tlog.Debugf(\"TEST FLAG ENABLED, TESTING LOCAL IPS\")\n",
      "\t}\n",
      "\tif c.Options.TestFlag || (!usingLocal && !c.Options.DisableLocal && !isIPset) {\n",
      "\t\tlog.Debug(\"sending ips?\")\n",
      "\t\tvar data []byte\n",
      "\t\tif err = c.conn[0].Send(ipRequest); err != nil {\n",
      "\t\t\tlog.Errorf(\"ips send error: %v\", err)\n",
      "\t\t}\n",
      "\t\tdata, err = c.conn[0].Receive()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"ips data: %s\", data)\n",
      "\t\tvar ips []string\n",
      "\t\tif err = json.Unmarshal(data, &ips); err != nil {\n",
      "\t\t\tlog.Debugf(\"ips unmarshal error: %v\", err)\n",
      "\t\t}\n",
      "\t\tif len(ips) > 1 {\n",
      "\t\t\tport := ips[0]\n",
      "\t\t\tips = ips[1:]\n",
      "\t\t\tfor _, ip := range ips {\n",
      "\t\t\t\tipv4Addr, ipv4Net, errNet := net.ParseCIDR(fmt.Sprintf(\"%s/24\", ip))\n",
      "\t\t\t\tlog.Debugf(\"ipv4Add4: %+v, ipv4Net: %+v, err: %+v\", ipv4Addr, ipv4Net, errNet)\n",
      "\t\t\t\tlocalIps, _ := utils.GetLocalIPs()\n",
      "\t\t\t\thaveLocalIP := false\n",
      "\t\t\t\tfor _, localIP := range localIps {\n",
      "\t\t\t\t\tlocalIPparsed := net.ParseIP(localIP)\n",
      "\t\t\t\t\tlog.Debugf(\"localIP: %+v, localIPparsed: %+v\", localIP, localIPparsed)\n",
      "\t\t\t\t\tif ipv4Net.Contains(localIPparsed) {\n",
      "\t\t\t\t\t\thaveLocalIP = true\n",
      "\t\t\t\t\t\tlog.Debugf(\"ip: %+v is a local IP\", ip)\n",
      "\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif !haveLocalIP {\n",
      "\t\t\t\t\tlog.Debugf(\"%s is not a local IP, skipping\", ip)\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tserverTry := net.JoinHostPort(ip, port)\n",
      "\t\t\t\tconn, banner2, externalIP, errConn := tcp.ConnectToTCPServer(serverTry, c.Options.RelayPassword, c.Options.SharedSecret[:3], 500*time.Millisecond)\n",
      "\t\t\t\tif errConn != nil {\n",
      "\t\t\t\t\tlog.Debug(errConn)\n",
      "\t\t\t\t\tlog.Debugf(\"could not connect to \" + serverTry)\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tlog.Debugf(\"local connection established to %s\", serverTry)\n",
      "\t\t\t\tlog.Debugf(\"banner: %s\", banner2)\n",
      "\t\t\t\tbanner = banner2\n",
      "\t\t\t\tc.Options.RelayAddress = serverTry\n",
      "\t\t\t\tc.ExternalIP = externalIP\n",
      "\t\t\t\tc.conn[0].Close()\n",
      "\t\t\t\tc.conn[0] = nil\n",
      "\t\t\t\tc.conn[0] = conn\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err = c.conn[0].Send(handshakeRequest); err != nil {\n",
      "\t\tlog.Errorf(\"handshake send error: %v\", err)\n",
      "\t}\n",
      "\tc.Options.RelayPorts = strings.Split(banner, \",\")\n",
      "\tif c.Options.NoMultiplexing {\n",
      "\t\tlog.Debug(\"no multiplexing\")\n",
      "\t\tc.Options.RelayPorts = []string{c.Options.RelayPorts[0]}\n",
      "\t}\n",
      "\tlog.Debug(\"exchanged header message\")\n",
      "\tfmt.Fprintf(os.Stderr, \"\\rsecuring channel...\")\n",
      "\terr = c.transfer()\n",
      "\tif err == nil {\n",
      "\t\tif c.numberOfTransferredFiles+len(c.EmptyFoldersToTransfer) == 0 {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"\\rNo files transferred.\")\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func saveConfig(c *cli.Context, crocOptions croc.Options) {\n",
      "\tif c.Bool(\"remember\") {\n",
      "\t\tconfigFile := getConfigFile()\n",
      "\t\tlog.Debug(\"saving config file\")\n",
      "\t\tvar bConfig []byte\n",
      "\t\tif c.String(\"code\") == \"\" {\n",
      "\t\t\tcrocOptions.SharedSecret = \"\"\n",
      "\t\t}\n",
      "\t\tbConfig, err := json.MarshalIndent(crocOptions, \"\", \"    \")\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\terr = os.WriteFile(configFile, bConfig, 0o644)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Debugf(\"wrote %s\", configFile)\n",
      "\t}\n",
      "}\n",
      "func Run() (err error) {\n",
      "\truntime.GOMAXPROCS(runtime.NumCPU())\n",
      "\tapp := cli.NewApp()\n",
      "\tapp.Name = \"croc\"\n",
      "\tif Version == \"\" {\n",
      "\t\tVersion = \"v9.6.13\"\n",
      "\t}\n",
      "\tapp.Version = Version\n",
      "\tapp.Compiled = time.Now()\n",
      "\tapp.Usage = \"easily and securely transfer stuff from one computer to another\"\n",
      "\tapp.UsageText = `Send a file:\n",
      "      croc send file.txt\n",
      "\n",
      "      -git to respect your .gitignore\n",
      "   Send multiple files:\n",
      "      croc send file1.txt file2.txt file3.txt\n",
      "    or\n",
      "      croc send *.jpg\n",
      "\n",
      "   Send everything in a folder:\n",
      "      croc send example-folder-name\n",
      "\n",
      "   Send a file with a custom code:\n",
      "      croc send --code secret-code file.txt\n",
      "\n",
      "   Receive a file using code:\n",
      "      croc secret-code`\n",
      "\tapp.Commands = []*cli.Command{{Name: \"send\", Usage: \"send file(s), or folder (see options with croc send -h)\", Description: \"send file(s), or folder, over the relay\", ArgsUsage: \"[filename(s) or folder]\", Flags: []cli.Flag{&cli.BoolFlag{Name: \"zip\", Usage: \"zip folder before sending\"}, &cli.StringFlag{Name: \"code\", Aliases: []string{\"c\"}, Usage: \"codephrase used to connect to relay\"}, &cli.StringFlag{Name: \"hash\", Value: \"xxhash\", Usage: \"hash algorithm (xxhash, imohash, md5)\"}, &cli.StringFlag{Name: \"text\", Aliases: []string{\"t\"}, Usage: \"send some text\"}, &cli.BoolFlag{Name: \"no-local\", Usage: \"disable local relay when sending\"}, &cli.BoolFlag{Name: \"no-multi\", Usage: \"disable multiplexing\"}, &cli.BoolFlag{Name: \"git\", Usage: \"enable .gitignore respect / don't send ignored files\"}, &cli.IntFlag{Name: \"port\", Value: 9009, Usage: \"base port for the relay\"}, &cli.IntFlag{Name: \"transfers\", Value: 4, Usage: \"number of ports to use for transfers\"}}, HelpName: \"croc send\", Action: send}, {Name: \"relay\", Usage: \"start your own relay (optional)\", Description: \"start relay\", HelpName: \"croc relay\", Action: relay, Flags: []cli.Flag{&cli.StringFlag{Name: \"host\", Usage: \"host of the relay\"}, &cli.StringFlag{Name: \"ports\", Value: \"9009,9010,9011,9012,9013\", Usage: \"ports of the relay\"}}}}\n",
      "\tapp.Flags = []cli.Flag{&cli.BoolFlag{Name: \"internal-dns\", Usage: \"use a built-in DNS stub resolver rather than the host operating system\"}, &cli.BoolFlag{Name: \"remember\", Usage: \"save these settings to reuse next time\"}, &cli.BoolFlag{Name: \"debug\", Usage: \"toggle debug mode\"}, &cli.BoolFlag{Name: \"yes\", Usage: \"automatically agree to all prompts\"}, &cli.BoolFlag{Name: \"stdout\", Usage: \"redirect file to stdout\"}, &cli.BoolFlag{Name: \"no-compress\", Usage: \"disable compression\"}, &cli.BoolFlag{Name: \"ask\", Usage: \"make sure sender and recipient are prompted\"}, &cli.BoolFlag{Name: \"local\", Usage: \"force to use only local connections\"}, &cli.BoolFlag{Name: \"ignore-stdin\", Usage: \"ignore piped stdin\"}, &cli.BoolFlag{Name: \"overwrite\", Usage: \"do not prompt to overwrite\"}, &cli.BoolFlag{Name: \"testing\", Usage: \"flag for testing purposes\"}, &cli.StringFlag{Name: \"curve\", Value: \"p256\", Usage: \"choose an encryption curve (\" + strings.Join(pake.AvailableCurves(), \", \") + \")\"}, &cli.StringFlag{Name: \"ip\", Value: \"\", Usage: \"set sender ip if known e.g. 10.0.0.1:9009, [::1]:9009\"}, &cli.StringFlag{Name: \"relay\", Value: models.DEFAULT_RELAY, Usage: \"address of the relay\", EnvVars: []string{\"CROC_RELAY\"}}, &cli.StringFlag{Name: \"relay6\", Value: models.DEFAULT_RELAY6, Usage: \"ipv6 address of the relay\", EnvVars: []string{\"CROC_RELAY6\"}}, &cli.StringFlag{Name: \"out\", Value: \".\", Usage: \"specify an output folder to receive the file\"}, &cli.StringFlag{Name: \"pass\", Value: models.DEFAULT_PASSPHRASE, Usage: \"password for the relay\", EnvVars: []string{\"CROC_PASS\"}}, &cli.StringFlag{Name: \"socks5\", Value: \"\", Usage: \"add a socks5 proxy\", EnvVars: []string{\"SOCKS5_PROXY\"}}, &cli.StringFlag{Name: \"connect\", Value: \"\", Usage: \"add a http proxy\", EnvVars: []string{\"HTTP_PROXY\"}}, &cli.StringFlag{Name: \"throttleUpload\", Value: \"\", Usage: \"Throttle the upload speed e.g. 500k\"}}\n",
      "\tapp.EnableBashCompletion = true\n",
      "\tapp.HideHelp = false\n",
      "\tapp.HideVersion = false\n",
      "\tapp.Action = func(c *cli.Context) error {\n",
      "\t\tallStringsAreFiles := func(strs []string) bool {\n",
      "\t\t\tfor _, str := range strs {\n",
      "\t\t\t\tif !utils.Exists(str) {\n",
      "\t\t\t\t\treturn false\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn true\n",
      "\t\t}\n",
      "\t\tif c.Args().Present() && allStringsAreFiles(c.Args().Slice()) {\n",
      "\t\t\tfnames := []string{}\n",
      "\t\t\tfor _, fpath := range c.Args().Slice() {\n",
      "\t\t\t\t_, basename := filepath.Split(fpath)\n",
      "\t\t\t\tfnames = append(fnames, \"'\"+basename+\"'\")\n",
      "\t\t\t}\n",
      "\t\t\tpromptMessage := fmt.Sprintf(\"Did you mean to send %s? (Y/n) \", strings.Join(fnames, \", \"))\n",
      "\t\t\tchoice := strings.ToLower(utils.GetInput(promptMessage))\n",
      "\t\t\tif choice == \"\" || choice == \"y\" || choice == \"yes\" {\n",
      "\t\t\t\treturn send(c)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn receive(c)\n",
      "\t}\n",
      "\treturn app.Run(os.Args)\n",
      "}\n",
      "func init() {\n",
      "\tdoRemember := false\n",
      "\tfor _, flag := range os.Args {\n",
      "\t\tif flag == \"--internal-dns\" {\n",
      "\t\t\tINTERNAL_DNS = true\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tif flag == \"--remember\" {\n",
      "\t\t\tdoRemember = true\n",
      "\t\t}\n",
      "\t}\n",
      "\tif doRemember {\n",
      "\t\tfname, err := getConfigFile()\n",
      "\t\tif err == nil {\n",
      "\t\t\tf, _ := os.Create(fname)\n",
      "\t\t\tf.Close()\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !INTERNAL_DNS {\n",
      "\t\tfname, err := getConfigFile()\n",
      "\t\tif err == nil {\n",
      "\t\t\tINTERNAL_DNS = utils.Exists(fname)\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar err error\n",
      "\tvar addr string\n",
      "\taddr, err = lookup(DEFAULT_RELAY)\n",
      "\tif err == nil {\n",
      "\t\tDEFAULT_RELAY = net.JoinHostPort(addr, DEFAULT_PORT)\n",
      "\t} else {\n",
      "\t\tDEFAULT_RELAY = \"\"\n",
      "\t}\n",
      "\taddr, err = lookup(DEFAULT_RELAY6)\n",
      "\tif err == nil {\n",
      "\t\tDEFAULT_RELAY6 = net.JoinHostPort(addr, DEFAULT_PORT)\n",
      "\t} else {\n",
      "\t\tDEFAULT_RELAY6 = \"\"\n",
      "\t}\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "inconshreveable/ngrok 1 23632\n",
      "1\n",
      "======================CLASS=======================\n",
      "func LoadConfiguration(opts *Options) (config *Configuration, err error) {\n",
      "\tconfigPath := opts.config\n",
      "\tif configPath == \"\" {\n",
      "\t\tconfigPath = defaultPath()\n",
      "\t}\n",
      "\tlog.Info(\"Reading configuration file %s\", configPath)\n",
      "\tconfigBuf, err := ioutil.ReadFile(configPath)\n",
      "\tif err != nil {\n",
      "\t\tif opts.config != \"\" {\n",
      "\t\t\terr = fmt.Errorf(\"Failed to read configuration file %s: %v\", configPath, err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig = new(Configuration)\n",
      "\tif err = yaml.Unmarshal(configBuf, &config); err != nil {\n",
      "\t\terr = fmt.Errorf(\"Error parsing configuration file %s: %v\", configPath, err)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tmatched := false\n",
      "\tcontent := strings.TrimSpace(string(configBuf))\n",
      "\tif matched, err = regexp.MatchString(\"^[0-9a-zA-Z_\\\\-!]+$\", content); err != nil {\n",
      "\t\treturn\n",
      "\t} else if matched {\n",
      "\t\tconfig = &Configuration{AuthToken: content}\n",
      "\t}\n",
      "\tif config.ServerAddr == \"\" {\n",
      "\t\tconfig.ServerAddr = defaultServerAddr\n",
      "\t}\n",
      "\tif config.InspectAddr == \"\" {\n",
      "\t\tconfig.InspectAddr = defaultInspectAddr\n",
      "\t}\n",
      "\tif config.HttpProxy == \"\" {\n",
      "\t\tconfig.HttpProxy = os.Getenv(\"http_proxy\")\n",
      "\t}\n",
      "\tif config.InspectAddr != \"disabled\" {\n",
      "\t\tif config.InspectAddr, err = normalizeAddress(config.InspectAddr, \"inspect_addr\"); err != nil {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.ServerAddr, err = normalizeAddress(config.ServerAddr, \"server_addr\"); err != nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif config.HttpProxy != \"\" {\n",
      "\t\tvar proxyUrl *url.URL\n",
      "\t\tif proxyUrl, err = url.Parse(config.HttpProxy); err != nil {\n",
      "\t\t\treturn\n",
      "\t\t} else {\n",
      "\t\t\tif proxyUrl.Scheme != \"http\" && proxyUrl.Scheme != \"https\" {\n",
      "\t\t\t\terr = fmt.Errorf(\"Proxy url scheme must be 'http' or 'https', got %v\", proxyUrl.Scheme)\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor name, t := range config.Tunnels {\n",
      "\t\tif t == nil || t.Protocols == nil || len(t.Protocols) == 0 {\n",
      "\t\t\terr = fmt.Errorf(\"Tunnel %s does not specify any protocols to tunnel.\", name)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tfor k, addr := range t.Protocols {\n",
      "\t\t\ttunnelName := fmt.Sprintf(\"for tunnel %s[%s]\", name, k)\n",
      "\t\t\tif t.Protocols[k], err = normalizeAddress(addr, tunnelName); err != nil {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\tif err = validateProtocol(k, tunnelName); err != nil {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif t.Hostname == \"\" && t.Subdomain == \"\" {\n",
      "\t\t\tif len(strings.Split(name, \".\")) > 1 {\n",
      "\t\t\t\tt.Hostname = name\n",
      "\t\t\t} else {\n",
      "\t\t\t\tt.Subdomain = name\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig.LogTo = opts.logto\n",
      "\tconfig.Path = configPath\n",
      "\tif opts.authtoken != \"\" {\n",
      "\t\tconfig.AuthToken = opts.authtoken\n",
      "\t}\n",
      "\tswitch opts.command {\n",
      "\tcase \"default\":\n",
      "\t\tconfig.Tunnels = make(map[string]*TunnelConfiguration)\n",
      "\t\tconfig.Tunnels[\"default\"] = &TunnelConfiguration{Subdomain: opts.subdomain, Hostname: opts.hostname, HttpAuth: opts.httpauth, Protocols: make(map[string]string)}\n",
      "\t\tfor _, proto := range strings.Split(opts.protocol, \"+\") {\n",
      "\t\t\tif err = validateProtocol(proto, \"default\"); err != nil {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\tif config.Tunnels[\"default\"].Protocols[proto], err = normalizeAddress(opts.args[0], \"\"); err != nil {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\tcase \"list\":\n",
      "\t\tfor name, _ := range config.Tunnels {\n",
      "\t\t\tfmt.Println(name)\n",
      "\t\t}\n",
      "\t\tos.Exit(0)\n",
      "\tcase \"start\":\n",
      "\t\tif len(opts.args) == 0 {\n",
      "\t\t\terr = fmt.Errorf(\"You must specify at least one tunnel to start\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\trequestedTunnels := make(map[string]bool)\n",
      "\t\tfor _, arg := range opts.args {\n",
      "\t\t\trequestedTunnels[arg] = true\n",
      "\t\t\tif _, ok := config.Tunnels[arg]; !ok {\n",
      "\t\t\t\terr = fmt.Errorf(\"Requested to start tunnel %s which is not defined in the config file.\", arg)\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor name, _ := range config.Tunnels {\n",
      "\t\t\tif !requestedTunnels[name] {\n",
      "\t\t\t\tdelete(config.Tunnels, name)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\tcase \"start-all\":\n",
      "\t\treturn\n",
      "\tdefault:\n",
      "\t\terr = fmt.Errorf(\"Unknown command: %s\", opts.command)\n",
      "\t\treturn\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func (c *ClientModel) control() {\n",
      "\tdefer func() {\n",
      "\t\tif r := recover(); r != nil {\n",
      "\t\t\tlog.Error(\"control recovering from failure %v\", r)\n",
      "\t\t}\n",
      "\t}()\n",
      "\tvar (\n",
      "\t\tctlConn\tconn.Conn\n",
      "\t\terr\terror\n",
      "\t)\n",
      "\tif c.proxyUrl == \"\" {\n",
      "\t\tctlConn, err = conn.Dial(c.serverAddr, \"ctl\", c.tlsConfig)\n",
      "\t} else {\n",
      "\t\tctlConn, err = conn.DialHttpProxy(c.proxyUrl, c.serverAddr, \"ctl\", c.tlsConfig)\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\tpanic(err)\n",
      "\t}\n",
      "\tdefer ctlConn.Close()\n",
      "\tauth := &msg.Auth{ClientId: c.id, OS: runtime.GOOS, Arch: runtime.GOARCH, Version: version.Proto, MmVersion: version.MajorMinor(), User: c.authToken}\n",
      "\tif err = msg.WriteMsg(ctlConn, auth); err != nil {\n",
      "\t\tpanic(err)\n",
      "\t}\n",
      "\tvar authResp msg.AuthResp\n",
      "\tif err = msg.ReadMsgInto(ctlConn, &authResp); err != nil {\n",
      "\t\tpanic(err)\n",
      "\t}\n",
      "\tif authResp.Error != \"\" {\n",
      "\t\temsg := fmt.Sprintf(\"Failed to authenticate to server: %s\", authResp.Error)\n",
      "\t\tc.ctl.Shutdown(emsg)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tc.id = authResp.ClientId\n",
      "\tc.serverVersion = authResp.MmVersion\n",
      "\tc.Info(\"Authenticated with server, client id: %v\", c.id)\n",
      "\tc.update()\n",
      "\tif err = SaveAuthToken(c.configPath, c.authToken); err != nil {\n",
      "\t\tc.Error(\"Failed to save auth token: %v\", err)\n",
      "\t}\n",
      "\treqIdToTunnelConfig := make(map[string]*TunnelConfiguration)\n",
      "\tfor _, config := range c.tunnelConfig {\n",
      "\t\tvar protocols []string\n",
      "\t\tfor proto, _ := range config.Protocols {\n",
      "\t\t\tprotocols = append(protocols, proto)\n",
      "\t\t}\n",
      "\t\treqTunnel := &msg.ReqTunnel{ReqId: util.RandId(8), Protocol: strings.Join(protocols, \"+\"), Hostname: config.Hostname, Subdomain: config.Subdomain, HttpAuth: config.HttpAuth, RemotePort: config.RemotePort}\n",
      "\t\tif err = msg.WriteMsg(ctlConn, reqTunnel); err != nil {\n",
      "\t\t\tpanic(err)\n",
      "\t\t}\n",
      "\t\treqIdToTunnelConfig[reqTunnel.ReqId] = config\n",
      "\t}\n",
      "\tlastPong := time.Now().UnixNano()\n",
      "\tc.ctl.Go(func() {\n",
      "\t\tc.heartbeat(&lastPong, ctlConn)\n",
      "\t})\n",
      "\tfor {\n",
      "\t\tvar rawMsg msg.Message\n",
      "\t\tif rawMsg, err = msg.ReadMsg(ctlConn); err != nil {\n",
      "\t\t\tpanic(err)\n",
      "\t\t}\n",
      "\t\tswitch m := rawMsg.(type) {\n",
      "\t\tcase *msg.ReqProxy:\n",
      "\t\t\tc.ctl.Go(c.proxy)\n",
      "\t\tcase *msg.Pong:\n",
      "\t\t\tatomic.StoreInt64(&lastPong, time.Now().UnixNano())\n",
      "\t\tcase *msg.NewTunnel:\n",
      "\t\t\tif m.Error != \"\" {\n",
      "\t\t\t\temsg := fmt.Sprintf(\"Server failed to allocate tunnel: %s\", m.Error)\n",
      "\t\t\t\tc.Error(emsg)\n",
      "\t\t\t\tc.ctl.Shutdown(emsg)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\ttunnel := mvc.Tunnel{PublicUrl: m.Url, LocalAddr: reqIdToTunnelConfig[m.ReqId].Protocols[m.Protocol], Protocol: c.protoMap[m.Protocol]}\n",
      "\t\t\tc.tunnels[tunnel.PublicUrl] = tunnel\n",
      "\t\t\tc.connStatus = mvc.ConnOnline\n",
      "\t\t\tc.Info(\"Tunnel established at %v\", tunnel.PublicUrl)\n",
      "\t\t\tc.update()\n",
      "\t\tdefault:\n",
      "\t\t\tctlConn.Warn(\"Ignoring unknown control message %v \", m)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (ctl *Controller) Run(config *Configuration) {\n",
      "\tctl.config = config\n",
      "\tvar model *ClientModel\n",
      "\tif ctl.model == nil {\n",
      "\t\tmodel = ctl.SetupModel(config)\n",
      "\t} else {\n",
      "\t\tmodel = ctl.model.(*ClientModel)\n",
      "\t}\n",
      "\tvar state mvc.State = model\n",
      "\tvar webView *web.WebView\n",
      "\tif config.InspectAddr != \"disabled\" {\n",
      "\t\twebView = web.NewWebView(ctl, config.InspectAddr)\n",
      "\t\tctl.AddView(webView)\n",
      "\t}\n",
      "\tvar termView *term.TermView\n",
      "\tif config.LogTo != \"stdout\" {\n",
      "\t\ttermView = term.NewTermView(ctl)\n",
      "\t\tctl.AddView(termView)\n",
      "\t}\n",
      "\tfor _, protocol := range model.GetProtocols() {\n",
      "\t\tswitch p := protocol.(type) {\n",
      "\t\tcase *proto.Http:\n",
      "\t\t\tif termView != nil {\n",
      "\t\t\t\tctl.AddView(termView.NewHttpView(p))\n",
      "\t\t\t}\n",
      "\t\t\tif webView != nil {\n",
      "\t\t\t\tctl.AddView(webView.NewHttpView(p))\n",
      "\t\t\t}\n",
      "\t\tdefault:\n",
      "\t\t}\n",
      "\t}\n",
      "\tctl.Go(func() {\n",
      "\t\tautoUpdate(state, config.AuthToken)\n",
      "\t})\n",
      "\tctl.Go(ctl.model.Run)\n",
      "\tupdates := ctl.updates.Reg()\n",
      "\tdefer ctl.updates.UnReg(updates)\n",
      "\tdone := make(chan int)\n",
      "\tfor {\n",
      "\t\tselect {\n",
      "\t\tcase obj := <-ctl.cmds:\n",
      "\t\t\tswitch cmd := obj.(type) {\n",
      "\t\t\tcase cmdQuit:\n",
      "\t\t\t\tmsg := cmd.message\n",
      "\t\t\t\tgo func() {\n",
      "\t\t\t\t\tctl.doShutdown()\n",
      "\t\t\t\t\tfmt.Println(msg)\n",
      "\t\t\t\t\tdone <- 1\n",
      "\t\t\t\t}()\n",
      "\t\t\tcase cmdPlayRequest:\n",
      "\t\t\t\tctl.Go(func() {\n",
      "\t\t\t\t\tctl.model.PlayRequest(cmd.tunnel, cmd.payload)\n",
      "\t\t\t\t})\n",
      "\t\t\t}\n",
      "\t\tcase obj := <-updates:\n",
      "\t\t\tstate = obj.(mvc.State)\n",
      "\t\tcase ctl.state <- state:\n",
      "\t\tcase <-done:\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "redis/go-redis 3 18715\n",
      "3\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func parseReplicaAddrs(addrs []map[string]string, keepDisconnected bool) []string {\n",
      "\tnodes := make([]string, 0, len(addrs))\n",
      "\tfor _, node := range addrs {\n",
      "\t\tisDown := false\n",
      "\t\tif flags, ok := node[\"flags\"]; ok {\n",
      "\t\t\tfor _, flag := range strings.Split(flags, \",\") {\n",
      "\t\t\t\tswitch flag {\n",
      "\t\t\t\tcase \"s_down\", \"o_down\":\n",
      "\t\t\t\t\tisDown = true\n",
      "\t\t\t\tcase \"disconnected\":\n",
      "\t\t\t\t\tif !keepDisconnected {\n",
      "\t\t\t\t\t\tisDown = true\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !isDown && node[\"ip\"] != \"\" && node[\"port\"] != \"\" {\n",
      "\t\t\tnodes = append(nodes, net.JoinHostPort(node[\"ip\"], node[\"port\"]))\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nodes\n",
      "}\n",
      "yudai/gotty 2 18326\n",
      "2\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (server *Server) processWSConn(ctx context.Context, conn *websocket.Conn) error {\n",
      "\ttyp, initLine, err := conn.ReadMessage()\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to authenticate websocket connection\")\n",
      "\t}\n",
      "\tif typ != websocket.TextMessage {\n",
      "\t\treturn errors.New(\"failed to authenticate websocket connection: invalid message type\")\n",
      "\t}\n",
      "\tvar init InitMessage\n",
      "\terr = json.Unmarshal(initLine, &init)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to authenticate websocket connection\")\n",
      "\t}\n",
      "\tif init.AuthToken != server.options.Credential {\n",
      "\t\treturn errors.New(\"failed to authenticate websocket connection\")\n",
      "\t}\n",
      "\tqueryPath := \"?\"\n",
      "\tif server.options.PermitArguments && init.Arguments != \"\" {\n",
      "\t\tqueryPath = init.Arguments\n",
      "\t}\n",
      "\tquery, err := url.Parse(queryPath)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to parse arguments\")\n",
      "\t}\n",
      "\tparams := query.Query()\n",
      "\tvar slave Slave\n",
      "\tslave, err = server.factory.New(params)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to create backend\")\n",
      "\t}\n",
      "\tdefer slave.Close()\n",
      "\ttitleVars := server.titleVariables([]string{\"server\", \"master\", \"slave\"}, map[string]map[string]interface{}{\"server\": server.options.TitleVariables, \"master\": map[string]interface{}{\"remote_addr\": conn.RemoteAddr()}, \"slave\": slave.WindowTitleVariables()})\n",
      "\ttitleBuf := new(bytes.Buffer)\n",
      "\terr = server.titleTemplate.Execute(titleBuf, titleVars)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to fill window title template\")\n",
      "\t}\n",
      "\topts := []webtty.Option{webtty.WithWindowTitle(titleBuf.Bytes())}\n",
      "\tif server.options.PermitWrite {\n",
      "\t\topts = append(opts, webtty.WithPermitWrite())\n",
      "\t}\n",
      "\tif server.options.EnableReconnect {\n",
      "\t\topts = append(opts, webtty.WithReconnect(server.options.ReconnectTime))\n",
      "\t}\n",
      "\tif server.options.Width > 0 {\n",
      "\t\topts = append(opts, webtty.WithFixedColumns(server.options.Width))\n",
      "\t}\n",
      "\tif server.options.Height > 0 {\n",
      "\t\topts = append(opts, webtty.WithFixedRows(server.options.Height))\n",
      "\t}\n",
      "\tif server.options.Preferences != nil {\n",
      "\t\topts = append(opts, webtty.WithMasterPreferences(server.options.Preferences))\n",
      "\t}\n",
      "\ttty, err := webtty.New(&wsWrapper{conn}, slave, opts...)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"failed to create webtty\")\n",
      "\t}\n",
      "\terr = tty.Run(ctx)\n",
      "\treturn err\n",
      "}\n",
      "func ApplyConfigFile(filePath string, options ...interface{}) error {\n",
      "\tfilePath = homedir.Expand(filePath)\n",
      "\tif _, err := os.Stat(filePath); os.IsNotExist(err) {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tfileString := []byte{}\n",
      "\tlog.Printf(\"Loading config file at: %s\", filePath)\n",
      "\tfileString, err := ioutil.ReadFile(filePath)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tfor _, object := range options {\n",
      "\t\tif err := hcl.Decode(object, string(fileString)); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "joewalnes/websocketd 6 17028\n",
      "6\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func createEnv(handler *WebsocketdHandler, req *http.Request, log *LogScope) []string {\n",
      "\theaders := req.Header\n",
      "\turl := req.URL\n",
      "\tserverName, serverPort, err := tellHostPort(req.Host, handler.server.Config.Ssl)\n",
      "\tif err != nil {\n",
      "\t\tlog.Debug(\"env\", \"Host port detection error: %s\", err)\n",
      "\t\tserverPort = \"\"\n",
      "\t}\n",
      "\tstandardEnvCount := 20\n",
      "\tif handler.server.Config.Ssl {\n",
      "\t\tstandardEnvCount += 1\n",
      "\t}\n",
      "\tparentLen := len(handler.server.Config.ParentEnv)\n",
      "\tenv := make([]string, 0, len(headers)+standardEnvCount+parentLen+len(handler.server.Config.Env))\n",
      "\tenv = appendEnv(env, \"SERVER_SOFTWARE\", handler.server.Config.ServerSoftware)\n",
      "\tparentStarts := len(env)\n",
      "\tenv = append(env, handler.server.Config.ParentEnv...)\n",
      "\tenv = appendEnv(env, \"REMOTE_ADDR\", handler.RemoteInfo.Addr)\n",
      "\tenv = appendEnv(env, \"REMOTE_HOST\", handler.RemoteInfo.Host)\n",
      "\tenv = appendEnv(env, \"SERVER_NAME\", serverName)\n",
      "\tenv = appendEnv(env, \"SERVER_PORT\", serverPort)\n",
      "\tenv = appendEnv(env, \"SERVER_PROTOCOL\", req.Proto)\n",
      "\tenv = appendEnv(env, \"GATEWAY_INTERFACE\", gatewayInterface)\n",
      "\tenv = appendEnv(env, \"REQUEST_METHOD\", req.Method)\n",
      "\tenv = appendEnv(env, \"SCRIPT_NAME\", handler.URLInfo.ScriptPath)\n",
      "\tenv = appendEnv(env, \"PATH_INFO\", handler.URLInfo.PathInfo)\n",
      "\tenv = appendEnv(env, \"PATH_TRANSLATED\", url.Path)\n",
      "\tenv = appendEnv(env, \"QUERY_STRING\", url.RawQuery)\n",
      "\tenv = appendEnv(env, \"AUTH_TYPE\", \"\")\n",
      "\tenv = appendEnv(env, \"CONTENT_LENGTH\", \"\")\n",
      "\tenv = appendEnv(env, \"CONTENT_TYPE\", \"\")\n",
      "\tenv = appendEnv(env, \"REMOTE_IDENT\", \"\")\n",
      "\tenv = appendEnv(env, \"REMOTE_USER\", \"\")\n",
      "\tenv = appendEnv(env, \"UNIQUE_ID\", handler.Id)\n",
      "\tenv = appendEnv(env, \"REMOTE_PORT\", handler.RemoteInfo.Port)\n",
      "\tenv = appendEnv(env, \"REQUEST_URI\", url.RequestURI())\n",
      "\tif handler.server.Config.Ssl {\n",
      "\t\tenv = appendEnv(env, \"HTTPS\", \"on\")\n",
      "\t}\n",
      "\tif log.MinLevel == LogDebug {\n",
      "\t\tfor i, v := range env {\n",
      "\t\t\tif i >= parentStarts && i < parentLen+parentStarts {\n",
      "\t\t\t\tlog.Debug(\"env\", \"Parent envvar: %v\", v)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tlog.Debug(\"env\", \"Std. variable: %v\", v)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor k, hdrs := range headers {\n",
      "\t\theader := fmt.Sprintf(\"HTTP_%s\", headerDashToUnderscore.Replace(k))\n",
      "\t\tenv = appendEnv(env, header, hdrs...)\n",
      "\t\tlog.Debug(\"env\", \"Header variable %s\", env[len(env)-1])\n",
      "\t}\n",
      "\tfor _, v := range handler.server.Config.Env {\n",
      "\t\tenv = append(env, v)\n",
      "\t\tlog.Debug(\"env\", \"External variable: %s\", v)\n",
      "\t}\n",
      "\treturn env\n",
      "}\n",
      "func GetURLInfo(path string, config *Config) (*URLInfo, error) {\n",
      "\tif !config.UsingScriptDir {\n",
      "\t\treturn &URLInfo{\"/\", path, \"\"}, nil\n",
      "\t}\n",
      "\tparts := strings.Split(path[1:], \"/\")\n",
      "\turlInfo := &URLInfo{}\n",
      "\tfor i, part := range parts {\n",
      "\t\turlInfo.ScriptPath = strings.Join([]string{urlInfo.ScriptPath, part}, \"/\")\n",
      "\t\turlInfo.FilePath = filepath.Join(config.ScriptDir, urlInfo.ScriptPath)\n",
      "\t\tisLastPart := i == len(parts)-1\n",
      "\t\tstatInfo, err := os.Stat(urlInfo.FilePath)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, ScriptNotFoundError\n",
      "\t\t}\n",
      "\t\tif isLastPart && statInfo.IsDir() {\n",
      "\t\t\treturn nil, ScriptNotFoundError\n",
      "\t\t}\n",
      "\t\tif statInfo.IsDir() {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif isLastPart {\n",
      "\t\t\treturn urlInfo, nil\n",
      "\t\t}\n",
      "\t\turlInfo.PathInfo = \"/\" + strings.Join(parts[i+1:], \"/\")\n",
      "\t\treturn urlInfo, nil\n",
      "\t}\n",
      "\tpanic(fmt.Sprintf(\"GetURLInfo cannot parse path %#v\", path))\n",
      "}\n",
      "func parseCommandLine() *Config {\n",
      "\tvar mainConfig Config\n",
      "\tvar config libwebsocketd.Config\n",
      "\tflag.CommandLine = flag.NewFlagSet(os.Args[0], flag.ContinueOnError)\n",
      "\tflag.CommandLine.Usage = func() {\n",
      "\t}\n",
      "\taddrlist := Arglist(make([]string, 0, 1))\n",
      "\tflag.Var(&addrlist, \"address\", \"Interfaces to bind to (e.g. 127.0.0.1 or [::1]).\")\n",
      "\tportFlag := flag.Int(\"port\", 0, \"HTTP port to listen on\")\n",
      "\tversionFlag := flag.Bool(\"version\", false, \"Print version and exit\")\n",
      "\tlicenseFlag := flag.Bool(\"license\", false, \"Print license and exit\")\n",
      "\tlogLevelFlag := flag.String(\"loglevel\", \"access\", \"Log level, one of: debug, trace, access, info, error, fatal\")\n",
      "\tsslFlag := flag.Bool(\"ssl\", false, \"Use TLS on listening socket (see also --sslcert and --sslkey)\")\n",
      "\tsslCert := flag.String(\"sslcert\", \"\", \"Should point to certificate PEM file when --ssl is used\")\n",
      "\tsslKey := flag.String(\"sslkey\", \"\", \"Should point to certificate private key file when --ssl is used\")\n",
      "\tmaxForksFlag := flag.Int(\"maxforks\", 0, \"Max forks, zero means unlimited\")\n",
      "\tcloseMsFlag := flag.Uint(\"closems\", 0, \"Time to start sending signals (0 never)\")\n",
      "\tredirPortFlag := flag.Int(\"redirport\", 0, \"HTTP port to redirect to canonical --port address\")\n",
      "\tbinaryFlag := flag.Bool(\"binary\", false, \"Set websocketd to experimental binary mode (default is line by line)\")\n",
      "\treverseLookupFlag := flag.Bool(\"reverselookup\", false, \"Perform reverse DNS lookups on remote clients\")\n",
      "\tscriptDirFlag := flag.String(\"dir\", \"\", \"Base directory for WebSocket scripts\")\n",
      "\tstaticDirFlag := flag.String(\"staticdir\", \"\", \"Serve static content from this directory over HTTP\")\n",
      "\tcgiDirFlag := flag.String(\"cgidir\", \"\", \"Serve CGI scripts from this directory over HTTP\")\n",
      "\tdevConsoleFlag := flag.Bool(\"devconsole\", false, \"Enable development console (cannot be used in conjunction with --staticdir)\")\n",
      "\tpassEnvFlag := flag.String(\"passenv\", defaultPassEnv[runtime.GOOS], \"List of envvars to pass to subprocesses (others will be cleaned out)\")\n",
      "\tsameOriginFlag := flag.Bool(\"sameorigin\", false, \"Restrict upgrades if origin and host headers differ\")\n",
      "\tallowOriginsFlag := flag.String(\"origin\", \"\", \"Restrict upgrades if origin does not match the list\")\n",
      "\theaders := Arglist(make([]string, 0))\n",
      "\theadersWs := Arglist(make([]string, 0))\n",
      "\theadersHttp := Arglist(make([]string, 0))\n",
      "\tflag.Var(&headers, \"header\", \"Custom headers for any response.\")\n",
      "\tflag.Var(&headersWs, \"header-ws\", \"Custom headers for successful WebSocket upgrade responses.\")\n",
      "\tflag.Var(&headersHttp, \"header-http\", \"Custom headers for all but WebSocket upgrade HTTP responses.\")\n",
      "\terr := flag.CommandLine.Parse(os.Args[1:])\n",
      "\tif err != nil {\n",
      "\t\tif err == flag.ErrHelp {\n",
      "\t\t\tPrintHelp()\n",
      "\t\t\tos.Exit(0)\n",
      "\t\t} else {\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(2)\n",
      "\t\t}\n",
      "\t}\n",
      "\tport := *portFlag\n",
      "\tif port == 0 {\n",
      "\t\tif *sslFlag {\n",
      "\t\t\tport = 443\n",
      "\t\t} else {\n",
      "\t\t\tport = 80\n",
      "\t\t}\n",
      "\t}\n",
      "\tif socknum := len(addrlist); socknum != 0 {\n",
      "\t\tmainConfig.Addr = make([]string, socknum)\n",
      "\t\tfor i, addrSingle := range addrlist {\n",
      "\t\t\tmainConfig.Addr[i] = fmt.Sprintf(\"%s:%d\", addrSingle, port)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tmainConfig.Addr = []string{fmt.Sprintf(\":%d\", port)}\n",
      "\t}\n",
      "\tmainConfig.MaxForks = *maxForksFlag\n",
      "\tmainConfig.RedirPort = *redirPortFlag\n",
      "\tmainConfig.LogLevel = libwebsocketd.LevelFromString(*logLevelFlag)\n",
      "\tif mainConfig.LogLevel == libwebsocketd.LogUnknown {\n",
      "\t\tfmt.Printf(\"Incorrect loglevel flag '%s'. Use --help to see allowed values.\\n\", *logLevelFlag)\n",
      "\t\tShortHelp()\n",
      "\t\tos.Exit(1)\n",
      "\t}\n",
      "\tconfig.Headers = []string(headers)\n",
      "\tconfig.HeadersWs = []string(headersWs)\n",
      "\tconfig.HeadersHTTP = []string(headersHttp)\n",
      "\tconfig.CloseMs = *closeMsFlag\n",
      "\tconfig.Binary = *binaryFlag\n",
      "\tconfig.ReverseLookup = *reverseLookupFlag\n",
      "\tconfig.Ssl = *sslFlag\n",
      "\tconfig.ScriptDir = *scriptDirFlag\n",
      "\tconfig.StaticDir = *staticDirFlag\n",
      "\tconfig.CgiDir = *cgiDirFlag\n",
      "\tconfig.DevConsole = *devConsoleFlag\n",
      "\tconfig.StartupTime = time.Now()\n",
      "\tconfig.ServerSoftware = fmt.Sprintf(\"websocketd/%s\", Version())\n",
      "\tconfig.HandshakeTimeout = time.Millisecond * 1500\n",
      "\tif len(os.Args) == 1 {\n",
      "\t\tfmt.Printf(\"Command line arguments are missing.\\n\")\n",
      "\t\tShortHelp()\n",
      "\t\tos.Exit(1)\n",
      "\t}\n",
      "\tif *versionFlag {\n",
      "\t\tfmt.Printf(\"%s %s\\n\", HelpProcessName(), Version())\n",
      "\t\tos.Exit(0)\n",
      "\t}\n",
      "\tif *licenseFlag {\n",
      "\t\tfmt.Printf(\"%s %s\\n\", HelpProcessName(), Version())\n",
      "\t\tfmt.Printf(\"%s\\n\", libwebsocketd.License)\n",
      "\t\tos.Exit(0)\n",
      "\t}\n",
      "\tif config.Ssl {\n",
      "\t\tif *sslCert == \"\" || *sslKey == \"\" {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Please specify both --sslcert and --sslkey when requesting --ssl.\\n\")\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tif *sslCert != \"\" || *sslKey != \"\" {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"You should not be using --ssl* flags when there is no --ssl option.\\n\")\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t}\n",
      "\tmainConfig.CertFile = *sslCert\n",
      "\tmainConfig.KeyFile = *sslKey\n",
      "\tconfig.ParentEnv = make([]string, 0)\n",
      "\tnewlineCleaner := strings.NewReplacer(\"\\n\", \" \", \"\\r\", \" \")\n",
      "\tfor _, key := range strings.Split(*passEnvFlag, \",\") {\n",
      "\t\tif key != \"HTTPS\" {\n",
      "\t\t\tif v := os.Getenv(key); v != \"\" {\n",
      "\t\t\t\tif clean := strings.TrimSpace(newlineCleaner.Replace(v)); clean != \"\" {\n",
      "\t\t\t\t\tconfig.ParentEnv = append(config.ParentEnv, fmt.Sprintf(\"%s=%s\", key, clean))\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif *allowOriginsFlag != \"\" {\n",
      "\t\tconfig.AllowOrigins = strings.Split(*allowOriginsFlag, \",\")\n",
      "\t}\n",
      "\tconfig.SameOrigin = *sameOriginFlag\n",
      "\targs := flag.Args()\n",
      "\tif len(args) < 1 && config.ScriptDir == \"\" && config.StaticDir == \"\" && config.CgiDir == \"\" {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"Please specify COMMAND or provide --dir, --staticdir or --cgidir argument.\\n\")\n",
      "\t\tShortHelp()\n",
      "\t\tos.Exit(1)\n",
      "\t}\n",
      "\tif len(args) > 0 {\n",
      "\t\tif config.ScriptDir != \"\" {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Ambiguous. Provided COMMAND and --dir argument. Please only specify just one.\\n\")\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t\tif path, err := exec.LookPath(args[0]); err == nil {\n",
      "\t\t\tconfig.CommandName = path\n",
      "\t\t\tconfig.CommandArgs = flag.Args()[1:]\n",
      "\t\t\tconfig.UsingScriptDir = false\n",
      "\t\t} else {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Unable to locate specified COMMAND '%s' in OS path.\\n\", args[0])\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.ScriptDir != \"\" {\n",
      "\t\tscriptDir, err := filepath.Abs(config.ScriptDir)\n",
      "\t\tif err != nil {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Could not resolve absolute path to dir '%s'.\\n\", config.ScriptDir)\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t\tinf, err := os.Stat(scriptDir)\n",
      "\t\tif err != nil {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Could not find your script dir '%s'.\\n\", config.ScriptDir)\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t\tif !inf.IsDir() {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Did you mean to specify COMMAND instead of --dir '%s'?\\n\", config.ScriptDir)\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t} else {\n",
      "\t\t\tconfig.ScriptDir = scriptDir\n",
      "\t\t\tconfig.UsingScriptDir = true\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.CgiDir != \"\" {\n",
      "\t\tif inf, err := os.Stat(config.CgiDir); err != nil || !inf.IsDir() {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Your CGI dir '%s' is not pointing to an accessible directory.\\n\", config.CgiDir)\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.StaticDir != \"\" {\n",
      "\t\tif inf, err := os.Stat(config.StaticDir); err != nil || !inf.IsDir() {\n",
      "\t\t\tfmt.Fprintf(os.Stderr, \"Your static dir '%s' is not pointing to an accessible directory.\\n\", config.StaticDir)\n",
      "\t\t\tShortHelp()\n",
      "\t\t\tos.Exit(1)\n",
      "\t\t}\n",
      "\t}\n",
      "\tmainConfig.Config = &config\n",
      "\treturn &mainConfig\n",
      "}\n",
      "func main() {\n",
      "\tconfig := parseCommandLine()\n",
      "\tlog := libwebsocketd.RootLogScope(config.LogLevel, logfunc)\n",
      "\tif config.DevConsole {\n",
      "\t\tif config.StaticDir != \"\" {\n",
      "\t\t\tlog.Fatal(\"server\", \"Invalid parameters: --devconsole cannot be used with --staticdir. Pick one.\")\n",
      "\t\t\tos.Exit(4)\n",
      "\t\t}\n",
      "\t\tif config.CgiDir != \"\" {\n",
      "\t\t\tlog.Fatal(\"server\", \"Invalid parameters: --devconsole cannot be used with --cgidir. Pick one.\")\n",
      "\t\t\tos.Exit(4)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif runtime.GOOS != \"windows\" {\n",
      "\t\tos.Clearenv()\n",
      "\t}\n",
      "\thandler := libwebsocketd.NewWebsocketdServer(config.Config, log, config.MaxForks)\n",
      "\thttp.Handle(\"/\", handler)\n",
      "\tif config.UsingScriptDir {\n",
      "\t\tlog.Info(\"server\", \"Serving from directory      : %s\", config.ScriptDir)\n",
      "\t} else if config.CommandName != \"\" {\n",
      "\t\tlog.Info(\"server\", \"Serving using application   : %s %s\", config.CommandName, strings.Join(config.CommandArgs, \" \"))\n",
      "\t}\n",
      "\tif config.StaticDir != \"\" {\n",
      "\t\tlog.Info(\"server\", \"Serving static content from : %s\", config.StaticDir)\n",
      "\t}\n",
      "\tif config.CgiDir != \"\" {\n",
      "\t\tlog.Info(\"server\", \"Serving CGI scripts from    : %s\", config.CgiDir)\n",
      "\t}\n",
      "\trejects := make(chan error, 1)\n",
      "\tfor _, addrSingle := range config.Addr {\n",
      "\t\tlog.Info(\"server\", \"Starting WebSocket server   : %s\", handler.TellURL(\"ws\", addrSingle, \"/\"))\n",
      "\t\tif config.DevConsole {\n",
      "\t\t\tlog.Info(\"server\", \"Developer console enabled   : %s\", handler.TellURL(\"http\", addrSingle, \"/\"))\n",
      "\t\t} else if config.StaticDir != \"\" || config.CgiDir != \"\" {\n",
      "\t\t\tlog.Info(\"server\", \"Serving CGI or static files : %s\", handler.TellURL(\"http\", addrSingle, \"/\"))\n",
      "\t\t}\n",
      "\t\tgo func(addr string) {\n",
      "\t\t\tif config.Ssl {\n",
      "\t\t\t\trejects <- http.ListenAndServeTLS(addr, config.CertFile, config.KeyFile, nil)\n",
      "\t\t\t} else {\n",
      "\t\t\t\trejects <- http.ListenAndServe(addr, nil)\n",
      "\t\t\t}\n",
      "\t\t}(addrSingle)\n",
      "\t\tif config.RedirPort != 0 {\n",
      "\t\t\tgo func(addr string) {\n",
      "\t\t\t\tpos := strings.IndexByte(addr, ':')\n",
      "\t\t\t\trediraddr := addr[:pos] + \":\" + strconv.Itoa(config.RedirPort)\n",
      "\t\t\t\tredir := &http.Server{Addr: rediraddr, Handler: http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n",
      "\t\t\t\t\turi := \"https://\"\n",
      "\t\t\t\t\tif !config.Ssl {\n",
      "\t\t\t\t\t\turi = \"http://\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif cpos := strings.IndexByte(r.Host, ':'); cpos > 0 {\n",
      "\t\t\t\t\t\turi += r.Host[:strings.IndexByte(r.Host, ':')] + addr[pos:] + \"/\"\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\turi += r.Host + addr[pos:] + \"/\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\thttp.Redirect(w, r, uri, http.StatusMovedPermanently)\n",
      "\t\t\t\t})}\n",
      "\t\t\t\tlog.Info(\"server\", \"Starting redirect server   : http://%s/\", rediraddr)\n",
      "\t\t\t\trejects <- redir.ListenAndServe()\n",
      "\t\t\t}(addrSingle)\n",
      "\t\t}\n",
      "\t}\n",
      "\terr := <-rejects\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"server\", \"Can't start server: %s\", err)\n",
      "\t\tos.Exit(3)\n",
      "\t}\n",
      "}\n",
      "func checkOrigin(req *http.Request, config *Config, log *LogScope) (err error) {\n",
      "\torigin := req.Header.Get(\"Origin\")\n",
      "\tif origin == \"\" || (origin == \"null\" && config.AllowOrigins == nil) {\n",
      "\t\torigin = \"file:\"\n",
      "\t}\n",
      "\toriginParsed, err := url.ParseRequestURI(origin)\n",
      "\tif err != nil {\n",
      "\t\tlog.Access(\"session\", \"Origin parsing error: %s\", err)\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tlog.Associate(\"origin\", originParsed.String())\n",
      "\tif config.SameOrigin || config.AllowOrigins != nil {\n",
      "\t\toriginServer, originPort, err := tellHostPort(originParsed.Host, originParsed.Scheme == \"https\")\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Access(\"session\", \"Origin hostname parsing error: %s\", err)\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif config.SameOrigin {\n",
      "\t\t\tlocalServer, localPort, err := tellHostPort(req.Host, req.TLS != nil)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlog.Access(\"session\", \"Request hostname parsing error: %s\", err)\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tif originServer != localServer || originPort != localPort {\n",
      "\t\t\t\tlog.Access(\"session\", \"Same origin policy mismatch\")\n",
      "\t\t\t\treturn fmt.Errorf(\"same origin policy violated\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif config.AllowOrigins != nil {\n",
      "\t\t\tmatchFound := false\n",
      "\t\t\tfor _, allowed := range config.AllowOrigins {\n",
      "\t\t\t\tif pos := strings.Index(allowed, \"://\"); pos > 0 {\n",
      "\t\t\t\t\tallowedURL, err := url.Parse(allowed)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif allowedURL.Scheme != originParsed.Scheme {\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tallowed = allowed[pos+3:]\n",
      "\t\t\t\t}\n",
      "\t\t\t\tallowServer, allowPort, err := tellHostPort(allowed, false)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif allowPort == \"80\" && allowed[len(allowed)-3:] != \":80\" {\n",
      "\t\t\t\t\tmatchFound = allowServer == originServer\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tmatchFound = allowServer == originServer && allowPort == originPort\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif matchFound {\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif !matchFound {\n",
      "\t\t\t\tlog.Access(\"session\", \"Origin is not listed in allowed list\")\n",
      "\t\t\t\treturn fmt.Errorf(\"origin list matches were not found\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func appendEnv(env []string, k string, v ...string) []string {\n",
      "\tif len(v) == 0 {\n",
      "\t\treturn env\n",
      "\t}\n",
      "\tvCleaned := make([]string, 0, len(v))\n",
      "\tfor _, val := range v {\n",
      "\t\tvCleaned = append(vCleaned, strings.TrimSpace(headerNewlineToSpace.Replace(val)))\n",
      "\t}\n",
      "\treturn append(env, fmt.Sprintf(\"%s=%s\", strings.ToUpper(k), strings.Join(vCleaned, \", \")))\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "rakyll/hey 2 16914\n",
      "2\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "XIU2/CloudflareSpeedTest 2 15319\n",
      "2\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "topic_2 10\n",
      "prometheus/prometheus 5 51732\n",
      "5\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (r *walReader) entry(cr io.Reader) (WALEntryType, byte, []byte, error) {\n",
      "\tr.crc32.Reset()\n",
      "\ttr := io.TeeReader(cr, r.crc32)\n",
      "\tb := make([]byte, 6)\n",
      "\tswitch n, err := tr.Read(b); {\n",
      "\tcase err != nil:\n",
      "\t\treturn 0, 0, nil, err\n",
      "\tcase n != 6:\n",
      "\t\treturn 0, 0, nil, r.corruptionErr(\"invalid entry header size %d\", n)\n",
      "\t}\n",
      "\tvar (\n",
      "\t\tetype\t= WALEntryType(b[0])\n",
      "\t\tflag\t= b[1]\n",
      "\t\tlength\t= int(binary.BigEndian.Uint32(b[2:]))\n",
      "\t)\n",
      "\tif etype == 0 {\n",
      "\t\treturn 0, 0, nil, io.EOF\n",
      "\t}\n",
      "\tif etype != WALEntrySeries && etype != WALEntrySamples && etype != WALEntryDeletes {\n",
      "\t\treturn 0, 0, nil, r.corruptionErr(\"invalid entry type %d\", etype)\n",
      "\t}\n",
      "\tif length > len(r.buf) {\n",
      "\t\tr.buf = make([]byte, length)\n",
      "\t}\n",
      "\tbuf := r.buf[:length]\n",
      "\tswitch n, err := tr.Read(buf); {\n",
      "\tcase err != nil:\n",
      "\t\treturn 0, 0, nil, err\n",
      "\tcase n != length:\n",
      "\t\treturn 0, 0, nil, r.corruptionErr(\"invalid entry body size %d\", n)\n",
      "\t}\n",
      "\tswitch n, err := cr.Read(b[:4]); {\n",
      "\tcase err != nil:\n",
      "\t\treturn 0, 0, nil, err\n",
      "\tcase n != 4:\n",
      "\t\treturn 0, 0, nil, r.corruptionErr(\"invalid checksum length %d\", n)\n",
      "\t}\n",
      "\tif exp, has := binary.BigEndian.Uint32(b[:4]), r.crc32.Sum32(); has != exp {\n",
      "\t\treturn 0, 0, nil, r.corruptionErr(\"unexpected CRC32 checksum %x, want %x\", has, exp)\n",
      "\t}\n",
      "\treturn etype, flag, buf, nil\n",
      "}\n",
      "func (w *SegmentWAL) writeTo(wr io.Writer, crc32 hash.Hash, t WALEntryType, flag uint8, buf []byte) (int, error) {\n",
      "\tif len(buf) == 0 {\n",
      "\t\treturn 0, nil\n",
      "\t}\n",
      "\tcrc32.Reset()\n",
      "\twr = io.MultiWriter(crc32, wr)\n",
      "\tvar b [6]byte\n",
      "\tb[0] = byte(t)\n",
      "\tb[1] = flag\n",
      "\tbinary.BigEndian.PutUint32(b[2:], uint32(len(buf)))\n",
      "\tn1, err := wr.Write(b[:])\n",
      "\tif err != nil {\n",
      "\t\treturn n1, err\n",
      "\t}\n",
      "\tn2, err := wr.Write(buf)\n",
      "\tif err != nil {\n",
      "\t\treturn n1 + n2, err\n",
      "\t}\n",
      "\tn3, err := wr.Write(crc32.Sum(b[:0]))\n",
      "\treturn n1 + n2 + n3, err\n",
      "}\n",
      "func (r *walReader) next() bool {\n",
      "\tif r.cur >= len(r.files) {\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tcf := r.files[r.cur]\n",
      "\tr.lastOffset, r.err = cf.Seek(0, io.SeekCurrent)\n",
      "\tif r.err != nil {\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tet, flag, b, err := r.entry(cf)\n",
      "\tif errors.Is(err, io.EOF) {\n",
      "\t\tif r.cur == len(r.files)-1 {\n",
      "\t\t\treturn false\n",
      "\t\t}\n",
      "\t\tif err := cf.Close(); err != nil {\n",
      "\t\t\tr.err = err\n",
      "\t\t\treturn false\n",
      "\t\t}\n",
      "\t\tr.cur++\n",
      "\t\treturn r.next()\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\tr.err = err\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tr.curType = et\n",
      "\tr.curFlag = flag\n",
      "\tr.curBuf = b\n",
      "\treturn r.err == nil\n",
      "}\n",
      "func (w *SegmentWAL) LogDeletes(stones []tombstones.Stone) error {\n",
      "\tbuf := w.getBuffer()\n",
      "\tflag := w.encodeDeletes(buf, stones)\n",
      "\tw.mtx.Lock()\n",
      "\tdefer w.mtx.Unlock()\n",
      "\terr := w.write(WALEntryDeletes, flag, buf.Get())\n",
      "\tw.putBuffer(buf)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"log series: %w\", err)\n",
      "\t}\n",
      "\ttf := w.head()\n",
      "\tfor _, s := range stones {\n",
      "\t\tfor _, iv := range s.Intervals {\n",
      "\t\t\tif tf.maxTime < iv.Maxt {\n",
      "\t\t\t\ttf.maxTime = iv.Maxt\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (w *SegmentWAL) Truncate(mint int64, keep func(chunks.HeadSeriesRef) bool) error {\n",
      "\tif len(w.files) < 2 {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tvar candidates []*segmentFile\n",
      "\tfor _, sf := range w.files[:len(w.files)-1] {\n",
      "\t\tif sf.maxTime >= mint {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tf, err := w.openSegmentFile(sf.Name())\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"open old WAL segment for read: %w\", err)\n",
      "\t\t}\n",
      "\t\tcandidates = append(candidates, &segmentFile{File: f, minSeries: sf.minSeries, maxTime: sf.maxTime})\n",
      "\t}\n",
      "\tif len(candidates) == 0 {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tr := newWALReader(candidates, w.logger)\n",
      "\tf, err := w.createSegmentFile(filepath.Join(w.dirFile.Name(), \"compact.tmp\"))\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"create compaction segment: %w\", err)\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\tif err := os.RemoveAll(f.Name()); err != nil {\n",
      "\t\t\tlevel.Error(w.logger).Log(\"msg\", \"remove tmp file\", \"err\", err.Error())\n",
      "\t\t}\n",
      "\t}()\n",
      "\tvar (\n",
      "\t\tcsf\t\t= newSegmentFile(f)\n",
      "\t\tcrc32\t\t= newCRC32()\n",
      "\t\tdecSeries\t= []record.RefSeries{}\n",
      "\t\tactiveSeries\t= []record.RefSeries{}\n",
      "\t)\n",
      "\tfor r.next() {\n",
      "\t\trt, flag, byt := r.at()\n",
      "\t\tif rt != WALEntrySeries {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tdecSeries = decSeries[:0]\n",
      "\t\tactiveSeries = activeSeries[:0]\n",
      "\t\terr := r.decodeSeries(flag, byt, &decSeries)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"decode samples while truncating: %w\", err)\n",
      "\t\t}\n",
      "\t\tfor _, s := range decSeries {\n",
      "\t\t\tif keep(s.Ref) {\n",
      "\t\t\t\tactiveSeries = append(activeSeries, s)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tbuf := w.getBuffer()\n",
      "\t\tflag = w.encodeSeries(buf, activeSeries)\n",
      "\t\t_, err = w.writeTo(csf, crc32, WALEntrySeries, flag, buf.Get())\n",
      "\t\tw.putBuffer(buf)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"write to compaction segment: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := r.Err(); err != nil {\n",
      "\t\treturn fmt.Errorf(\"read candidate WAL files: %w\", err)\n",
      "\t}\n",
      "\toff, err := csf.Seek(0, io.SeekCurrent)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := csf.Truncate(off); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := csf.Sync(); err != nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif err := csf.Close(); err != nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\t_ = candidates[0].Close()\n",
      "\tif err := fileutil.Replace(csf.Name(), candidates[0].Name()); err != nil {\n",
      "\t\treturn fmt.Errorf(\"rename compaction segment: %w\", err)\n",
      "\t}\n",
      "\tfor _, f := range candidates[1:] {\n",
      "\t\tf.Close()\n",
      "\t\tif err := os.RemoveAll(f.Name()); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"delete WAL segment file: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := w.dirFile.Sync(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tcsf.File, err = w.openSegmentFile(candidates[0].Name())\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := csf.Close(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tw.mtx.Lock()\n",
      "\tw.files = append([]*segmentFile{csf}, w.files[len(candidates):]...)\n",
      "\tw.mtx.Unlock()\n",
      "\treturn nil\n",
      "}\n",
      "func (w *SegmentWAL) write(t WALEntryType, flag uint8, buf []byte) error {\n",
      "\tvar (\n",
      "\t\tsz\t= int64(len(buf)) + 6\n",
      "\t\tnewsz\t= w.curN + sz\n",
      "\t)\n",
      "\tif w.cur == nil || w.curN > w.segmentSize || newsz > w.segmentSize && sz <= w.segmentSize {\n",
      "\t\tif err := w.cut(); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tn, err := w.writeTo(w.cur, w.crc32, t, flag, buf)\n",
      "\tw.curN += int64(n)\n",
      "\treturn err\n",
      "}\n",
      "func (w *SegmentWAL) LogSeries(series []record.RefSeries) error {\n",
      "\tbuf := w.getBuffer()\n",
      "\tflag := w.encodeSeries(buf, series)\n",
      "\tw.mtx.Lock()\n",
      "\tdefer w.mtx.Unlock()\n",
      "\terr := w.write(WALEntrySeries, flag, buf.Get())\n",
      "\tw.putBuffer(buf)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"log series: %w\", err)\n",
      "\t}\n",
      "\ttf := w.head()\n",
      "\tfor _, s := range series {\n",
      "\t\tif tf.minSeries > s.Ref {\n",
      "\t\t\ttf.minSeries = s.Ref\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (w *SegmentWAL) LogSamples(samples []record.RefSample) error {\n",
      "\tbuf := w.getBuffer()\n",
      "\tflag := w.encodeSamples(buf, samples)\n",
      "\tw.mtx.Lock()\n",
      "\tdefer w.mtx.Unlock()\n",
      "\terr := w.write(WALEntrySamples, flag, buf.Get())\n",
      "\tw.putBuffer(buf)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"log series: %w\", err)\n",
      "\t}\n",
      "\ttf := w.head()\n",
      "\tfor _, s := range samples {\n",
      "\t\tif tf.maxTime < s.T {\n",
      "\t\t\ttf.maxTime = s.T\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "rclone/rclone 6 42712\n",
      "6\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func attemptCopyGroup(fromPath, toPath string) {\n",
      "\tinfo, err := os.Stat(fromPath)\n",
      "\tif err != nil || info.Sys() == nil {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif stat, ok := info.Sys().(*syscall.Stat_t); ok {\n",
      "\t\tuid := int(stat.Uid)\n",
      "\t\tif user, err := user.Current(); err == nil {\n",
      "\t\t\tif tmpUID, err := strconv.Atoi(user.Uid); err == nil {\n",
      "\t\t\t\tuid = tmpUID\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err = os.Chown(toPath, uid, int(stat.Gid)); err != nil {\n",
      "\t\t\tfs.Debugf(nil, \"Failed to keep previous owner of config file: %v\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "hashicorp/terraform 6 40408\n",
      "6\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func ParseUndeclaredVariableValues(vv map[string]UnparsedVariableValue, decls map[string]*configs.Variable) (terraform.InputValues, tfdiags.Diagnostics) {\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tret := make(terraform.InputValues, len(vv))\n",
      "\tseenUndeclaredInFile := 0\n",
      "\tfor name, rv := range vv {\n",
      "\t\tif _, declared := decls[name]; declared {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tval, valDiags := rv.ParseVariableValue(configs.VariableParseLiteral)\n",
      "\t\tif valDiags.HasErrors() {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tret[name] = val\n",
      "\t\tswitch val.SourceType {\n",
      "\t\tcase terraform.ValueFromConfig, terraform.ValueFromAutoFile, terraform.ValueFromNamedFile:\n",
      "\t\t\tif seenUndeclaredInFile < 2 {\n",
      "\t\t\t\tdiags = diags.Append(tfdiags.Sourceless(tfdiags.Warning, \"Value for undeclared variable\", fmt.Sprintf(\"The root module does not declare a variable named %q but a value was found in file %q. If you meant to use this value, add a \\\"variable\\\" block to the configuration.\\n\\nTo silence these warnings, use TF_VAR_... environment variables to provide certain \\\"global\\\" settings to all configurations in your organization. To reduce the verbosity of these warnings, use the -compact-warnings option.\", name, val.SourceRange.Filename)))\n",
      "\t\t\t}\n",
      "\t\t\tseenUndeclaredInFile++\n",
      "\t\tcase terraform.ValueFromEnvVar:\n",
      "\t\tcase terraform.ValueFromCLIArg:\n",
      "\t\t\tdiags = diags.Append(tfdiags.Sourceless(tfdiags.Error, \"Value for undeclared variable\", fmt.Sprintf(\"A variable named %q was assigned on the command line, but the root module does not declare a variable of that name. To use this value, add a \\\"variable\\\" block to the configuration.\", name)))\n",
      "\t\tdefault:\n",
      "\t\t\tdiags = diags.Append(tfdiags.Sourceless(tfdiags.Error, \"Value for undeclared variable\", fmt.Sprintf(\"A variable named %q was assigned a value, but the root module does not declare a variable of that name. To use this value, add a \\\"variable\\\" block to the configuration.\", name)))\n",
      "\t\t}\n",
      "\t}\n",
      "\tif seenUndeclaredInFile > 2 {\n",
      "\t\textras := seenUndeclaredInFile - 2\n",
      "\t\tdiags = diags.Append(&hcl.Diagnostic{Severity: hcl.DiagWarning, Summary: \"Values for undeclared variables\", Detail: fmt.Sprintf(\"In addition to the other similar warnings shown, %d other variable(s) defined without being declared.\", extras)})\n",
      "\t}\n",
      "\treturn ret, diags\n",
      "}\n",
      "func loadProvisionerSchemas(schemas map[string]*configschema.Block, config *configs.Config, plugins *contextPlugins) tfdiags.Diagnostics {\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tensure := func(name string) {\n",
      "\t\tif _, exists := schemas[name]; exists {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[TRACE] LoadSchemas: retrieving schema for provisioner %q\", name)\n",
      "\t\tschema, err := plugins.ProvisionerSchema(name)\n",
      "\t\tif err != nil {\n",
      "\t\t\tschemas[name] = &configschema.Block{}\n",
      "\t\t\tdiags = diags.Append(tfdiags.Sourceless(tfdiags.Error, \"Failed to obtain provisioner schema\", fmt.Sprintf(\"Could not load the schema for provisioner %q: %s.\", name, err)))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tschemas[name] = schema\n",
      "\t}\n",
      "\tif config != nil {\n",
      "\t\tfor _, rc := range config.Module.ManagedResources {\n",
      "\t\t\tfor _, pc := range rc.Managed.Provisioners {\n",
      "\t\t\t\tensure(pc.Type)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor _, cc := range config.Children {\n",
      "\t\t\tchildDiags := loadProvisionerSchemas(schemas, cc, plugins)\n",
      "\t\t\tdiags = diags.Append(childDiags)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "func loadProviderSchemas(schemas map[addrs.Provider]*ProviderSchema, config *configs.Config, state *states.State, components contextComponentFactory) tfdiags.Diagnostics {\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tensure := func(fqn addrs.Provider) {\n",
      "\t\tname := fqn.String()\n",
      "\t\tif _, exists := schemas[fqn]; exists {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[TRACE] LoadSchemas: retrieving schema for provider type %q\", name)\n",
      "\t\tprovider, err := components.ResourceProvider(fqn)\n",
      "\t\tif err != nil {\n",
      "\t\t\tschemas[fqn] = &ProviderSchema{}\n",
      "\t\t\tdiags = diags.Append(fmt.Errorf(\"Failed to instantiate provider %q to obtain schema: %s\", name, err))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tdefer func() {\n",
      "\t\t\tprovider.Close()\n",
      "\t\t}()\n",
      "\t\tresp := provider.GetProviderSchema()\n",
      "\t\tif resp.Diagnostics.HasErrors() {\n",
      "\t\t\tschemas[fqn] = &ProviderSchema{}\n",
      "\t\t\tdiags = diags.Append(fmt.Errorf(\"Failed to retrieve schema from provider %q: %s\", name, resp.Diagnostics.Err()))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\ts := &ProviderSchema{Provider: resp.Provider.Block, ResourceTypes: make(map[string]*configschema.Block), DataSources: make(map[string]*configschema.Block), ResourceTypeSchemaVersions: make(map[string]uint64)}\n",
      "\t\tif resp.Provider.Version < 0 {\n",
      "\t\t\tdiags = diags.Append(fmt.Errorf(\"invalid negative schema version provider configuration for provider %q\", name))\n",
      "\t\t}\n",
      "\t\tfor t, r := range resp.ResourceTypes {\n",
      "\t\t\ts.ResourceTypes[t] = r.Block\n",
      "\t\t\ts.ResourceTypeSchemaVersions[t] = uint64(r.Version)\n",
      "\t\t\tif r.Version < 0 {\n",
      "\t\t\t\tdiags = diags.Append(fmt.Errorf(\"invalid negative schema version for resource type %s in provider %q\", t, name))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor t, d := range resp.DataSources {\n",
      "\t\t\ts.DataSources[t] = d.Block\n",
      "\t\t\tif d.Version < 0 {\n",
      "\t\t\t\tdiags = diags.Append(fmt.Errorf(\"invalid negative schema version for data source %s in provider %q\", t, name))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tschemas[fqn] = s\n",
      "\t\tif resp.ProviderMeta.Block != nil {\n",
      "\t\t\ts.ProviderMeta = resp.ProviderMeta.Block\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config != nil {\n",
      "\t\tfor _, fqn := range config.ProviderTypes() {\n",
      "\t\t\tensure(fqn)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif state != nil {\n",
      "\t\tneeded := providers.AddressedTypesAbs(state.ProviderAddrs())\n",
      "\t\tfor _, typeAddr := range needed {\n",
      "\t\t\tensure(typeAddr)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "func loadProvisionerSchemas(schemas map[string]*configschema.Block, config *configs.Config, components contextComponentFactory) tfdiags.Diagnostics {\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tensure := func(name string) {\n",
      "\t\tif _, exists := schemas[name]; exists {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[TRACE] LoadSchemas: retrieving schema for provisioner %q\", name)\n",
      "\t\tprovisioner, err := components.ResourceProvisioner(name)\n",
      "\t\tif err != nil {\n",
      "\t\t\tschemas[name] = &configschema.Block{}\n",
      "\t\t\tdiags = diags.Append(fmt.Errorf(\"Failed to instantiate provisioner %q to obtain schema: %s\", name, err))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tdefer func() {\n",
      "\t\t\tif closer, ok := provisioner.(ResourceProvisionerCloser); ok {\n",
      "\t\t\t\tcloser.Close()\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tresp := provisioner.GetSchema()\n",
      "\t\tif resp.Diagnostics.HasErrors() {\n",
      "\t\t\tschemas[name] = &configschema.Block{}\n",
      "\t\t\tdiags = diags.Append(fmt.Errorf(\"Failed to retrieve schema from provisioner %q: %s\", name, resp.Diagnostics.Err()))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tschemas[name] = resp.Provisioner\n",
      "\t}\n",
      "\tif config != nil {\n",
      "\t\tfor _, rc := range config.Module.ManagedResources {\n",
      "\t\t\tfor _, pc := range rc.Managed.Provisioners {\n",
      "\t\t\t\tensure(pc.Type)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor _, cc := range config.Children {\n",
      "\t\t\tchildDiags := loadProvisionerSchemas(schemas, cc, components)\n",
      "\t\t\tdiags = diags.Append(childDiags)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "func CheckCoreVersionRequirements(config *configs.Config) tfdiags.Diagnostics {\n",
      "\tif config == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tdiags = diags.Append(config.CheckCoreVersionRequirements())\n",
      "\treturn diags\n",
      "}\n",
      "func globalPluginDirs() []string {\n",
      "\tvar ret []string\n",
      "\tdir, err := cliconfig.ConfigDir()\n",
      "\tif err != nil {\n",
      "\t\tlog.Printf(\"[ERROR] Error finding global config directory: %s\", err)\n",
      "\t} else {\n",
      "\t\tmachineDir := fmt.Sprintf(\"%s_%s\", runtime.GOOS, runtime.GOARCH)\n",
      "\t\tret = append(ret, filepath.Join(dir, \"plugins\"))\n",
      "\t\tret = append(ret, filepath.Join(dir, \"plugins\", machineDir))\n",
      "\t}\n",
      "\treturn ret\n",
      "}\n",
      "func loadProviderSchemas(schemas map[addrs.Provider]providers.ProviderSchema, config *configs.Config, state *states.State, plugins *contextPlugins) tfdiags.Diagnostics {\n",
      "\tvar diags tfdiags.Diagnostics\n",
      "\tensure := func(fqn addrs.Provider) {\n",
      "\t\tname := fqn.String()\n",
      "\t\tif _, exists := schemas[fqn]; exists {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[TRACE] LoadSchemas: retrieving schema for provider type %q\", name)\n",
      "\t\tschema, err := plugins.ProviderSchema(fqn)\n",
      "\t\tif err != nil {\n",
      "\t\t\tschemas[fqn] = providers.ProviderSchema{}\n",
      "\t\t\tdiags = diags.Append(tfdiags.Sourceless(tfdiags.Error, \"Failed to obtain provider schema\", fmt.Sprintf(\"Could not load the schema for provider %s: %s.\", fqn, err)))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tschemas[fqn] = schema\n",
      "\t}\n",
      "\tif config != nil {\n",
      "\t\tfor _, fqn := range config.ProviderTypes() {\n",
      "\t\t\tensure(fqn)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif state != nil {\n",
      "\t\tneeded := providers.AddressedTypesAbs(state.ProviderAddrs())\n",
      "\t\tfor _, typeAddr := range needed {\n",
      "\t\t\tensure(typeAddr)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "hashicorp/vault 703 29289\n",
      "703\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (d *Delegate) AutopilotConfig() *autopilot.Config {\n",
      "\td.l.RLock()\n",
      "\tconfig := &autopilot.Config{CleanupDeadServers: d.autopilotConfig.CleanupDeadServers, LastContactThreshold: d.autopilotConfig.LastContactThreshold, MaxTrailingLogs: d.autopilotConfig.MaxTrailingLogs, MinQuorum: d.autopilotConfig.MinQuorum, ServerStabilizationTime: d.autopilotConfig.ServerStabilizationTime, Ext: d.autopilotConfigExt()}\n",
      "\td.l.RUnlock()\n",
      "\treturn config\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *DebugCommand) captureStaticTargets() error {\n",
      "\tif strutil.StrListContains(c.flagTargets, \"config\") {\n",
      "\t\tc.logger.Info(\"capturing configuration state\")\n",
      "\t\tresp, err := c.cachedClient.Logical().Read(\"sys/config/state/sanitized\")\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.captureError(\"config\", err)\n",
      "\t\t\tc.logger.Error(\"config: error capturing config state\", \"error\", err)\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tif resp != nil && resp.Data != nil {\n",
      "\t\t\tcollection := []map[string]interface{}{{\"timestamp\": time.Now().UTC(), \"config\": resp.Data}}\n",
      "\t\t\tif err := c.persistCollection(collection, \"config.json\"); err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error writing data to %s: %v\", \"config.json\", err))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (a *ActivityLog) loadConfigOrDefault(ctx context.Context) (activityConfig, error) {\n",
      "\tvar config activityConfig\n",
      "\tconfigRaw, err := a.view.Get(ctx, activityConfigKey)\n",
      "\tif err != nil {\n",
      "\t\treturn config, err\n",
      "\t}\n",
      "\tif configRaw == nil {\n",
      "\t\treturn defaultActivityConfig(), nil\n",
      "\t}\n",
      "\tif err := configRaw.DecodeJSON(&config); err != nil {\n",
      "\t\treturn config, err\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func getAcmeRoleAndIssuer(sc *storageContext, data *framework.FieldData, config *acmeConfigEntry) (*issuing.RoleEntry, *issuing.IssuerEntry, error) {\n",
      "\trequestedIssuer := getRequestedAcmeIssuerFromPath(data)\n",
      "\trequestedRole := getRequestedAcmeRoleFromPath(data)\n",
      "\tissuerToLoad := requestedIssuer\n",
      "\tvar role *issuing.RoleEntry\n",
      "\tvar err error\n",
      "\tif len(requestedRole) == 0 {\n",
      "\t\tpolicyType, extraInfo, err := getDefaultDirectoryPolicyType(config.DefaultDirectoryPolicy)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tswitch policyType {\n",
      "\t\tcase Forbid:\n",
      "\t\t\treturn nil, nil, fmt.Errorf(\"%w: default directory not allowed by ACME policy\", ErrServerInternal)\n",
      "\t\tcase SignVerbatim, ExternalPolicy:\n",
      "\t\t\trole = issuing.SignVerbatimRoleWithOpts(issuing.WithIssuer(requestedIssuer), issuing.WithNoStore(false))\n",
      "\t\tcase Role:\n",
      "\t\t\trole, err = getAndValidateAcmeRole(sc, extraInfo)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, nil, err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\trole, err = getAndValidateAcmeRole(sc, requestedRole)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tallowAnyRole := len(config.AllowedRoles) == 1 && config.AllowedRoles[0] == \"*\"\n",
      "\t\tif !allowAnyRole {\n",
      "\t\t\tvar foundRole bool\n",
      "\t\t\tfor _, name := range config.AllowedRoles {\n",
      "\t\t\t\tif name == role.Name {\n",
      "\t\t\t\t\tfoundRole = true\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif !foundRole {\n",
      "\t\t\t\treturn nil, nil, fmt.Errorf(\"%w: specified role not allowed by ACME policy\", ErrServerInternal)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(role.Issuer) > 0 && len(requestedIssuer) == 0 {\n",
      "\t\tissuerToLoad = role.Issuer\n",
      "\t}\n",
      "\tissuer, err := getAcmeIssuer(sc, issuerToLoad)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tallowAnyIssuer := len(config.AllowedIssuers) == 1 && config.AllowedIssuers[0] == \"*\"\n",
      "\tif !allowAnyIssuer {\n",
      "\t\tvar foundIssuer bool\n",
      "\t\tfor index, name := range config.AllowedIssuers {\n",
      "\t\t\tcandidateId, err := sc.resolveIssuerReference(name)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to resolve reference for allowed_issuer entry %d: %w\", index, err)\n",
      "\t\t\t}\n",
      "\t\t\tif candidateId == issuer.ID {\n",
      "\t\t\t\tfoundIssuer = true\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !foundIssuer {\n",
      "\t\t\treturn nil, nil, fmt.Errorf(\"%w: specified issuer not allowed by ACME policy\", ErrServerInternal)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !config.AllowRoleExtKeyUsage {\n",
      "\t\trole.ExtKeyUsage = []string{\"serverauth\"}\n",
      "\t\trole.ExtKeyUsageOIDs = []string{}\n",
      "\t\trole.ServerFlag = true\n",
      "\t\trole.ClientFlag = false\n",
      "\t\trole.CodeSigningFlag = false\n",
      "\t\trole.EmailProtectionFlag = false\n",
      "\t}\n",
      "\treturn role, issuer, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Core) SetSeals(barrierSeal Seal, secureRandomReader io.Reader, shouldRewrap bool) error {\n",
      "\tctx, _ := c.GetContext()\n",
      "\tc.stateLock.Lock()\n",
      "\tdefer c.stateLock.Unlock()\n",
      "\tcurrentSealBarrierConfig, err := c.SealAccess().BarrierConfig(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error retrieving barrier config: %s\", err)\n",
      "\t}\n",
      "\tbarrierConfigCopy := currentSealBarrierConfig.Clone()\n",
      "\tbarrierConfigCopy.Type = barrierSeal.BarrierSealConfigType().String()\n",
      "\tbarrierSeal.SetCore(c)\n",
      "\trootKey, err := c.seal.GetStoredKeys(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif len(rootKey) < 1 {\n",
      "\t\treturn errors.New(\"root key not found\")\n",
      "\t}\n",
      "\tbarrierConfigCopy.Type = barrierSeal.BarrierSealConfigType().String()\n",
      "\terr = barrierSeal.SetBarrierConfig(ctx, barrierConfigCopy)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error setting barrier config for new seal: %s\", err)\n",
      "\t}\n",
      "\terr = barrierSeal.SetStoredKeys(ctx, rootKey)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error setting root key in new seal: %s\", err)\n",
      "\t}\n",
      "\tc.seal = barrierSeal\n",
      "\tc.reloadSealsEnt(secureRandomReader, barrierSeal, c.logger, shouldRewrap)\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (sd *SignedData) AddSignerChain(ee *x509.Certificate, pkey crypto.PrivateKey, parents []*x509.Certificate, config SignerInfoConfig) error {\n",
      "\tvar ias issuerAndSerial\n",
      "\tias.SerialNumber = ee.SerialNumber\n",
      "\tif len(parents) == 0 {\n",
      "\t\tias.IssuerName = asn1.RawValue{FullBytes: ee.RawIssuer}\n",
      "\t} else {\n",
      "\t\terr := verifyPartialChain(ee, parents)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tias.IssuerName = asn1.RawValue{FullBytes: parents[0].RawSubject}\n",
      "\t}\n",
      "\tsd.sd.DigestAlgorithmIdentifiers = append(sd.sd.DigestAlgorithmIdentifiers, pkix.AlgorithmIdentifier{Algorithm: sd.digestOid})\n",
      "\thash, err := getHashForOID(sd.digestOid)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\th := hash.New()\n",
      "\th.Write(sd.data)\n",
      "\tsd.messageDigest = h.Sum(nil)\n",
      "\tencryptionOid, err := getOIDForEncryptionAlgorithm(pkey, sd.digestOid)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tattrs := &attributes{}\n",
      "\tattrs.Add(OIDAttributeContentType, sd.sd.ContentInfo.ContentType)\n",
      "\tattrs.Add(OIDAttributeMessageDigest, sd.messageDigest)\n",
      "\tattrs.Add(OIDAttributeSigningTime, time.Now().UTC())\n",
      "\tfor _, attr := range config.ExtraSignedAttributes {\n",
      "\t\tattrs.Add(attr.Type, attr.Value)\n",
      "\t}\n",
      "\tfinalAttrs, err := attrs.ForMarshalling()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tunsignedAttrs := &attributes{}\n",
      "\tfor _, attr := range config.ExtraUnsignedAttributes {\n",
      "\t\tunsignedAttrs.Add(attr.Type, attr.Value)\n",
      "\t}\n",
      "\tfinalUnsignedAttrs, err := unsignedAttrs.ForMarshalling()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tsignature, err := signAttributes(finalAttrs, pkey, hash)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tsigner := signerInfo{AuthenticatedAttributes: finalAttrs, UnauthenticatedAttributes: finalUnsignedAttrs, DigestAlgorithm: pkix.AlgorithmIdentifier{Algorithm: sd.digestOid}, DigestEncryptionAlgorithm: pkix.AlgorithmIdentifier{Algorithm: encryptionOid}, IssuerAndSerialNumber: ias, EncryptedDigest: signature, Version: 1}\n",
      "\tsd.certs = append(sd.certs, ee)\n",
      "\tif len(parents) > 0 {\n",
      "\t\tsd.certs = append(sd.certs, parents...)\n",
      "\t}\n",
      "\tsd.sd.SignerInfos = append(sd.sd.SignerInfos, signer)\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *BackendTracingMiddleware) Setup(ctx context.Context, config *logical.BackendConfig) (err error) {\n",
      "\tdefer func(then time.Time) {\n",
      "\t\tb.logger.Trace(\"setup\", \"status\", \"finished\", \"err\", err, \"took\", time.Since(then))\n",
      "\t}(time.Now())\n",
      "\tb.logger.Trace(\"setup\", \"status\", \"started\")\n",
      "\treturn b.next.Setup(ctx, config)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *AuthEnableCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"description\", Target: &c.flagDescription, Completion: complete.PredictAnything, Usage: \"Human-friendly description for the purpose of this \" + \"auth method.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"path\", Target: &c.flagPath, Default: \"\", Completion: complete.PredictAnything, Usage: \"Place where the auth method will be accessible. This must be \" + \"unique across all auth methods. This defaults to the \\\"type\\\" of \" + \"the auth method. The auth method will be accessible at \" + \"\\\"/auth/<path>\\\".\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"default-lease-ttl\", Target: &c.flagDefaultLeaseTTL, Completion: complete.PredictAnything, Usage: \"The default lease TTL for this auth method. If unspecified, \" + \"this defaults to the Vault server's globally configured default lease \" + \"TTL.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"max-lease-ttl\", Target: &c.flagMaxLeaseTTL, Completion: complete.PredictAnything, Usage: \"The maximum lease TTL for this auth method. If unspecified, \" + \"this defaults to the Vault server's globally configured maximum lease \" + \"TTL.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACRequestKeys, Target: &c.flagAuditNonHMACRequestKeys, Usage: \"Key that will not be HMAC'd by audit devices in the request data object. \" + \"To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACResponseKeys, Target: &c.flagAuditNonHMACResponseKeys, Usage: \"Key that will not be HMAC'd by audit devices in the response data object. \" + \"To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameListingVisibility, Target: &c.flagListingVisibility, Usage: \"Determines the visibility of the mount in the UI-specific listing endpoint.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNamePassthroughRequestHeaders, Target: &c.flagPassthroughRequestHeaders, Usage: \"Request header value that will be sent to the plugin. To specify multiple \" + \"values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedResponseHeaders, Target: &c.flagAllowedResponseHeaders, Usage: \"Response header value that plugins will be allowed to set. To specify multiple \" + \"values, specify this flag multiple times.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"plugin-name\", Target: &c.flagPluginName, Completion: c.PredictVaultPlugins(api.PluginTypeCredential), Usage: \"Name of the auth method plugin. This plugin name must already \" + \"exist in the Vault server's plugin catalog.\"})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"options\", Target: &c.flagOptions, Completion: complete.PredictAnything, Usage: \"Key-value pair provided as key=value for the mount options. \" + \"This can be specified multiple times.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"local\", Target: &c.flagLocal, Default: false, Usage: \"Mark the auth method as local-only. Local auth methods are \" + \"not replicated nor removed by replication.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"seal-wrap\", Target: &c.flagSealWrap, Default: false, Usage: \"Enable seal wrapping of critical values in the secrets engine.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"external-entropy-access\", Target: &c.flagExternalEntropyAccess, Default: false, Usage: \"Enable auth method to access Vault's external entropy source.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameTokenType, Target: &c.flagTokenType, Usage: \"Sets a forced token type for the mount.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Default: 0, Usage: \"Select the version of the auth method to run. Not supported by all auth methods.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNamePluginVersion, Target: &c.flagPluginVersion, Default: \"\", Usage: \"Select the semantic version of the plugin to enable.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameIdentityTokenKey, Target: &c.flagIdentityTokenKey, Default: \"default\", Usage: \"Select the key used to sign plugin identity tokens.\"})\n",
      "\treturn set\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *SystemBackend) handleStorageRaftAutopilotConfigUpdate() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\t\traftBackend := b.Core.getRaftBackend()\n",
      "\t\tif raftBackend == nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"raft storage is not in use\"), logical.ErrInvalidRequest\n",
      "\t\t}\n",
      "\t\tconfig, err := b.Core.loadAutopilotConfiguration(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tb.logger.Error(\"failed to load autopilot config from storage when setting up cluster; continuing since autopilot falls back to default config\", \"error\", err)\n",
      "\t\t}\n",
      "\t\tif config == nil {\n",
      "\t\t\tconfig = &raft.AutopilotConfig{}\n",
      "\t\t}\n",
      "\t\tpersist := false\n",
      "\t\tcleanupDeadServers, ok := d.GetOk(\"cleanup_dead_servers\")\n",
      "\t\tif ok {\n",
      "\t\t\tif cleanupDeadServers.(bool) {\n",
      "\t\t\t\tconfig.CleanupDeadServersValue = raft.CleanupDeadServersTrue\n",
      "\t\t\t} else {\n",
      "\t\t\t\tconfig.CleanupDeadServersValue = raft.CleanupDeadServersFalse\n",
      "\t\t\t}\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tlastContactThreshold, ok := d.GetOk(\"last_contact_threshold\")\n",
      "\t\tif ok {\n",
      "\t\t\tconfig.LastContactThreshold = time.Duration(lastContactThreshold.(int)) * time.Second\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tdeadServerLastContactThreshold, ok := d.GetOk(\"dead_server_last_contact_threshold\")\n",
      "\t\tif ok {\n",
      "\t\t\tconfig.DeadServerLastContactThreshold = time.Duration(deadServerLastContactThreshold.(int)) * time.Second\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tmaxTrailingLogs, ok := d.GetOk(\"max_trailing_logs\")\n",
      "\t\tif ok {\n",
      "\t\t\tconfig.MaxTrailingLogs = uint64(maxTrailingLogs.(int))\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tminQuorum, ok := d.GetOk(\"min_quorum\")\n",
      "\t\tif ok {\n",
      "\t\t\tconfig.MinQuorum = uint(minQuorum.(int))\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tserverStabilizationTime, ok := d.GetOk(\"server_stabilization_time\")\n",
      "\t\tif ok {\n",
      "\t\t\tconfig.ServerStabilizationTime = time.Duration(serverStabilizationTime.(int)) * time.Second\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\tdisableUpgradeMigration, ok := d.GetOk(\"disable_upgrade_migration\")\n",
      "\t\tif ok {\n",
      "\t\t\tif !constants.IsEnterprise {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"disable_upgrade_migration is only available in Vault Enterprise\"), logical.ErrInvalidRequest\n",
      "\t\t\t}\n",
      "\t\t\tconfig.DisableUpgradeMigration = disableUpgradeMigration.(bool)\n",
      "\t\t\tpersist = true\n",
      "\t\t}\n",
      "\t\teffectiveConf := raftBackend.AutopilotConfig()\n",
      "\t\teffectiveConf.Merge(config)\n",
      "\t\tif effectiveConf.CleanupDeadServers && effectiveConf.MinQuorum < 3 {\n",
      "\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"min_quorum must be set when cleanup_dead_servers is set and it should at least be 3; cleanup_dead_servers: %#v, min_quorum: %#v\", effectiveConf.CleanupDeadServers, effectiveConf.MinQuorum)), logical.ErrInvalidRequest\n",
      "\t\t}\n",
      "\t\tif effectiveConf.CleanupDeadServers && effectiveConf.DeadServerLastContactThreshold.Seconds() < 60 {\n",
      "\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"dead_server_last_contact_threshold should not be set to less than 1m; received: %v\", deadServerLastContactThreshold)), logical.ErrInvalidRequest\n",
      "\t\t}\n",
      "\t\tif persist {\n",
      "\t\t\tentry, err := logical.StorageEntryJSON(raftAutopilotConfigurationStoragePath, config)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif err := b.Core.barrier.Put(ctx, entry); err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\traftBackend.SetAutopilotConfig(effectiveConf)\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (sd *SignedData) AddSigner(ee *x509.Certificate, pkey crypto.PrivateKey, config SignerInfoConfig) error {\n",
      "\tvar parents []*x509.Certificate\n",
      "\treturn sd.AddSignerChain(ee, pkey, parents, config)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *SystemBackend) handleConfigStateSanitized(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tconfig := b.Core.SanitizedConfig()\n",
      "\tresp := &logical.Response{Data: config}\n",
      "\treturn resp, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewBackendV5(ctx context.Context, pluginName string, pluginType consts.PluginType, pluginVersion string, sys pluginutil.LookRunnerUtil, conf *logical.BackendConfig) (logical.Backend, error) {\n",
      "\tpluginRunner, err := sys.LookupPluginVersion(ctx, pluginName, pluginType, pluginVersion)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar backend logical.Backend\n",
      "\tif pluginRunner.Builtin {\n",
      "\t\trawFactory, err := pluginRunner.BuiltinFactory()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error getting plugin type: %q\", err)\n",
      "\t\t}\n",
      "\t\tif factory, ok := rawFactory.(logical.Factory); !ok {\n",
      "\t\t\treturn nil, fmt.Errorf(\"unsupported backend type: %q\", pluginName)\n",
      "\t\t} else {\n",
      "\t\t\tif backend, err = factory(ctx, conf); err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tconfig := pluginutil.PluginClientConfig{Name: pluginName, PluginSets: PluginSet, PluginType: pluginType, Version: pluginVersion, HandshakeConfig: HandshakeConfig, Logger: conf.Logger.Named(pluginName), AutoMTLS: true, Wrapper: sys}\n",
      "\t\tbackend, err = NewPluginClientV5(ctx, sys, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn backend, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewIdentityStore(ctx context.Context, core *Core, config *logical.BackendConfig, logger log.Logger) (*IdentityStore, error) {\n",
      "\tiStore := &IdentityStore{view: config.StorageView, logger: logger, router: core.router, redirectAddr: core.redirectAddr, localNode: core, namespacer: core, metrics: core.MetricSink(), totpPersister: core, groupUpdater: core, tokenStorer: core, entityCreator: core, mountLister: core, mfaBackend: core.loginMFABackend}\n",
      "\terr := iStore.resetDB(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tentitiesPackerLogger := iStore.logger.Named(\"storagepacker\").Named(\"entities\")\n",
      "\tcore.AddLogger(entitiesPackerLogger)\n",
      "\tlocalAliasesPackerLogger := iStore.logger.Named(\"storagepacker\").Named(\"local-aliases\")\n",
      "\tcore.AddLogger(localAliasesPackerLogger)\n",
      "\tgroupsPackerLogger := iStore.logger.Named(\"storagepacker\").Named(\"groups\")\n",
      "\tcore.AddLogger(groupsPackerLogger)\n",
      "\tiStore.entityPacker, err = storagepacker.NewStoragePacker(iStore.view, entitiesPackerLogger, \"\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to create entity packer: %w\", err)\n",
      "\t}\n",
      "\tiStore.localAliasPacker, err = storagepacker.NewStoragePacker(iStore.view, localAliasesPackerLogger, localAliasesBucketsPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to create local alias packer: %w\", err)\n",
      "\t}\n",
      "\tiStore.groupPacker, err = storagepacker.NewStoragePacker(iStore.view, groupsPackerLogger, groupBucketsPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to create group packer: %w\", err)\n",
      "\t}\n",
      "\tiStore.Backend = &framework.Backend{BackendType: logical.TypeLogical, Paths: iStore.paths(), Invalidate: iStore.Invalidate, InitializeFunc: iStore.initialize, PathsSpecial: &logical.Paths{Unauthenticated: []string{\"oidc/.well-known/*\", \"oidc/+/.well-known/*\", \"oidc/provider/+/.well-known/*\", \"oidc/provider/+/token\"}, LocalStorage: []string{localAliasesBucketsPrefix}}, PeriodicFunc: func(ctx context.Context, req *logical.Request) error {\n",
      "\t\tiStore.oidcPeriodicFunc(ctx)\n",
      "\t\treturn nil\n",
      "\t}, RunningVersion: versions.DefaultBuiltinVersion}\n",
      "\tiStore.oidcCache = newOIDCCache(cache.NoExpiration, cache.NoExpiration)\n",
      "\tiStore.oidcAuthCodeCache = newOIDCCache(5*time.Minute, 5*time.Minute)\n",
      "\terr = iStore.Setup(ctx, config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn iStore, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *databaseBackend) GetConnectionWithConfig(ctx context.Context, name string, config *DatabaseConfig) (*dbPluginInstance, error) {\n",
      "\tdbi := b.connections.Get(name)\n",
      "\tif dbi != nil {\n",
      "\t\treturn dbi, nil\n",
      "\t}\n",
      "\tid, err := uuid.GenerateUUID()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tpinnedVersion, err := b.getPinnedVersion(ctx, config.PluginName)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tpluginVersion := config.PluginVersion\n",
      "\tif pinnedVersion != \"\" {\n",
      "\t\tpluginVersion = pinnedVersion\n",
      "\t}\n",
      "\tdbw, err := newDatabaseWrapper(ctx, config.PluginName, pluginVersion, b.System(), b.logger)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"unable to create database instance: %w\", err)\n",
      "\t}\n",
      "\tinitReq := v5.InitializeRequest{Config: config.ConnectionDetails, VerifyConnection: true}\n",
      "\t_, err = dbw.Initialize(ctx, initReq)\n",
      "\tif err != nil {\n",
      "\t\tdbw.Close()\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdbi = &dbPluginInstance{database: dbw, id: id, name: name, runningPluginVersion: pluginVersion}\n",
      "\toldConn := b.connections.Put(name, dbi)\n",
      "\tif oldConn != nil {\n",
      "\t\terr := oldConn.Close()\n",
      "\t\tif err != nil {\n",
      "\t\t\tb.Logger().Warn(\"Error closing database connection\", \"error\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn dbi, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *UIConfig) SetHeader(ctx context.Context, header string, values []string) error {\n",
      "\tc.l.Lock()\n",
      "\tdefer c.l.Unlock()\n",
      "\tconfig, err := c.get(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\tconfig = &uiConfigEntry{Headers: http.Header{}}\n",
      "\t}\n",
      "\tconfig.Headers.Del(header)\n",
      "\tfor _, value := range values {\n",
      "\t\tconfig.Headers.Add(header, value)\n",
      "\t}\n",
      "\treturn c.save(ctx, config)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *PluginRuntimeCatalog) Set(ctx context.Context, conf *pluginruntimeutil.PluginRuntimeConfig) error {\n",
      "\tc.lock.Lock()\n",
      "\tdefer c.lock.Unlock()\n",
      "\tif conf == nil {\n",
      "\t\treturn fmt.Errorf(\"plugin runtime config reference is nil\")\n",
      "\t}\n",
      "\tbuf, err := json.Marshal(conf)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to encode plugin entry: %w\", err)\n",
      "\t}\n",
      "\tstorageKey := path.Join(conf.Type.String(), conf.Name)\n",
      "\tlogicalEntry := logical.StorageEntry{Key: storageKey, Value: buf}\n",
      "\tif err := c.catalogView.Put(ctx, &logicalEntry); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to persist plugin runtime entry: %w\", err)\n",
      "\t}\n",
      "\treturn err\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Sys) RekeyRecoveryKeyInitWithContext(ctx context.Context, config *RekeyInitRequest) (*RekeyStatusResponse, error) {\n",
      "\tctx, cancelFunc := c.c.withConfiguredTimeout(ctx)\n",
      "\tdefer cancelFunc()\n",
      "\tr := c.c.NewRequest(http.MethodPut, \"/v1/sys/rekey-recovery-key/init\")\n",
      "\tif err := r.SetJSONBody(config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tresp, err := c.c.rawRequestWithContext(ctx, r)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdefer resp.Body.Close()\n",
      "\tvar result RekeyStatusResponse\n",
      "\terr = resp.DecodeJSON(&result)\n",
      "\treturn &result, err\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (d *defaultSeal) SetRecoveryConfig(ctx context.Context, config *SealConfig) error {\n",
      "\treturn fmt.Errorf(\"recovery not supported\")\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (r *roleEntry) setCredentialConfig(config map[string]string) error {\n",
      "\tc := make(map[string]interface{})\n",
      "\tfor k, v := range config {\n",
      "\t\tc[k] = v\n",
      "\t}\n",
      "\tswitch r.CredentialType {\n",
      "\tcase v5.CredentialTypePassword:\n",
      "\t\tgenerator, err := newPasswordGenerator(c)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tcm, err := generator.configMap()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif len(cm) > 0 {\n",
      "\t\t\tr.CredentialConfig = cm\n",
      "\t\t}\n",
      "\tcase v5.CredentialTypeRSAPrivateKey:\n",
      "\t\tgenerator, err := newRSAKeyGenerator(c)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tcm, err := generator.configMap()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif len(cm) > 0 {\n",
      "\t\t\tr.CredentialConfig = cm\n",
      "\t\t}\n",
      "\tcase v5.CredentialTypeClientCertificate:\n",
      "\t\tgenerator, err := newClientCertificateGenerator(c)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tcm, err := generator.configMap()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif len(cm) > 0 {\n",
      "\t\t\tr.CredentialConfig = cm\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *LeaseRevokeCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.BoolVar(&BoolVar{Name: \"force\", Aliases: []string{\"f\"}, Target: &c.flagForce, Default: false, Usage: \"Delete the lease from Vault even if the secret engine revocation \" + \"fails. This is meant for recovery situations where the secret \" + \"in the target secret engine was manually removed. If this flag is \" + \"specified, -prefix is also required.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"prefix\", Target: &c.flagPrefix, Default: false, Usage: \"Treat the ID as a prefix instead of an exact lease ID. This can \" + \"revoke multiple leases simultaneously.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"sync\", Target: &c.flagSync, Default: false, Usage: \"Force a synchronous operation; on failure it is up to the client \" + \"to retry.\"})\n",
      "\treturn set\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func doUnifiedTransferMissingLocalSerials(sc *storageContext, clusterId string) error {\n",
      "\tlocalRevokedSerialNums, err := sc.listRevokedCerts()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif len(localRevokedSerialNums) == 0 {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tunifiedSerials, err := listClusterSpecificUnifiedRevokedCerts(sc, clusterId)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tunifiedCertLookup := sliceToMapKey(unifiedSerials)\n",
      "\terrCount := 0\n",
      "\tfor i, serialNum := range localRevokedSerialNums {\n",
      "\t\tif i%25 == 0 {\n",
      "\t\t\tconfig, _ := sc.Backend.CrlBuilder().getConfigWithUpdate(sc)\n",
      "\t\t\tif config != nil && !config.UnifiedCRL {\n",
      "\t\t\t\treturn errors.New(\"unified crl has been disabled after we started, stopping\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif _, ok := unifiedCertLookup[serialNum]; !ok {\n",
      "\t\t\terr := readRevocationEntryAndTransfer(sc, serialNum)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\terrCount++\n",
      "\t\t\t\tsc.Backend.Logger().Error(\"Failed transferring local revocation to unified space\", \"serial\", serialNum, \"error\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif errCount > 0 {\n",
      "\t\tsc.Backend.Logger().Warn(fmt.Sprintf(\"Failed transfering %d local serials to unified storage\", errCount))\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *BaseCommand) flagSet(bit FlagSetBit) *FlagSets {\n",
      "\tc.flagsOnce.Do(func() {\n",
      "\t\tset := NewFlagSets(c.UI)\n",
      "\t\tbit = bit | FlagSetHTTP\n",
      "\t\tif bit&FlagSetHTTP != 0 {\n",
      "\t\t\tf := set.NewFlagSet(\"HTTP Options\")\n",
      "\t\t\taddrStringVar := &StringVar{Name: flagNameAddress, Target: &c.flagAddress, EnvVar: api.EnvVaultAddress, Completion: complete.PredictAnything, Usage: \"Address of the Vault server.\"}\n",
      "\t\t\tif c.flagAddress != \"\" {\n",
      "\t\t\t\taddrStringVar.Default = c.flagAddress\n",
      "\t\t\t} else {\n",
      "\t\t\t\taddrStringVar.Default = \"https://127.0.0.1:8200\"\n",
      "\t\t\t\tc.addrWarning = fmt.Sprintf(\"WARNING! VAULT_ADDR and -address unset. Defaulting to %s.\", addrStringVar.Default)\n",
      "\t\t\t}\n",
      "\t\t\tf.StringVar(addrStringVar)\n",
      "\t\t\tagentAddrStringVar := &StringVar{Name: \"agent-address\", Target: &c.flagAgentProxyAddress, EnvVar: api.EnvVaultAgentAddr, Completion: complete.PredictAnything, Usage: \"Address of the Agent.\"}\n",
      "\t\t\tf.StringVar(agentAddrStringVar)\n",
      "\t\t\tf.StringVar(&StringVar{Name: flagNameCACert, Target: &c.flagCACert, Default: \"\", EnvVar: api.EnvVaultCACert, Completion: complete.PredictFiles(\"*\"), Usage: \"Path on the local disk to a single PEM-encoded CA \" + \"certificate to verify the Vault server's SSL certificate. This \" + \"takes precedence over -ca-path.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: flagNameCAPath, Target: &c.flagCAPath, Default: \"\", EnvVar: api.EnvVaultCAPath, Completion: complete.PredictDirs(\"*\"), Usage: \"Path on the local disk to a directory of PEM-encoded CA \" + \"certificates to verify the Vault server's SSL certificate.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: flagNameClientCert, Target: &c.flagClientCert, Default: \"\", EnvVar: api.EnvVaultClientCert, Completion: complete.PredictFiles(\"*\"), Usage: \"Path on the local disk to a single PEM-encoded CA \" + \"certificate to use for TLS authentication to the Vault server. If \" + \"this flag is specified, -client-key is also required.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: flagNameClientKey, Target: &c.flagClientKey, Default: \"\", EnvVar: api.EnvVaultClientKey, Completion: complete.PredictFiles(\"*\"), Usage: \"Path on the local disk to a single PEM-encoded private key \" + \"matching the client certificate from -client-cert.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: \"namespace\", Target: &c.flagNamespace, Default: notSetValue, EnvVar: api.EnvVaultNamespace, Completion: complete.PredictAnything, Usage: \"The namespace to use for the command. Setting this is not \" + \"necessary but allows using relative paths. -ns can be used as \" + \"shortcut.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: \"ns\", Target: &c.flagNS, Default: notSetValue, Completion: complete.PredictAnything, Hidden: true, Usage: \"Alias for -namespace. This takes precedence over -namespace.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: flagTLSServerName, Target: &c.flagTLSServerName, Default: \"\", EnvVar: api.EnvVaultTLSServerName, Completion: complete.PredictAnything, Usage: \"Name to use as the SNI host when connecting to the Vault \" + \"server via TLS.\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: flagNameTLSSkipVerify, Target: &c.flagTLSSkipVerify, Default: false, EnvVar: api.EnvVaultSkipVerify, Usage: \"Disable verification of TLS certificates. Using this option \" + \"is highly discouraged as it decreases the security of data \" + \"transmissions to and from the Vault server.\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: flagNameDisableRedirects, Target: &c.flagDisableRedirects, Default: false, EnvVar: api.EnvVaultDisableRedirects, Usage: \"Disable the default client behavior, which honors a single \" + \"redirect response from a request\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: \"policy-override\", Target: &c.flagPolicyOverride, Default: false, Usage: \"Override a Sentinel policy that has a soft-mandatory \" + \"enforcement_level specified\"})\n",
      "\t\t\tf.DurationVar(&DurationVar{Name: \"wrap-ttl\", Target: &c.flagWrapTTL, Default: 0, EnvVar: api.EnvVaultWrapTTL, Completion: complete.PredictAnything, Usage: \"Wraps the response in a cubbyhole token with the requested \" + \"TTL. The response is available via the \\\"vault unwrap\\\" command. \" + \"The TTL is specified as a numeric string with suffix like \\\"30s\\\" \" + \"or \\\"5m\\\".\"})\n",
      "\t\t\tf.StringSliceVar(&StringSliceVar{Name: \"mfa\", Target: &c.flagMFA, Default: nil, EnvVar: api.EnvVaultMFA, Completion: complete.PredictAnything, Usage: \"Supply MFA credentials as part of X-Vault-MFA header.\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: \"output-curl-string\", Target: &c.flagOutputCurlString, Default: false, Usage: \"Instead of executing the request, print an equivalent cURL \" + \"command string and exit.\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: \"output-policy\", Target: &c.flagOutputPolicy, Default: false, Usage: \"Instead of executing the request, print an example HCL \" + \"policy that would be required to run this command, and exit.\"})\n",
      "\t\t\tf.StringVar(&StringVar{Name: \"unlock-key\", Target: &c.flagUnlockKey, Default: notSetValue, Completion: complete.PredictNothing, Usage: \"Key to unlock a namespace API lock.\"})\n",
      "\t\t\tf.StringMapVar(&StringMapVar{Name: \"header\", Target: &c.flagHeader, Completion: complete.PredictAnything, Usage: \"Key-value pair provided as key=value to provide http header added to any request done by the CLI.\" + \"Trying to add headers starting with 'X-Vault-' is forbidden and will make the command fail \" + \"This can be specified multiple times.\"})\n",
      "\t\t\tf.BoolVar(&BoolVar{Name: \"non-interactive\", Target: &c.flagNonInteractive, Default: false, Usage: \"When set true, prevents asking the user for input via the terminal.\"})\n",
      "\t\t}\n",
      "\t\tif bit&(FlagSetOutputField|FlagSetOutputFormat|FlagSetOutputDetailed) != 0 {\n",
      "\t\t\toutputSet := set.NewFlagSet(\"Output Options\")\n",
      "\t\t\tif bit&FlagSetOutputField != 0 {\n",
      "\t\t\t\toutputSet.StringVar(&StringVar{Name: \"field\", Target: &c.flagField, Default: \"\", Completion: complete.PredictAnything, Usage: \"Print only the field with the given name. Specifying \" + \"this option will take precedence over other formatting \" + \"directives. The result will not have a trailing newline \" + \"making it ideal for piping to other processes.\"})\n",
      "\t\t\t}\n",
      "\t\t\tif bit&FlagSetOutputFormat != 0 {\n",
      "\t\t\t\toutputSet.StringVar(&StringVar{Name: \"format\", Target: &c.flagFormat, Default: \"table\", EnvVar: EnvVaultFormat, Completion: complete.PredictSet(\"table\", \"json\", \"yaml\", \"pretty\", \"raw\"), Usage: `Print the output in the given format. Valid formats\n",
      "\t\t\t\t\t\tare \"table\", \"json\", \"yaml\", or \"pretty\". \"raw\" is allowed\n",
      "\t\t\t\t\t\tfor 'vault read' operations only.`})\n",
      "\t\t\t}\n",
      "\t\t\tif bit&FlagSetOutputDetailed != 0 {\n",
      "\t\t\t\toutputSet.BoolVar(&BoolVar{Name: \"detailed\", Target: &c.flagDetailed, Default: false, EnvVar: EnvVaultDetailed, Usage: \"Enables additional metadata during some operations\"})\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tc.flags = set\n",
      "\t})\n",
      "\treturn c.flags\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Config) Clone() (*Config, error) {\n",
      "\tif c == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil config\")\n",
      "\t}\n",
      "\tmarshaledConfig, err := proto.Marshal(c)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to marshal config: %w\", err)\n",
      "\t}\n",
      "\tvar clonedConfig Config\n",
      "\terr = proto.Unmarshal(marshaledConfig, &clonedConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to unmarshal config: %w\", err)\n",
      "\t}\n",
      "\treturn &clonedConfig, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func getSysHealth(core *vault.Core, r *http.Request) (int, *HealthResponse, error) {\n",
      "\tvar err error\n",
      "\tstandbyOKStr, standbyOK := r.URL.Query()[\"standbyok\"]\n",
      "\tif standbyOK {\n",
      "\t\tstandbyOK, err = parseutil.ParseBool(standbyOKStr[0])\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn http.StatusBadRequest, nil, fmt.Errorf(\"bad value for standbyok parameter: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tperfStandbyOKStr, perfStandbyOK := r.URL.Query()[\"perfstandbyok\"]\n",
      "\tif perfStandbyOK {\n",
      "\t\tperfStandbyOK, err = parseutil.ParseBool(perfStandbyOKStr[0])\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn http.StatusBadRequest, nil, fmt.Errorf(\"bad value for perfstandbyok parameter: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tuninitCode := http.StatusNotImplemented\n",
      "\tif code, found, ok := fetchStatusCode(r, \"uninitcode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tuninitCode = code\n",
      "\t}\n",
      "\tsealedCode := http.StatusServiceUnavailable\n",
      "\tif code, found, ok := fetchStatusCode(r, \"sealedcode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tsealedCode = code\n",
      "\t}\n",
      "\tstandbyCode := http.StatusTooManyRequests\n",
      "\tif code, found, ok := fetchStatusCode(r, \"standbycode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tstandbyCode = code\n",
      "\t}\n",
      "\tactiveCode := http.StatusOK\n",
      "\tif code, found, ok := fetchStatusCode(r, \"activecode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tactiveCode = code\n",
      "\t}\n",
      "\tdrSecondaryCode := 472\n",
      "\tif code, found, ok := fetchStatusCode(r, \"drsecondarycode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tdrSecondaryCode = code\n",
      "\t}\n",
      "\tperfStandbyCode := 473\n",
      "\tif code, found, ok := fetchStatusCode(r, \"performancestandbycode\"); !ok {\n",
      "\t\treturn http.StatusBadRequest, nil, nil\n",
      "\t} else if found {\n",
      "\t\tperfStandbyCode = code\n",
      "\t}\n",
      "\tctx := context.Background()\n",
      "\tsealed := core.Sealed()\n",
      "\tstandby, perfStandby := core.StandbyStates()\n",
      "\tvar replicationState consts.ReplicationState\n",
      "\tif standby {\n",
      "\t\treplicationState = core.ActiveNodeReplicationState()\n",
      "\t} else {\n",
      "\t\treplicationState = core.ReplicationState()\n",
      "\t}\n",
      "\tinit, err := core.Initialized(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn http.StatusInternalServerError, nil, err\n",
      "\t}\n",
      "\tcode := activeCode\n",
      "\tswitch {\n",
      "\tcase !init:\n",
      "\t\tcode = uninitCode\n",
      "\tcase sealed:\n",
      "\t\tcode = sealedCode\n",
      "\tcase replicationState.HasState(consts.ReplicationDRSecondary):\n",
      "\t\tcode = drSecondaryCode\n",
      "\tcase perfStandby:\n",
      "\t\tif !perfStandbyOK {\n",
      "\t\t\tcode = perfStandbyCode\n",
      "\t\t}\n",
      "\tcase standby:\n",
      "\t\tif !standbyOK {\n",
      "\t\t\tcode = standbyCode\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar clusterName, clusterID string\n",
      "\tif !sealed {\n",
      "\t\tcluster, err := core.Cluster(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn http.StatusInternalServerError, nil, err\n",
      "\t\t}\n",
      "\t\tif cluster == nil {\n",
      "\t\t\treturn http.StatusInternalServerError, nil, fmt.Errorf(\"failed to fetch cluster details\")\n",
      "\t\t}\n",
      "\t\tclusterName = cluster.Name\n",
      "\t\tclusterID = cluster.ID\n",
      "\t}\n",
      "\tbody := &HealthResponse{Initialized: init, Sealed: sealed, Standby: standby, PerformanceStandby: perfStandby, ReplicationPerformanceMode: replicationState.GetPerformanceString(), ReplicationDRMode: replicationState.GetDRString(), ServerTimeUTC: time.Now().UTC().Unix(), Version: version.GetVersion().VersionNumber(), Enterprise: constants.IsEnterprise, ClusterName: clusterName, ClusterID: clusterID, ClockSkewMillis: core.ActiveNodeClockSkewMillis(), EchoDurationMillis: core.EchoDuration().Milliseconds()}\n",
      "\tlicenseState, err := core.EntGetLicenseState()\n",
      "\tif err != nil {\n",
      "\t\treturn http.StatusInternalServerError, nil, err\n",
      "\t}\n",
      "\tif licenseState != nil {\n",
      "\t\tbody.License = &HealthResponseLicense{State: licenseState.State, Terminated: licenseState.Terminated}\n",
      "\t\tif !licenseState.ExpiryTime.IsZero() {\n",
      "\t\t\tbody.License.ExpiryTime = licenseState.ExpiryTime.Format(time.RFC3339)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif init && !sealed && !standby {\n",
      "\t\tbody.LastWAL = core.EntLastWAL()\n",
      "\t}\n",
      "\treturn code, body, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *PluginBackend) Setup(ctx context.Context, config *logical.BackendConfig) error {\n",
      "\tb.RLock()\n",
      "\tdefer b.RUnlock()\n",
      "\treturn b.Backend.Setup(ctx, config)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func DefaultConfig() *Config {\n",
      "\tconfig := &Config{Address: DefaultAddress, HttpClient: cleanhttp.DefaultPooledClient(), Timeout: time.Second * 60, MinRetryWait: time.Millisecond * 1000, MaxRetryWait: time.Millisecond * 1500, MaxRetries: 2, Backoff: retryablehttp.LinearJitterBackoff}\n",
      "\ttransport := config.HttpClient.Transport.(*http.Transport)\n",
      "\ttransport.TLSHandshakeTimeout = 10 * time.Second\n",
      "\ttransport.TLSClientConfig = &tls.Config{MinVersion: tls.VersionTLS12}\n",
      "\tif err := http2.ConfigureTransport(transport); err != nil {\n",
      "\t\tconfig.Error = err\n",
      "\t\treturn config\n",
      "\t}\n",
      "\tif err := config.ReadEnvironment(); err != nil {\n",
      "\t\tconfig.Error = err\n",
      "\t\treturn config\n",
      "\t}\n",
      "\tconfig.HttpClient.CheckRedirect = func(req *http.Request, via []*http.Request) error {\n",
      "\t\treturn http.ErrUseLastResponse\n",
      "\t}\n",
      "\treturn config\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func PluginFactoryVersion(ctx context.Context, pluginName string, pluginVersion string, sys pluginutil.LookRunnerUtil, logger log.Logger) (Database, error) {\n",
      "\tpluginRunner, err := sys.LookupPluginVersion(ctx, pluginName, consts.PluginTypeDatabase, pluginVersion)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tnamedLogger := logger.Named(pluginName)\n",
      "\tvar transport string\n",
      "\tvar db Database\n",
      "\tif pluginRunner.Builtin {\n",
      "\t\tdbRaw, err := pluginRunner.BuiltinFactory()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, errwrap.Wrapf(\"error initializing plugin: {{err}}\", err)\n",
      "\t\t}\n",
      "\t\tvar ok bool\n",
      "\t\tdb, ok = dbRaw.(Database)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, fmt.Errorf(\"unsupported database type: %q\", pluginName)\n",
      "\t\t}\n",
      "\t\ttransport = \"builtin\"\n",
      "\t} else {\n",
      "\t\tconfig := pluginutil.PluginClientConfig{Name: pluginName, PluginType: consts.PluginTypeDatabase, Version: pluginVersion, PluginSets: PluginSets, HandshakeConfig: HandshakeConfig, Logger: namedLogger, IsMetadataMode: false, AutoMTLS: true, Wrapper: sys}\n",
      "\t\tdb, err = NewPluginClient(ctx, sys, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tswitch db.(*DatabasePluginClient).Database.(type) {\n",
      "\t\tcase *gRPCClient:\n",
      "\t\t\ttransport = \"gRPC\"\n",
      "\t\t}\n",
      "\t}\n",
      "\ttypeStr, err := db.Type()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errwrap.Wrapf(\"error getting plugin type: {{err}}\", err)\n",
      "\t}\n",
      "\tlogger.Debug(\"got database plugin instance\", \"type\", typeStr)\n",
      "\tdb = &databaseMetricsMiddleware{next: db, typeStr: typeStr}\n",
      "\tif namedLogger.IsTrace() {\n",
      "\t\tdb = &databaseTracingMiddleware{next: db, logger: namedLogger.With(\"transport\", transport)}\n",
      "\t}\n",
      "\treturn db, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (ace *ACMEChallengeEngine) VerifyChallenge(runnerSc *storageContext, id string, validationQueueRetries int, finished chan bool, config *acmeConfigEntry) {\n",
      "\tsc, cancel := runnerSc.WithFreshTimeout(MaxChallengeTimeout)\n",
      "\tdefer cancel()\n",
      "\trunnerSc.Backend.Logger().Debug(\"Starting verification of challenge\", \"id\", id)\n",
      "\tif retry, retryAfter, err := ace._verifyChallenge(sc, id, config); err != nil {\n",
      "\t\tsc.Backend.Logger().Error(fmt.Sprintf(\"ACME validation failed for %v: %v\", id, err))\n",
      "\t\tif retry {\n",
      "\t\t\tvalidationQueueRetries++\n",
      "\t\t\tif validationQueueRetries > MaxRetryAttempts*2 {\n",
      "\t\t\t\tsc.Backend.Logger().Warn(\"reached max error attempts within challenge queue: %v, giving up\", id)\n",
      "\t\t\t\t_, _, err = ace._verifyChallengeCleanup(sc, nil, id)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tsc.Backend.Logger().Warn(\"Failed cleaning up challenge entry: %v\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfinished <- true\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\tace.ValidationLock.Lock()\n",
      "\t\t\tdefer ace.ValidationLock.Unlock()\n",
      "\t\t\tace.Validations.PushBack(&ChallengeQueueEntry{Identifier: id, RetryAfter: retryAfter, NumRetries: validationQueueRetries})\n",
      "\t\t\tselect {\n",
      "\t\t\tcase ace.NewValidation <- id:\n",
      "\t\t\tdefault:\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfinished <- true\n",
      "\t\treturn\n",
      "\t}\n",
      "\tfinished <- false\n",
      "}\n",
      "======================CLASS=======================\n",
      "func (c *KVGetCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Default: 0, Usage: `If passed, the value at the version number will be returned.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /data/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *backend) maybeRevokeCrossCluster(sc *storageContext, config *crlConfig, serial string, havePrivateKey bool) (*logical.Response, error) {\n",
      "\tif !config.UseGlobalQueue {\n",
      "\t\treturn logical.ErrorResponse(fmt.Sprintf(\"certificate with serial %s not found.\", serial)), nil\n",
      "\t}\n",
      "\tif havePrivateKey {\n",
      "\t\treturn logical.ErrorResponse(fmt.Sprintf(\"certificate with serial %s not found, \"+\"and cross-cluster revocation not supported with key revocation.\", serial)), nil\n",
      "\t}\n",
      "\tcurrTime := time.Now()\n",
      "\tnSerial := normalizeSerial(serial)\n",
      "\tqueueReq := revocationRequest{RequestedAt: currTime}\n",
      "\tpath := crossRevocationPath + nSerial\n",
      "\treqEntry, err := logical.StorageEntryJSON(path, queueReq)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to create storage entry for cross-cluster revocation request: %w\", err)\n",
      "\t}\n",
      "\tif err := sc.Storage.Put(sc.Context, reqEntry); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error persisting cross-cluster revocation request: %w\", err)\n",
      "\t}\n",
      "\tresp := &logical.Response{Data: map[string]interface{}{\"state\": \"pending\"}}\n",
      "\tresp.AddWarning(\"Revocation request was not found on this present node. This request will be in a pending state until the PR cluster which issued this certificate sees the request and revokes the certificate. If no online cluster has this certificate, the request will eventually be removed without revoking any certificates.\")\n",
      "\treturn resp, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *backend) Config(ctx context.Context, s logical.Storage) (*config, error) {\n",
      "\tentry, err := s.Get(ctx, \"config\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar result config\n",
      "\tif entry != nil {\n",
      "\t\tif err := entry.DecodeJSON(&result); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error reading configuration: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn &result, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *OperatorMigrateCommand) Run(args []string) int {\n",
      "\tf := c.Flags()\n",
      "\tif err := f.Parse(args); err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.flagLogLevel = strings.ToLower(c.flagLogLevel)\n",
      "\tvalidLevels := []string{\"trace\", \"debug\", \"info\", \"warn\", \"error\"}\n",
      "\tif !strutil.StrListContains(validLevels, c.flagLogLevel) {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"%s is an unknown log level. Valid log levels are: %s\", c.flagLogLevel, validLevels))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.logger = logging.NewVaultLogger(log.LevelFromString(c.flagLogLevel))\n",
      "\tif c.flagMaxParallel < 1 {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Argument to flag -max-parallel must be between 1 and %d\", math.MaxInt))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif c.flagConfig == \"\" {\n",
      "\t\tc.UI.Error(\"Must specify exactly one config path using -config\")\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tconfig, err := c.loadMigratorConfig(c.flagConfig)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error loading configuration from %s: %s\", c.flagConfig, err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif err := c.migrate(config); err != nil {\n",
      "\t\tif err == errAbort {\n",
      "\t\t\treturn 0\n",
      "\t\t}\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error migrating: %s\", err))\n",
      "\t\treturn 2\n",
      "\t}\n",
      "\tif c.flagReset {\n",
      "\t\tc.UI.Output(\"Success! Migration lock reset (if it was set).\")\n",
      "\t} else {\n",
      "\t\tc.UI.Output(\"Success! All of the keys have been migrated.\")\n",
      "\t}\n",
      "\treturn 0\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewAWSAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &awsMethod{logger: conf.Logger, mountPath: conf.MountPath, credsFound: make(chan struct{}), stopCh: make(chan struct{}), region: awsutil.DefaultRegion}\n",
      "\ttypeRaw, ok := conf.Config[\"type\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'type' value\")\n",
      "\t}\n",
      "\ta.authType, ok = typeRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'type' config value to string\")\n",
      "\t}\n",
      "\troleRaw, ok := conf.Config[\"role\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role' value\")\n",
      "\t}\n",
      "\ta.role, ok = roleRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase a.role == \"\":\n",
      "\t\treturn nil, errors.New(\"'role' value is empty\")\n",
      "\tcase a.authType == \"\":\n",
      "\t\treturn nil, errors.New(\"'type' value is empty\")\n",
      "\tcase a.authType != typeEC2 && a.authType != typeIAM:\n",
      "\t\treturn nil, errors.New(\"'type' value is invalid\")\n",
      "\t}\n",
      "\taccessKey := \"\"\n",
      "\taccessKeyRaw, ok := conf.Config[\"access_key\"]\n",
      "\tif ok {\n",
      "\t\taccessKey, ok = accessKeyRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'access_key' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tsecretKey := \"\"\n",
      "\tsecretKeyRaw, ok := conf.Config[\"secret_key\"]\n",
      "\tif ok {\n",
      "\t\tsecretKey, ok = secretKeyRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'secret_key' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tsessionToken := \"\"\n",
      "\tsessionTokenRaw, ok := conf.Config[\"session_token\"]\n",
      "\tif ok {\n",
      "\t\tsessionToken, ok = sessionTokenRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'session_token' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\theaderValueRaw, ok := conf.Config[\"header_value\"]\n",
      "\tif ok {\n",
      "\t\ta.headerValue, ok = headerValueRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'header_value' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tnonceRaw, ok := conf.Config[\"nonce\"]\n",
      "\tif ok {\n",
      "\t\ta.nonce, ok = nonceRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'nonce' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tregionRaw, ok := conf.Config[\"region\"]\n",
      "\tif ok {\n",
      "\t\ta.region, ok = regionRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'region' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif a.authType == typeIAM {\n",
      "\t\tcredentialPollIntervalSec := defaultCredentialPollInterval\n",
      "\t\tif credentialPollIntervalRaw, ok := conf.Config[\"credential_poll_interval\"]; ok {\n",
      "\t\t\tif credentialPollInterval, ok := credentialPollIntervalRaw.(int); ok && credentialPollInterval > 0 {\n",
      "\t\t\t\tcredentialPollIntervalSec = credentialPollInterval\n",
      "\t\t\t} else {\n",
      "\t\t\t\treturn nil, errors.New(\"could not convert 'credential_poll_interval' into positive int\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tcreds, err := awsutil.RetrieveCreds(accessKey, secretKey, sessionToken, a.logger)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\ta.lastCreds = creds\n",
      "\t\tgo a.pollForCreds(accessKey, secretKey, sessionToken, credentialPollIntervalSec)\n",
      "\t}\n",
      "\treturn a, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func ParseSSHHelperConfig(contents string) (*SSHHelperConfig, error) {\n",
      "\troot, err := hcl.Parse(string(contents))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errwrap.Wrapf(\"error parsing config: {{err}}\", err)\n",
      "\t}\n",
      "\tlist, ok := root.Node.(*ast.ObjectList)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"error parsing config: file doesn't contain a root object\")\n",
      "\t}\n",
      "\tvalid := []string{\"vault_addr\", \"ssh_mount_point\", \"namespace\", \"ca_cert\", \"ca_path\", \"allowed_cidr_list\", \"allowed_roles\", \"tls_skip_verify\", \"tls_server_name\"}\n",
      "\tif err := CheckHCLKeys(list, valid); err != nil {\n",
      "\t\treturn nil, multierror.Prefix(err, \"ssh_helper:\")\n",
      "\t}\n",
      "\tvar c SSHHelperConfig\n",
      "\tc.SSHMountPoint = SSHHelperDefaultMountPoint\n",
      "\tif err := hcl.DecodeObject(&c, list); err != nil {\n",
      "\t\treturn nil, multierror.Prefix(err, \"ssh_helper:\")\n",
      "\t}\n",
      "\tif c.VaultAddr == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(`missing config \"vault_addr\"`)\n",
      "\t}\n",
      "\treturn &c, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func envKeys(env []string) map[string]struct{} {\n",
      "\tkeys := make(map[string]struct{}, len(env))\n",
      "\tfor _, env := range env {\n",
      "\t\tparts := strings.SplitN(env, \"=\", 2)\n",
      "\t\tif len(parts) == 0 {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tkeys[parts[0]] = struct{}{}\n",
      "\t}\n",
      "\treturn keys\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (pg passwordGenerator) configMap() (map[string]interface{}, error) {\n",
      "\tconfig := make(map[string]interface{})\n",
      "\tif err := mapstructure.WeakDecode(pg, &config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (r *PluginRunner) RunMetadataMode(ctx context.Context, wrapper RunnerUtil, pluginSets map[int]plugin.PluginSet, hs plugin.HandshakeConfig, env []string, logger log.Logger) (*plugin.Client, error) {\n",
      "\treturn r.RunConfig(ctx, Runner(wrapper), PluginSets(pluginSets), HandshakeConfig(hs), Env(env...), Logger(logger), MetadataMode(true))\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (cg ClientCertificateGenerator) configMap() (map[string]interface{}, error) {\n",
      "\tconfig := make(map[string]interface{})\n",
      "\tif err := mapstructure.WeakDecode(cg, &config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *LoginMFABackend) MemDBMFAConfigByName(ctx context.Context, name string) (*mfa.Config, error) {\n",
      "\tif name == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing config name\")\n",
      "\t}\n",
      "\ttxn := b.db.Txn(false)\n",
      "\treturn b.MemDBMFAConfigByNameInTxn(ctx, txn, name)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func EncodeJSONAndCompress(in interface{}, config *compressutil.CompressionConfig) ([]byte, error) {\n",
      "\tif in == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"input for encoding is nil\")\n",
      "\t}\n",
      "\tencodedBytes, err := EncodeJSON(in)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\tconfig = &compressutil.CompressionConfig{Type: compressutil.CompressionTypeGzip, GzipCompressionLevel: gzip.BestCompression}\n",
      "\t}\n",
      "\treturn compressutil.Compress(encodedBytes, config)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func physicalSealConfig(ctx context.Context, c *Core, label, configPath string) (*SealConfig, error) {\n",
      "\tpe, err := c.physical.Get(ctx, configPath)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to fetch %s seal configuration: %w\", label, err)\n",
      "\t}\n",
      "\tif pe == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tconfig := new(SealConfig)\n",
      "\tif err := jsonutil.DecodeJSON(pe.Value, config); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to decode %s seal configuration: %w\", label, err)\n",
      "\t}\n",
      "\terr = config.Validate()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to validate %s seal configuration: %w\", label, err)\n",
      "\t}\n",
      "\tif config.Type == \"\" {\n",
      "\t\tconfig.Type = SealConfigTypeShamir.String()\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func ConvertConfig(cfg *ConfigEntry) *capldap.ClientConfig {\n",
      "\tminTimeout := min(cfg.ConnectionTimeout, cfg.RequestTimeout)\n",
      "\turls := strings.Split(cfg.Url, \",\")\n",
      "\tconfig := &capldap.ClientConfig{URLs: urls, UserDN: cfg.UserDN, AnonymousGroupSearch: cfg.AnonymousGroupSearch, GroupDN: cfg.GroupDN, GroupFilter: cfg.GroupFilter, GroupAttr: cfg.GroupAttr, UPNDomain: cfg.UPNDomain, UserFilter: cfg.UserFilter, UserAttr: cfg.UserAttr, ClientTLSCert: cfg.ClientTLSCert, ClientTLSKey: cfg.ClientTLSKey, InsecureTLS: cfg.InsecureTLS, StartTLS: cfg.StartTLS, BindDN: cfg.BindDN, BindPassword: cfg.BindPassword, AllowEmptyPasswordBinds: !cfg.DenyNullBind, DiscoverDN: cfg.DiscoverDN, TLSMinVersion: cfg.TLSMinVersion, TLSMaxVersion: cfg.TLSMaxVersion, UseTokenGroups: cfg.UseTokenGroups, RequestTimeout: minTimeout, IncludeUserAttributes: true, ExcludedUserAttributes: nil, IncludeUserGroups: true, MaximumPageSize: cfg.MaximumPageSize, DerefAliases: cfg.DerefAliases, DeprecatedVaultPre111GroupCNBehavior: cfg.UsePre111GroupCNBehavior}\n",
      "\tif cfg.Certificate != \"\" {\n",
      "\t\tconfig.Certificates = []string{cfg.Certificate}\n",
      "\t}\n",
      "\treturn config\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (d *dispatcher) dispatch(job Job, init initFn, cleanup cleanupFn) {\n",
      "\twJob := wrappedJob{init: init, job: job, cleanup: cleanup}\n",
      "\tselect {\n",
      "\tcase d.jobCh <- wJob:\n",
      "\tcase <-d.quit:\n",
      "\t\td.logger.Info(\"shutting down during dispatch\")\n",
      "\t}\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *UIConfig) save(ctx context.Context, config *uiConfigEntry) error {\n",
      "\tif len(config.Headers) == 0 {\n",
      "\t\tif err := c.physicalStorage.Delete(ctx, uiConfigPlaintextKey); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\treturn c.barrierStorage.Delete(ctx, uiConfigKey)\n",
      "\t}\n",
      "\tconfigRaw, err := json.Marshal(config)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tentry := &physical.Entry{Key: uiConfigPlaintextKey, Value: configRaw}\n",
      "\tif err := c.physicalStorage.Put(ctx, entry); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tbarrEntry := &logical.StorageEntry{Key: uiConfigKey, Value: configRaw}\n",
      "\treturn c.barrierStorage.Put(ctx, barrEntry)\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *KVMetadataPutCommand) Synopsis() string {\n",
      "\treturn \"Sets or updates key settings in the KV store\"\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func SetIssuersConfig(ctx context.Context, s logical.Storage, config *IssuerConfigEntry) error {\n",
      "\tjson, err := logical.StorageEntryJSON(StorageIssuerConfig, config)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := s.Put(ctx, json); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := changeDefaultIssuerTimestamps(ctx, s, config.fetchedDefault, config.DefaultIssuerId); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *backend) Config(ctx context.Context, s logical.Storage) (*config, error) {\n",
      "\tentry, err := s.Get(ctx, \"config\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif entry == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tvar result config\n",
      "\tif entry != nil {\n",
      "\t\tif err := entry.DecodeJSON(&result); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error reading configuration: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif result.TokenTTL == 0 && result.TTL > 0 {\n",
      "\t\tresult.TokenTTL = result.TTL\n",
      "\t}\n",
      "\tif result.TokenMaxTTL == 0 && result.MaxTTL > 0 {\n",
      "\t\tresult.TokenMaxTTL = result.MaxTTL\n",
      "\t}\n",
      "\treturn &result, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Core) postUnseal(ctx context.Context, ctxCancelFunc context.CancelFunc, unsealer UnsealStrategy) (retErr error) {\n",
      "\tdefer metrics.MeasureSince([]string{\"core\", \"post_unseal\"}, time.Now())\n",
      "\tc.postUnsealFuncs = nil\n",
      "\tc.activeContext = ctx\n",
      "\tc.activeContextCancelFunc.Store(ctxCancelFunc)\n",
      "\tdefer func() {\n",
      "\t\tif retErr != nil {\n",
      "\t\t\tctxCancelFunc()\n",
      "\t\t\t_ = c.preSeal()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tc.logger.Info(\"post-unseal setup starting\")\n",
      "\tc.physicalCache.Purge(ctx)\n",
      "\tif !c.cachingDisabled {\n",
      "\t\tc.physicalCache.SetEnabled(true)\n",
      "\t}\n",
      "\t_ = c.seal.ClearBarrierConfig(ctx)\n",
      "\tif c.seal.RecoveryKeySupported() {\n",
      "\t\t_ = c.seal.ClearRecoveryConfig(ctx)\n",
      "\t}\n",
      "\tif err := c.loadVersionHistory(ctx); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := unsealer.unseal(ctx, c.logger, c); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif seal, ok := c.seal.(*autoSeal); ok {\n",
      "\t\tif err := seal.UpgradeKeys(c.activeContext); err != nil {\n",
      "\t\t\tc.logger.Warn(\"post-unseal upgrade seal keys failed\", \"error\", err)\n",
      "\t\t}\n",
      "\t\tseal.StartHealthCheck()\n",
      "\t}\n",
      "\tpostUnsealFuncConcurrency := runtime.NumCPU() * 2\n",
      "\tif v := os.Getenv(\"VAULT_POSTUNSEAL_FUNC_CONCURRENCY\"); v != \"\" {\n",
      "\t\tpv, err := strconv.Atoi(v)\n",
      "\t\tif err != nil || pv < 1 {\n",
      "\t\t\tc.logger.Warn(\"invalid value for VAULT_POSTUNSEAL_FUNC_CURRENCY, must be a positive integer\", \"error\", err, \"value\", pv)\n",
      "\t\t} else {\n",
      "\t\t\tpostUnsealFuncConcurrency = pv\n",
      "\t\t}\n",
      "\t}\n",
      "\tif postUnsealFuncConcurrency <= 1 {\n",
      "\t\tfor _, v := range c.postUnsealFuncs {\n",
      "\t\t\tv()\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tjobs := make(chan func())\n",
      "\t\tvar wg sync.WaitGroup\n",
      "\t\tfor i := 0; i < postUnsealFuncConcurrency; i++ {\n",
      "\t\t\tgo func() {\n",
      "\t\t\t\tfor v := range jobs {\n",
      "\t\t\t\t\tv()\n",
      "\t\t\t\t\twg.Done()\n",
      "\t\t\t\t}\n",
      "\t\t\t}()\n",
      "\t\t}\n",
      "\t\tfor _, v := range c.postUnsealFuncs {\n",
      "\t\t\twg.Add(1)\n",
      "\t\t\tjobs <- v\n",
      "\t\t}\n",
      "\t\twg.Wait()\n",
      "\t\tclose(jobs)\n",
      "\t}\n",
      "\tif atomic.LoadUint32(c.sealMigrationDone) == 1 {\n",
      "\t\tif err := c.postSealMigration(ctx); err != nil {\n",
      "\t\t\tc.logger.Warn(\"post-unseal post seal migration failed\", \"error\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif os.Getenv(EnvVaultDisableLocalAuthMountEntities) != \"\" {\n",
      "\t\tc.logger.Warn(\"disabling entities for local auth mounts through env var\", \"env\", EnvVaultDisableLocalAuthMountEntities)\n",
      "\t}\n",
      "\tc.loginMFABackend.usedCodes = cache.New(0, 30*time.Second)\n",
      "\tif c.systemBackend != nil && c.systemBackend.mfaBackend != nil {\n",
      "\t\tc.systemBackend.mfaBackend.usedCodes = cache.New(0, 30*time.Second)\n",
      "\t}\n",
      "\tif c.systemBackend != nil {\n",
      "\t\tsysActivityLogReporting(c.systemBackend)\n",
      "\t}\n",
      "\tc.logger.Info(\"post-unseal setup complete\")\n",
      "\treturn nil\n",
      "}\n",
      "func (b *databaseBackend) connectionWriteHandler() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\t\tverifyConnection := data.Get(\"verify_connection\").(bool)\n",
      "\t\tname := data.Get(\"name\").(string)\n",
      "\t\tif name == \"\" {\n",
      "\t\t\treturn logical.ErrorResponse(respErrEmptyName), nil\n",
      "\t\t}\n",
      "\t\tconfig := &DatabaseConfig{}\n",
      "\t\tentry, err := req.Storage.Get(ctx, fmt.Sprintf(\"config/%s\", name))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to read connection configuration: %w\", err)\n",
      "\t\t}\n",
      "\t\tif entry != nil {\n",
      "\t\t\tif err := entry.DecodeJSON(config); err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif pluginNameRaw, ok := data.GetOk(\"plugin_name\"); ok {\n",
      "\t\t\tconfig.PluginName = pluginNameRaw.(string)\n",
      "\t\t} else if req.Operation == logical.CreateOperation {\n",
      "\t\t\tconfig.PluginName = data.Get(\"plugin_name\").(string)\n",
      "\t\t}\n",
      "\t\tif config.PluginName == \"\" {\n",
      "\t\t\treturn logical.ErrorResponse(respErrEmptyPluginName), nil\n",
      "\t\t}\n",
      "\t\tpluginVersion, respErr, err := b.selectPluginVersion(ctx, config, data, req.Operation)\n",
      "\t\tif respErr != nil || err != nil {\n",
      "\t\t\treturn respErr, err\n",
      "\t\t}\n",
      "\t\tif allowedRolesRaw, ok := data.GetOk(\"allowed_roles\"); ok {\n",
      "\t\t\tconfig.AllowedRoles = allowedRolesRaw.([]string)\n",
      "\t\t} else if req.Operation == logical.CreateOperation {\n",
      "\t\t\tconfig.AllowedRoles = data.Get(\"allowed_roles\").([]string)\n",
      "\t\t}\n",
      "\t\tif rootRotationStatementsRaw, ok := data.GetOk(\"root_rotation_statements\"); ok {\n",
      "\t\t\tconfig.RootCredentialsRotateStatements = rootRotationStatementsRaw.([]string)\n",
      "\t\t} else if req.Operation == logical.CreateOperation {\n",
      "\t\t\tconfig.RootCredentialsRotateStatements = data.Get(\"root_rotation_statements\").([]string)\n",
      "\t\t}\n",
      "\t\tif passwordPolicyRaw, ok := data.GetOk(\"password_policy\"); ok {\n",
      "\t\t\tconfig.PasswordPolicy = passwordPolicyRaw.(string)\n",
      "\t\t}\n",
      "\t\tdelete(data.Raw, \"name\")\n",
      "\t\tdelete(data.Raw, \"plugin_name\")\n",
      "\t\tdelete(data.Raw, \"plugin_version\")\n",
      "\t\tdelete(data.Raw, \"allowed_roles\")\n",
      "\t\tdelete(data.Raw, \"verify_connection\")\n",
      "\t\tdelete(data.Raw, \"root_rotation_statements\")\n",
      "\t\tdelete(data.Raw, \"password_policy\")\n",
      "\t\tid, err := uuid.GenerateUUID()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif req.Operation == logical.CreateOperation {\n",
      "\t\t\tconfig.ConnectionDetails = data.Raw\n",
      "\t\t} else {\n",
      "\t\t\tif config.ConnectionDetails == nil {\n",
      "\t\t\t\tconfig.ConnectionDetails = make(map[string]interface{})\n",
      "\t\t\t}\n",
      "\t\t\tfor k, v := range data.Raw {\n",
      "\t\t\t\tconfig.ConnectionDetails[k] = v\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tdbw, err := newDatabaseWrapper(ctx, config.PluginName, pluginVersion, b.System(), b.logger)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"error creating database object: %s\", err), nil\n",
      "\t\t}\n",
      "\t\tinitReq := v5.InitializeRequest{Config: config.ConnectionDetails, VerifyConnection: verifyConnection}\n",
      "\t\tinitResp, err := dbw.Initialize(ctx, initReq)\n",
      "\t\tif err != nil {\n",
      "\t\t\tdbw.Close()\n",
      "\t\t\treturn logical.ErrorResponse(\"error creating database object: %s\", err), nil\n",
      "\t\t}\n",
      "\t\tconfig.ConnectionDetails = initResp.Config\n",
      "\t\tb.Logger().Debug(\"created database object\", \"name\", name, \"plugin_name\", config.PluginName)\n",
      "\t\toldConn := b.connections.Put(name, &dbPluginInstance{database: dbw, name: name, id: id, runningPluginVersion: pluginVersion})\n",
      "\t\tif oldConn != nil {\n",
      "\t\t\toldConn.Close()\n",
      "\t\t}\n",
      "\t\tif versions.IsBuiltinVersion(config.PluginVersion) {\n",
      "\t\t\tconfig.PluginVersion = \"\"\n",
      "\t\t}\n",
      "\t\terr = storeConfig(ctx, req.Storage, name, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tresp := &logical.Response{}\n",
      "\t\tif connURLRaw, ok := config.ConnectionDetails[\"connection_url\"]; ok {\n",
      "\t\t\tif connURL, err := url.Parse(connURLRaw.(string)); err == nil {\n",
      "\t\t\t\tif _, ok := connURL.User.Password(); ok {\n",
      "\t\t\t\t\tresp.AddWarning(\"Password found in connection_url, use a templated url to enable root rotation and prevent read access to password information.\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif dbw.isV4() && config.PasswordPolicy != \"\" {\n",
      "\t\t\tresp.AddWarning(fmt.Sprintf(\"%s does not support password policies - upgrade to the latest version of \"+\"Vault (or the sdk if using a custom plugin) to gain password policy support\", config.PluginName))\n",
      "\t\t}\n",
      "\t\tb.dbEvent(ctx, \"config-write\", req.Path, name, true)\n",
      "\t\tif len(resp.Warnings) == 0 {\n",
      "\t\t\treturn nil, nil\n",
      "\t\t}\n",
      "\t\treturn resp, nil\n",
      "\t}\n",
      "}\n",
      "func (b *backend) pathStaticRolesRead(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\troleName, ok := data.GetOk(paramRoleName)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"missing %q parameter\", paramRoleName)\n",
      "\t}\n",
      "\tb.roleMutex.RLock()\n",
      "\tdefer b.roleMutex.RUnlock()\n",
      "\tentry, err := req.Storage.Get(ctx, formatRoleStoragePath(roleName.(string)))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to read configuration for static role %q: %w\", roleName, err)\n",
      "\t}\n",
      "\tif entry == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tvar config staticRoleEntry\n",
      "\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to decode configuration for static role %q: %w\", roleName, err)\n",
      "\t}\n",
      "\treturn &logical.Response{Data: formatResponse(config)}, nil\n",
      "}\n",
      "func createCoreConfig(c *ServerCommand, config *server.Config, backend physical.Backend, configSR sr.ServiceRegistration, barrierSeal, unwrapSeal vault.Seal, metricsHelper *metricsutil.MetricsHelper, metricSink *metricsutil.ClusterMetricSink, secureRandomReader io.Reader) vault.CoreConfig {\n",
      "\tcoreConfig := &vault.CoreConfig{RawConfig: config, Physical: backend, RedirectAddr: config.Storage.RedirectAddr, StorageType: config.Storage.Type, HAPhysical: nil, ServiceRegistration: configSR, Seal: barrierSeal, UnwrapSeal: unwrapSeal, AuditBackends: c.AuditBackends, CredentialBackends: c.CredentialBackends, LogicalBackends: c.LogicalBackends, EventBackends: c.EventBackends, LogLevel: config.LogLevel, Logger: c.logger, DetectDeadlocks: config.DetectDeadlocks, ImpreciseLeaseRoleTracking: config.ImpreciseLeaseRoleTracking, DisableSentinelTrace: config.DisableSentinelTrace, DisableCache: config.DisableCache, DisableMlock: config.DisableMlock, MaxLeaseTTL: config.MaxLeaseTTL, DefaultLeaseTTL: config.DefaultLeaseTTL, ClusterName: config.ClusterName, CacheSize: config.CacheSize, PluginDirectory: config.PluginDirectory, PluginTmpdir: config.PluginTmpdir, PluginFileUid: config.PluginFileUid, PluginFilePermissions: config.PluginFilePermissions, EnableUI: config.EnableUI, EnableRaw: config.EnableRawEndpoint, EnableIntrospection: config.EnableIntrospectionEndpoint, DisableSealWrap: config.DisableSealWrap, DisablePerformanceStandby: config.DisablePerformanceStandby, DisableIndexing: config.DisableIndexing, AllLoggers: c.allLoggers, BuiltinRegistry: builtinplugins.Registry, DisableKeyEncodingChecks: config.DisablePrintableCheck, MetricsHelper: metricsHelper, MetricSink: metricSink, SecureRandomReader: secureRandomReader, EnableResponseHeaderHostname: config.EnableResponseHeaderHostname, EnableResponseHeaderRaftNodeID: config.EnableResponseHeaderRaftNodeID, License: config.License, LicensePath: config.LicensePath, DisableSSCTokens: config.DisableSSCTokens, Experiments: config.Experiments, AdministrativeNamespacePath: config.AdministrativeNamespacePath}\n",
      "\tif c.flagDev {\n",
      "\t\tcoreConfig.EnableRaw = true\n",
      "\t\tcoreConfig.EnableIntrospection = true\n",
      "\t\tcoreConfig.DevToken = c.flagDevRootTokenID\n",
      "\t\tif c.flagDevLeasedKV {\n",
      "\t\t\tcoreConfig.LogicalBackends[\"kv\"] = vault.LeasedPassthroughBackendFactory\n",
      "\t\t}\n",
      "\t\tif c.flagDevPluginDir != \"\" {\n",
      "\t\t\tcoreConfig.PluginDirectory = c.flagDevPluginDir\n",
      "\t\t}\n",
      "\t\tif c.flagDevLatency > 0 {\n",
      "\t\t\tinjectLatency := time.Duration(c.flagDevLatency) * time.Millisecond\n",
      "\t\t\tif _, txnOK := backend.(physical.Transactional); txnOK {\n",
      "\t\t\t\tcoreConfig.Physical = physical.NewTransactionalLatencyInjector(backend, injectLatency, c.flagDevLatencyJitter, c.logger)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tcoreConfig.Physical = physical.NewLatencyInjector(backend, injectLatency, c.flagDevLatencyJitter, c.logger)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn *coreConfig\n",
      "}\n",
      "func (c *ServerCommand) Run(args []string) int {\n",
      "\tf := c.Flags()\n",
      "\tif err := f.Parse(args); err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tdeadlock.Opts.OnPotentialDeadlock = func() {\n",
      "\t}\n",
      "\tc.logGate = gatedwriter.NewWriter(os.Stderr)\n",
      "\tc.logWriter = c.logGate\n",
      "\tif c.logFlags.flagCombineLogs {\n",
      "\t\tc.logWriter = os.Stdout\n",
      "\t}\n",
      "\tif c.flagRecovery {\n",
      "\t\treturn c.runRecoveryMode()\n",
      "\t}\n",
      "\tif c.flagDevConsul || c.flagDevHA || c.flagDevTransactional || c.flagDevLeasedKV || c.flagDevThreeNode || c.flagDevFourCluster || c.flagDevAutoSeal || c.flagDevKVV1 || c.flagDevTLS {\n",
      "\t\tc.flagDev = true\n",
      "\t}\n",
      "\tif !c.flagDev {\n",
      "\t\tswitch {\n",
      "\t\tcase len(c.flagConfigs) == 0:\n",
      "\t\t\tc.UI.Error(\"Must specify at least one config path using -config\")\n",
      "\t\t\treturn 1\n",
      "\t\tcase c.flagDevRootTokenID != \"\":\n",
      "\t\t\tc.UI.Warn(wrapAtLength(\"You cannot specify a custom root token ID outside of \\\"dev\\\" mode. \" + \"Your request has been ignored.\"))\n",
      "\t\t\tc.flagDevRootTokenID = \"\"\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar config *server.Config\n",
      "\tvar certDir string\n",
      "\tif c.flagDev {\n",
      "\t\tdf, cfg, dir, err := configureDevTLS(c)\n",
      "\t\tif df != nil {\n",
      "\t\t\tdefer df()\n",
      "\t\t}\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tconfig = cfg\n",
      "\t\tcertDir = dir\n",
      "\t\tif c.flagDevListenAddr != \"\" {\n",
      "\t\t\tconfig.Listeners[0].Address = c.flagDevListenAddr\n",
      "\t\t}\n",
      "\t\tconfig.Listeners[0].Telemetry.UnauthenticatedMetricsAccess = true\n",
      "\t}\n",
      "\tparsedConfig, configErrors, err := c.parseConfig()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\tconfig = parsedConfig\n",
      "\t} else {\n",
      "\t\tconfig = config.Merge(parsedConfig)\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\tc.UI.Output(wrapAtLength(\"No configuration files found. Please provide configurations with the \" + \"-config flag. If you are supplying the path to a directory, please \" + \"ensure the directory contains files with the .hcl or .json \" + \"extension.\"))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tf.applyLogConfigOverrides(config.SharedConfig)\n",
      "\tif c.flagDevThreeNode || c.flagDevFourCluster {\n",
      "\t\tconfig.LogLevel = \"trace\"\n",
      "\t}\n",
      "\tl, err := c.configureLogging(config)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.logger = l\n",
      "\tc.allLoggers = append(c.allLoggers, l)\n",
      "\tif c.logFlags.flagDisableGatedLogs {\n",
      "\t\tc.flushLog()\n",
      "\t}\n",
      "\tfor _, cErr := range configErrors {\n",
      "\t\tc.logger.Warn(cErr.String())\n",
      "\t}\n",
      "\tdefer c.flushLog()\n",
      "\tnamedGRPCLogFaker := c.logger.Named(\"grpclogfaker\")\n",
      "\tc.allLoggers = append(c.allLoggers, namedGRPCLogFaker)\n",
      "\tgrpclog.SetLogger(&grpclogFaker{logger: namedGRPCLogFaker, log: os.Getenv(\"VAULT_GRPC_LOGGING\") != \"\"})\n",
      "\tif memProfilerEnabled {\n",
      "\t\tc.startMemProfiler()\n",
      "\t}\n",
      "\tif config.DefaultMaxRequestDuration != 0 {\n",
      "\t\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\n",
      "\t}\n",
      "\tlogProxyEnvironmentVariables(c.logger)\n",
      "\tif envMlock := os.Getenv(\"VAULT_DISABLE_MLOCK\"); envMlock != \"\" {\n",
      "\t\tvar err error\n",
      "\t\tconfig.DisableMlock, err = strconv.ParseBool(envMlock)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Output(\"Error parsing the environment variable VAULT_DISABLE_MLOCK\")\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tif envLicensePath := os.Getenv(EnvVaultLicensePath); envLicensePath != \"\" {\n",
      "\t\tconfig.LicensePath = envLicensePath\n",
      "\t}\n",
      "\tif envLicense := os.Getenv(EnvVaultLicense); envLicense != \"\" {\n",
      "\t\tconfig.License = envLicense\n",
      "\t}\n",
      "\tif envPluginTmpdir := os.Getenv(EnvVaultPluginTmpdir); envPluginTmpdir != \"\" {\n",
      "\t\tconfig.PluginTmpdir = envPluginTmpdir\n",
      "\t}\n",
      "\tif err := server.ExperimentsFromEnvAndCLI(config, EnvVaultExperiments, c.flagExperiments); err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tfor _, experiment := range config.Experiments {\n",
      "\t\tif experiments.IsUnused(experiment) {\n",
      "\t\t\tc.UI.Warn(fmt.Sprintf(\"WARNING! Experiment %s is no longer used\", experiment))\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !c.flagDev && !config.DisableMlock && !mlock.Supported() {\n",
      "\t\tc.UI.Warn(wrapAtLength(\"WARNING! mlock is not supported on this system! An mlockall(2)-like \" + \"syscall to prevent memory from being swapped to disk is not \" + \"supported on this system. For better security, only run Vault on \" + \"systems where this call is supported. If you are running Vault \" + \"in a Docker container, provide the IPC_LOCK cap to the container.\"))\n",
      "\t}\n",
      "\tinmemMetrics, metricSink, prometheusEnabled, err := configutil.SetupTelemetry(&configutil.SetupTelemetryOpts{Config: config.Telemetry, Ui: c.UI, ServiceName: \"vault\", DisplayName: \"Vault\", UserAgent: useragent.String(), ClusterName: config.ClusterName})\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error initializing telemetry: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tmetricsHelper := metricsutil.NewMetricsHelper(inmemMetrics, prometheusEnabled)\n",
      "\tvar backend physical.Backend\n",
      "\tif !c.flagDev || config.Storage != nil {\n",
      "\t\tbackend, err = c.setupStorage(config)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif c.storageMigrationActive(backend) {\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar configSR sr.ServiceRegistration\n",
      "\tif config.ServiceRegistration != nil {\n",
      "\t\tconfigSR, err = beginServiceRegistration(c, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Output(err.Error())\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tinfoKeys := make([]string, 0, 10)\n",
      "\tinfo := make(map[string]string)\n",
      "\tinfo[\"log level\"] = config.LogLevel\n",
      "\tinfoKeys = append(infoKeys, \"log level\")\n",
      "\tenvVars := os.Environ()\n",
      "\tvar envVarKeys []string\n",
      "\tfor _, v := range envVars {\n",
      "\t\tsplitEnvVars := strings.Split(v, \"=\")\n",
      "\t\tenvVarKeys = append(envVarKeys, splitEnvVars[0])\n",
      "\t}\n",
      "\tsort.Strings(envVarKeys)\n",
      "\tkey := \"environment variables\"\n",
      "\tinfo[key] = strings.Join(envVarKeys, \", \")\n",
      "\tinfoKeys = append(infoKeys, key)\n",
      "\tif len(config.Experiments) != 0 {\n",
      "\t\texpKey := \"experiments\"\n",
      "\t\tinfo[expKey] = strings.Join(config.Experiments, \", \")\n",
      "\t\tinfoKeys = append(infoKeys, expKey)\n",
      "\t}\n",
      "\tctx := context.Background()\n",
      "\tsetSealResponse, secureRandomReader, err := c.configureSeals(ctx, config, backend, infoKeys, info)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tcurrentSeals := setSealResponse.getCreatedSeals()\n",
      "\tdefer c.finalizeSeals(ctx, &currentSeals)\n",
      "\tcoreConfig := createCoreConfig(c, config, backend, configSR, setSealResponse.barrierSeal, setSealResponse.unwrapSeal, metricsHelper, metricSink, secureRandomReader)\n",
      "\tif c.flagDevThreeNode {\n",
      "\t\treturn c.enableThreeNodeDevCluster(&coreConfig, info, infoKeys, c.flagDevListenAddr, os.Getenv(\"VAULT_DEV_TEMP_DIR\"))\n",
      "\t}\n",
      "\tif c.flagDevFourCluster {\n",
      "\t\treturn entEnableFourClusterDev(c, &coreConfig, info, infoKeys, os.Getenv(\"VAULT_DEV_TEMP_DIR\"))\n",
      "\t}\n",
      "\tif allowPendingRemoval := os.Getenv(consts.EnvVaultAllowPendingRemovalMounts); allowPendingRemoval != \"\" {\n",
      "\t\tvar err error\n",
      "\t\tcoreConfig.PendingRemovalMountsAllowed, err = strconv.ParseBool(allowPendingRemoval)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Warn(wrapAtLength(\"WARNING! failed to parse \" + consts.EnvVaultAllowPendingRemovalMounts + \" env var: \" + \"defaulting to false.\"))\n",
      "\t\t}\n",
      "\t}\n",
      "\tdisableClustering, err := initHaBackend(c, config, &coreConfig, backend)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Output(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\terr = determineRedirectAddr(c, &coreConfig, config)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Output(err.Error())\n",
      "\t}\n",
      "\terr = findClusterAddress(c, &coreConfig, config, disableClustering)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Output(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif enableUI := os.Getenv(\"VAULT_UI\"); enableUI != \"\" {\n",
      "\t\tvar err error\n",
      "\t\tcoreConfig.EnableUI, err = strconv.ParseBool(enableUI)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Output(\"Error parsing the environment variable VAULT_UI\")\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tisBackendHA := coreConfig.HAPhysical != nil && coreConfig.HAPhysical.HAEnabled()\n",
      "\tif !c.flagDev && (coreConfig.GetServiceRegistration() != nil) && !isBackendHA {\n",
      "\t\tc.UI.Output(\"service_registration is configured, but storage does not support HA\")\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tentAdjustCoreConfig(config, &coreConfig)\n",
      "\tif !entCheckStorageType(&coreConfig) {\n",
      "\t\tc.UI.Warn(\"\")\n",
      "\t\tc.UI.Warn(wrapAtLength(fmt.Sprintf(\"WARNING: storage configured to use %q which is not supported for Vault Enterprise, must be \\\"raft\\\" or \\\"consul\\\"\", coreConfig.StorageType)))\n",
      "\t\tc.UI.Warn(\"\")\n",
      "\t}\n",
      "\tif !c.flagDev {\n",
      "\t\tinMemStorageTypes := []string{\"inmem\", \"inmem_ha\", \"inmem_transactional\", \"inmem_transactional_ha\"}\n",
      "\t\tif strutil.StrListContains(inMemStorageTypes, coreConfig.StorageType) {\n",
      "\t\t\tc.UI.Warn(\"\")\n",
      "\t\t\tc.UI.Warn(wrapAtLength(fmt.Sprintf(\"WARNING: storage configured to use %q which should NOT be used in production\", coreConfig.StorageType)))\n",
      "\t\t\tc.UI.Warn(\"\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tcore, newCoreError := vault.NewCore(&coreConfig)\n",
      "\tif newCoreError != nil {\n",
      "\t\tif vault.IsFatalError(newCoreError) {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error initializing core: %s\", newCoreError))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tc.UI.Warn(wrapAtLength(\"WARNING! A non-fatal error occurred during initialization. Please \" + \"check the logs for more information.\"))\n",
      "\t\tc.UI.Warn(\"\")\n",
      "\t}\n",
      "\tc.reloadFuncs = coreConfig.ReloadFuncs\n",
      "\tc.reloadFuncsLock = coreConfig.ReloadFuncsLock\n",
      "\tinfo[\"storage\"] = config.Storage.Type\n",
      "\tinfo[\"mlock\"] = fmt.Sprintf(\"supported: %v, enabled: %v\", mlock.Supported(), !config.DisableMlock && mlock.Supported())\n",
      "\tinfoKeys = append(infoKeys, \"mlock\", \"storage\")\n",
      "\tif coreConfig.ClusterAddr != \"\" {\n",
      "\t\tinfo[\"cluster address\"] = coreConfig.ClusterAddr\n",
      "\t\tinfoKeys = append(infoKeys, \"cluster address\")\n",
      "\t}\n",
      "\tif coreConfig.RedirectAddr != \"\" {\n",
      "\t\tinfo[\"api address\"] = coreConfig.RedirectAddr\n",
      "\t\tinfoKeys = append(infoKeys, \"api address\")\n",
      "\t}\n",
      "\tif config.HAStorage != nil {\n",
      "\t\tinfo[\"HA storage\"] = config.HAStorage.Type\n",
      "\t\tinfoKeys = append(infoKeys, \"HA storage\")\n",
      "\t} else {\n",
      "\t\tif coreConfig.HAPhysical != nil {\n",
      "\t\t\tif coreConfig.HAPhysical.HAEnabled() {\n",
      "\t\t\t\tinfo[\"storage\"] += \" (HA available)\"\n",
      "\t\t\t} else {\n",
      "\t\t\t\tinfo[\"storage\"] += \" (HA disabled)\"\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tstatus, lns, clusterAddrs, errMsg := c.InitListeners(config, disableClustering, &infoKeys, &info)\n",
      "\tif status != 0 {\n",
      "\t\tc.UI.Output(\"Error parsing listener configuration.\")\n",
      "\t\tc.UI.Error(errMsg.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tlistenerCloseFunc := func() {\n",
      "\t\tfor _, ln := range lns {\n",
      "\t\t\tln.Listener.Close()\n",
      "\t\t}\n",
      "\t}\n",
      "\tdefer c.cleanupGuard.Do(listenerCloseFunc)\n",
      "\tinfoKeys = append(infoKeys, \"version\")\n",
      "\tverInfo := version.GetVersion()\n",
      "\tinfo[\"version\"] = verInfo.FullVersionNumber(false)\n",
      "\tif verInfo.Revision != \"\" {\n",
      "\t\tinfo[\"version sha\"] = strings.Trim(verInfo.Revision, \"'\")\n",
      "\t\tinfoKeys = append(infoKeys, \"version sha\")\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"cgo\")\n",
      "\tinfo[\"cgo\"] = \"disabled\"\n",
      "\tif version.CgoEnabled {\n",
      "\t\tinfo[\"cgo\"] = \"enabled\"\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"recovery mode\")\n",
      "\tinfo[\"recovery mode\"] = \"false\"\n",
      "\tinfoKeys = append(infoKeys, \"go version\")\n",
      "\tinfo[\"go version\"] = runtime.Version()\n",
      "\tfipsStatus := entGetFIPSInfoKey()\n",
      "\tif fipsStatus != \"\" {\n",
      "\t\tinfoKeys = append(infoKeys, \"fips\")\n",
      "\t\tinfo[\"fips\"] = fipsStatus\n",
      "\t}\n",
      "\tif config.HCPLinkConf != nil {\n",
      "\t\tinfoKeys = append(infoKeys, \"HCP organization\")\n",
      "\t\tinfo[\"HCP organization\"] = config.HCPLinkConf.Resource.Organization\n",
      "\t\tinfoKeys = append(infoKeys, \"HCP project\")\n",
      "\t\tinfo[\"HCP project\"] = config.HCPLinkConf.Resource.Project\n",
      "\t\tinfoKeys = append(infoKeys, \"HCP resource ID\")\n",
      "\t\tinfo[\"HCP resource ID\"] = config.HCPLinkConf.Resource.ID\n",
      "\t}\n",
      "\trequestLimiterStatus := entGetRequestLimiterStatus(coreConfig)\n",
      "\tif requestLimiterStatus != \"\" {\n",
      "\t\tinfoKeys = append(infoKeys, \"request limiter\")\n",
      "\t\tinfo[\"request limiter\"] = requestLimiterStatus\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"administrative namespace\")\n",
      "\tinfo[\"administrative namespace\"] = config.AdministrativeNamespacePath\n",
      "\tsort.Strings(infoKeys)\n",
      "\tc.UI.Output(\"==> Vault server configuration:\\n\")\n",
      "\tfor _, k := range infoKeys {\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"%24s: %s\", strings.Title(k), info[k]))\n",
      "\t}\n",
      "\tc.UI.Output(\"\")\n",
      "\tif c.flagTestVerifyOnly {\n",
      "\t\treturn 0\n",
      "\t}\n",
      "\tcore.SetClusterListenerAddrs(clusterAddrs)\n",
      "\tcore.SetClusterHandler(vaulthttp.Handler.Handler(&vault.HandlerProperties{Core: core, ListenerConfig: &configutil.Listener{}}))\n",
      "\tif !core.IsInSealMigrationMode(true) {\n",
      "\t\tgo runUnseal(c, core, ctx)\n",
      "\t}\n",
      "\tif config.Storage.Type == storageTypeRaft {\n",
      "\t\tif err := core.InitiateRetryJoin(ctx); err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to initiate raft retry join, %q\", err.Error()))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.WaitGroup = &sync.WaitGroup{}\n",
      "\terr = runListeners(c, &coreConfig, config, configSR)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tclusterJson := &testcluster.ClusterJson{}\n",
      "\terr = initDevCore(c, &coreConfig, config, core, certDir, clusterJson)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\terr = startHttpServers(c, core, config, lns)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\thcpLogger := c.logger.Named(\"hcp-connectivity\")\n",
      "\thcpLink, err := hcp_link.NewHCPLink(config.HCPLinkConf, core, hcpLogger)\n",
      "\tif err != nil {\n",
      "\t\tc.logger.Error(\"failed to establish HCP connection\", \"error\", err)\n",
      "\t} else if hcpLink != nil {\n",
      "\t\tc.logger.Trace(\"established HCP connection\")\n",
      "\t}\n",
      "\tif c.flagTestServerConfig {\n",
      "\t\treturn 0\n",
      "\t}\n",
      "\tif setSealResponse.sealConfigError != nil {\n",
      "\t\tinit, err := core.InitializedLocally(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error checking if core is initialized: %v\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif init {\n",
      "\t\t\tc.UI.Error(\"Vault is initialized but no Seal key could be loaded\")\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !c.logFlags.flagCombineLogs {\n",
      "\t\tc.UI.Output(\"==> Vault server started! Log data will stream in below:\\n\")\n",
      "\t}\n",
      "\tselect {\n",
      "\tcase c.startedCh <- struct{}{}:\n",
      "\tdefault:\n",
      "\t}\n",
      "\tc.flushLog()\n",
      "\tif err := c.storePidFile(config.PidFile); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error storing PID: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.notifySystemd(systemd.SdNotifyReady)\n",
      "\tif c.flagDev {\n",
      "\t\tprotocol := \"http://\"\n",
      "\t\tif c.flagDevTLS {\n",
      "\t\t\tprotocol = \"https://\"\n",
      "\t\t}\n",
      "\t\tclusterJson.Nodes = []testcluster.ClusterNode{{APIAddress: protocol + config.Listeners[0].Address}}\n",
      "\t\tif c.flagDevTLS {\n",
      "\t\t\tclusterJson.CACertPath = fmt.Sprintf(\"%s/%s\", certDir, server.VaultDevCAFilename)\n",
      "\t\t}\n",
      "\t\tif c.flagDevClusterJson != \"\" && !c.flagDevThreeNode {\n",
      "\t\t\tb, err := jsonutil.EncodeJSON(clusterJson)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error encoding cluster.json: %s\", err))\n",
      "\t\t\t\treturn 1\n",
      "\t\t\t}\n",
      "\t\t\terr = os.WriteFile(c.flagDevClusterJson, b, 0o600)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error writing cluster.json %q: %s\", c.flagDevClusterJson, err))\n",
      "\t\t\t\treturn 1\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\tif err := c.removePidFile(config.PidFile); err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error deleting the PID file: %s\", err))\n",
      "\t\t}\n",
      "\t}()\n",
      "\tvar coreShutdownDoneCh <-chan struct{}\n",
      "\tif c.flagExitOnCoreShutdown {\n",
      "\t\tcoreShutdownDoneCh = core.ShutdownDone()\n",
      "\t}\n",
      "\tshutdownTriggered := false\n",
      "\tretCode := 0\n",
      "\tfor !shutdownTriggered {\n",
      "\t\tselect {\n",
      "\t\tcase <-coreShutdownDoneCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault core was shut down\")\n",
      "\t\t\tretCode = 1\n",
      "\t\t\tshutdownTriggered = true\n",
      "\t\tcase <-c.ShutdownCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault shutdown triggered\")\n",
      "\t\t\tshutdownTriggered = true\n",
      "\t\tcase <-c.SighupCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault reload triggered\")\n",
      "\t\t\tc.notifySystemd(systemd.SdNotifyReloading)\n",
      "\t\t\tvar config *server.Config\n",
      "\t\t\tvar configErrors []configutil.ConfigError\n",
      "\t\t\tfor _, path := range c.flagConfigs {\n",
      "\t\t\t\tcurrent, err := server.LoadConfig(path)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tc.logger.Error(\"could not reload config\", \"path\", path, \"error\", err)\n",
      "\t\t\t\t\tgoto RUNRELOADFUNCS\n",
      "\t\t\t\t}\n",
      "\t\t\t\tconfigErrors = append(configErrors, current.Validate(path)...)\n",
      "\t\t\t\tif config == nil {\n",
      "\t\t\t\t\tconfig = current\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tconfig = config.Merge(current)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif config == nil {\n",
      "\t\t\t\tc.logger.Error(\"no config found at reload time\")\n",
      "\t\t\t\tgoto RUNRELOADFUNCS\n",
      "\t\t\t}\n",
      "\t\t\tfor _, cErr := range configErrors {\n",
      "\t\t\t\tc.logger.Warn(cErr.String())\n",
      "\t\t\t}\n",
      "\t\t\tif !cmp.Equal(core.GetCoreConfigInternal().Seals, config.Seals) {\n",
      "\t\t\t\tsetSealResponse, err = c.reloadSeals(ctx, core, config)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tc.UI.Error(fmt.Errorf(\"error reloading seal config: %s\", err).Error())\n",
      "\t\t\t\t\tconfig.Seals = core.GetCoreConfigInternal().Seals\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tc.finalizeSeals(ctx, &currentSeals)\n",
      "\t\t\t\t\tcurrentSeals = setSealResponse.getCreatedSeals()\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tcore.SetConfig(config)\n",
      "\t\t\tif err = core.ReloadCustomResponseHeaders(); err != nil {\n",
      "\t\t\t\tc.logger.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tcore.ReloadLogRequestsLevel()\n",
      "\t\t\tcore.ReloadRequestLimiter()\n",
      "\t\t\thcpLink, err = c.reloadHCPLink(hcpLink, config, core, hcpLogger)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.logger.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif config.LogLevel != \"\" {\n",
      "\t\t\t\tlevel, err := loghelper.ParseLogLevel(config.LogLevel)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tc.logger.Error(\"unknown log level found on reload\", \"level\", config.LogLevel)\n",
      "\t\t\t\t\tgoto RUNRELOADFUNCS\n",
      "\t\t\t\t}\n",
      "\t\t\t\tcore.SetLogLevel(level)\n",
      "\t\t\t}\n",
      "\t\tRUNRELOADFUNCS:\n",
      "\t\t\tif err := c.Reload(c.reloadFuncsLock, c.reloadFuncs, c.flagConfigs, core); err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error(s) were encountered during reload: %s\", err))\n",
      "\t\t\t}\n",
      "\t\t\tif err = core.EntReloadLicense(); err != nil {\n",
      "\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif err := core.ReloadCensus(); err != nil {\n",
      "\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tselect {\n",
      "\t\t\tcase c.licenseReloadedCh <- err:\n",
      "\t\t\tdefault:\n",
      "\t\t\t}\n",
      "\t\t\tcore.ReloadManagedKeyRegistryConfig()\n",
      "\t\t\tc.notifySystemd(systemd.SdNotifyReady)\n",
      "\t\tcase <-c.SigUSR2Ch:\n",
      "\t\t\tlogWriter := c.logger.StandardWriter(&hclog.StandardLoggerOptions{})\n",
      "\t\t\tpprof.Lookup(\"goroutine\").WriteTo(logWriter, 2)\n",
      "\t\t\tif os.Getenv(\"VAULT_STACKTRACE_WRITE_TO_FILE\") != \"\" {\n",
      "\t\t\t\tc.logger.Info(\"Writing stacktrace to file\")\n",
      "\t\t\t\tdir := \"\"\n",
      "\t\t\t\tpath := os.Getenv(\"VAULT_STACKTRACE_FILE_PATH\")\n",
      "\t\t\t\tif path != \"\" {\n",
      "\t\t\t\t\tif _, err := os.Stat(path); err != nil {\n",
      "\t\t\t\t\t\tc.logger.Error(\"Checking stacktrace path failed\", \"error\", err)\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tdir = path\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tdir, err = os.MkdirTemp(\"\", \"vault-stacktrace\")\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tc.logger.Error(\"Could not create temporary directory for stacktrace\", \"error\", err)\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tf, err := os.CreateTemp(dir, \"stacktrace\")\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tc.logger.Error(\"Could not create stacktrace file\", \"error\", err)\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif err := pprof.Lookup(\"goroutine\").WriteTo(f, 2); err != nil {\n",
      "\t\t\t\t\tf.Close()\n",
      "\t\t\t\t\tc.logger.Error(\"Could not write stacktrace to file\", \"error\", err)\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tc.logger.Info(fmt.Sprintf(\"Wrote stacktrace to: %s\", f.Name()))\n",
      "\t\t\t\tf.Close()\n",
      "\t\t\t}\n",
      "\t\t\tpprofPath := filepath.Join(os.TempDir(), \"vault-pprof\")\n",
      "\t\t\terr := os.MkdirAll(pprofPath, os.ModePerm)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.logger.Error(\"Could not create temporary directory for pprof\", \"error\", err)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tdumps := []string{\"goroutine\", \"heap\", \"allocs\", \"threadcreate\", \"profile\"}\n",
      "\t\t\tfor _, dump := range dumps {\n",
      "\t\t\t\tpFile, err := os.Create(filepath.Join(pprofPath, dump))\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tc.logger.Error(\"error creating pprof file\", \"name\", dump, \"error\", err)\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dump != \"profile\" {\n",
      "\t\t\t\t\terr = pprof.Lookup(dump).WriteTo(pFile, 0)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tc.logger.Error(\"error generating pprof data\", \"name\", dump, \"error\", err)\n",
      "\t\t\t\t\t\tpFile.Close()\n",
      "\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tif err := pprof.StartCPUProfile(pFile); err != nil {\n",
      "\t\t\t\t\t\tc.logger.Error(\"could not start CPU profile: \", err)\n",
      "\t\t\t\t\t\tpFile.Close()\n",
      "\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\ttime.Sleep(time.Second * 1)\n",
      "\t\t\t\t\tpprof.StopCPUProfile()\n",
      "\t\t\t\t}\n",
      "\t\t\t\tpFile.Close()\n",
      "\t\t\t}\n",
      "\t\t\tc.logger.Info(fmt.Sprintf(\"Wrote pprof files to: %s\", pprofPath))\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.notifySystemd(systemd.SdNotifyStopping)\n",
      "\tc.cleanupGuard.Do(listenerCloseFunc)\n",
      "\tif hcpLink != nil {\n",
      "\t\tif err := hcpLink.Shutdown(); err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error with HCP Link shutdown: %v\", err.Error()))\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := core.Shutdown(); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error with core shutdown: %s\", err))\n",
      "\t}\n",
      "\tc.WaitGroup.Wait()\n",
      "\treturn retCode\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBMFAConfigByNameInTxn(ctx context.Context, txn *memdb.Txn, mConfigName string) (*mfa.Config, error) {\n",
      "\tif mConfigName == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing config name\")\n",
      "\t}\n",
      "\tif txn == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"txn is nil\")\n",
      "\t}\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tmConfigRaw, err := txn.First(b.methodTable, \"name\", ns.ID, mConfigName)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to fetch MFA config from memdb using name: %w\", err)\n",
      "\t}\n",
      "\tif mConfigRaw == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tmConfig, ok := mConfigRaw.(*mfa.Config)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to declare the type of fetched MFA config\")\n",
      "\t}\n",
      "\treturn mConfig.Clone()\n",
      "}\n",
      "func (b *databaseBackend) DatabaseConfig(ctx context.Context, s logical.Storage, name string) (*DatabaseConfig, error) {\n",
      "\tentry, err := s.Get(ctx, fmt.Sprintf(\"config/%s\", name))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to read connection configuration: %w\", err)\n",
      "\t}\n",
      "\tif entry == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to find entry for connection with name: %q\", name)\n",
      "\t}\n",
      "\tvar config DatabaseConfig\n",
      "\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn &config, nil\n",
      "}\n",
      "func (c *OperatorInitCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.BoolVar(&BoolVar{Name: \"status\", Target: &c.flagStatus, Default: false, Usage: \"Print the current initialization status. An exit code of 0 means \" + \"the Vault is already initialized. An exit code of 1 means an error \" + \"occurred. An exit code of 2 means the Vault is not initialized.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"key-shares\", Aliases: []string{\"n\"}, Target: &c.flagKeyShares, Completion: complete.PredictAnything, Usage: \"Number of key shares to split the generated root key into. \" + \"This is the number of \\\"unseal keys\\\" to generate.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"key-threshold\", Aliases: []string{\"t\"}, Target: &c.flagKeyThreshold, Completion: complete.PredictAnything, Usage: \"Number of key shares required to reconstruct the root key. \" + \"This must be less than or equal to -key-shares.\"})\n",
      "\tf.VarFlag(&VarFlag{Name: \"pgp-keys\", Value: (*pgpkeys.PubKeyFilesFlag)(&c.flagPGPKeys), Completion: complete.PredictAnything, Usage: \"Comma-separated list of paths to files on disk containing \" + \"public PGP keys OR a comma-separated list of Keybase usernames using \" + \"the format \\\"keybase:<username>\\\". When supplied, the generated \" + \"unseal keys will be encrypted and base64-encoded in the order \" + \"specified in this list. The number of entries must match -key-shares, \" + \"unless -stored-shares are used.\"})\n",
      "\tf.VarFlag(&VarFlag{Name: \"root-token-pgp-key\", Value: (*pgpkeys.PubKeyFileFlag)(&c.flagRootTokenPGPKey), Completion: complete.PredictAnything, Usage: \"Path to a file on disk containing a binary or base64-encoded \" + \"public PGP key. This can also be specified as a Keybase username \" + \"using the format \\\"keybase:<username>\\\". When supplied, the generated \" + \"root token will be encrypted and base64-encoded with the given public \" + \"key.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"stored-shares\", Target: &c.flagStoredShares, Default: -1, Usage: \"DEPRECATED: This flag does nothing. It will be removed in Vault 1.3.\"})\n",
      "\tf = set.NewFlagSet(\"Consul Options\")\n",
      "\tf.BoolVar(&BoolVar{Name: \"consul-auto\", Target: &c.flagConsulAuto, Default: false, Usage: \"Perform automatic service discovery using Consul in HA mode. \" + \"When all nodes in a Vault HA cluster are registered with Consul, \" + \"enabling this option will trigger automatic service discovery based \" + \"on the provided -consul-service value. When Consul is Vault's HA \" + \"backend, this functionality is automatically enabled. Ensure the \" + \"proper Consul environment variables are set (CONSUL_HTTP_ADDR, etc). \" + \"When only one Vault server is discovered, it will be initialized \" + \"automatically. When more than one Vault server is discovered, they \" + \"will each be output for selection.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"consul-service\", Target: &c.flagConsulService, Default: \"vault\", Completion: complete.PredictAnything, Usage: \"Name of the service in Consul under which the Vault servers are \" + \"registered.\"})\n",
      "\tf = set.NewFlagSet(\"Auto Unseal Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"recovery-shares\", Target: &c.flagRecoveryShares, Completion: complete.PredictAnything, Usage: \"Number of key shares to split the recovery key into. \" + \"This is only used in auto-unseal mode.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"recovery-threshold\", Target: &c.flagRecoveryThreshold, Completion: complete.PredictAnything, Usage: \"Number of key shares required to reconstruct the recovery key. \" + \"This is only used in Auto Unseal mode.\"})\n",
      "\tf.VarFlag(&VarFlag{Name: \"recovery-pgp-keys\", Value: (*pgpkeys.PubKeyFilesFlag)(&c.flagRecoveryPGPKeys), Completion: complete.PredictAnything, Usage: \"Behaves like -pgp-keys, but for the recovery key shares. This \" + \"is only used in Auto Unseal mode.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (c *Core) configureLogicalBackends(backends map[string]logical.Factory, logger log.Logger, adminNamespacePath string) {\n",
      "\tlogicalBackends := make(map[string]logical.Factory, len(backends))\n",
      "\tfor k, f := range backends {\n",
      "\t\tlogicalBackends[k] = f\n",
      "\t}\n",
      "\t_, ok := logicalBackends[mountTypeKV]\n",
      "\tif !ok {\n",
      "\t\tlogicalBackends[mountTypeKV] = kv.Factory\n",
      "\t}\n",
      "\tlogicalBackends[mountTypeCubbyhole] = CubbyholeBackendFactory\n",
      "\tlogicalBackends[mountTypeSystem] = func(ctx context.Context, config *logical.BackendConfig) (logical.Backend, error) {\n",
      "\t\tsysBackendLogger := logger.Named(\"system\")\n",
      "\t\tc.AddLogger(sysBackendLogger)\n",
      "\t\tb := NewSystemBackend(c, sysBackendLogger, config)\n",
      "\t\tif err := b.Setup(ctx, config); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\treturn b, nil\n",
      "\t}\n",
      "\tlogicalBackends[mountTypeIdentity] = func(ctx context.Context, config *logical.BackendConfig) (logical.Backend, error) {\n",
      "\t\tidentityLogger := logger.Named(\"identity\")\n",
      "\t\tc.AddLogger(identityLogger)\n",
      "\t\treturn NewIdentityStore(ctx, c, config, identityLogger)\n",
      "\t}\n",
      "\tc.logicalBackends = logicalBackends\n",
      "\tc.addExtraLogicalBackends(adminNamespacePath)\n",
      "}\n",
      "func (b *RaftBackend) SetAutopilotConfig(config *AutopilotConfig) {\n",
      "\tb.l.Lock()\n",
      "\tb.autopilotConfig = config\n",
      "\tb.logger.Info(\"updated autopilot configuration\", \"config\", b.autopilotConfig)\n",
      "\tb.l.Unlock()\n",
      "}\n",
      "func (b *LoginMFABackend) deleteMFALoginEnforcementConfigByNameAndNamespace(ctx context.Context, name, namespaceId string) error {\n",
      "\tvar err error\n",
      "\tif name == \"\" {\n",
      "\t\treturn fmt.Errorf(\"missing config name\")\n",
      "\t}\n",
      "\tb.mfaLock.Lock()\n",
      "\tdefer b.mfaLock.Unlock()\n",
      "\teConfig, err := b.MemDBMFALoginEnforcementConfigByNameAndNamespace(name, namespaceId)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif eConfig == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tentryIndex := mfaLoginEnforcementPrefix + eConfig.ID\n",
      "\tbarrierView, err := b.Core.barrierViewForNamespace(eConfig.NamespaceID)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\terr = barrierView.Delete(ctx, entryIndex)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\ttxn := b.db.Txn(true)\n",
      "\tdefer txn.Abort()\n",
      "\terr = txn.Delete(memDBMFALoginEnforcementsTable, eConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to delete MFA login enforcement config from memdb: %w\", err)\n",
      "\t}\n",
      "\ttxn.Commit()\n",
      "\treturn nil\n",
      "}\n",
      "func (c *PKIHealthCheckCommand) Run(args []string) int {\n",
      "\tf := c.Flags()\n",
      "\tif err := f.Parse(args); err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\targs = f.Args()\n",
      "\tif !c.flagList && len(args) < 1 {\n",
      "\t\tc.UI.Error(\"Not enough arguments (expected mount path, got nothing)\")\n",
      "\t\treturn pkiRetUsage\n",
      "\t} else if !c.flagList && len(args) > 1 {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Too many arguments (expected only mount path, got %d arguments)\", len(args)))\n",
      "\t\tfor _, arg := range args {\n",
      "\t\t\tif strings.HasPrefix(arg, \"-\") {\n",
      "\t\t\t\tc.UI.Warn(fmt.Sprintf(\"Options (%v) must be specified before positional arguments (%v)\", arg, args[0]))\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\tif !c.isValidRetIndicator() {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Invalid flag -return-indicator=%v; known options are default, informational, warning, critical, and permission\", c.flagReturnIndicator))\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\tclient, err := c.Client()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\tpkiPath := \"<mount>\"\n",
      "\tif len(args) == 1 {\n",
      "\t\tpkiPath = args[0]\n",
      "\t}\n",
      "\tmount := sanitizePath(pkiPath)\n",
      "\texecutor := healthcheck.NewExecutor(client, mount)\n",
      "\texecutor.AddCheck(healthcheck.NewCAValidityPeriodCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewCRLValidityPeriodCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewHardwareBackedRootCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewRootIssuedLeavesCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewRoleAllowsLocalhostCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewRoleAllowsGlobWildcardsCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewRoleNoStoreFalseCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewAuditVisibilityCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewAllowIfModifiedSinceCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewEnableAutoTidyCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewTidyLastRunCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewTooManyCertsCheck())\n",
      "\texecutor.AddCheck(healthcheck.NewEnableAcmeIssuance())\n",
      "\texecutor.AddCheck(healthcheck.NewAllowAcmeHeaders())\n",
      "\tif c.flagDefaultDisabled {\n",
      "\t\texecutor.DefaultEnabled = false\n",
      "\t}\n",
      "\tif c.flagList {\n",
      "\t\tuiFormat := Format(c.UI)\n",
      "\t\tif uiFormat == \"yaml\" {\n",
      "\t\t\tc.UI.Error(\"YAML output format is not supported by the --list command\")\n",
      "\t\t\treturn pkiRetUsage\n",
      "\t\t}\n",
      "\t\tif uiFormat != \"json\" {\n",
      "\t\t\tc.UI.Output(\"Default health check config:\")\n",
      "\t\t}\n",
      "\t\tconfig := map[string]map[string]interface{}{}\n",
      "\t\tfor _, checker := range executor.Checkers {\n",
      "\t\t\tconfig[checker.Name()] = checker.DefaultConfig()\n",
      "\t\t}\n",
      "\t\tmarshaled, err := json.MarshalIndent(config, \"\", \"  \")\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to marshal default config for check: %v\", err))\n",
      "\t\t\treturn pkiRetUsage\n",
      "\t\t}\n",
      "\t\tc.UI.Output(string(marshaled))\n",
      "\t\treturn pkiRetOK\n",
      "\t}\n",
      "\texternal_config := map[string]interface{}{}\n",
      "\tif c.flagConfig != \"\" {\n",
      "\t\tcontents, err := os.Open(c.flagConfig)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to read configuration file %v: %v\", c.flagConfig, err))\n",
      "\t\t\treturn pkiRetUsage\n",
      "\t\t}\n",
      "\t\tdecoder := json.NewDecoder(contents)\n",
      "\t\tdecoder.UseNumber()\n",
      "\t\tif err := decoder.Decode(&external_config); err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to parse configuration file %v: %v\", c.flagConfig, err))\n",
      "\t\t\treturn pkiRetUsage\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := executor.BuildConfig(external_config); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Failed to build health check configuration: %v\", err))\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\tresults, err := executor.Execute()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Failed to run health check: %v\", err))\n",
      "\t\treturn pkiRetUsage\n",
      "\t}\n",
      "\tif err := c.outputResults(executor, results); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Failed to render results for display: %v\", err))\n",
      "\t}\n",
      "\treturn c.selectRetCode(results)\n",
      "}\n",
      "func NewGCPAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\tvar err error\n",
      "\tg := &gcpMethod{logger: conf.Logger, mountPath: conf.MountPath, serviceAccount: \"default\"}\n",
      "\ttypeRaw, ok := conf.Config[\"type\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'type' value\")\n",
      "\t}\n",
      "\tg.authType, ok = typeRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'type' config value to string\")\n",
      "\t}\n",
      "\troleRaw, ok := conf.Config[\"role\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role' value\")\n",
      "\t}\n",
      "\tg.role, ok = roleRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase g.role == \"\":\n",
      "\t\treturn nil, errors.New(\"'role' value is empty\")\n",
      "\tcase g.authType == \"\":\n",
      "\t\treturn nil, errors.New(\"'type' value is empty\")\n",
      "\tcase g.authType != typeGCE && g.authType != typeIAM:\n",
      "\t\treturn nil, errors.New(\"'type' value is invalid\")\n",
      "\t}\n",
      "\tcredentialsRaw, ok := conf.Config[\"credentials\"]\n",
      "\tif ok {\n",
      "\t\tg.credentials, ok = credentialsRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'credentials' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tserviceAccountRaw, ok := conf.Config[\"service_account\"]\n",
      "\tif ok {\n",
      "\t\tg.serviceAccount, ok = serviceAccountRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'service_account' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tprojectRaw, ok := conf.Config[\"project\"]\n",
      "\tif ok {\n",
      "\t\tg.project, ok = projectRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'project' value into string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tjwtExpRaw, ok := conf.Config[\"jwt_exp\"]\n",
      "\tif ok {\n",
      "\t\tg.jwtExp, err = parseutil.ParseInt(jwtExpRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'jwt_raw' into integer: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn g, nil\n",
      "}\n",
      "func (c *PluginCatalog) NewPluginClient(ctx context.Context, config pluginutil.PluginClientConfig) (*pluginClient, error) {\n",
      "\tc.lock.Lock()\n",
      "\tdefer c.lock.Unlock()\n",
      "\tif config.Name == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"no name provided for plugin\")\n",
      "\t}\n",
      "\tif config.PluginType == consts.PluginTypeUnknown {\n",
      "\t\treturn nil, fmt.Errorf(\"no plugin type provided\")\n",
      "\t}\n",
      "\tpluginRunner, err := c.get(ctx, config.Name, config.PluginType, config.Version)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to lookup plugin: %w\", err)\n",
      "\t}\n",
      "\tif pluginRunner == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"no plugin found\")\n",
      "\t}\n",
      "\tpc, err := c.newPluginClient(ctx, pluginRunner, config)\n",
      "\treturn pc, err\n",
      "}\n",
      "func (c *KVMetadataPutCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"max-versions\", Target: &c.flagMaxVersions, Default: -1, Usage: `The number of versions to keep. If not set, the backends configured max version is used.`})\n",
      "\tf.BoolPtrVar(&BoolPtrVar{Name: \"cas-required\", Target: &c.flagCASRequired, Usage: `If true the key will require the cas parameter to be set on all write requests. If false, the backends configuration will be used.`})\n",
      "\tf.DurationVar(&DurationVar{Name: \"delete-version-after\", Target: &c.flagDeleteVersionAfter, Default: -1, EnvVar: \"\", Completion: complete.PredictAnything, Usage: `Specifies the length of time before a version is deleted.\n",
      "\t\tIf not set, the backend's configured delete-version-after is used. Cannot be\n",
      "\t\tgreater than the backend's delete-version-after. The delete-version-after is\n",
      "\t\tspecified as a numeric string with a suffix like \"30s\" or\n",
      "\t\t\"3h25m19s\".`})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"custom-metadata\", Target: &c.flagCustomMetadata, Default: map[string]string{}, Usage: \"Specifies arbitrary version-agnostic key=value metadata meant to describe a secret.\" + \"This can be specified multiple times to add multiple pieces of metadata.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /metadata/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func PluginString(env *logical.PluginEnvironment, pluginName string, comments ...string) string {\n",
      "\tif env == nil {\n",
      "\t\treturn \"\"\n",
      "\t}\n",
      "\tc := []string{\"+\" + projectURL}\n",
      "\tif pluginName != \"\" {\n",
      "\t\tc = append(c, pluginName)\n",
      "\t}\n",
      "\tc = append(c, rt)\n",
      "\tc = append(c, comments...)\n",
      "\tv := env.VaultVersion\n",
      "\tif env.VaultVersionPrerelease != \"\" {\n",
      "\t\tv = fmt.Sprintf(\"%s-%s\", v, env.VaultVersionPrerelease)\n",
      "\t}\n",
      "\tif env.VaultVersionMetadata != \"\" {\n",
      "\t\tv = fmt.Sprintf(\"%s+%s\", v, env.VaultVersionMetadata)\n",
      "\t}\n",
      "\treturn fmt.Sprintf(\"Vault/%s (%s)\", v, strings.Join(c, \"; \"))\n",
      "}\n",
      "func (b *backend) pathTidyWrite(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\tsafetyBuffer := d.Get(\"safety_buffer\").(int)\n",
      "\ttidyCertStore := d.Get(\"tidy_cert_store\").(bool)\n",
      "\ttidyRevokedCerts := d.Get(\"tidy_revoked_certs\").(bool) || d.Get(\"tidy_revocation_list\").(bool)\n",
      "\ttidyRevokedAssocs := d.Get(\"tidy_revoked_cert_issuer_associations\").(bool)\n",
      "\ttidyExpiredIssuers := d.Get(\"tidy_expired_issuers\").(bool)\n",
      "\ttidyBackupBundle := d.Get(\"tidy_move_legacy_ca_bundle\").(bool)\n",
      "\tissuerSafetyBuffer := d.Get(\"issuer_safety_buffer\").(int)\n",
      "\tpauseDurationStr := d.Get(\"pause_duration\").(string)\n",
      "\tpauseDuration := 0 * time.Second\n",
      "\ttidyRevocationQueue := d.Get(\"tidy_revocation_queue\").(bool)\n",
      "\tqueueSafetyBuffer := d.Get(\"revocation_queue_safety_buffer\").(int)\n",
      "\ttidyCrossRevokedCerts := d.Get(\"tidy_cross_cluster_revoked_certs\").(bool)\n",
      "\ttidyAcme := d.Get(\"tidy_acme\").(bool)\n",
      "\tacmeAccountSafetyBuffer := d.Get(\"acme_account_safety_buffer\").(int)\n",
      "\tif safetyBuffer < 1 {\n",
      "\t\treturn logical.ErrorResponse(\"safety_buffer must be greater than zero\"), nil\n",
      "\t}\n",
      "\tif issuerSafetyBuffer < 1 {\n",
      "\t\treturn logical.ErrorResponse(\"issuer_safety_buffer must be greater than zero\"), nil\n",
      "\t}\n",
      "\tif queueSafetyBuffer < 1 {\n",
      "\t\treturn logical.ErrorResponse(\"revocation_queue_safety_buffer must be greater than zero\"), nil\n",
      "\t}\n",
      "\tif acmeAccountSafetyBuffer < 1 {\n",
      "\t\treturn logical.ErrorResponse(\"acme_account_safety_buffer must be greater than zero\"), nil\n",
      "\t}\n",
      "\tif pauseDurationStr != \"\" {\n",
      "\t\tvar err error\n",
      "\t\tpauseDuration, err = parseutil.ParseDurationSecond(pauseDurationStr)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"Error parsing pause_duration: %v\", err)), nil\n",
      "\t\t}\n",
      "\t\tif pauseDuration < (0 * time.Second) {\n",
      "\t\t\treturn logical.ErrorResponse(\"received invalid, negative pause_duration\"), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tbufferDuration := time.Duration(safetyBuffer) * time.Second\n",
      "\tissuerBufferDuration := time.Duration(issuerSafetyBuffer) * time.Second\n",
      "\tqueueSafetyBufferDuration := time.Duration(queueSafetyBuffer) * time.Second\n",
      "\tacmeAccountSafetyBufferDuration := time.Duration(acmeAccountSafetyBuffer) * time.Second\n",
      "\tconfig := &tidyConfig{Enabled: true, Interval: 0 * time.Second, CertStore: tidyCertStore, RevokedCerts: tidyRevokedCerts, IssuerAssocs: tidyRevokedAssocs, ExpiredIssuers: tidyExpiredIssuers, BackupBundle: tidyBackupBundle, SafetyBuffer: bufferDuration, IssuerSafetyBuffer: issuerBufferDuration, PauseDuration: pauseDuration, RevocationQueue: tidyRevocationQueue, QueueSafetyBuffer: queueSafetyBufferDuration, CrossRevokedCerts: tidyCrossRevokedCerts, TidyAcme: tidyAcme, AcmeAccountSafetyBuffer: acmeAccountSafetyBufferDuration}\n",
      "\tif !atomic.CompareAndSwapUint32(b.tidyCASGuard, 0, 1) {\n",
      "\t\tresp := &logical.Response{}\n",
      "\t\tresp.AddWarning(\"Tidy operation already in progress.\")\n",
      "\t\treturn resp, nil\n",
      "\t}\n",
      "\treq = &logical.Request{Storage: req.Storage}\n",
      "\tb.tidyStatusLock.Lock()\n",
      "\tb.lastTidy = time.Now()\n",
      "\tb.tidyStatusLock.Unlock()\n",
      "\tb.startTidyOperation(req, config)\n",
      "\tresp := &logical.Response{}\n",
      "\tif !config.IsAnyTidyEnabled() {\n",
      "\t\tresp.AddWarning(\"Manual tidy requested but no tidy operations were set. Enable at least one tidy operation to be run (\" + config.AnyTidyConfig() + \").\")\n",
      "\t} else {\n",
      "\t\tresp.AddWarning(\"Tidy operation successfully started. Any information from the operation will be printed to Vault's server logs.\")\n",
      "\t}\n",
      "\tif tidyRevocationQueue || tidyCrossRevokedCerts {\n",
      "\t\tisNotPerfPrimary := b.System().ReplicationState().HasState(consts.ReplicationDRSecondary|consts.ReplicationPerformanceStandby) || (!b.System().LocalMount() && b.System().ReplicationState().HasState(consts.ReplicationPerformanceSecondary))\n",
      "\t\tif isNotPerfPrimary {\n",
      "\t\t\tresp.AddWarning(\"tidy_revocation_queue=true and tidy_cross_cluster_revoked_certs=true can only be set on the active node of the primary cluster unless a local mount is used; this option has been ignored.\")\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn logical.RespondWithStatusCode(resp, req, http.StatusAccepted)\n",
      "}\n",
      "func (h *CLIHandler) Help() string {\n",
      "\thelp := `\n",
      "Usage: vault login -method=aws [CONFIG K=V...]\n",
      "\n",
      "  The AWS auth method allows users to authenticate with AWS IAM\n",
      "  credentials. The AWS IAM credentials, and optionally the AWS region, may be \n",
      "  specified in a number of ways, listed in order of precedence below:\n",
      "\n",
      "    1. Explicitly via the command line (not recommended)\n",
      "\n",
      "    2. Via the standard AWS environment variables (AWS_ACCESS_KEY, etc.)\n",
      "\n",
      "    3. Via the ~/.aws/credentials file\n",
      "\n",
      "    4. Via EC2 instance profile\n",
      "\n",
      "  Authenticate using locally stored credentials:\n",
      "\n",
      "      $ vault login -method=aws\n",
      "\n",
      "  Authenticate by passing keys:\n",
      "\n",
      "      $ vault login -method=aws aws_access_key_id=... aws_secret_access_key=...\n",
      "\n",
      "Configuration:\n",
      "\n",
      "  aws_access_key_id=<string>\n",
      "      Explicit AWS access key ID\n",
      "\n",
      "  aws_secret_access_key=<string>\n",
      "      Explicit AWS secret access key\n",
      "\n",
      "  aws_security_token=<string>\n",
      "      Explicit AWS security token for temporary credentials\n",
      "\n",
      "  header_value=<string>\n",
      "      Value for the x-vault-aws-iam-server-id header in requests\n",
      "\n",
      "  mount=<string>\n",
      "      Path where the AWS credential method is mounted. This is usually provided\n",
      "      via the -path flag in the \"vault login\" command, but it can be specified\n",
      "      here as well. If specified here, it takes precedence over the value for\n",
      "      -path. The default value is \"aws\".\n",
      "\n",
      "  region=<string>\n",
      "      Explicit AWS region to reach out to for authentication request signing. A value\n",
      "      of \"auto\" enables auto-detection of region based on the precedence described above.\n",
      "      Defaults to \"us-east-1\" if not specified.\n",
      "\n",
      "  role=<string>\n",
      "      Name of the role to request a token against\n",
      "\n",
      "  log_level=<string>\n",
      "      Set logging level during AWS credential acquisition. Valid levels are\n",
      "      trace, debug, info, warn, error. Defaults to info.\n",
      "`\n",
      "\treturn strings.TrimSpace(help)\n",
      "}\n",
      "func (c *BaseCommand) Client() (*api.Client, error) {\n",
      "\tif c.client != nil {\n",
      "\t\tif err := c.applyHCPConfig(); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\treturn c.client, nil\n",
      "\t}\n",
      "\tconfig := api.DefaultConfig()\n",
      "\tif err := config.ReadEnvironment(); err != nil {\n",
      "\t\treturn nil, errors.Wrap(err, \"failed to read environment\")\n",
      "\t}\n",
      "\tif c.flagAddress != \"\" {\n",
      "\t\tconfig.Address = c.flagAddress\n",
      "\t}\n",
      "\tif c.flagAgentProxyAddress != \"\" {\n",
      "\t\tconfig.Address = c.flagAgentProxyAddress\n",
      "\t}\n",
      "\tif c.flagOutputCurlString {\n",
      "\t\tconfig.OutputCurlString = c.flagOutputCurlString\n",
      "\t}\n",
      "\tif c.flagOutputPolicy {\n",
      "\t\tconfig.OutputPolicy = c.flagOutputPolicy\n",
      "\t}\n",
      "\tif c.flagCACert != \"\" || c.flagCAPath != \"\" || c.flagClientCert != \"\" || c.flagClientKey != \"\" || c.flagTLSServerName != \"\" || c.flagTLSSkipVerify {\n",
      "\t\tt := &api.TLSConfig{CACert: c.flagCACert, CAPath: c.flagCAPath, ClientCert: c.flagClientCert, ClientKey: c.flagClientKey, TLSServerName: c.flagTLSServerName, Insecure: c.flagTLSSkipVerify}\n",
      "\t\tif err := config.ConfigureTLS(t); err != nil {\n",
      "\t\t\treturn nil, errors.Wrap(err, \"failed to setup TLS config\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tclient, err := api.NewClient(config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errors.Wrap(err, \"failed to create client\")\n",
      "\t}\n",
      "\tif os.Getenv(api.EnvVaultMaxRetries) == \"\" {\n",
      "\t\tclient.SetMaxRetries(0)\n",
      "\t}\n",
      "\tclient.SetWrappingLookupFunc(c.DefaultWrappingLookupFunc)\n",
      "\ttoken := client.Token()\n",
      "\tif token == \"\" {\n",
      "\t\thelper, err := c.TokenHelper()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, errors.Wrap(err, \"failed to get token helper\")\n",
      "\t\t}\n",
      "\t\ttoken, err = helper.Get()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, errors.Wrap(err, \"failed to get token from token helper\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif token != \"\" {\n",
      "\t\tclient.SetToken(token)\n",
      "\t}\n",
      "\tclient.SetMFACreds(c.flagMFA)\n",
      "\tif c.flagNS != notSetValue {\n",
      "\t\tc.flagNamespace = c.flagNS\n",
      "\t}\n",
      "\tif c.flagNamespace != notSetValue {\n",
      "\t\tclient.SetNamespace(namespace.Canonicalize(c.flagNamespace))\n",
      "\t}\n",
      "\tif c.flagPolicyOverride {\n",
      "\t\tclient.SetPolicyOverride(c.flagPolicyOverride)\n",
      "\t}\n",
      "\tif c.flagHeader != nil {\n",
      "\t\tvar forbiddenHeaders []string\n",
      "\t\tfor key, val := range c.flagHeader {\n",
      "\t\t\tif strings.HasPrefix(key, \"X-Vault-\") {\n",
      "\t\t\t\tforbiddenHeaders = append(forbiddenHeaders, key)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tclient.AddHeader(key, val)\n",
      "\t\t}\n",
      "\t\tif len(forbiddenHeaders) > 0 {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to setup Headers[%s]: Header starting by 'X-Vault-' are for internal usage only\", strings.Join(forbiddenHeaders, \", \"))\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.client = client\n",
      "\tif err := c.applyHCPConfig(); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif c.addrWarning != \"\" && c.UI != nil {\n",
      "\t\tif os.Getenv(\"VAULT_ADDR\") == \"\" {\n",
      "\t\t\tif !c.flagNonInteractive && isatty.IsTerminal(os.Stdin.Fd()) {\n",
      "\t\t\t\tc.UI.Warn(wrapAtLength(c.addrWarning))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn client, nil\n",
      "}\n",
      "func ListenerChecks(ctx context.Context, listeners []*configutil.Listener) ([]string, []error) {\n",
      "\ttestName := \"Check Listener TLS\"\n",
      "\tctx, span := StartSpan(ctx, testName)\n",
      "\tdefer span.End()\n",
      "\tvar listenerWarnings []string\n",
      "\tvar listenerErrors []error\n",
      "\tfor _, l := range listeners {\n",
      "\t\tlistenerID := l.Address\n",
      "\t\tif l.TLSDisable {\n",
      "\t\t\tWarn(ctx, fmt.Sprintf(\"Listener at address %s: TLS is disabled in a listener config stanza.\", listenerID))\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif l.TLSDisableClientCerts {\n",
      "\t\t\tWarn(ctx, fmt.Sprintf(\"Listener at address %s: TLS for a listener is turned on without requiring client certificates.\", listenerID))\n",
      "\t\t}\n",
      "\t\tstatus, warning := TLSMutualExclusionCertCheck(l)\n",
      "\t\tif status == 1 {\n",
      "\t\t\tWarn(ctx, warning)\n",
      "\t\t}\n",
      "\t\tif l.TLSMinVersion == \"\" {\n",
      "\t\t\tl.TLSMinVersion = \"tls12\"\n",
      "\t\t}\n",
      "\t\tif l.TLSMaxVersion == \"\" {\n",
      "\t\t\tl.TLSMaxVersion = \"tls13\"\n",
      "\t\t}\n",
      "\t\t_, ok := tlsutil.TLSLookup[l.TLSMinVersion]\n",
      "\t\tif !ok {\n",
      "\t\t\terr := fmt.Errorf(\"Listener at address %s: %s.\", listenerID, fmt.Sprintf(minVersionError, l.TLSMinVersion))\n",
      "\t\t\tlistenerErrors = append(listenerErrors, err)\n",
      "\t\t\tFail(ctx, err.Error())\n",
      "\t\t}\n",
      "\t\t_, ok = tlsutil.TLSLookup[l.TLSMaxVersion]\n",
      "\t\tif !ok {\n",
      "\t\t\terr := fmt.Errorf(\"Listener at address %s: %s.\", listenerID, fmt.Sprintf(maxVersionError, l.TLSMaxVersion))\n",
      "\t\t\tlistenerErrors = append(listenerErrors, err)\n",
      "\t\t\tFail(ctx, err.Error())\n",
      "\t\t}\n",
      "\t\twarnings, err := TLSFileChecks(l.TLSCertFile, l.TLSKeyFile)\n",
      "\t\tlistenerWarnings, listenerErrors = outputError(ctx, warnings, listenerWarnings, err, listenerErrors, listenerID)\n",
      "\t\twarnings, err = TLSClientCAFileCheck(l)\n",
      "\t\tlistenerWarnings, listenerErrors = outputError(ctx, warnings, listenerWarnings, err, listenerErrors, listenerID)\n",
      "\t}\n",
      "\treturn listenerWarnings, listenerErrors\n",
      "}\n",
      "func (cl *Listener) GetDialerFunc(ctx context.Context, alpn string) func(string, time.Duration) (net.Conn, error) {\n",
      "\treturn func(addr string, timeout time.Duration) (net.Conn, error) {\n",
      "\t\ttlsConfig, err := cl.TLSConfig(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tcl.logger.Error(\"failed to get tls configuration\", \"error\", err)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif tlsConfig == nil {\n",
      "\t\t\treturn nil, errors.New(\"no tls config found\")\n",
      "\t\t}\n",
      "\t\tcl.l.RLock()\n",
      "\t\tclient, ok := cl.clients[alpn]\n",
      "\t\tcl.l.RUnlock()\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, fmt.Errorf(\"no client configured for alpn: %q\", alpn)\n",
      "\t\t}\n",
      "\t\tserverName := client.ServerName()\n",
      "\t\tif serverName != \"\" {\n",
      "\t\t\ttlsConfig.ServerName = serverName\n",
      "\t\t}\n",
      "\t\tcaCert := client.CACert(ctx)\n",
      "\t\tif caCert != nil {\n",
      "\t\t\tpool := x509.NewCertPool()\n",
      "\t\t\tpool.AddCert(caCert)\n",
      "\t\t\ttlsConfig.RootCAs = pool\n",
      "\t\t\ttlsConfig.ClientCAs = pool\n",
      "\t\t}\n",
      "\t\ttlsConfig.NextProtos = []string{alpn}\n",
      "\t\tcl.logger.Debug(\"creating rpc dialer\", \"address\", addr, \"alpn\", alpn, \"host\", tlsConfig.ServerName)\n",
      "\t\tconn, err := cl.networkLayer.Dial(addr, timeout, tlsConfig)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tcl.logTLSSessionStart(conn.RemoteAddr().String(), conn.ConnectionState())\n",
      "\t\treturn conn, nil\n",
      "\t}\n",
      "}\n",
      "func (b *backend) startTidyOperation(req *logical.Request, config *tidyConfig) {\n",
      "\tgo func() {\n",
      "\t\tatomic.StoreUint32(b.tidyCancelCAS, 0)\n",
      "\t\tdefer atomic.StoreUint32(b.tidyCASGuard, 0)\n",
      "\t\tb.tidyStatusStart(config)\n",
      "\t\tctx := context.Background()\n",
      "\t\tlogger := b.Logger().Named(\"tidy\")\n",
      "\t\tdoTidy := func() error {\n",
      "\t\t\tif config.CertStore {\n",
      "\t\t\t\tif err := b.doTidyCertStore(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.RevokedCerts || config.IssuerAssocs {\n",
      "\t\t\t\tif err := b.doTidyRevocationStore(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.ExpiredIssuers {\n",
      "\t\t\t\tif err := b.doTidyExpiredIssuers(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.BackupBundle {\n",
      "\t\t\t\tif err := b.doTidyMoveCABundle(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.RevocationQueue {\n",
      "\t\t\t\tif err := b.doTidyRevocationQueue(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.CrossRevokedCerts {\n",
      "\t\t\t\tif err := b.doTidyCrossRevocationStore(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.TidyAcme {\n",
      "\t\t\t\tif err := b.doTidyAcme(ctx, req, logger, config); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tif err := doTidy(); err != nil {\n",
      "\t\t\tlogger.Error(\"error running tidy\", \"error\", err)\n",
      "\t\t\tb.tidyStatusStop(err)\n",
      "\t\t} else {\n",
      "\t\t\tb.tidyStatusStop(nil)\n",
      "\t\t\tb.tidyStatusLock.Lock()\n",
      "\t\t\tb.lastTidy = time.Now()\n",
      "\t\t\tb.tidyStatusLock.Unlock()\n",
      "\t\t}\n",
      "\t}()\n",
      "}\n",
      "func (b *databaseBackend) reloadPlugin() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\t\tpluginName := data.Get(\"plugin_name\").(string)\n",
      "\t\tif pluginName == \"\" {\n",
      "\t\t\treturn logical.ErrorResponse(respErrEmptyPluginName), nil\n",
      "\t\t}\n",
      "\t\tconnNames, err := req.Storage.List(ctx, \"config/\")\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\treloaded := []string{}\n",
      "\t\tfor _, connName := range connNames {\n",
      "\t\t\tentry, err := req.Storage.Get(ctx, fmt.Sprintf(\"config/%s\", connName))\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to read connection configuration: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tif entry == nil {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tvar config DatabaseConfig\n",
      "\t\t\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif config.PluginName == pluginName {\n",
      "\t\t\t\tif err := b.reloadConnection(ctx, req.Storage, connName); err != nil {\n",
      "\t\t\t\t\tvar successfullyReloaded string\n",
      "\t\t\t\t\tif len(reloaded) > 0 {\n",
      "\t\t\t\t\t\tsuccessfullyReloaded = fmt.Sprintf(\"successfully reloaded %d connection(s): %s; \", len(reloaded), strings.Join(reloaded, \", \"))\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treturn nil, fmt.Errorf(\"%sfailed to reload connection %q: %w\", successfullyReloaded, connName, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treloaded = append(reloaded, connName)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tresp := &logical.Response{Data: map[string]interface{}{\"connections\": reloaded, \"count\": len(reloaded)}}\n",
      "\t\tif len(reloaded) == 0 {\n",
      "\t\t\tresp.AddWarning(fmt.Sprintf(\"no connections were found with plugin_name %q\", pluginName))\n",
      "\t\t}\n",
      "\t\tb.dbEvent(ctx, \"reload\", req.Path, \"\", true, \"plugin_name\", pluginName)\n",
      "\t\treturn resp, nil\n",
      "\t}\n",
      "}\n",
      "func (c *AuthTuneCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACRequestKeys, Target: &c.flagAuditNonHMACRequestKeys, Usage: \"Key that will not be HMAC'd by audit devices in the request data \" + \"object. To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACResponseKeys, Target: &c.flagAuditNonHMACResponseKeys, Usage: \"Key that will not be HMAC'd by audit devices in the response data \" + \"object. To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"default-lease-ttl\", Target: &c.flagDefaultLeaseTTL, Default: 0, EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"The default lease TTL for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured default lease TTL, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameDescription, Target: &c.flagDescription, Usage: \"Human-friendly description of the this auth method. This overrides \" + \"the current stored value, if any.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameListingVisibility, Target: &c.flagListingVisibility, Usage: \"Determines the visibility of the mount in the UI-specific listing \" + \"endpoint.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"max-lease-ttl\", Target: &c.flagMaxLeaseTTL, Default: 0, EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"The maximum lease TTL for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured maximum lease TTL, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNamePassthroughRequestHeaders, Target: &c.flagPassthroughRequestHeaders, Usage: \"Request header value that will be sent to the plugin. To specify \" + \"multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedResponseHeaders, Target: &c.flagAllowedResponseHeaders, Usage: \"Response header value that plugins will be allowed to set. To specify \" + \"multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"options\", Target: &c.flagOptions, Completion: complete.PredictAnything, Usage: \"Key-value pair provided as key=value for the mount options. \" + \"This can be specified multiple times.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameTokenType, Target: &c.flagTokenType, Usage: \"Sets a forced token type for the mount.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Default: 0, Usage: \"Select the version of the auth method to run. Not supported by all auth methods.\"})\n",
      "\tf.UintVar(&UintVar{Name: flagNameUserLockoutThreshold, Target: &c.flagUserLockoutThreshold, Usage: \"The threshold for user lockout for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured user lockout threshold, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: flagNameUserLockoutDuration, Target: &c.flagUserLockoutDuration, Completion: complete.PredictAnything, Usage: \"The user lockout duration for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured user lockout duration, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: flagNameUserLockoutCounterResetDuration, Target: &c.flagUserLockoutCounterResetDuration, Completion: complete.PredictAnything, Usage: \"The user lockout counter reset duration for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured user lockout counter reset duration, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: flagNameUserLockoutDisable, Target: &c.flagUserLockoutDisable, Default: false, Usage: \"Disable user lockout for this auth method. If unspecified, this \" + \"defaults to the Vault server's globally configured user lockout disable, \" + \"or a previously configured value for the auth method.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNamePluginVersion, Target: &c.flagPluginVersion, Default: \"\", Usage: \"Select the semantic version of the plugin to run. The new version must be registered in \" + \"the plugin catalog, and will not start running until the plugin is reloaded.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameIdentityTokenKey, Target: &c.flagIdentityTokenKey, Default: \"default\", Usage: \"Select the key used to sign plugin identity tokens.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (b *databaseBackend) setStaticAccount(ctx context.Context, s logical.Storage, input *setStaticAccountInput) (_ *setStaticAccountOutput, err error) {\n",
      "\tif input == nil || input.Role == nil || input.RoleName == \"\" {\n",
      "\t\treturn nil, errors.New(\"input was empty when attempting to set credentials for static account\")\n",
      "\t}\n",
      "\tmodified := false\n",
      "\tdefer func() {\n",
      "\t\tif err == nil {\n",
      "\t\t\tb.dbEvent(ctx, \"static-creds-create\", \"\", input.RoleName, modified)\n",
      "\t\t} else {\n",
      "\t\t\tb.dbEvent(ctx, \"static-creds-create-fail\", \"\", input.RoleName, modified)\n",
      "\t\t}\n",
      "\t}()\n",
      "\toutput := &setStaticAccountOutput{WALID: input.WALID}\n",
      "\tdbConfig, err := b.DatabaseConfig(ctx, s, input.Role.DBName)\n",
      "\tif err != nil {\n",
      "\t\treturn output, err\n",
      "\t}\n",
      "\tif dbConfig == nil {\n",
      "\t\treturn output, errors.New(\"the config is currently unset\")\n",
      "\t}\n",
      "\tif !strutil.StrListContains(dbConfig.AllowedRoles, \"*\") && !strutil.StrListContainsGlob(dbConfig.AllowedRoles, input.RoleName) {\n",
      "\t\treturn output, fmt.Errorf(\"%q is not an allowed role\", input.RoleName)\n",
      "\t}\n",
      "\tif !dbConfig.SupportsCredentialType(input.Role.CredentialType) {\n",
      "\t\treturn output, fmt.Errorf(\"unsupported credential_type: %q\", input.Role.CredentialType.String())\n",
      "\t}\n",
      "\tdbi, err := b.GetConnection(ctx, s, input.Role.DBName)\n",
      "\tif err != nil {\n",
      "\t\treturn output, err\n",
      "\t}\n",
      "\tdbi.RLock()\n",
      "\tdefer dbi.RUnlock()\n",
      "\tupdateReq := v5.UpdateUserRequest{Username: input.Role.StaticAccount.Username}\n",
      "\tstatements := v5.Statements{Commands: input.Role.Statements.Rotation}\n",
      "\tif output.WALID != \"\" {\n",
      "\t\twal, err := b.findStaticWAL(ctx, s, output.WALID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn output, fmt.Errorf(\"error retrieving WAL entry: %w\", err)\n",
      "\t\t}\n",
      "\t\tswitch {\n",
      "\t\tcase wal == nil:\n",
      "\t\t\tb.Logger().Error(\"expected role to have WAL, but WAL not found in storage\", \"role\", input.RoleName, \"WAL ID\", output.WALID)\n",
      "\t\t\toutput.WALID = \"\"\n",
      "\t\tcase !wal.credentialIsSet():\n",
      "\t\t\tb.Logger().Error(\"expected WAL to have a new credential set, but empty\", \"role\", input.RoleName, \"WAL ID\", output.WALID)\n",
      "\t\t\tif err := framework.DeleteWAL(ctx, s, output.WALID); err != nil {\n",
      "\t\t\t\tb.Logger().Warn(\"failed to delete WAL with no new credential\", \"error\", err, \"WAL ID\", output.WALID)\n",
      "\t\t\t}\n",
      "\t\t\toutput.WALID = \"\"\n",
      "\t\tcase wal.CredentialType == v5.CredentialTypePassword:\n",
      "\t\t\tupdateReq.CredentialType = v5.CredentialTypePassword\n",
      "\t\t\tupdateReq.Password = &v5.ChangePassword{NewPassword: wal.NewPassword, Statements: statements}\n",
      "\t\t\tinput.Role.StaticAccount.Password = wal.NewPassword\n",
      "\t\tcase wal.CredentialType == v5.CredentialTypeRSAPrivateKey:\n",
      "\t\t\tupdateReq.CredentialType = v5.CredentialTypeRSAPrivateKey\n",
      "\t\t\tupdateReq.PublicKey = &v5.ChangePublicKey{NewPublicKey: wal.NewPublicKey, Statements: statements}\n",
      "\t\t\tinput.Role.StaticAccount.PrivateKey = wal.NewPrivateKey\n",
      "\t\t}\n",
      "\t}\n",
      "\tif output.WALID == \"\" {\n",
      "\t\twalEntry := &setCredentialsWAL{RoleName: input.RoleName, Username: input.Role.StaticAccount.Username, LastVaultRotation: input.Role.StaticAccount.LastVaultRotation}\n",
      "\t\tswitch input.Role.CredentialType {\n",
      "\t\tcase v5.CredentialTypePassword:\n",
      "\t\t\tgenerator, err := newPasswordGenerator(input.Role.CredentialConfig)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn output, fmt.Errorf(\"failed to construct credential generator: %s\", err)\n",
      "\t\t\t}\n",
      "\t\t\tif generator.PasswordPolicy == \"\" {\n",
      "\t\t\t\tgenerator.PasswordPolicy = dbConfig.PasswordPolicy\n",
      "\t\t\t}\n",
      "\t\t\tnewPassword, err := generator.generate(ctx, b, dbi.database)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tb.CloseIfShutdown(dbi, err)\n",
      "\t\t\t\treturn output, fmt.Errorf(\"failed to generate password: %s\", err)\n",
      "\t\t\t}\n",
      "\t\t\twalEntry.NewPassword = newPassword\n",
      "\t\t\tupdateReq.CredentialType = v5.CredentialTypePassword\n",
      "\t\t\tupdateReq.Password = &v5.ChangePassword{NewPassword: newPassword, Statements: statements}\n",
      "\t\t\tinput.Role.StaticAccount.Password = newPassword\n",
      "\t\tcase v5.CredentialTypeRSAPrivateKey:\n",
      "\t\t\tgenerator, err := newRSAKeyGenerator(input.Role.CredentialConfig)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn output, fmt.Errorf(\"failed to construct credential generator: %s\", err)\n",
      "\t\t\t}\n",
      "\t\t\tpublic, private, err := generator.generate(b.GetRandomReader())\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn output, fmt.Errorf(\"failed to generate RSA key pair: %s\", err)\n",
      "\t\t\t}\n",
      "\t\t\twalEntry.NewPublicKey = public\n",
      "\t\t\tupdateReq.CredentialType = v5.CredentialTypeRSAPrivateKey\n",
      "\t\t\tupdateReq.PublicKey = &v5.ChangePublicKey{NewPublicKey: public, Statements: statements}\n",
      "\t\t\tinput.Role.StaticAccount.PrivateKey = private\n",
      "\t\t}\n",
      "\t\toutput.WALID, err = framework.PutWAL(ctx, s, staticWALKey, walEntry)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn output, fmt.Errorf(\"error writing WAL entry: %w\", err)\n",
      "\t\t}\n",
      "\t\tb.Logger().Debug(\"writing WAL\", \"role\", input.RoleName, \"WAL ID\", output.WALID)\n",
      "\t}\n",
      "\t_, err = dbi.database.UpdateUser(ctx, updateReq, false)\n",
      "\tif err != nil {\n",
      "\t\tb.CloseIfShutdown(dbi, err)\n",
      "\t\treturn output, fmt.Errorf(\"error setting credentials: %w\", err)\n",
      "\t}\n",
      "\tmodified = true\n",
      "\tlvr := time.Now()\n",
      "\tinput.Role.StaticAccount.LastVaultRotation = lvr\n",
      "\tinput.Role.StaticAccount.SetNextVaultRotation(lvr)\n",
      "\toutput.RotationTime = lvr\n",
      "\tentry, err := logical.StorageEntryJSON(databaseStaticRolePath+input.RoleName, input.Role)\n",
      "\tif err != nil {\n",
      "\t\treturn output, err\n",
      "\t}\n",
      "\tif err := s.Put(ctx, entry); err != nil {\n",
      "\t\treturn output, err\n",
      "\t}\n",
      "\tif err := framework.DeleteWAL(ctx, s, output.WALID); err != nil {\n",
      "\t\tb.Logger().Warn(\"error deleting WAL\", \"WAL ID\", output.WALID, \"error\", err)\n",
      "\t\treturn output, err\n",
      "\t}\n",
      "\tb.Logger().Debug(\"deleted WAL\", \"WAL ID\", output.WALID)\n",
      "\treturn &setStaticAccountOutput{RotationTime: lvr}, nil\n",
      "}\n",
      "func (b *databaseBackend) connectionReadHandler() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\t\tname := data.Get(\"name\").(string)\n",
      "\t\tif name == \"\" {\n",
      "\t\t\treturn logical.ErrorResponse(respErrEmptyName), nil\n",
      "\t\t}\n",
      "\t\tentry, err := req.Storage.Get(ctx, fmt.Sprintf(\"config/%s\", name))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to read connection configuration: %w\", err)\n",
      "\t\t}\n",
      "\t\tif entry == nil {\n",
      "\t\t\treturn nil, nil\n",
      "\t\t}\n",
      "\t\tvar config DatabaseConfig\n",
      "\t\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif connURLRaw, ok := config.ConnectionDetails[\"connection_url\"]; ok {\n",
      "\t\t\tif p, err := url.Parse(connURLRaw.(string)); err == nil {\n",
      "\t\t\t\tconfig.ConnectionDetails[\"connection_url\"] = p.Redacted()\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif versions.IsBuiltinVersion(config.PluginVersion) {\n",
      "\t\t\tconfig.PluginVersion = \"\"\n",
      "\t\t}\n",
      "\t\tdelete(config.ConnectionDetails, \"password\")\n",
      "\t\tdelete(config.ConnectionDetails, \"private_key\")\n",
      "\t\tdelete(config.ConnectionDetails, \"service_account_json\")\n",
      "\t\tresp := &logical.Response{}\n",
      "\t\tif dbi, err := b.GetConnection(ctx, req.Storage, name); err == nil {\n",
      "\t\t\tconfig.RunningPluginVersion = dbi.runningPluginVersion\n",
      "\t\t\tif config.PluginVersion != \"\" && config.PluginVersion != config.RunningPluginVersion {\n",
      "\t\t\t\twarning := fmt.Sprintf(\"Plugin version is configured as %q, but running %q\", config.PluginVersion, config.RunningPluginVersion)\n",
      "\t\t\t\tif pinnedVersion, _ := b.getPinnedVersion(ctx, config.PluginName); pinnedVersion == config.RunningPluginVersion {\n",
      "\t\t\t\t\twarning += \" because that version is pinned\"\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\twarning += \" either due to a pinned version or because the plugin was upgraded and not yet reloaded\"\n",
      "\t\t\t\t}\n",
      "\t\t\t\tresp.AddWarning(warning)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tresp.Data = structs.New(config).Map()\n",
      "\t\treturn resp, nil\n",
      "\t}\n",
      "}\n",
      "func NewLinkConfig(nodeID string, nodeVersion string, resource cloud.HashicorpCloudLocationLink, scadaProvider scada.SCADAProvider, hcpConfig sdkConfig.HCPConfig, nodeStatusReporter nodestatus.Reporter, logger hclog.Logger) (*linkConfig.Config, error) {\n",
      "\tconfig := &linkConfig.Config{NodeID: nodeID, NodeVersion: nodeVersion, HCPConfig: hcpConfig, Resource: resource, NodeStatusReporter: nodeStatusReporter, SCADAProvider: scadaProvider, Logger: logger}\n",
      "\terr := config.Validate()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to create the link config: %w\", err)\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "func (m *ExpirationManager) listIrrevocableLeases(ctx context.Context, includeChildNamespaces, returnAll bool, limit int) (map[string]interface{}, string, error) {\n",
      "\trequestNS, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\tm.logger.Error(\"could not get namespace from context\", \"error\", err)\n",
      "\t\treturn nil, \"\", err\n",
      "\t}\n",
      "\tmatchingLeases := make([]*leaseResponse, 0)\n",
      "\tnumMatchingLeases := 0\n",
      "\tvar warning string\n",
      "\tm.irrevocable.Range(func(k, v interface{}) bool {\n",
      "\t\tleaseID := k.(string)\n",
      "\t\tleaseInfo := v.(*leaseEntry)\n",
      "\t\tleaseNS, err := m.getNamespaceFromLeaseID(ctx, leaseID)\n",
      "\t\tif err != nil {\n",
      "\t\t\tm.logger.Warn(\"could not get lease namespace from ID\", \"error\", err)\n",
      "\t\t\treturn true\n",
      "\t\t}\n",
      "\t\tleaseMatches := (leaseNS == requestNS) || (includeChildNamespaces && leaseNS.HasParent(requestNS))\n",
      "\t\tif !leaseMatches {\n",
      "\t\t\treturn true\n",
      "\t\t}\n",
      "\t\tif !returnAll && (numMatchingLeases >= limit) {\n",
      "\t\t\tm.logger.Warn(\"hit max irrevocable leases without force flag set\")\n",
      "\t\t\twarning = MaxIrrevocableLeasesWarning\n",
      "\t\t\treturn false\n",
      "\t\t}\n",
      "\t\tmountAccessor := m.getLeaseMountAccessor(ctx, leaseID)\n",
      "\t\tnumMatchingLeases++\n",
      "\t\tmatchingLeases = append(matchingLeases, &leaseResponse{LeaseID: leaseID, MountID: mountAccessor, ErrMsg: leaseInfo.RevokeErr, expireTime: leaseInfo.ExpireTime})\n",
      "\t\treturn true\n",
      "\t})\n",
      "\tsort.Slice(matchingLeases, func(i, j int) bool {\n",
      "\t\tif !matchingLeases[i].expireTime.Equal(matchingLeases[j].expireTime) {\n",
      "\t\t\treturn matchingLeases[i].expireTime.Before(matchingLeases[j].expireTime)\n",
      "\t\t}\n",
      "\t\treturn matchingLeases[i].LeaseID < matchingLeases[j].LeaseID\n",
      "\t})\n",
      "\tresp := make(map[string]interface{})\n",
      "\tresp[\"lease_count\"] = numMatchingLeases\n",
      "\tresp[\"leases\"] = matchingLeases\n",
      "\treturn resp, warning, nil\n",
      "}\n",
      "func removedFactory(ctx context.Context, config *logical.BackendConfig) (logical.Backend, error) {\n",
      "\tremovedBackend := &removedBackend{}\n",
      "\tremovedBackend.Backend = &framework.Backend{}\n",
      "\treturn removedBackend, nil\n",
      "}\n",
      "func (b *backend) pathConfigRootRead(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tb.clientMutex.RLock()\n",
      "\tdefer b.clientMutex.RUnlock()\n",
      "\tentry, err := req.Storage.Get(ctx, \"config/root\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif entry == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tvar config rootConfig\n",
      "\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfigData := map[string]interface{}{\"access_key\": config.AccessKey, \"region\": config.Region, \"iam_endpoint\": config.IAMEndpoint, \"sts_endpoint\": config.STSEndpoint, \"max_retries\": config.MaxRetries, \"username_template\": config.UsernameTemplate, \"role_arn\": config.RoleARN}\n",
      "\tconfig.PopulatePluginIdentityTokenData(configData)\n",
      "\treturn &logical.Response{Data: configData}, nil\n",
      "}\n",
      "func NewOCIAuthMethod(conf *auth.AuthConfig, vaultAddress string) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &ociMethod{logger: conf.Logger, vaultAddress: vaultAddress, mountPath: conf.MountPath, credsFound: make(chan struct{}), stopCh: make(chan struct{})}\n",
      "\ttypeRaw, ok := conf.Config[\"type\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'type' value\")\n",
      "\t}\n",
      "\tauthType, ok := typeRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'type' config value to string\")\n",
      "\t}\n",
      "\troleRaw, ok := conf.Config[\"role\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role' value\")\n",
      "\t}\n",
      "\ta.role, ok = roleRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t}\n",
      "\tcredCheckFreqSec := defaultCredCheckFreqSeconds\n",
      "\tif checkFreqRaw, ok := conf.Config[\"credential_poll_interval\"]; ok {\n",
      "\t\tcheckFreq, err := parseutil.ParseDurationSecond(checkFreqRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"could not parse credential_poll_interval: %v\", err)\n",
      "\t\t}\n",
      "\t\tcredCheckFreqSec = checkFreq\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase a.role == \"\":\n",
      "\t\treturn nil, errors.New(\"'role' value is empty\")\n",
      "\tcase authType == \"\":\n",
      "\t\treturn nil, errors.New(\"'type' value is empty\")\n",
      "\tcase authType != typeAPIKey && authType != typeInstance:\n",
      "\t\treturn nil, errors.New(\"'type' value is invalid\")\n",
      "\tcase authType == typeAPIKey:\n",
      "\t\tdefaultConfigFile := getDefaultConfigFilePath()\n",
      "\t\thomeFolder := getHomeFolder()\n",
      "\t\tsecondaryConfigFile := path.Join(homeFolder, secondaryConfigDirName, defaultConfigFileName)\n",
      "\t\tenvironmentProvider := common.ConfigurationProviderEnvironmentVariables(\"OCI\", \"\")\n",
      "\t\tdefaultFileProvider, _ := common.ConfigurationProviderFromFile(defaultConfigFile, \"\")\n",
      "\t\tsecondaryFileProvider, _ := common.ConfigurationProviderFromFile(secondaryConfigFile, \"\")\n",
      "\t\tprovider, _ := common.ComposingConfigurationProvider([]common.ConfigurationProvider{environmentProvider, defaultFileProvider, secondaryFileProvider})\n",
      "\t\ta.configurationProvider = provider\n",
      "\tcase authType == typeInstance:\n",
      "\t\tconfigurationProvider, err := ociAuth.InstancePrincipalConfigurationProvider()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to create instance principal configuration provider: %v\", err)\n",
      "\t\t}\n",
      "\t\ta.configurationProvider = configurationProvider\n",
      "\t}\n",
      "\tcreds, err := a.configurationProvider.KeyID()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\ta.lastCreds = creds\n",
      "\tgo a.pollForCreds(credCheckFreqSec)\n",
      "\treturn a, nil\n",
      "}\n",
      "func ConfigFields() map[string]*framework.FieldSchema {\n",
      "\treturn map[string]*framework.FieldSchema{\"anonymous_group_search\": {Type: framework.TypeBool, Default: false, Description: \"Use anonymous binds when performing LDAP group searches (if true the initial credentials will still be used for the initial connection test).\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Anonymous group search\"}}, \"url\": {Type: framework.TypeString, Default: \"ldap://127.0.0.1\", Description: \"LDAP URL to connect to (default: ldap://127.0.0.1). Multiple URLs can be specified by concatenating them with commas; they will be tried in-order.\", DisplayAttrs: &framework.DisplayAttributes{Name: \"URL\"}}, \"userdn\": {Type: framework.TypeString, Description: \"LDAP domain to use for users (eg: ou=People,dc=example,dc=org)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"User DN\"}}, \"binddn\": {Type: framework.TypeString, Description: \"LDAP DN for searching for the user DN (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Name of Object to bind (binddn)\"}}, \"bindpass\": {Type: framework.TypeString, Description: \"LDAP password for searching for the user DN (optional)\", DisplayAttrs: &framework.DisplayAttributes{Sensitive: true}}, \"groupdn\": {Type: framework.TypeString, Description: \"LDAP search base to use for group membership search (eg: ou=Groups,dc=example,dc=org)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Group DN\"}}, \"groupfilter\": {Type: framework.TypeString, Default: \"(|(memberUid={{.Username}})(member={{.UserDN}})(uniqueMember={{.UserDN}}))\", Description: `Go template for querying group membership of user (optional)\n",
      "The template can access the following context variables: UserDN, Username\n",
      "Example: (&(objectClass=group)(member:1.2.840.113556.1.4.1941:={{.UserDN}}))\n",
      "Default: (|(memberUid={{.Username}})(member={{.UserDN}})(uniqueMember={{.UserDN}}))`, DisplayAttrs: &framework.DisplayAttributes{Name: \"Group Filter\"}}, \"groupattr\": {Type: framework.TypeString, Default: \"cn\", Description: `LDAP attribute to follow on objects returned by <groupfilter>\n",
      "in order to enumerate user group membership.\n",
      "Examples: \"cn\" or \"memberOf\", etc.\n",
      "Default: cn`, DisplayAttrs: &framework.DisplayAttributes{Name: \"Group Attribute\", Value: \"cn\"}}, \"userfilter\": {Type: framework.TypeString, Default: \"({{.UserAttr}}={{.Username}})\", Description: `Go template for LDAP user search filer (optional)\n",
      "The template can access the following context variables: UserAttr, Username\n",
      "Default: ({{.UserAttr}}={{.Username}})`, DisplayAttrs: &framework.DisplayAttributes{Name: \"User Search Filter\"}}, \"upndomain\": {Type: framework.TypeString, Description: \"Enables userPrincipalDomain login with [username]@UPNDomain (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"User Principal (UPN) Domain\"}}, \"username_as_alias\": {Type: framework.TypeBool, Default: false, Description: \"If true, sets the alias name to the username\"}, \"userattr\": {Type: framework.TypeString, Default: \"cn\", Description: \"Attribute used for users (default: cn)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"User Attribute\", Value: \"cn\"}}, \"certificate\": {Type: framework.TypeString, Description: \"CA certificate to use when verifying LDAP server certificate, must be x509 PEM encoded (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"CA certificate\", EditType: \"file\"}}, \"client_tls_cert\": {Type: framework.TypeString, Description: \"Client certificate to provide to the LDAP server, must be x509 PEM encoded (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Client certificate\", EditType: \"file\"}}, \"client_tls_key\": {Type: framework.TypeString, Description: \"Client certificate key to provide to the LDAP server, must be x509 PEM encoded (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Client key\", EditType: \"file\"}}, \"discoverdn\": {Type: framework.TypeBool, Description: \"Use anonymous bind to discover the bind DN of a user (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Discover DN\"}}, \"insecure_tls\": {Type: framework.TypeBool, Description: \"Skip LDAP server SSL Certificate verification - VERY insecure (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Insecure TLS\"}}, \"starttls\": {Type: framework.TypeBool, Description: \"Issue a StartTLS command after establishing unencrypted connection (optional)\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Issue StartTLS\"}}, \"tls_min_version\": {Type: framework.TypeString, Default: \"tls12\", Description: \"Minimum TLS version to use. Accepted values are 'tls10', 'tls11', 'tls12' or 'tls13'. Defaults to 'tls12'\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Minimum TLS Version\"}, AllowedValues: []interface{}{\"tls10\", \"tls11\", \"tls12\", \"tls13\"}}, \"tls_max_version\": {Type: framework.TypeString, Default: \"tls12\", Description: \"Maximum TLS version to use. Accepted values are 'tls10', 'tls11', 'tls12' or 'tls13'. Defaults to 'tls12'\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Maximum TLS Version\"}, AllowedValues: []interface{}{\"tls10\", \"tls11\", \"tls12\", \"tls13\"}}, \"deny_null_bind\": {Type: framework.TypeBool, Default: true, Description: \"Denies an unauthenticated LDAP bind request if the user's password is empty; defaults to true\"}, \"case_sensitive_names\": {Type: framework.TypeBool, Description: \"If true, case sensitivity will be used when comparing usernames and groups for matching policies.\"}, \"use_token_groups\": {Type: framework.TypeBool, Default: false, Description: \"If true, use the Active Directory tokenGroups constructed attribute of the user to find the group memberships. This will find all security groups including nested ones.\"}, \"use_pre111_group_cn_behavior\": {Type: framework.TypeBool, Description: \"In Vault 1.1.1 a fix for handling group CN values of different cases unfortunately introduced a regression that could cause previously defined groups to not be found due to a change in the resulting name. If set true, the pre-1.1.1 behavior for matching group CNs will be used. This is only needed in some upgrade scenarios for backwards compatibility. It is enabled by default if the config is upgraded but disabled by default on new configurations.\"}, \"request_timeout\": {Type: framework.TypeDurationSecond, Description: \"Timeout, in seconds, for the connection when making requests against the server before returning back an error.\", Default: \"90s\"}, \"connection_timeout\": {Type: framework.TypeDurationSecond, Description: \"Timeout, in seconds, when attempting to connect to the LDAP server before trying the next URL in the configuration.\", Default: \"30s\"}, \"dereference_aliases\": {Type: framework.TypeString, Description: \"When aliases should be dereferenced on search operations. Accepted values are 'never', 'finding', 'searching', 'always'. Defaults to 'never'.\", Default: \"never\", AllowedValues: []interface{}{\"never\", \"finding\", \"searching\", \"always\"}}, \"max_page_size\": {Type: framework.TypeInt, Description: \"If set to a value greater than 0, the LDAP backend will use the LDAP server's paged search control to request pages of up to the given size. This can be used to avoid hitting the LDAP server's maximum result size limit. Otherwise, the LDAP backend will not use the paged search control.\", Default: 0}}\n",
      "}\n",
      "func (c *SSHCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"SSH Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"mode\", Target: &c.flagMode, Default: \"\", EnvVar: \"\", Completion: complete.PredictSet(\"ca\", \"dynamic\", \"otp\"), Usage: \"Name of the authentication mode (ca, dynamic, otp).\"})\n",
      "\tf.StringVar(&StringVar{Name: \"role\", Target: &c.flagRole, Default: \"\", EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"Name of the role to use to generate the key.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"no-exec\", Target: &c.flagNoExec, Default: false, EnvVar: \"\", Completion: complete.PredictNothing, Usage: \"Print the generated credentials, but do not establish a \" + \"connection.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"mount-point\", Target: &c.flagMountPoint, Default: \"ssh/\", EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"Mount point to the SSH secrets engine.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"strict-host-key-checking\", Target: &c.flagStrictHostKeyChecking, Default: \"ask\", EnvVar: \"VAULT_SSH_STRICT_HOST_KEY_CHECKING\", Completion: complete.PredictSet(\"ask\", \"no\", \"yes\"), Usage: \"Value to use for the SSH configuration option \" + \"\\\"StrictHostKeyChecking\\\".\"})\n",
      "\tf.StringVar(&StringVar{Name: \"user-known-hosts-file\", Target: &c.flagUserKnownHostsFile, Default: \"\", EnvVar: \"VAULT_SSH_USER_KNOWN_HOSTS_FILE\", Completion: complete.PredictFiles(\"*\"), Usage: \"Value to use for the SSH configuration option \" + \"\\\"UserKnownHostsFile\\\".\"})\n",
      "\tf = set.NewFlagSet(\"CA Mode Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"public-key-path\", Target: &c.flagPublicKeyPath, Default: \"~/.ssh/id_rsa.pub\", EnvVar: \"\", Completion: complete.PredictFiles(\"*\"), Usage: \"Path to the SSH public key to send to Vault for signing.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"private-key-path\", Target: &c.flagPrivateKeyPath, Default: \"~/.ssh/id_rsa\", EnvVar: \"\", Completion: complete.PredictFiles(\"*\"), Usage: \"Path to the SSH private key to use for authentication. This must \" + \"be the corresponding private key to -public-key-path.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"host-key-mount-point\", Target: &c.flagHostKeyMountPoint, Default: \"\", EnvVar: \"VAULT_SSH_HOST_KEY_MOUNT_POINT\", Completion: complete.PredictAnything, Usage: \"Mount point to the SSH secrets engine where host keys are signed. \" + \"When given a value, Vault will generate a custom \\\"known_hosts\\\" file \" + \"with delegation to the CA at the provided mount point to verify the \" + \"SSH connection's host keys against the provided CA. By default, host \" + \"keys are validated against the user's local \\\"known_hosts\\\" file. \" + \"This flag forces strict key host checking and ignores a custom user \" + \"known hosts file.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"host-key-hostnames\", Target: &c.flagHostKeyHostnames, Default: \"*\", EnvVar: \"VAULT_SSH_HOST_KEY_HOSTNAMES\", Completion: complete.PredictAnything, Usage: \"List of hostnames to delegate for the CA. The default value \" + \"allows all domains and IPs. This is specified as a comma-separated \" + \"list of values.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"valid-principals\", Target: &c.flagValidPrincipals, Default: \"\", EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"List of valid principal names to include in the generated \" + \"user certificate. This is specified as a comma-separated list of values.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"ssh-executable\", Target: &c.flagSSHExecutable, Default: \"ssh\", EnvVar: \"VAULT_SSH_EXECUTABLE\", Completion: complete.PredictAnything, Usage: \"Path to the SSH executable to use when connecting to the host\"})\n",
      "\treturn set\n",
      "}\n",
      "func (c *PluginCatalog) getBackendPluginType(ctx context.Context, pluginRunner *pluginutil.PluginRunner) (consts.PluginType, error) {\n",
      "\tmerr := &multierror.Error{}\n",
      "\tconfig := pluginutil.PluginClientConfig{Name: pluginRunner.Name, PluginSets: backendplugin.PluginSet, HandshakeConfig: backendplugin.HandshakeConfig, Logger: log.NewNullLogger(), IsMetadataMode: false, AutoMTLS: true, Wrapper: c.wrapper}\n",
      "\tvar client logical.Backend\n",
      "\tvar attemptV4 bool\n",
      "\tc.logger.Debug(\"attempting to load backend plugin\", \"name\", pluginRunner.Name)\n",
      "\tpc, err := c.newPluginClient(ctx, pluginRunner, config)\n",
      "\tif err == nil {\n",
      "\t\tkey, err := makeExternalPluginsKey(pluginRunner)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn consts.PluginTypeUnknown, err\n",
      "\t\t}\n",
      "\t\tdefer func() {\n",
      "\t\t\terr = c.cleanupExternalPlugin(key, pc.id, pluginRunner.BinaryReference())\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.logger.Error(\"error closing plugin client\", \"error\", err)\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tclient, err = backendplugin.Dispense(pc.ClientProtocol, pc)\n",
      "\t\tif err != nil {\n",
      "\t\t\tmerr = multierror.Append(merr, fmt.Errorf(\"failed to dispense plugin as backend v5: %w\", err))\n",
      "\t\t\tc.logger.Debug(\"failed to dispense v5 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\t\t\tattemptV4 = true\n",
      "\t\t} else {\n",
      "\t\t\tc.logger.Debug(\"successfully dispensed v5 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tattemptV4 = true\n",
      "\t}\n",
      "\tif attemptV4 {\n",
      "\t\tc.logger.Debug(\"failed to dispense v5 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\t\tconfig.AutoMTLS = false\n",
      "\t\tconfig.IsMetadataMode = true\n",
      "\t\tclient, err = backendplugin.NewPluginClient(ctx, c.wrapper, pluginRunner, log.NewNullLogger(), true)\n",
      "\t\tif err != nil {\n",
      "\t\t\tmerr = multierror.Append(merr, fmt.Errorf(\"failed to dispense v4 backend plugin: %w\", err))\n",
      "\t\t\tc.logger.Debug(\"failed to dispense v4 backend plugin\", \"name\", pluginRunner.Name, \"error\", merr)\n",
      "\t\t\treturn consts.PluginTypeUnknown, merr.ErrorOrNil()\n",
      "\t\t}\n",
      "\t\tc.logger.Debug(\"successfully dispensed v4 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\t\tdefer client.Cleanup(ctx)\n",
      "\t}\n",
      "\terr = client.Setup(ctx, &logical.BackendConfig{})\n",
      "\tif err != nil {\n",
      "\t\treturn consts.PluginTypeUnknown, err\n",
      "\t}\n",
      "\tbackendType := client.Type()\n",
      "\tswitch backendType {\n",
      "\tcase logical.TypeCredential:\n",
      "\t\treturn consts.PluginTypeCredential, nil\n",
      "\tcase logical.TypeLogical:\n",
      "\t\treturn consts.PluginTypeSecrets, nil\n",
      "\t}\n",
      "\tif client == nil || client.Type() == logical.TypeUnknown {\n",
      "\t\tc.logger.Warn(\"unknown plugin type\", \"plugin name\", pluginRunner.Name, \"error\", merr.Error())\n",
      "\t} else {\n",
      "\t\tc.logger.Warn(\"unsupported plugin type\", \"plugin name\", pluginRunner.Name, \"plugin type\", client.Type().String(), \"error\", merr.Error())\n",
      "\t}\n",
      "\tmerr = multierror.Append(merr, fmt.Errorf(\"failed to load plugin as backend plugin: %w\", err))\n",
      "\treturn consts.PluginTypeUnknown, merr.ErrorOrNil()\n",
      "}\n",
      "func (c *OperatorDiagnoseCommand) offlineDiagnostics(ctx context.Context) error {\n",
      "\trloadFuncs := make(map[string][]reloadutil.ReloadFunc)\n",
      "\tserver := &ServerCommand{BaseCommand: c.BaseCommand, AuditBackends: auditBackends, CredentialBackends: credentialBackends, LogicalBackends: logicalBackends, PhysicalBackends: physicalBackends, ServiceRegistrations: serviceRegistrations, logger: log.NewInterceptLogger(&log.LoggerOptions{Level: log.Off}), allLoggers: []log.Logger{}, reloadFuncs: &rloadFuncs, reloadFuncsLock: new(sync.RWMutex)}\n",
      "\tctx, span := diagnose.StartSpan(ctx, \"Vault Diagnose\")\n",
      "\tdefer span.End()\n",
      "\tdiagnose.OSChecks(ctx)\n",
      "\tvar config *cserver.Config\n",
      "\tdiagnose.Test(ctx, \"Parse Configuration\", func(ctx context.Context) (err error) {\n",
      "\t\tserver.flagConfigs = c.flagConfigs\n",
      "\t\tvar configErrors []configutil.ConfigError\n",
      "\t\tconfig, configErrors, err = server.parseConfig()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"Could not parse configuration: %w.\", err)\n",
      "\t\t}\n",
      "\t\tfor _, ce := range configErrors {\n",
      "\t\t\tdiagnose.Warn(ctx, diagnose.CapitalizeFirstLetter(ce.String())+\".\")\n",
      "\t\t}\n",
      "\t\tdiagnose.Success(ctx, \"Vault configuration syntax is ok.\")\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif config == nil {\n",
      "\t\treturn fmt.Errorf(\"No vault server configuration found.\")\n",
      "\t}\n",
      "\tdiagnose.Test(ctx, \"Check Telemetry\", func(ctx context.Context) (err error) {\n",
      "\t\tif config.Telemetry == nil {\n",
      "\t\t\tdiagnose.Warn(ctx, \"Telemetry is using default configuration\")\n",
      "\t\t\tdiagnose.Advise(ctx, \"By default only Prometheus and JSON metrics are available.  Ignore this warning if you are using telemetry or are using these metrics and are satisfied with the default retention time and gauge period.\")\n",
      "\t\t} else {\n",
      "\t\t\tt := config.Telemetry\n",
      "\t\t\tif coalesce(t.CirconusAPIURL, t.CirconusAPIToken, t.CirconusCheckID, t.CirconusCheckTags, t.CirconusCheckSearchTag, t.CirconusBrokerID, t.CirconusBrokerSelectTag, t.CirconusCheckForceMetricActivation, t.CirconusCheckInstanceID, t.CirconusCheckSubmissionURL, t.CirconusCheckDisplayName) != nil {\n",
      "\t\t\t\tif t.CirconusAPIURL == \"\" {\n",
      "\t\t\t\t\treturn errors.New(\"incomplete Circonus telemetry configuration, missing circonus_api_url\")\n",
      "\t\t\t\t} else if t.CirconusAPIToken != \"\" {\n",
      "\t\t\t\t\treturn errors.New(\"incomplete Circonus telemetry configuration, missing circonus_api_token\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif len(t.DogStatsDTags) > 0 && t.DogStatsDAddr == \"\" {\n",
      "\t\t\t\treturn errors.New(\"incomplete DogStatsD telemetry configuration, missing dogstatsd_addr, while dogstatsd_tags specified\")\n",
      "\t\t\t}\n",
      "\t\t\tif coalesce(t.StackdriverNamespace, t.StackdriverLocation, t.StackdriverDebugLogs, t.StackdriverNamespace) != nil {\n",
      "\t\t\t\tif t.StackdriverProjectID == \"\" {\n",
      "\t\t\t\t\treturn errors.New(\"incomplete Stackdriver telemetry configuration, missing stackdriver_project_id\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif t.StackdriverLocation == \"\" {\n",
      "\t\t\t\t\treturn errors.New(\"incomplete Stackdriver telemetry configuration, missing stackdriver_location\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif t.StackdriverNamespace == \"\" {\n",
      "\t\t\t\t\treturn errors.New(\"incomplete Stackdriver telemetry configuration, missing stackdriver_namespace\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tvar metricSink *metricsutil.ClusterMetricSink\n",
      "\tvar metricsHelper *metricsutil.MetricsHelper\n",
      "\tvar backend *physical.Backend\n",
      "\tdiagnose.Test(ctx, \"Check Storage\", func(ctx context.Context) error {\n",
      "\t\tif config.Storage == nil {\n",
      "\t\t\tdiagnose.Advise(ctx, \"To learn how to specify a storage backend, see the Vault server configuration documentation.\")\n",
      "\t\t\treturn fmt.Errorf(\"No storage stanza in Vault server configuration.\")\n",
      "\t\t}\n",
      "\t\tdiagnose.Test(ctx, \"Create Storage Backend\", func(ctx context.Context) error {\n",
      "\t\t\tb, err := server.setupStorage(config)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tif b == nil {\n",
      "\t\t\t\tdiagnose.Advise(ctx, \"To learn how to specify a storage backend, see the Vault server configuration documentation.\")\n",
      "\t\t\t\treturn fmt.Errorf(\"Storage backend could not be initialized.\")\n",
      "\t\t\t}\n",
      "\t\t\tbackend = &b\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t\tif backend == nil {\n",
      "\t\t\tdiagnose.Fail(ctx, \"Diagnose could not initialize storage backend.\")\n",
      "\t\t\tspan.End()\n",
      "\t\t\treturn fmt.Errorf(\"Diagnose could not initialize storage backend.\")\n",
      "\t\t}\n",
      "\t\tif config.Storage.Type == storageTypeRaft {\n",
      "\t\t\tpath := os.Getenv(raft.EnvVaultRaftPath)\n",
      "\t\t\tif path == \"\" {\n",
      "\t\t\t\tpath, ok := config.Storage.Config[\"path\"]\n",
      "\t\t\t\tif !ok {\n",
      "\t\t\t\t\tdiagnose.SpotError(ctx, \"Check Raft Folder Permissions\", fmt.Errorf(\"Storage folder path is required.\"))\n",
      "\t\t\t\t}\n",
      "\t\t\t\tdiagnose.RaftFileChecks(ctx, path)\n",
      "\t\t\t}\n",
      "\t\t\tdiagnose.RaftStorageQuorum(ctx, (*backend).(*raft.RaftBackend))\n",
      "\t\t}\n",
      "\t\tif config.Storage != nil && config.Storage.Type == storageTypeConsul {\n",
      "\t\t\tdiagnose.Test(ctx, \"Check Consul TLS\", func(ctx context.Context) error {\n",
      "\t\t\t\terr := physconsul.SetupSecureTLS(ctx, api.DefaultConfig(), config.Storage.Config, server.logger, true)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t})\n",
      "\t\t\tdiagnose.Test(ctx, \"Check Consul Direct Storage Access\", func(ctx context.Context) error {\n",
      "\t\t\t\tdirAccess := diagnose.ConsulDirectAccess(config.Storage.Config)\n",
      "\t\t\t\tif dirAccess != \"\" {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, dirAccess)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dirAccess == diagnose.DirAccessErr {\n",
      "\t\t\t\t\tdiagnose.Advise(ctx, diagnose.DirAccessAdvice)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t\tif !c.skipEndEnd && config.Storage.Type != storageTypeRaft {\n",
      "\t\t\tdiagnose.Test(ctx, \"Check Storage Access\", diagnose.WithTimeout(30*time.Second, func(ctx context.Context) error {\n",
      "\t\t\t\tmaxDurationCrudOperation := \"write\"\n",
      "\t\t\t\tmaxDuration := time.Duration(0)\n",
      "\t\t\t\tuuidSuffix, err := uuid.GenerateUUID()\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\tuuid := \"diagnose/latency/\" + uuidSuffix\n",
      "\t\t\t\tdur, err := diagnose.EndToEndLatencyCheckWrite(ctx, uuid, *backend)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\tmaxDuration = dur\n",
      "\t\t\t\tdur, err = diagnose.EndToEndLatencyCheckRead(ctx, uuid, *backend)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dur > maxDuration {\n",
      "\t\t\t\t\tmaxDuration = dur\n",
      "\t\t\t\t\tmaxDurationCrudOperation = \"read\"\n",
      "\t\t\t\t}\n",
      "\t\t\t\tdur, err = diagnose.EndToEndLatencyCheckDelete(ctx, uuid, *backend)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dur > maxDuration {\n",
      "\t\t\t\t\tmaxDuration = dur\n",
      "\t\t\t\t\tmaxDurationCrudOperation = \"delete\"\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif maxDuration > time.Duration(0) {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, diagnose.LatencyWarning+fmt.Sprintf(\"duration: %s, operation: %s\", maxDuration, maxDurationCrudOperation))\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t}))\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif backend == nil {\n",
      "\t\treturn fmt.Errorf(\"Diagnose could not initialize storage backend.\")\n",
      "\t}\n",
      "\tvar configSR sr.ServiceRegistration\n",
      "\tdiagnose.Test(ctx, \"Check Service Discovery\", func(ctx context.Context) error {\n",
      "\t\tif config.ServiceRegistration == nil || config.ServiceRegistration.Config == nil {\n",
      "\t\t\tdiagnose.Skipped(ctx, \"No service registration configured.\")\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tsrConfig := config.ServiceRegistration.Config\n",
      "\t\tdiagnose.Test(ctx, \"Check Consul Service Discovery TLS\", func(ctx context.Context) error {\n",
      "\t\t\terr := srconsul.SetupSecureTLS(ctx, api.DefaultConfig(), srConfig, server.logger, true)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t\tif config.ServiceRegistration != nil && config.ServiceRegistration.Type == \"consul\" {\n",
      "\t\t\tdiagnose.Test(ctx, \"Check Consul Direct Service Discovery\", func(ctx context.Context) error {\n",
      "\t\t\t\tdirAccess := diagnose.ConsulDirectAccess(config.ServiceRegistration.Config)\n",
      "\t\t\t\tif dirAccess != \"\" {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, dirAccess)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dirAccess == diagnose.DirAccessErr {\n",
      "\t\t\t\t\tdiagnose.Advise(ctx, diagnose.DirAccessAdvice)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tsealcontext, sealspan := diagnose.StartSpan(ctx, \"Create Vault Server Configuration Seals\")\n",
      "\tvar setSealResponse *SetSealResponse\n",
      "\texistingSealGenerationInfo, err := vault.PhysicalSealGenInfo(sealcontext, *backend)\n",
      "\tif err != nil {\n",
      "\t\tdiagnose.Fail(sealcontext, fmt.Sprintf(\"Unable to get Seal generation information from storage: %s.\", err.Error()))\n",
      "\t\tgoto SEALFAIL\n",
      "\t}\n",
      "\tsetSealResponse, err = setSeal(server, config, make([]string, 0), make(map[string]string), existingSealGenerationInfo, false)\n",
      "\tif err != nil {\n",
      "\t\tdiagnose.Advise(ctx, \"For assistance with the seal stanza, see the Vault configuration documentation.\")\n",
      "\t\tdiagnose.Fail(sealcontext, fmt.Sprintf(\"Seal creation resulted in the following error: %s.\", err.Error()))\n",
      "\t\tgoto SEALFAIL\n",
      "\t}\n",
      "\tfor _, seal := range setSealResponse.getCreatedSeals() {\n",
      "\t\tseal := seal\n",
      "\t\tdefer func(seal *vault.Seal) {\n",
      "\t\t\tsealType := diagnose.CapitalizeFirstLetter((*seal).BarrierSealConfigType().String())\n",
      "\t\t\tfinalizeSealContext, finalizeSealSpan := diagnose.StartSpan(ctx, \"Finalize \"+sealType+\" Seal\")\n",
      "\t\t\terr = (*seal).Finalize(finalizeSealContext)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tdiagnose.Fail(finalizeSealContext, \"Error finalizing seal.\")\n",
      "\t\t\t\tdiagnose.Advise(finalizeSealContext, \"This likely means that the barrier is still in use; therefore, finalizing the seal timed out.\")\n",
      "\t\t\t\tfinalizeSealSpan.End()\n",
      "\t\t\t}\n",
      "\t\t\tfinalizeSealSpan.End()\n",
      "\t\t}(seal)\n",
      "\t}\n",
      "\tif setSealResponse.sealConfigError != nil {\n",
      "\t\tdiagnose.Fail(sealcontext, \"Seal could not be configured: seals may already be initialized.\")\n",
      "\t} else if setSealResponse.barrierSeal == nil {\n",
      "\t\tdiagnose.Fail(sealcontext, \"Could not create barrier seal. No error was generated, but it is likely that the seal stanza is misconfigured. For guidance, see Vault's configuration documentation on the seal stanza.\")\n",
      "\t}\n",
      "SEALFAIL:\n",
      "\tsealspan.End()\n",
      "\tvar barrierSeal vault.Seal\n",
      "\tvar unwrapSeal vault.Seal\n",
      "\tif setSealResponse != nil {\n",
      "\t\tbarrierSeal = setSealResponse.barrierSeal\n",
      "\t\tunwrapSeal = setSealResponse.unwrapSeal\n",
      "\t}\n",
      "\tdiagnose.Test(ctx, \"Check Transit Seal TLS\", func(ctx context.Context) error {\n",
      "\t\tvar checkSealTransit bool\n",
      "\t\tfor _, seal := range config.Seals {\n",
      "\t\t\tif seal.Type == \"transit\" {\n",
      "\t\t\t\tcheckSealTransit = true\n",
      "\t\t\t\ttlsSkipVerify, _ := seal.Config[\"tls_skip_verify\"]\n",
      "\t\t\t\tif tlsSkipVerify == \"true\" {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, \"TLS verification is skipped. This is highly discouraged and decreases the security of data transmissions to and from the Vault server.\")\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t\ttlsClientCert, ok := seal.Config[\"tls_client_cert\"]\n",
      "\t\t\t\tif !ok {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, \"Missing tls_client_cert in the seal configuration.\")\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t\ttlsClientKey, ok := seal.Config[\"tls_client_key\"]\n",
      "\t\t\t\tif !ok {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, \"Missing tls_client_key in the seal configuration.\")\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t\t_, err := diagnose.TLSFileChecks(tlsClientCert, tlsClientKey)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"The TLS certificate and key configured through the tls_client_cert and tls_client_key fields of the transit seal configuration are invalid: %w.\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\ttlsCACert, ok := seal.Config[\"tls_ca_cert\"]\n",
      "\t\t\t\tif !ok {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, \"Missing tls_ca_cert in the seal configuration.\")\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t\twarnings, err := diagnose.TLSCAFileCheck(tlsCACert)\n",
      "\t\t\t\tif len(warnings) != 0 {\n",
      "\t\t\t\t\tfor _, warning := range warnings {\n",
      "\t\t\t\t\t\tdiagnose.Warn(ctx, warning)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"The TLS CA certificate configured through the tls_ca_cert field of the transit seal configuration is invalid: %w.\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !checkSealTransit {\n",
      "\t\t\tdiagnose.Skipped(ctx, \"No transit seal found in seal configuration.\")\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tvar coreConfig vault.CoreConfig\n",
      "\tdiagnose.Test(ctx, \"Create Core Configuration\", func(ctx context.Context) error {\n",
      "\t\tvar secureRandomReader io.Reader\n",
      "\t\trandReaderTestName := \"Initialize Randomness for Core\"\n",
      "\t\tvar sources []*configutil.EntropySourcerInfo\n",
      "\t\tif barrierSeal != nil {\n",
      "\t\t\tfor _, sealWrapper := range barrierSeal.GetAccess().GetEnabledSealWrappersByPriority() {\n",
      "\t\t\t\tif s, ok := sealWrapper.Wrapper.(entropy.Sourcer); ok {\n",
      "\t\t\t\t\tsources = append(sources, &configutil.EntropySourcerInfo{Sourcer: s, Name: sealWrapper.Name})\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tsecureRandomReader, err = configutil.CreateSecureRandomReaderFunc(config.SharedConfig, sources, server.logger)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn diagnose.SpotError(ctx, randReaderTestName, fmt.Errorf(\"could not initialize randomness for core: %w\", err))\n",
      "\t\t}\n",
      "\t\tdiagnose.SpotOk(ctx, randReaderTestName, \"\")\n",
      "\t\tcoreConfig = createCoreConfig(server, config, *backend, configSR, barrierSeal, unwrapSeal, metricsHelper, metricSink, secureRandomReader)\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tvar disableClustering bool\n",
      "\tdiagnose.Test(ctx, \"HA Storage\", func(ctx context.Context) error {\n",
      "\t\tdiagnose.Test(ctx, \"Create HA Storage Backend\", func(ctx context.Context) error {\n",
      "\t\t\tdisableClustering, err = initHaBackend(server, config, &coreConfig, *backend)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t\tdiagnose.Test(ctx, \"Check HA Consul Direct Storage Access\", func(ctx context.Context) error {\n",
      "\t\t\tif config.HAStorage == nil {\n",
      "\t\t\t\tdiagnose.Skipped(ctx, \"No HA storage stanza is configured.\")\n",
      "\t\t\t} else {\n",
      "\t\t\t\tdirAccess := diagnose.ConsulDirectAccess(config.HAStorage.Config)\n",
      "\t\t\t\tif dirAccess != \"\" {\n",
      "\t\t\t\t\tdiagnose.Warn(ctx, dirAccess)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif dirAccess == diagnose.DirAccessErr {\n",
      "\t\t\t\t\tdiagnose.Advise(ctx, diagnose.DirAccessAdvice)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t\tif config.HAStorage != nil && config.HAStorage.Type == storageTypeConsul {\n",
      "\t\t\tdiagnose.Test(ctx, \"Check Consul TLS\", func(ctx context.Context) error {\n",
      "\t\t\t\terr = physconsul.SetupSecureTLS(ctx, api.DefaultConfig(), config.HAStorage.Config, server.logger, true)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\terr = determineRedirectAddr(server, &coreConfig, config)\n",
      "\tif err != nil {\n",
      "\t\treturn diagnose.SpotError(ctx, \"Determine Redirect Address\", fmt.Errorf(\"Redirect Address could not be determined: %w.\", err))\n",
      "\t}\n",
      "\tdiagnose.SpotOk(ctx, \"Determine Redirect Address\", \"\")\n",
      "\terr = findClusterAddress(server, &coreConfig, config, disableClustering)\n",
      "\tif err != nil {\n",
      "\t\treturn diagnose.SpotError(ctx, \"Check Cluster Address\", fmt.Errorf(\"Cluster Address could not be determined or was invalid: %w.\", err), diagnose.Advice(\"Please check that the API and Cluster addresses are different, and that the API, Cluster and Redirect addresses have both a host and port.\"))\n",
      "\t}\n",
      "\tdiagnose.SpotOk(ctx, \"Check Cluster Address\", \"Cluster address is logically valid and can be found.\")\n",
      "\tvar vaultCore *vault.Core\n",
      "\tdiagnose.Test(ctx, \"Check Core Creation\", func(ctx context.Context) error {\n",
      "\t\tvar newCoreError error\n",
      "\t\tif coreConfig.RawConfig == nil {\n",
      "\t\t\treturn fmt.Errorf(CoreConfigUninitializedErr)\n",
      "\t\t}\n",
      "\t\tcore, newCoreError := vault.CreateCore(&coreConfig)\n",
      "\t\tif newCoreError != nil {\n",
      "\t\t\tif vault.IsFatalError(newCoreError) {\n",
      "\t\t\t\treturn fmt.Errorf(\"Error initializing core: %s.\", newCoreError)\n",
      "\t\t\t}\n",
      "\t\t\tdiagnose.Warn(ctx, wrapAtLength(\"A non-fatal error occurred during initialization. Please check the logs for more information.\"))\n",
      "\t\t} else {\n",
      "\t\t\tvaultCore = core\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif vaultCore == nil {\n",
      "\t\treturn fmt.Errorf(\"Diagnose could not initialize the Vault core from the Vault server configuration.\")\n",
      "\t}\n",
      "\tlicenseCtx, licenseSpan := diagnose.StartSpan(ctx, \"Check For Autoloaded License\")\n",
      "\tif !constants.IsEnterprise {\n",
      "\t\tdiagnose.Skipped(licenseCtx, \"License check will not run on OSS Vault.\")\n",
      "\t} else {\n",
      "\t\tif envLicensePath := os.Getenv(EnvVaultLicensePath); envLicensePath != \"\" {\n",
      "\t\t\tcoreConfig.LicensePath = envLicensePath\n",
      "\t\t}\n",
      "\t\tif envLicense := os.Getenv(EnvVaultLicense); envLicense != \"\" {\n",
      "\t\t\tcoreConfig.License = envLicense\n",
      "\t\t}\n",
      "\t\tvault.DiagnoseCheckLicense(licenseCtx, vaultCore, coreConfig, false)\n",
      "\t}\n",
      "\tlicenseSpan.End()\n",
      "\tvar lns []listenerutil.Listener\n",
      "\tdiagnose.Test(ctx, \"Start Listeners\", func(ctx context.Context) error {\n",
      "\t\tdisableClustering := config.HAStorage != nil && config.HAStorage.DisableClustering\n",
      "\t\tinfoKeys := make([]string, 0, 10)\n",
      "\t\tinfo := make(map[string]string)\n",
      "\t\tvar listeners []listenerutil.Listener\n",
      "\t\tvar status int\n",
      "\t\tdiagnose.ListenerChecks(ctx, config.Listeners)\n",
      "\t\tdiagnose.Test(ctx, \"Create Listeners\", func(ctx context.Context) error {\n",
      "\t\t\tstatus, listeners, _, err = server.InitListeners(config, disableClustering, &infoKeys, &info)\n",
      "\t\t\tif status != 0 {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t\tlns = listeners\n",
      "\t\tlistenerCloseFunc := func() {\n",
      "\t\t\tfor _, ln := range lns {\n",
      "\t\t\t\tln.Listener.Close()\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tc.cleanupGuard.Do(listenerCloseFunc)\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tdiagnose.Test(ctx, \"Check Autounseal Encryption\", diagnose.WithTimeout(30*time.Second, func(ctx context.Context) error {\n",
      "\t\tif barrierSeal == nil {\n",
      "\t\t\treturn fmt.Errorf(\"Diagnose could not create a barrier seal object.\")\n",
      "\t\t}\n",
      "\t\tif barrierSeal.BarrierSealConfigType() == vault.SealConfigTypeShamir {\n",
      "\t\t\tdiagnose.Skipped(ctx, \"Skipping barrier encryption test. Only supported for auto-unseal.\")\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tbarrierUUID, err := uuid.GenerateUUID()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"Diagnose could not create unique UUID for unsealing.\")\n",
      "\t\t}\n",
      "\t\tbarrierEncValue := \"diagnose-\" + barrierUUID\n",
      "\t\tciphertext, errMap := barrierSeal.GetAccess().Encrypt(ctx, []byte(barrierEncValue), nil)\n",
      "\t\tif len(errMap) > 0 {\n",
      "\t\t\tvar sealErrors []error\n",
      "\t\t\tfor name, err := range errMap {\n",
      "\t\t\t\tsealErrors = append(sealErrors, fmt.Errorf(\"error encrypting with seal %q: %w\", name, err))\n",
      "\t\t\t}\n",
      "\t\t\tif ciphertext == nil {\n",
      "\t\t\t\tif len(sealErrors) == 1 {\n",
      "\t\t\t\t\treturn sealErrors[0]\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"complete seal encryption failure: %w\", errors.Join())\n",
      "\t\t\t\t}\n",
      "\t\t\t} else {\n",
      "\t\t\t\treturn fmt.Errorf(\"partial seal encryption failure: %w\", errors.Join())\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tplaintext, _, err := barrierSeal.GetAccess().Decrypt(ctx, ciphertext, nil)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"Error decrypting with seal barrier: %w\", err)\n",
      "\t\t}\n",
      "\t\tif string(plaintext) != barrierEncValue {\n",
      "\t\t\treturn fmt.Errorf(\"Barrier returned incorrect decrypted value for mock data.\")\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}))\n",
      "\tdiagnose.Test(ctx, \"Check Server Before Runtime\", func(ctx context.Context) error {\n",
      "\t\tfor _, ln := range lns {\n",
      "\t\t\tif ln.Config == nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"Found no listener config after parsing the Vault configuration.\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif !constants.IsEnterprise {\n",
      "\t\tdiagnose.Skipped(ctx, \"HCP link check will not run on OSS Vault.\")\n",
      "\t} else {\n",
      "\t\tif config.HCPLinkConf != nil {\n",
      "\t\t\tconfig.HCPLinkConf.EnablePassThroughCapability = false\n",
      "\t\t\tconfig.HCPLinkConf.EnableAPICapability = false\n",
      "\t\t\tdiagnose.Test(ctx, \"Check HCP Connection\", func(ctx context.Context) error {\n",
      "\t\t\t\thcpLink, err := hcp_link.NewHCPLink(config.HCPLinkConf, vaultCore, server.logger)\n",
      "\t\t\t\tif err != nil || hcpLink == nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"failed to start HCP link, %w\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tdeadline := time.Now().Add(5 * time.Second)\n",
      "\t\t\t\tlinkSessionStatus := \"disconnected\"\n",
      "\t\t\t\tfor time.Now().Before(deadline) {\n",
      "\t\t\t\t\tlinkSessionStatus = hcpLink.GetConnectionStatusMessage(hcpLink.GetScadaSessionStatus())\n",
      "\t\t\t\t\tif linkSessionStatus == \"connected\" {\n",
      "\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\ttime.Sleep(500 * time.Millisecond)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif linkSessionStatus != \"connected\" {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"failed to connect to HCP in 5 seconds. HCP session status is: %s\", linkSessionStatus)\n",
      "\t\t\t\t}\n",
      "\t\t\t\terr = hcpLink.Shutdown()\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"failed to shutdown HCP link: %w\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn nil\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *ServerCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.addLogFlags(&c.logFlags)\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"config\", Target: &c.flagConfigs, Completion: complete.PredictOr(complete.PredictFiles(\"*.hcl\"), complete.PredictFiles(\"*.json\"), complete.PredictDirs(\"*\")), Usage: \"Path to a configuration file or directory of configuration \" + \"files. This flag can be specified multiple times to load multiple \" + \"configurations. If the path is a directory, all files which end in \" + \".hcl or .json are loaded.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"exit-on-core-shutdown\", Target: &c.flagExitOnCoreShutdown, Default: false, Usage: \"Exit the vault server if the vault core is shutdown.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"recovery\", Target: &c.flagRecovery, Usage: \"Enable recovery mode. In this mode, Vault is used to perform recovery actions. \" + \"Using a recovery token, \\\"sys/raw\\\" API can be used to manipulate the storage.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"experiment\", Target: &c.flagExperiments, Completion: complete.PredictSet(experiments.ValidExperiments()...), Usage: \"Name of an experiment to enable. Experiments should NOT be used in production, and \" + \"the associated APIs may have backwards incompatible changes between releases. This \" + \"flag can be specified multiple times to specify multiple experiments. This can also be \" + fmt.Sprintf(\"specified via the %s environment variable as a comma-separated list. \", EnvVaultExperiments) + \"Valid experiments are: \" + strings.Join(experiments.ValidExperiments(), \", \")})\n",
      "\tf = set.NewFlagSet(\"Dev Options\")\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev\", Target: &c.flagDev, Usage: \"Enable development mode. In this mode, Vault runs in-memory and \" + \"starts unsealed. As the name implies, do not run \\\"dev\\\" mode in \" + \"production.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-tls\", Target: &c.flagDevTLS, Usage: \"Enable TLS development mode. In this mode, Vault runs in-memory and \" + \"starts unsealed, with a generated TLS CA, certificate and key. \" + \"As the name implies, do not run \\\"dev-tls\\\" mode in \" + \"production.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"dev-tls-cert-dir\", Target: &c.flagDevTLSCertDir, Default: \"\", Usage: \"Directory where generated TLS files are created if `-dev-tls` is \" + \"specified. If left unset, files are generated in a temporary directory.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"dev-tls-san\", Target: &c.flagDevTLSSANs, Default: nil, Usage: \"Additional Subject Alternative Name (as a DNS name or IP address) \" + \"to generate the certificate with if `-dev-tls` is specified. The \" + \"certificate will always use localhost, localhost4, localhost6, \" + \"localhost.localdomain, and the host name as alternate DNS names, \" + \"and 127.0.0.1 as an alternate IP address. This flag can be specified \" + \"multiple times to specify multiple SANs.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"dev-root-token-id\", Target: &c.flagDevRootTokenID, Default: \"\", EnvVar: \"VAULT_DEV_ROOT_TOKEN_ID\", Usage: \"Initial root token. This only applies when running in \\\"dev\\\" \" + \"mode.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"dev-listen-address\", Target: &c.flagDevListenAddr, Default: \"127.0.0.1:8200\", EnvVar: \"VAULT_DEV_LISTEN_ADDRESS\", Usage: \"Address to bind to in \\\"dev\\\" mode.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-no-store-token\", Target: &c.flagDevNoStoreToken, Default: false, Usage: \"Do not persist the dev root token to the token helper \" + \"(usually the local filesystem) for use in future requests. \" + \"The token will only be displayed in the command output.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"dev-plugin-dir\", Target: &c.flagDevPluginDir, Default: \"\", Completion: complete.PredictDirs(\"*\"), Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-plugin-init\", Target: &c.flagDevPluginInit, Default: true, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-ha\", Target: &c.flagDevHA, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-transactional\", Target: &c.flagDevTransactional, Default: false, Hidden: true})\n",
      "\tf.IntVar(&IntVar{Name: \"dev-latency\", Target: &c.flagDevLatency, Hidden: true})\n",
      "\tf.IntVar(&IntVar{Name: \"dev-latency-jitter\", Target: &c.flagDevLatencyJitter, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-leased-kv\", Target: &c.flagDevLeasedKV, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-kv-v1\", Target: &c.flagDevKVV1, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-auto-seal\", Target: &c.flagDevAutoSeal, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-skip-init\", Target: &c.flagDevSkipInit, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-three-node\", Target: &c.flagDevThreeNode, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-four-cluster\", Target: &c.flagDevFourCluster, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"dev-consul\", Target: &c.flagDevConsul, Default: false, Hidden: true})\n",
      "\tf.StringVar(&StringVar{Name: \"dev-cluster-json\", Target: &c.flagDevClusterJson, Usage: \"File to write cluster definition to\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"test-verify-only\", Target: &c.flagTestVerifyOnly, Default: false, Hidden: true})\n",
      "\tf.BoolVar(&BoolVar{Name: \"test-server-config\", Target: &c.flagTestServerConfig, Default: false, Hidden: true})\n",
      "\treturn set\n",
      "}\n",
      "func doUnifiedTransferMissingDeltaWALSerials(sc *storageContext, clusterId string) error {\n",
      "\tthisUnifiedWALEntryPath := unifiedDeltaWALPath + deltaWALLastRevokedSerialName\n",
      "\tlastUnifiedWALEntry, err := getLastWALSerial(sc, thisUnifiedWALEntryPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to fetch last cross-cluster unified revoked delta WAL serial number: %w\", err)\n",
      "\t}\n",
      "\tlastLocalWALEntry, err := getLastWALSerial(sc, localDeltaWALLastRevokedSerial)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to fetch last locally revoked delta WAL serial number: %w\", err)\n",
      "\t}\n",
      "\t_unifiedWALEntries, err := sc.Storage.List(sc.Context, unifiedDeltaWALPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list cross-cluster unified delta WAL storage: %w\", err)\n",
      "\t}\n",
      "\tunifiedWALEntries := sliceToMapKey(_unifiedWALEntries)\n",
      "\t_unifiedRevokedSerials, err := listClusterSpecificUnifiedRevokedCerts(sc, clusterId)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list cross-cluster revoked certificates: %w\", err)\n",
      "\t}\n",
      "\tunifiedRevokedSerials := sliceToMapKey(_unifiedRevokedSerials)\n",
      "\tlocalWALEntries, err := sc.Storage.List(sc.Context, localDeltaWALPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list local delta WAL storage: %w\", err)\n",
      "\t}\n",
      "\tif lastUnifiedWALEntry == lastLocalWALEntry && len(_unifiedWALEntries) == len(localWALEntries) {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\terrCount := 0\n",
      "\tfor index, serial := range localWALEntries {\n",
      "\t\tif index%25 == 0 {\n",
      "\t\t\tconfig, _ := sc.Backend.CrlBuilder().getConfigWithUpdate(sc)\n",
      "\t\t\tif config != nil && (!config.UnifiedCRL || !config.EnableDelta) {\n",
      "\t\t\t\treturn errors.New(\"unified or delta CRLs have been disabled after we started, stopping\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif serial == deltaWALLastBuildSerialName || serial == deltaWALLastRevokedSerialName {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\t_, isAlreadyPresent := unifiedWALEntries[serial]\n",
      "\t\tif isAlreadyPresent {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\t_, isRevokedCopied := unifiedRevokedSerials[serial]\n",
      "\t\tif !isRevokedCopied {\n",
      "\t\t\terrCount += 1\n",
      "\t\t\tsc.Backend.Logger().Debug(\"Delta WAL exists locally, but corresponding cross-cluster full revocation entry is missing; skipping\", \"serial\", serial)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tlocalPath := localDeltaWALPath + serial\n",
      "\t\tunifiedPath := unifiedDeltaWALPath + serial\n",
      "\t\tentry, err := sc.Storage.Get(sc.Context, localPath)\n",
      "\t\tif err != nil || entry == nil {\n",
      "\t\t\terrCount += 1\n",
      "\t\t\tsc.Backend.Logger().Error(\"Failed reading local delta WAL entry to copy to cross-cluster\", \"serial\", serial, \"err\", err)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tentry.Key = unifiedPath\n",
      "\t\terr = sc.Storage.Put(sc.Context, entry)\n",
      "\t\tif err != nil {\n",
      "\t\t\terrCount += 1\n",
      "\t\t\tsc.Backend.Logger().Error(\"Failed sync local delta WAL entry to cross-cluster unified delta WAL location\", \"serial\", serial, \"err\", err)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t}\n",
      "\tif errCount > 0 {\n",
      "\t\tsc.Backend.Logger().Warn(fmt.Sprintf(\"Failed transfering %d local delta WAL serials to unified storage\", errCount))\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tlastRevSerial := lastWALInfo{Serial: lastLocalWALEntry}\n",
      "\tlastWALEntry, err := logical.StorageEntryJSON(thisUnifiedWALEntryPath, lastRevSerial)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"unable to create cross-cluster unified last delta CRL WAL entry: %w\", err)\n",
      "\t}\n",
      "\tif err = sc.Storage.Put(sc.Context, lastWALEntry); err != nil {\n",
      "\t\treturn fmt.Errorf(\"error saving cross-cluster unified last delta CRL WAL entry: %w\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *KVMetadataGetCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /metadata/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func generateConfiguration(ctx context.Context, client *api.Client, flagExec string, flagPaths []string) (io.WriterTo, error) {\n",
      "\tvar execCommand []string\n",
      "\tif flagExec != \"\" {\n",
      "\t\texecCommand = strings.Split(flagExec, \" \")\n",
      "\t} else {\n",
      "\t\texecCommand = []string{\"env\"}\n",
      "\t}\n",
      "\ttokenPath, err := homedir.Expand(\"~/.vault-token\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"could not expand home directory: %w\", err)\n",
      "\t}\n",
      "\ttemplates, err := constructTemplates(ctx, client, flagPaths)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"could not generate templates: %w\", err)\n",
      "\t}\n",
      "\tconfig := generatedConfig{AutoAuth: generatedConfigAutoAuth{Method: generatedConfigAutoAuthMethod{Type: \"token_file\", Config: generatedConfigAutoAuthMethodConfig{TokenFilePath: tokenPath}}}, TemplateConfig: generatedConfigTemplateConfig{StaticSecretRenderInterval: \"5m\", ExitOnRetryFailure: true, MaxConnectionsPerHost: 10}, Vault: generatedConfigVault{Address: client.Address()}, Exec: generatedConfigExec{Command: execCommand, RestartOnSecretChanges: \"always\", RestartStopSignal: \"SIGTERM\"}, EnvTemplates: templates}\n",
      "\tcontents := hclwrite.NewEmptyFile()\n",
      "\tgohcl.EncodeIntoBody(&config, contents.Body())\n",
      "\treturn contents, nil\n",
      "}\n",
      "func (b *backendGRPCPluginClient) Setup(ctx context.Context, config *logical.BackendConfig) error {\n",
      "\tstorageImpl := config.StorageView\n",
      "\tif b.metadataMode {\n",
      "\t\tstorageImpl = &NOOPStorage{}\n",
      "\t}\n",
      "\tstorage := &GRPCStorageServer{impl: storageImpl}\n",
      "\tsysViewImpl := config.System\n",
      "\tif b.metadataMode {\n",
      "\t\tsysViewImpl = &logical.StaticSystemView{}\n",
      "\t}\n",
      "\tsysView := &gRPCSystemViewServer{impl: sysViewImpl}\n",
      "\tevents := &GRPCEventsServer{impl: config.EventsSender}\n",
      "\tserverFunc := func(opts []grpc.ServerOption) *grpc.Server {\n",
      "\t\topts = append(opts, grpc.MaxRecvMsgSize(math.MaxInt32))\n",
      "\t\topts = append(opts, grpc.MaxSendMsgSize(math.MaxInt32))\n",
      "\t\ts := grpc.NewServer(opts...)\n",
      "\t\tpb.RegisterSystemViewServer(s, sysView)\n",
      "\t\tpb.RegisterStorageServer(s, storage)\n",
      "\t\tpb.RegisterEventsServer(s, events)\n",
      "\t\tb.server.Store(s)\n",
      "\t\tclose(b.cleanupCh)\n",
      "\t\treturn s\n",
      "\t}\n",
      "\tbrokerID := b.broker.NextId()\n",
      "\tgo b.broker.AcceptAndServe(brokerID, serverFunc)\n",
      "\targs := &pb.SetupArgs{BrokerID: brokerID, Config: config.Config, BackendUUID: config.BackendUUID}\n",
      "\tctx, cancel := context.WithCancel(ctx)\n",
      "\tquitCh := pluginutil.CtxCancelIfCanceled(cancel, b.doneCtx)\n",
      "\tdefer close(quitCh)\n",
      "\tdefer cancel()\n",
      "\treply, err := b.client.Setup(ctx, args)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif reply.Err != \"\" {\n",
      "\t\treturn errors.New(reply.Err)\n",
      "\t}\n",
      "\tb.system = config.System\n",
      "\tb.logger = config.Logger\n",
      "\treturn nil\n",
      "}\n",
      "func (c *LoginCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault login [options] [AUTH K=V...]\n",
      "\n",
      "  Authenticates users or machines to Vault using the provided arguments. A\n",
      "  successful authentication results in a Vault token - conceptually similar to\n",
      "  a session token on a website. By default, this token is cached on the local\n",
      "  machine for future requests.\n",
      "\n",
      "  The default auth method is \"token\". If not supplied via the CLI,\n",
      "  Vault will prompt for input. If the argument is \"-\", the values are read\n",
      "  from stdin.\n",
      "\n",
      "  The -method flag allows using other auth methods, such as userpass, github, or\n",
      "  cert. For these, additional \"K=V\" pairs may be required. For example, to\n",
      "  authenticate to the userpass auth method:\n",
      "\n",
      "      $ vault login -method=userpass username=my-username\n",
      "\n",
      "  For more information about the list of configuration parameters available for\n",
      "  a given auth method, use the \"vault auth help TYPE\" command. You can also use\n",
      "  \"vault auth list\" to see the list of enabled auth methods.\n",
      "\n",
      "  If an auth method is enabled at a non-standard path, the -method flag still\n",
      "  refers to the canonical type, but the -path flag refers to the enabled path.\n",
      "  If a github auth method was enabled at \"github-prod\", authenticate like this:\n",
      "\n",
      "      $ vault login -method=github -path=github-prod\n",
      "\n",
      "  If the authentication is requested with response wrapping (via -wrap-ttl),\n",
      "  the returned token is automatically unwrapped unless:\n",
      "\n",
      "    - The -token-only flag is used, in which case this command will output\n",
      "      the wrapping token.\n",
      "\n",
      "    - The -no-store flag is used, in which case this command will output the\n",
      "      details of the wrapping token.\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (b *backend) verifyCredentials(ctx context.Context, req *logical.Request, token string) (*verifyCredentialsResp, error) {\n",
      "\tvar warnings []string\n",
      "\tconfig, err := b.Config(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\treturn nil, errors.New(\"configuration has not been set\")\n",
      "\t}\n",
      "\tif len(config.TokenBoundCIDRs) > 0 {\n",
      "\t\tif req.Connection == nil {\n",
      "\t\t\tb.Logger().Error(\"token bound CIDRs found but no connection information available for validation\")\n",
      "\t\t\treturn nil, logical.ErrPermissionDenied\n",
      "\t\t}\n",
      "\t\tif !cidrutil.RemoteAddrIsOk(req.Connection.RemoteAddr, config.TokenBoundCIDRs) {\n",
      "\t\t\treturn nil, logical.ErrPermissionDenied\n",
      "\t\t}\n",
      "\t}\n",
      "\tclient, err := b.Client(token)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif config.BaseURL != \"\" {\n",
      "\t\tparsedURL, err := url.Parse(config.BaseURL)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"successfully parsed base_url when set but failing to parse now: %w\", err)\n",
      "\t\t}\n",
      "\t\tclient.BaseURL = parsedURL\n",
      "\t}\n",
      "\tif config.OrganizationID == 0 {\n",
      "\t\terr = config.setOrganizationID(ctx, client)\n",
      "\t\tif err != nil {\n",
      "\t\t\tb.Logger().Error(\"failed to set the organization_id on login\", \"error\", err)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tentry, err := logical.StorageEntryJSON(\"config\", config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif err := req.Storage.Put(ctx, entry); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tb.Logger().Info(\"set ID on a trust-on-first-use basis\", \"organization_id\", config.OrganizationID)\n",
      "\t}\n",
      "\tuser, _, err := client.Users.Get(ctx, \"\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar org *github.Organization\n",
      "\torgOpt := &github.ListOptions{PerPage: 100}\n",
      "\tvar allOrgs []*github.Organization\n",
      "\tfor {\n",
      "\t\torgs, resp, err := client.Organizations.List(ctx, \"\", orgOpt)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tallOrgs = append(allOrgs, orgs...)\n",
      "\t\tif resp.NextPage == 0 {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\torgOpt.Page = resp.NextPage\n",
      "\t}\n",
      "\torgLoginName := \"\"\n",
      "\tfor _, o := range allOrgs {\n",
      "\t\tif o.GetID() == config.OrganizationID {\n",
      "\t\t\torg = o\n",
      "\t\t\torgLoginName = *o.Login\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t}\n",
      "\tif org == nil {\n",
      "\t\treturn nil, errors.New(\"user is not part of required org\")\n",
      "\t}\n",
      "\tif orgLoginName != config.Organization {\n",
      "\t\twarningMsg := fmt.Sprintf(\"the organization name has changed to %q. It is recommended to verify and update the organization name in the config: %s=%d\", orgLoginName, \"organization_id\", config.OrganizationID)\n",
      "\t\tb.Logger().Warn(warningMsg)\n",
      "\t\twarnings = append(warnings, warningMsg)\n",
      "\t}\n",
      "\tvar teamNames []string\n",
      "\tteamOpt := &github.ListOptions{PerPage: 100}\n",
      "\tvar allTeams []*github.Team\n",
      "\tfor {\n",
      "\t\tteams, resp, err := client.Teams.ListUserTeams(ctx, teamOpt)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tallTeams = append(allTeams, teams...)\n",
      "\t\tif resp.NextPage == 0 {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tteamOpt.Page = resp.NextPage\n",
      "\t}\n",
      "\tfor _, t := range allTeams {\n",
      "\t\tif *t.Organization.ID != *org.ID {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tteamNames = append(teamNames, *t.Name)\n",
      "\t\tif *t.Name != *t.Slug {\n",
      "\t\t\tteamNames = append(teamNames, *t.Slug)\n",
      "\t\t}\n",
      "\t}\n",
      "\tgroupPoliciesList, err := b.TeamMap.Policies(ctx, req.Storage, teamNames...)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tuserPoliciesList, err := b.UserMap.Policies(ctx, req.Storage, []string{*user.Login}...)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tverifyResp := &verifyCredentialsResp{User: user, Org: org, Policies: append(groupPoliciesList, userPoliciesList...), TeamNames: teamNames, Config: config, Warnings: warnings}\n",
      "\treturn verifyResp, nil\n",
      "}\n",
      "func parseRaftBackendConfig(conf map[string]string, logger log.Logger) (*RaftBackendConfig, error) {\n",
      "\tc := &RaftBackendConfig{}\n",
      "\tc.Path = conf[\"path\"]\n",
      "\tenvPath := os.Getenv(EnvVaultRaftPath)\n",
      "\tif envPath != \"\" {\n",
      "\t\tc.Path = envPath\n",
      "\t}\n",
      "\tif c.Path == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"'path' must be set\")\n",
      "\t}\n",
      "\tc.NodeId = conf[\"node_id\"]\n",
      "\tenvNodeId := os.Getenv(EnvVaultRaftNodeID)\n",
      "\tif envNodeId != \"\" {\n",
      "\t\tc.NodeId = envNodeId\n",
      "\t}\n",
      "\tif c.NodeId == \"\" {\n",
      "\t\tlocalIDRaw, err := os.ReadFile(filepath.Join(c.Path, \"node-id\"))\n",
      "\t\tif err == nil && len(localIDRaw) > 0 {\n",
      "\t\t\tc.NodeId = string(localIDRaw)\n",
      "\t\t}\n",
      "\t\tif err != nil && !errors.Is(err, os.ErrNotExist) {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif c.NodeId == \"\" {\n",
      "\t\tid, err := uuid.GenerateUUID()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif err = os.WriteFile(filepath.Join(c.Path, \"node-id\"), []byte(id), 0o600); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tc.NodeId = id\n",
      "\t}\n",
      "\tif delayRaw, ok := conf[\"apply_delay\"]; ok {\n",
      "\t\tdelay, err := parseutil.ParseDurationSecond(delayRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"apply_delay does not parse as a duration: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.ApplyDelay = delay\n",
      "\t}\n",
      "\tif walRaw, ok := conf[\"raft_wal\"]; ok {\n",
      "\t\tuseRaftWal, err := strconv.ParseBool(walRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"raft_wal does not parse as a boolean: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.RaftWal = useRaftWal\n",
      "\t}\n",
      "\tif rlveRaw, ok := conf[\"raft_log_verifier_enabled\"]; ok {\n",
      "\t\trlve, err := strconv.ParseBool(rlveRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"raft_log_verifier_enabled does not parse as a boolean: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.RaftLogVerifierEnabled = rlve\n",
      "\t\tc.RaftLogVerificationInterval = defaultRaftLogVerificationInterval\n",
      "\t\tif rlviRaw, ok := conf[\"raft_log_verification_interval\"]; ok {\n",
      "\t\t\trlvi, err := parseutil.ParseDurationSecond(rlviRaw)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"raft_log_verification_interval does not parse as a duration: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tif rlvi >= minimumRaftLogVerificationInterval {\n",
      "\t\t\t\tc.RaftLogVerificationInterval = rlvi\n",
      "\t\t\t} else {\n",
      "\t\t\t\tlogger.Warn(\"raft_log_verification_interval is less than the minimum allowed, using default instead\", \"given\", rlveRaw, \"minimum\", minimumRaftLogVerificationInterval, \"default\", defaultRaftLogVerificationInterval)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif delayRaw, ok := conf[\"snapshot_delay\"]; ok {\n",
      "\t\tdelay, err := parseutil.ParseDurationSecond(delayRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"snapshot_delay does not parse as a duration: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.SnapshotDelay = delay\n",
      "\t}\n",
      "\tc.MaxEntrySize = defaultMaxEntrySize\n",
      "\tif maxEntrySizeCfg := conf[\"max_entry_size\"]; len(maxEntrySizeCfg) != 0 {\n",
      "\t\ti, err := strconv.Atoi(maxEntrySizeCfg)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to parse 'max_entry_size': %w\", err)\n",
      "\t\t}\n",
      "\t\tc.MaxEntrySize = uint64(i)\n",
      "\t}\n",
      "\tc.MaxBatchEntries, c.MaxBatchSize = batchLimitsFromEnv(logger)\n",
      "\tif interval := conf[\"autopilot_reconcile_interval\"]; interval != \"\" {\n",
      "\t\tinterval, err := parseutil.ParseDurationSecond(interval)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"autopilot_reconcile_interval does not parse as a duration: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.AutopilotReconcileInterval = interval\n",
      "\t}\n",
      "\tif interval := conf[\"autopilot_update_interval\"]; interval != \"\" {\n",
      "\t\tinterval, err := parseutil.ParseDurationSecond(interval)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"autopilot_update_interval does not parse as a duration: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.AutopilotUpdateInterval = interval\n",
      "\t}\n",
      "\teffectiveReconcileInterval := autopilot.DefaultReconcileInterval\n",
      "\teffectiveUpdateInterval := autopilot.DefaultUpdateInterval\n",
      "\tif c.AutopilotReconcileInterval != 0 {\n",
      "\t\teffectiveReconcileInterval = c.AutopilotReconcileInterval\n",
      "\t}\n",
      "\tif c.AutopilotUpdateInterval != 0 {\n",
      "\t\teffectiveUpdateInterval = c.AutopilotUpdateInterval\n",
      "\t}\n",
      "\tif effectiveReconcileInterval < effectiveUpdateInterval {\n",
      "\t\treturn nil, fmt.Errorf(\"autopilot_reconcile_interval (%v) should be larger than autopilot_update_interval (%v)\", effectiveReconcileInterval, effectiveUpdateInterval)\n",
      "\t}\n",
      "\tif uv, ok := conf[\"autopilot_upgrade_version\"]; ok && uv != \"\" {\n",
      "\t\t_, err := goversion.NewVersion(uv)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"autopilot_upgrade_version does not parse as a semantic version: %w\", err)\n",
      "\t\t}\n",
      "\t\tc.AutopilotUpgradeVersion = uv\n",
      "\t}\n",
      "\tc.RaftNonVoter = false\n",
      "\tif v := os.Getenv(EnvVaultRaftNonVoter); v != \"\" {\n",
      "\t\tc.RaftNonVoter = true\n",
      "\t} else if v, ok := conf[raftNonVoterConfigKey]; ok {\n",
      "\t\tnonVoter, err := strconv.ParseBool(v)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to parse %s config value %q as a boolean: %w\", raftNonVoterConfigKey, v, err)\n",
      "\t\t}\n",
      "\t\tc.RaftNonVoter = nonVoter\n",
      "\t}\n",
      "\tif c.RaftNonVoter && conf[\"retry_join\"] == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"setting %s to true is only valid if at least one retry_join stanza is specified\", raftNonVoterConfigKey)\n",
      "\t}\n",
      "\tc.AutopilotRedundancyZone = conf[\"autopilot_redundancy_zone\"]\n",
      "\treturn c, nil\n",
      "}\n",
      "func (f *FSM) ApplyBatch(logs []*raft.Log) []interface{} {\n",
      "\tnumLogs := len(logs)\n",
      "\tif numLogs == 0 {\n",
      "\t\treturn []interface{}{}\n",
      "\t}\n",
      "\tentrySlices := make([][]*FSMEntry, 0, numLogs)\n",
      "\tvar latestConfiguration *ConfigurationValue\n",
      "\tcommands := make([]interface{}, 0, numLogs)\n",
      "\tfor _, l := range logs {\n",
      "\t\tswitch l.Type {\n",
      "\t\tcase raft.LogCommand:\n",
      "\t\t\tcommand := &LogData{}\n",
      "\t\t\tif len(l.Data) > 0 {\n",
      "\t\t\t\terr := proto.Unmarshal(l.Data, command)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tf.logger.Error(\"error proto unmarshaling log data\", \"error\", err, \"data\", l.Data)\n",
      "\t\t\t\t\tpanic(\"error proto unmarshaling log data\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tcommands = append(commands, command)\n",
      "\t\tcase raft.LogConfiguration:\n",
      "\t\t\tconfiguration := raft.DecodeConfiguration(l.Data)\n",
      "\t\t\tconfig := raftConfigurationToProtoConfiguration(l.Index, configuration)\n",
      "\t\t\tcommands = append(commands, config)\n",
      "\t\t\tlatestConfiguration = config\n",
      "\t\tdefault:\n",
      "\t\t\tpanic(fmt.Sprintf(\"got unexpected log type: %d\", l.Type))\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar logIndex []byte\n",
      "\tvar err error\n",
      "\tlatestIndex, _ := f.LatestState()\n",
      "\tlastLog := logs[numLogs-1]\n",
      "\tif latestIndex.Index < lastLog.Index {\n",
      "\t\tlogIndex, err = proto.Marshal(&IndexValue{Term: lastLog.Term, Index: lastLog.Index})\n",
      "\t\tif err != nil {\n",
      "\t\t\tf.logger.Error(\"unable to marshal latest index\", \"error\", err)\n",
      "\t\t\tpanic(\"unable to marshal latest index\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tf.l.RLock()\n",
      "\tdefer f.l.RUnlock()\n",
      "\tif f.applyCallback != nil {\n",
      "\t\tf.applyCallback()\n",
      "\t}\n",
      "\terr = f.db.Update(func(tx *bolt.Tx) error {\n",
      "\t\tb := tx.Bucket(dataBucketName)\n",
      "\t\tfor _, commandRaw := range commands {\n",
      "\t\t\tentrySlice := make([]*FSMEntry, 0)\n",
      "\t\t\tswitch command := commandRaw.(type) {\n",
      "\t\t\tcase *LogData:\n",
      "\t\t\t\tfor _, op := range command.Operations {\n",
      "\t\t\t\t\tvar err error\n",
      "\t\t\t\t\tswitch op.OpType {\n",
      "\t\t\t\t\tcase putOp:\n",
      "\t\t\t\t\t\terr = b.Put([]byte(op.Key), op.Value)\n",
      "\t\t\t\t\tcase deleteOp:\n",
      "\t\t\t\t\t\terr = b.Delete([]byte(op.Key))\n",
      "\t\t\t\t\tcase getOp:\n",
      "\t\t\t\t\t\tfsmEntry := &FSMEntry{Key: op.Key}\n",
      "\t\t\t\t\t\tval := b.Get([]byte(op.Key))\n",
      "\t\t\t\t\t\tif len(val) > 0 {\n",
      "\t\t\t\t\t\t\tnewVal := make([]byte, len(val))\n",
      "\t\t\t\t\t\t\tcopy(newVal, val)\n",
      "\t\t\t\t\t\t\tfsmEntry.Value = newVal\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tentrySlice = append(entrySlice, fsmEntry)\n",
      "\t\t\t\t\tcase restoreCallbackOp:\n",
      "\t\t\t\t\t\tif f.restoreCb != nil {\n",
      "\t\t\t\t\t\t\tgo f.restoreCb(context.Background())\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\tdefault:\n",
      "\t\t\t\t\t\tif _, ok := f.unknownOpTypes.Load(op.OpType); !ok {\n",
      "\t\t\t\t\t\t\tf.logger.Error(\"unsupported transaction operation\", \"op\", op.OpType)\n",
      "\t\t\t\t\t\t\tf.unknownOpTypes.Store(op.OpType, struct{}{})\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\treturn err\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\tcase *ConfigurationValue:\n",
      "\t\t\t\tb := tx.Bucket(configBucketName)\n",
      "\t\t\t\tconfigBytes, err := proto.Marshal(command)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif err := b.Put(latestConfigKey, configBytes); err != nil {\n",
      "\t\t\t\t\treturn err\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tentrySlices = append(entrySlices, entrySlice)\n",
      "\t\t}\n",
      "\t\tif len(logIndex) > 0 {\n",
      "\t\t\tb := tx.Bucket(configBucketName)\n",
      "\t\t\terr = b.Put(latestIndexKey, logIndex)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif err != nil {\n",
      "\t\tf.logger.Error(\"failed to store data\", \"error\", err)\n",
      "\t\tpanic(\"failed to store data\")\n",
      "\t}\n",
      "\tif len(logIndex) > 0 {\n",
      "\t\tatomic.StoreUint64(f.latestTerm, lastLog.Term)\n",
      "\t\tatomic.StoreUint64(f.latestIndex, lastLog.Index)\n",
      "\t}\n",
      "\tif latestConfiguration != nil {\n",
      "\t\tf.latestConfig.Store(latestConfiguration)\n",
      "\t}\n",
      "\tresp := make([]interface{}, numLogs)\n",
      "\tfor i := range logs {\n",
      "\t\tresp[i] = &FSMApplyResponse{Success: true, EntrySlice: entrySlices[i]}\n",
      "\t}\n",
      "\treturn resp\n",
      "}\n",
      "func (cb *CrlBuilder) reloadConfigIfRequired(sc *storageContext) error {\n",
      "\tif cb.dirty.Load() {\n",
      "\t\tcb._config.Lock()\n",
      "\t\tdefer cb._config.Unlock()\n",
      "\t\tif !cb.dirty.Load() {\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tconfig, err := sc.getRevocationConfig()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tpreviousConfig := cb.config\n",
      "\t\tif config != nil {\n",
      "\t\t\tcb.config = *config\n",
      "\t\t} else {\n",
      "\t\t\tcb.config = defaultCrlConfig\n",
      "\t\t}\n",
      "\t\tcb.dirty.Store(false)\n",
      "\t\ttriggerChangeNotification := true\n",
      "\t\tif !cb.haveInitializedConfig {\n",
      "\t\t\tcb.haveInitializedConfig = true\n",
      "\t\t\ttriggerChangeNotification = false\n",
      "\t\t}\n",
      "\t\tif triggerChangeNotification {\n",
      "\t\t\tcb.notifyOnConfigChange(sc, previousConfig, cb.config)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (b *backend) pathLoginIamGetRoleNameCallerIdAndEntity(ctx context.Context, req *logical.Request, data *framework.FieldData) (string, *GetCallerIdentityResult, *iamEntity, *logical.Response, error) {\n",
      "\tmethod := data.Get(\"iam_http_request_method\").(string)\n",
      "\tif method == \"\" {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"missing iam_http_request_method\"), nil\n",
      "\t}\n",
      "\tif method != http.MethodGet && method != http.MethodPost {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"invalid iam_http_request_method; currently only 'GET' and 'POST' are supported\"), nil\n",
      "\t}\n",
      "\trawUrlB64 := data.Get(\"iam_request_url\").(string)\n",
      "\tif rawUrlB64 == \"\" {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"missing iam_request_url\"), nil\n",
      "\t}\n",
      "\trawUrl, err := base64.StdEncoding.DecodeString(rawUrlB64)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"failed to base64 decode iam_request_url\"), nil\n",
      "\t}\n",
      "\tparsedUrl, err := url.Parse(string(rawUrl))\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"error parsing iam_request_url\"), nil\n",
      "\t}\n",
      "\tif err = validateLoginIamRequestUrl(method, parsedUrl); err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(err.Error()), nil\n",
      "\t}\n",
      "\tbodyB64 := data.Get(\"iam_request_body\").(string)\n",
      "\tif bodyB64 == \"\" && method != http.MethodGet {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"missing iam_request_body which is required for POST requests\"), nil\n",
      "\t}\n",
      "\tbodyRaw, err := base64.StdEncoding.DecodeString(bodyB64)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"failed to base64 decode iam_request_body\"), nil\n",
      "\t}\n",
      "\tbody := string(bodyRaw)\n",
      "\tif err = validateLoginIamRequestBody(body); err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(err.Error()), nil\n",
      "\t}\n",
      "\theaders := data.Get(\"iam_request_headers\").(http.Header)\n",
      "\tif len(headers) == 0 {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(\"missing iam_request_headers\"), nil\n",
      "\t}\n",
      "\tconfig, err := b.lockedClientConfigEntry(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, nil, fmt.Errorf(\"error getting configuration: %w\", err)\n",
      "\t}\n",
      "\tendpoint := \"https://sts.amazonaws.com\"\n",
      "\tmaxRetries := awsClient.DefaultRetryerMaxNumRetries\n",
      "\tif config != nil {\n",
      "\t\tif config.IAMServerIdHeaderValue != \"\" {\n",
      "\t\t\terr = validateVaultHeaderValue(method, headers, parsedUrl, config.IAMServerIdHeaderValue)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn \"\", nil, nil, logical.ErrorResponse(fmt.Sprintf(\"error validating %s header: %v\", iamServerIdHeader, err)), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err = config.validateAllowedSTSHeaderValues(headers); err != nil {\n",
      "\t\t\treturn \"\", nil, nil, logical.ErrorResponse(err.Error()), nil\n",
      "\t\t}\n",
      "\t\tif method == http.MethodGet {\n",
      "\t\t\tif err = config.validateAllowedSTSQueryValues(parsedUrl.Query()); err != nil {\n",
      "\t\t\t\treturn \"\", nil, nil, logical.ErrorResponse(err.Error()), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif config.STSEndpoint != \"\" {\n",
      "\t\t\tendpoint = config.STSEndpoint\n",
      "\t\t}\n",
      "\t\tif config.MaxRetries >= 0 {\n",
      "\t\t\tmaxRetries = config.MaxRetries\n",
      "\t\t}\n",
      "\t\tif config.UseSTSRegionFromClient {\n",
      "\t\t\tclientSpecifiedRegion, err := awsRegionFromHeader(headers.Get(\"Authorization\"))\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn \"\", nil, nil, logical.ErrorResponse(\"region missing from Authorization header\"), nil\n",
      "\t\t\t}\n",
      "\t\t\turl, err := stsRegionalEndpoint(clientSpecifiedRegion)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn \"\", nil, nil, logical.ErrorResponse(err.Error()), nil\n",
      "\t\t\t}\n",
      "\t\t\tb.Logger().Debug(\"use_sts_region_from_client set; using region specified from header\", \"region\", clientSpecifiedRegion)\n",
      "\t\t\tendpoint = url\n",
      "\t\t}\n",
      "\t}\n",
      "\tb.Logger().Debug(\"submitting caller identity request\", \"endpoint\", endpoint)\n",
      "\tcallerID, err := submitCallerIdentityRequest(ctx, maxRetries, method, endpoint, parsedUrl, body, headers)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(fmt.Sprintf(\"error making upstream request: %v\", err)), nil\n",
      "\t}\n",
      "\tentity, err := parseIamArn(callerID.Arn)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, nil, logical.ErrorResponse(fmt.Sprintf(\"error parsing arn %q: %v\", callerID.Arn, err)), nil\n",
      "\t}\n",
      "\troleName := data.Get(\"role\").(string)\n",
      "\tif roleName == \"\" {\n",
      "\t\troleName = entity.FriendlyName\n",
      "\t}\n",
      "\treturn roleName, callerID, entity, nil, nil\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBDeleteMFAConfigByIDInTxn(txn *memdb.Txn, configID string) error {\n",
      "\tif configID == \"\" {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif txn == nil {\n",
      "\t\treturn fmt.Errorf(\"txn is nil\")\n",
      "\t}\n",
      "\tmConfig, err := b.MemDBMFAConfigByIDInTxn(txn, configID)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif mConfig == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\terr = txn.Delete(b.methodTable, mConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn errwrap.Wrapf(\"failed to delete MFA config from memdb: {{err}}\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func mfaPingIDPaths(i *IdentityStore) []*framework.Path {\n",
      "\treturn makeMFAMethodPaths(mfaMethodTypePingID, \"ping-id\", map[string]*framework.FieldSchema{\"method_name\": {Type: framework.TypeString, Description: `The unique name identifier for this MFA method.`}, \"username_format\": {Type: framework.TypeString, Description: `A template string for mapping Identity names to MFA method names. Values to subtitute should be placed in {{}}. For example, \"{{alias.name}}@example.com\". Currently-supported mappings: alias.name: The name returned by the mount configured via the mount_accessor parameter If blank, the Alias's name field will be used as-is. `}, \"settings_file_base64\": {Type: framework.TypeString, Description: \"The settings file provided by Ping, Base64-encoded. This must be a settings file suitable for third-party clients, not the PingID SDK or PingFederate.\"}}, i)\n",
      "}\n",
      "func (c *UIConfig) GetHeader(ctx context.Context, header string) ([]string, error) {\n",
      "\tc.l.RLock()\n",
      "\tdefer c.l.RUnlock()\n",
      "\tconfig, err := c.get(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tvalue := config.Headers.Values(header)\n",
      "\treturn value, nil\n",
      "}\n",
      "func newMachineInit(req *api.InitRequest, resp *api.InitResponse) *machineInit {\n",
      "\tinit := &machineInit{}\n",
      "\tinit.UnsealKeysHex = make([]string, len(resp.Keys))\n",
      "\tfor i, v := range resp.Keys {\n",
      "\t\tinit.UnsealKeysHex[i] = v\n",
      "\t}\n",
      "\tinit.UnsealKeysB64 = make([]string, len(resp.KeysB64))\n",
      "\tfor i, v := range resp.KeysB64 {\n",
      "\t\tinit.UnsealKeysB64[i] = v\n",
      "\t}\n",
      "\tif len(resp.Keys) == 0 {\n",
      "\t\tinit.UnsealShares = 1\n",
      "\t\tinit.UnsealThreshold = 1\n",
      "\t} else {\n",
      "\t\tinit.UnsealShares = req.SecretShares\n",
      "\t\tinit.UnsealThreshold = req.SecretThreshold\n",
      "\t}\n",
      "\tinit.RecoveryKeysHex = make([]string, len(resp.RecoveryKeys))\n",
      "\tfor i, v := range resp.RecoveryKeys {\n",
      "\t\tinit.RecoveryKeysHex[i] = v\n",
      "\t}\n",
      "\tinit.RecoveryKeysB64 = make([]string, len(resp.RecoveryKeysB64))\n",
      "\tfor i, v := range resp.RecoveryKeysB64 {\n",
      "\t\tinit.RecoveryKeysB64[i] = v\n",
      "\t}\n",
      "\tinit.RecoveryShares = req.RecoveryShares\n",
      "\tinit.RecoveryThreshold = req.RecoveryThreshold\n",
      "\tinit.RootToken = resp.RootToken\n",
      "\treturn init\n",
      "}\n",
      "func initHaBackend(c *ServerCommand, config *server.Config, coreConfig *vault.CoreConfig, backend physical.Backend) (bool, error) {\n",
      "\tvar ok bool\n",
      "\tif config.HAStorage != nil {\n",
      "\t\tif config.Storage.Type == storageTypeRaft && config.HAStorage.Type == storageTypeRaft {\n",
      "\t\t\treturn false, fmt.Errorf(\"Raft cannot be set both as 'storage' and 'ha_storage'. Setting 'storage' to 'raft' will automatically set it up for HA operations as well\")\n",
      "\t\t}\n",
      "\t\tif config.Storage.Type == storageTypeRaft {\n",
      "\t\t\treturn false, fmt.Errorf(\"HA storage cannot be declared when Raft is the storage type\")\n",
      "\t\t}\n",
      "\t\tfactory, exists := c.PhysicalBackends[config.HAStorage.Type]\n",
      "\t\tif !exists {\n",
      "\t\t\treturn false, fmt.Errorf(\"Unknown HA storage type %s\", config.HAStorage.Type)\n",
      "\t\t}\n",
      "\t\tnamedHALogger := c.logger.Named(\"ha.\" + config.HAStorage.Type)\n",
      "\t\tc.allLoggers = append(c.allLoggers, namedHALogger)\n",
      "\t\thabackend, err := factory(config.HAStorage.Config, namedHALogger)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn false, fmt.Errorf(\"Error initializing HA storage of type %s: %s\", config.HAStorage.Type, err)\n",
      "\t\t}\n",
      "\t\tif coreConfig.HAPhysical, ok = habackend.(physical.HABackend); !ok {\n",
      "\t\t\treturn false, fmt.Errorf(\"Specified HA storage does not support HA\")\n",
      "\t\t}\n",
      "\t\tif !coreConfig.HAPhysical.HAEnabled() {\n",
      "\t\t\treturn false, fmt.Errorf(\"Specified HA storage has HA support disabled; please consult documentation\")\n",
      "\t\t}\n",
      "\t\tcoreConfig.RedirectAddr = config.HAStorage.RedirectAddr\n",
      "\t\tdisableClustering := config.HAStorage.DisableClustering\n",
      "\t\tif config.HAStorage.Type == storageTypeRaft && disableClustering {\n",
      "\t\t\treturn disableClustering, fmt.Errorf(\"Disable clustering cannot be set to true when Raft is the HA storage type\")\n",
      "\t\t}\n",
      "\t\tif !disableClustering {\n",
      "\t\t\tcoreConfig.ClusterAddr = config.HAStorage.ClusterAddr\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tif coreConfig.HAPhysical, ok = backend.(physical.HABackend); ok {\n",
      "\t\t\tcoreConfig.RedirectAddr = config.Storage.RedirectAddr\n",
      "\t\t\tdisableClustering := config.Storage.DisableClustering\n",
      "\t\t\tif (config.Storage.Type == storageTypeRaft) && disableClustering {\n",
      "\t\t\t\treturn disableClustering, fmt.Errorf(\"Disable clustering cannot be set to true when Raft is the storage type\")\n",
      "\t\t\t}\n",
      "\t\t\tif !disableClustering {\n",
      "\t\t\t\tcoreConfig.ClusterAddr = config.Storage.ClusterAddr\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn config.DisableClustering, nil\n",
      "}\n",
      "func (c *KVPutCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"cas\", Target: &c.flagCAS, Default: -1, Usage: `Specifies to use a Check-And-Set operation. If not set the write\n",
      "\t\twill be allowed. If set to 0 a write will only be allowed if the key\n",
      "\t\tdoesnt exist. If the index is non-zero the write will only be allowed\n",
      "\t\tif the keys current version matches the version specified in the cas\n",
      "\t\tparameter.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /data/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func NewKerberosAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\tusername, err := read(\"username\", conf.Config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tservice, err := read(\"service\", conf.Config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\trealm, err := read(\"realm\", conf.Config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tkeytabPath, err := read(\"keytab_path\", conf.Config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tkrb5ConfPath, err := read(\"krb5conf_path\", conf.Config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdisableFast := false\n",
      "\tdisableFastRaw, ok := conf.Config[\"disable_fast_negotiation\"]\n",
      "\tif ok {\n",
      "\t\tdisableFast, err = parseutil.ParseBool(disableFastRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'disable_fast_negotiation': %s\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn &kerberosMethod{logger: conf.Logger, mountPath: conf.MountPath, loginCfg: &kerberos.LoginCfg{Username: username, Service: service, Realm: realm, KeytabPath: keytabPath, Krb5ConfPath: krb5ConfPath, DisableFASTNegotiation: disableFast}}, nil\n",
      "}\n",
      "func beginServiceRegistration(c *ServerCommand, config *server.Config) (sr.ServiceRegistration, error) {\n",
      "\tsdFactory, ok := c.ServiceRegistrations[config.ServiceRegistration.Type]\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"Unknown service_registration type %s\", config.ServiceRegistration.Type)\n",
      "\t}\n",
      "\tnamedSDLogger := c.logger.Named(\"service_registration.\" + config.ServiceRegistration.Type)\n",
      "\tc.allLoggers = append(c.allLoggers, namedSDLogger)\n",
      "\tstate := sr.State{VaultVersion: version.GetVersion().VersionNumber(), IsInitialized: false, IsSealed: true, IsActive: false, IsPerformanceStandby: false}\n",
      "\tvar err error\n",
      "\tconfigSR, err := sdFactory(config.ServiceRegistration.Config, namedSDLogger, state)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"Error initializing service_registration of type %s: %s\", config.ServiceRegistration.Type, err)\n",
      "\t}\n",
      "\treturn configSR, nil\n",
      "}\n",
      "func (c *Sys) RekeyInitWithContext(ctx context.Context, config *RekeyInitRequest) (*RekeyStatusResponse, error) {\n",
      "\tctx, cancelFunc := c.c.withConfiguredTimeout(ctx)\n",
      "\tdefer cancelFunc()\n",
      "\tr := c.c.NewRequest(http.MethodPut, \"/v1/sys/rekey/init\")\n",
      "\tif err := r.SetJSONBody(config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tresp, err := c.c.rawRequestWithContext(ctx, r)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdefer resp.Body.Close()\n",
      "\tvar result RekeyStatusResponse\n",
      "\terr = resp.DecodeJSON(&result)\n",
      "\treturn &result, err\n",
      "}\n",
      "func (c *UIConfig) get(ctx context.Context) (*uiConfigEntry, error) {\n",
      "\tplaintextConfigRaw, err := c.physicalStorage.Get(ctx, uiConfigPlaintextKey)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfigRaw, uiConfigGetErr := c.barrierStorage.Get(ctx, uiConfigKey)\n",
      "\tif uiConfigGetErr != nil && !strings.Contains(uiConfigGetErr.Error(), ErrBarrierSealed.Error()) {\n",
      "\t\treturn nil, uiConfigGetErr\n",
      "\t}\n",
      "\tif configRaw == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tconfig := new(uiConfigEntry)\n",
      "\tif config == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tif err := json.Unmarshal(configRaw.Value, config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif uiConfigGetErr == nil && (plaintextConfigRaw == nil || !bytes.Equal(plaintextConfigRaw.Value, configRaw.Value)) {\n",
      "\t\tif err := c.save(ctx, config); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "func (c *ServerCommand) enableThreeNodeDevCluster(base *vault.CoreConfig, info map[string]string, infoKeys []string, devListenAddress, tempDir string) int {\n",
      "\tconf, opts := teststorage.ClusterSetup(base, &vault.TestClusterOptions{HandlerFunc: vaulthttp.Handler, BaseListenAddress: c.flagDevListenAddr, Logger: c.logger, TempDir: tempDir, DefaultHandlerProperties: vault.HandlerProperties{ListenerConfig: &configutil.Listener{Profiling: configutil.ListenerProfiling{UnauthenticatedPProfAccess: true}, Telemetry: configutil.ListenerTelemetry{UnauthenticatedMetricsAccess: true}}}}, nil)\n",
      "\ttestCluster := vault.NewTestCluster(&testing.RuntimeT{}, conf, opts)\n",
      "\tdefer c.cleanupGuard.Do(testCluster.Cleanup)\n",
      "\tif constants.IsEnterprise {\n",
      "\t\terr := testcluster.WaitForActiveNodeAndPerfStandbys(context.Background(), testCluster)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"perf standbys didn't become ready: %v\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tinfo[\"cluster parameters path\"] = testCluster.TempDir\n",
      "\tinfoKeys = append(infoKeys, \"cluster parameters path\")\n",
      "\tfor i, core := range testCluster.Cores {\n",
      "\t\tinfo[fmt.Sprintf(\"node %d api address\", i)] = fmt.Sprintf(\"https://%s\", core.Listeners[0].Address.String())\n",
      "\t\tinfoKeys = append(infoKeys, fmt.Sprintf(\"node %d api address\", i))\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"version\")\n",
      "\tverInfo := version.GetVersion()\n",
      "\tinfo[\"version\"] = verInfo.FullVersionNumber(false)\n",
      "\tif verInfo.Revision != \"\" {\n",
      "\t\tinfo[\"version sha\"] = strings.Trim(verInfo.Revision, \"'\")\n",
      "\t\tinfoKeys = append(infoKeys, \"version sha\")\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"cgo\")\n",
      "\tinfo[\"cgo\"] = \"disabled\"\n",
      "\tif version.CgoEnabled {\n",
      "\t\tinfo[\"cgo\"] = \"enabled\"\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"go version\")\n",
      "\tinfo[\"go version\"] = runtime.Version()\n",
      "\tfipsStatus := entGetFIPSInfoKey()\n",
      "\tif fipsStatus != \"\" {\n",
      "\t\tinfoKeys = append(infoKeys, \"fips\")\n",
      "\t\tinfo[\"fips\"] = fipsStatus\n",
      "\t}\n",
      "\tpadding := 24\n",
      "\tsort.Strings(infoKeys)\n",
      "\tc.UI.Output(\"==> Vault server configuration:\\n\")\n",
      "\tfor _, k := range infoKeys {\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"%s%s: %s\", strings.Repeat(\" \", padding-len(k)), strings.Title(k), info[k]))\n",
      "\t}\n",
      "\tc.UI.Output(\"\")\n",
      "\tfor _, core := range testCluster.Cores {\n",
      "\t\tcore.Server.Handler = vaulthttp.Handler.Handler(&vault.HandlerProperties{Core: core.Core, ListenerConfig: &configutil.Listener{}})\n",
      "\t\tcore.SetClusterHandler(core.Server.Handler)\n",
      "\t}\n",
      "\ttestCluster.Start()\n",
      "\tctx := namespace.ContextWithNamespace(context.Background(), namespace.RootNamespace)\n",
      "\tif base.DevToken != \"\" {\n",
      "\t\treq := &logical.Request{ID: \"dev-gen-root\", Operation: logical.UpdateOperation, ClientToken: testCluster.RootToken, Path: \"auth/token/create\", Data: map[string]interface{}{\"id\": base.DevToken, \"policies\": []string{\"root\"}, \"no_parent\": true, \"no_default_policy\": true}}\n",
      "\t\tresp, err := testCluster.Cores[0].HandleRequest(ctx, req)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"failed to create root token with ID %s: %s\", base.DevToken, err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif resp == nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"nil response when creating root token with ID %s\", base.DevToken))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif resp.Auth == nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"nil auth when creating root token with ID %s\", base.DevToken))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\ttestCluster.RootToken = resp.Auth.ClientToken\n",
      "\t\treq.ID = \"dev-revoke-init-root\"\n",
      "\t\treq.Path = \"auth/token/revoke-self\"\n",
      "\t\treq.Data = nil\n",
      "\t\t_, err = testCluster.Cores[0].HandleRequest(ctx, req)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Output(fmt.Sprintf(\"failed to revoke initial root token: %s\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\ttokenHelper, err := c.TokenHelper()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error getting token helper: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif err := tokenHelper.Store(testCluster.RootToken); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error storing in token helper: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif err := ioutil.WriteFile(filepath.Join(testCluster.TempDir, \"root_token\"), []byte(testCluster.RootToken), 0o600); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error writing token to tempfile: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.UI.Output(fmt.Sprintf(\"==> Three node dev mode is enabled\\n\\n\" + \"The unseal key and root token are reproduced below in case you\\n\" + \"want to seal/unseal the Vault or play with authentication.\\n\"))\n",
      "\tfor i, key := range testCluster.BarrierKeys {\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"Unseal Key %d: %s\", i+1, base64.StdEncoding.EncodeToString(key)))\n",
      "\t}\n",
      "\tc.UI.Output(fmt.Sprintf(\"\\nRoot Token: %s\\n\", testCluster.RootToken))\n",
      "\tc.UI.Output(fmt.Sprintf(\"\\nUseful env vars:\\n\"+\"VAULT_TOKEN=%s\\n\"+\"VAULT_ADDR=%s\\n\"+\"VAULT_CACERT=%s/ca_cert.pem\\n\", testCluster.RootToken, testCluster.Cores[0].Client.Address(), testCluster.TempDir))\n",
      "\tif c.flagDevClusterJson != \"\" {\n",
      "\t\tclusterJson := testcluster.ClusterJson{Nodes: []testcluster.ClusterNode{}, CACertPath: filepath.Join(testCluster.TempDir, \"ca_cert.pem\"), RootToken: testCluster.RootToken}\n",
      "\t\tfor _, core := range testCluster.Cores {\n",
      "\t\t\tclusterJson.Nodes = append(clusterJson.Nodes, testcluster.ClusterNode{APIAddress: core.Client.Address()})\n",
      "\t\t}\n",
      "\t\tb, err := jsonutil.EncodeJSON(clusterJson)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error encoding cluster.json: %s\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\terr = os.WriteFile(c.flagDevClusterJson, b, 0o600)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error writing cluster.json %q: %s\", c.flagDevClusterJson, err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.UI.Output(\"==> Vault server started! Log data will stream in below:\\n\")\n",
      "\tselect {\n",
      "\tcase c.startedCh <- struct{}{}:\n",
      "\tdefault:\n",
      "\t}\n",
      "\tc.flushLog()\n",
      "\tshutdownTriggered := false\n",
      "\tfor !shutdownTriggered {\n",
      "\t\tselect {\n",
      "\t\tcase <-c.ShutdownCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault shutdown triggered\")\n",
      "\t\t\tc.cleanupGuard.Do(testCluster.Cleanup)\n",
      "\t\t\tfor _, core := range testCluster.Cores {\n",
      "\t\t\t\tif err := core.Shutdown(); err != nil {\n",
      "\t\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error with core shutdown: %s\", err))\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tshutdownTriggered = true\n",
      "\t\tcase <-c.SighupCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault reload triggered\")\n",
      "\t\t\tfor _, core := range testCluster.Cores {\n",
      "\t\t\t\tif err := c.Reload(core.ReloadFuncsLock, core.ReloadFuncs, nil, core.Core); err != nil {\n",
      "\t\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error(s) were encountered during reload: %s\", err))\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn 0\n",
      "}\n",
      "func NewApproleAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &approleMethod{logger: conf.Logger, mountPath: conf.MountPath, removeSecretIDFileAfterReading: true}\n",
      "\troleIDFilePathRaw, ok := conf.Config[\"role_id_file_path\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role_id_file_path' value\")\n",
      "\t}\n",
      "\ta.roleIDFilePath, ok = roleIDFilePathRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role_id_file_path' config value to string\")\n",
      "\t}\n",
      "\tif a.roleIDFilePath == \"\" {\n",
      "\t\treturn nil, errors.New(\"'role_id_file_path' value is empty\")\n",
      "\t}\n",
      "\tsecretIDFilePathRaw, ok := conf.Config[\"secret_id_file_path\"]\n",
      "\tif ok {\n",
      "\t\ta.secretIDFilePath, ok = secretIDFilePathRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'secret_id_file_path' config value to string\")\n",
      "\t\t}\n",
      "\t\tif a.secretIDFilePath == \"\" {\n",
      "\t\t\treturn a, nil\n",
      "\t\t}\n",
      "\t\tremoveSecretIDFileAfterReadingRaw, ok := conf.Config[\"remove_secret_id_file_after_reading\"]\n",
      "\t\tif ok {\n",
      "\t\t\tremoveSecretIDFileAfterReading, err := parseutil.ParseBool(removeSecretIDFileAfterReadingRaw)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"error parsing 'remove_secret_id_file_after_reading' value: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\ta.removeSecretIDFileAfterReading = removeSecretIDFileAfterReading\n",
      "\t\t}\n",
      "\t\tsecretIDResponseWrappingPathRaw, ok := conf.Config[\"secret_id_response_wrapping_path\"]\n",
      "\t\tif ok {\n",
      "\t\t\ta.secretIDResponseWrappingPath, ok = secretIDResponseWrappingPathRaw.(string)\n",
      "\t\t\tif !ok {\n",
      "\t\t\t\treturn nil, errors.New(\"could not convert 'secret_id_response_wrapping_path' config value to string\")\n",
      "\t\t\t}\n",
      "\t\t\tif a.secretIDResponseWrappingPath == \"\" {\n",
      "\t\t\t\treturn nil, errors.New(\"'secret_id_response_wrapping_path' value is empty\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn a, nil\n",
      "}\n",
      "func NewLdapAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\tk := &ldapMethod{logger: conf.Logger, mountPath: conf.MountPath, removePasswordAfterReading: true, credsFound: make(chan struct{}), watchCh: make(chan string), stopCh: make(chan struct{}), doneCh: make(chan struct{}), credSuccessGate: make(chan struct{}), once: new(sync.Once), latestPass: new(atomic.Value)}\n",
      "\tk.latestPass.Store(\"\")\n",
      "\tusernameRaw, ok := conf.Config[\"username\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'username' value\")\n",
      "\t}\n",
      "\tk.username, ok = usernameRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'username' config value to string\")\n",
      "\t}\n",
      "\tpassFilePathRaw, ok := conf.Config[\"password_file_path\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'password_file_path' value\")\n",
      "\t}\n",
      "\tk.passwordFilePath, ok = passFilePathRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'password_file_path' config value to string\")\n",
      "\t}\n",
      "\tif removePassAfterReadingRaw, ok := conf.Config[\"remove_password_after_reading\"]; ok {\n",
      "\t\tremovePassAfterReading, err := parseutil.ParseBool(removePassAfterReadingRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'remove_password_after_reading' value: %w\", err)\n",
      "\t\t}\n",
      "\t\tk.removePasswordAfterReading = removePassAfterReading\n",
      "\t}\n",
      "\tif removePassFollowsSymlinksRaw, ok := conf.Config[\"remove_password_follows_symlinks\"]; ok {\n",
      "\t\tremovePassFollowsSymlinks, err := parseutil.ParseBool(removePassFollowsSymlinksRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'remove_password_follows_symlinks' value: %w\", err)\n",
      "\t\t}\n",
      "\t\tk.removePasswordFollowsSymlinks = removePassFollowsSymlinks\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase k.passwordFilePath == \"\":\n",
      "\t\treturn nil, errors.New(\"'password_file_path' value is empty\")\n",
      "\tcase k.username == \"\":\n",
      "\t\treturn nil, errors.New(\"'username' value is empty\")\n",
      "\t}\n",
      "\treadPeriod := 1 * time.Minute\n",
      "\tif passReadPeriodRaw, ok := conf.Config[\"password_read_period\"]; ok {\n",
      "\t\tpassReadPeriod, err := parseutil.ParseDurationSecond(passReadPeriodRaw)\n",
      "\t\tif err != nil || passReadPeriod <= 0 {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'password_read_period' value into a positive value: %w\", err)\n",
      "\t\t}\n",
      "\t\treadPeriod = passReadPeriod\n",
      "\t} else {\n",
      "\t\tif k.removePasswordAfterReading {\n",
      "\t\t\treadPeriod = 500 * time.Millisecond\n",
      "\t\t}\n",
      "\t}\n",
      "\tk.ticker = time.NewTicker(readPeriod)\n",
      "\tgo k.runWatcher()\n",
      "\tk.logger.Info(\"ldap auth method created\", \"password_file_path\", k.passwordFilePath)\n",
      "\treturn k, nil\n",
      "}\n",
      "func (c *ServerCommand) runRecoveryMode() int {\n",
      "\tconfig, configErrors, err := c.parseConfig()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\tc.UI.Output(wrapAtLength(\"No configuration files found. Please provide configurations with the \" + \"-config flag. If you are supplying the path to a directory, please \" + \"ensure the directory contains files with the .hcl or .json \" + \"extension.\"))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.flags.applyLogConfigOverrides(config.SharedConfig)\n",
      "\tl, err := c.configureLogging(config)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.logger = l\n",
      "\tc.allLoggers = append(c.allLoggers, l)\n",
      "\tfor _, cErr := range configErrors {\n",
      "\t\tc.logger.Warn(cErr.String())\n",
      "\t}\n",
      "\tdefer c.flushLog()\n",
      "\tnamedGRPCLogFaker := c.logger.Named(\"grpclogfaker\")\n",
      "\tgrpclog.SetLogger(&grpclogFaker{logger: namedGRPCLogFaker, log: os.Getenv(\"VAULT_GRPC_LOGGING\") != \"\"})\n",
      "\tif config.Storage == nil {\n",
      "\t\tc.UI.Output(\"A storage backend must be specified\")\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif config.DefaultMaxRequestDuration != 0 {\n",
      "\t\tvault.DefaultMaxRequestDuration = config.DefaultMaxRequestDuration\n",
      "\t}\n",
      "\tlogProxyEnvironmentVariables(c.logger)\n",
      "\tfactory, exists := c.PhysicalBackends[config.Storage.Type]\n",
      "\tif !exists {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Unknown storage type %s\", config.Storage.Type))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif config.Storage.Type == storageTypeRaft || (config.HAStorage != nil && config.HAStorage.Type == storageTypeRaft) {\n",
      "\t\tif envCA := os.Getenv(\"VAULT_CLUSTER_ADDR\"); envCA != \"\" {\n",
      "\t\t\tconfig.ClusterAddr = envCA\n",
      "\t\t}\n",
      "\t\tif len(config.ClusterAddr) == 0 {\n",
      "\t\t\tc.UI.Error(\"Cluster address must be set when using raft storage\")\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tnamedStorageLogger := c.logger.Named(\"storage.\" + config.Storage.Type)\n",
      "\tbackend, err := factory(config.Storage.Config, namedStorageLogger)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error initializing storage of type %s: %s\", config.Storage.Type, err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tinfoKeys := make([]string, 0, 10)\n",
      "\tinfo := make(map[string]string)\n",
      "\tinfo[\"log level\"] = config.LogLevel\n",
      "\tinfoKeys = append(infoKeys, \"log level\")\n",
      "\tvar barrierSeal vault.Seal\n",
      "\tvar sealConfigError error\n",
      "\tif len(config.Seals) == 0 {\n",
      "\t\tconfig.Seals = append(config.Seals, &configutil.KMS{Type: wrapping.WrapperTypeShamir.String()})\n",
      "\t}\n",
      "\tctx := context.Background()\n",
      "\texistingSealGenerationInfo, err := vault.PhysicalSealGenInfo(ctx, backend)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error getting seal generation info: %v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\thasPartialPaths, err := hasPartiallyWrappedPaths(ctx, backend)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Cannot determine if there are partially seal wrapped entries in storage: %v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tsetSealResponse, err := setSeal(c, config, infoKeys, info, existingSealGenerationInfo, hasPartialPaths)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif setSealResponse.barrierSeal == nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error setting up seal: %v\", setSealResponse.sealConfigError))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tbarrierSeal = setSealResponse.barrierSeal\n",
      "\tdefer func() {\n",
      "\t\terr = barrierSeal.Finalize(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error finalizing seals: %v\", err))\n",
      "\t\t}\n",
      "\t}()\n",
      "\tcoreConfig := &vault.CoreConfig{Physical: backend, StorageType: config.Storage.Type, Seal: barrierSeal, UnwrapSeal: setSealResponse.unwrapSeal, LogLevel: config.LogLevel, Logger: c.logger, DisableMlock: config.DisableMlock, RecoveryMode: c.flagRecovery, ClusterAddr: config.ClusterAddr}\n",
      "\tcore, newCoreError := vault.NewCore(coreConfig)\n",
      "\tif newCoreError != nil {\n",
      "\t\tif vault.IsFatalError(newCoreError) {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error initializing core: %s\", newCoreError))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := core.InitializeRecovery(ctx); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Error initializing core in recovery mode: %s\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"storage\")\n",
      "\tinfo[\"storage\"] = config.Storage.Type\n",
      "\tif coreConfig.ClusterAddr != \"\" {\n",
      "\t\tinfo[\"cluster address\"] = coreConfig.ClusterAddr\n",
      "\t\tinfoKeys = append(infoKeys, \"cluster address\")\n",
      "\t}\n",
      "\tlns := make([]listenerutil.Listener, 0, len(config.Listeners))\n",
      "\tfor _, lnConfig := range config.Listeners {\n",
      "\t\tln, _, _, err := server.NewListener(lnConfig, c.logGate, c.UI)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error initializing listener of type %s: %s\", lnConfig.Type, err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tlns = append(lns, listenerutil.Listener{Listener: ln, Config: lnConfig})\n",
      "\t}\n",
      "\tlistenerCloseFunc := func() {\n",
      "\t\tfor _, ln := range lns {\n",
      "\t\t\tln.Listener.Close()\n",
      "\t\t}\n",
      "\t}\n",
      "\tdefer c.cleanupGuard.Do(listenerCloseFunc)\n",
      "\tinfoKeys = append(infoKeys, \"version\")\n",
      "\tverInfo := version.GetVersion()\n",
      "\tinfo[\"version\"] = verInfo.FullVersionNumber(false)\n",
      "\tif verInfo.Revision != \"\" {\n",
      "\t\tinfo[\"version sha\"] = strings.Trim(verInfo.Revision, \"'\")\n",
      "\t\tinfoKeys = append(infoKeys, \"version sha\")\n",
      "\t}\n",
      "\tinfoKeys = append(infoKeys, \"recovery mode\")\n",
      "\tinfo[\"recovery mode\"] = \"true\"\n",
      "\tinfoKeys = append(infoKeys, \"go version\")\n",
      "\tinfo[\"go version\"] = runtime.Version()\n",
      "\tfipsStatus := entGetFIPSInfoKey()\n",
      "\tif fipsStatus != \"\" {\n",
      "\t\tinfoKeys = append(infoKeys, \"fips\")\n",
      "\t\tinfo[\"fips\"] = fipsStatus\n",
      "\t}\n",
      "\tpadding := 24\n",
      "\tsort.Strings(infoKeys)\n",
      "\tc.UI.Output(\"==> Vault server configuration:\\n\")\n",
      "\tfor _, k := range infoKeys {\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"%s%s: %s\", strings.Repeat(\" \", padding-len(k)), strings.Title(k), info[k]))\n",
      "\t}\n",
      "\tc.UI.Output(\"\")\n",
      "\tif c.flagTestVerifyOnly {\n",
      "\t\treturn 0\n",
      "\t}\n",
      "\tfor _, ln := range lns {\n",
      "\t\thandler := vaulthttp.Handler.Handler(&vault.HandlerProperties{Core: core, ListenerConfig: ln.Config, DisablePrintableCheck: config.DisablePrintableCheck, RecoveryMode: c.flagRecovery, RecoveryToken: atomic.NewString(\"\")})\n",
      "\t\tserver := &http.Server{Handler: handler, ReadHeaderTimeout: 10 * time.Second, ReadTimeout: 30 * time.Second, IdleTimeout: 5 * time.Minute, ErrorLog: c.logger.StandardLogger(nil)}\n",
      "\t\tgo server.Serve(ln.Listener)\n",
      "\t}\n",
      "\tif sealConfigError != nil {\n",
      "\t\tinit, err := core.InitializedLocally(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Error checking if core is initialized: %v\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif init {\n",
      "\t\t\tc.UI.Error(\"Vault is initialized but no Seal key could be loaded\")\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\tif newCoreError != nil {\n",
      "\t\tc.UI.Warn(wrapAtLength(\"WARNING! A non-fatal error occurred during initialization. Please \" + \"check the logs for more information.\"))\n",
      "\t\tc.UI.Warn(\"\")\n",
      "\t}\n",
      "\tif !c.logFlags.flagCombineLogs {\n",
      "\t\tc.UI.Output(\"==> Vault server started! Log data will stream in below:\\n\")\n",
      "\t}\n",
      "\tc.flushLog()\n",
      "\tfor {\n",
      "\t\tselect {\n",
      "\t\tcase <-c.ShutdownCh:\n",
      "\t\t\tc.UI.Output(\"==> Vault shutdown triggered\")\n",
      "\t\t\tc.cleanupGuard.Do(listenerCloseFunc)\n",
      "\t\t\tif err := core.Shutdown(); err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error with core shutdown: %s\", err))\n",
      "\t\t\t}\n",
      "\t\t\treturn 0\n",
      "\t\tcase <-c.SigUSR2Ch:\n",
      "\t\t\tbuf := make([]byte, 32*1024*1024)\n",
      "\t\t\tn := runtime.Stack(buf[:], true)\n",
      "\t\t\tc.logger.Info(\"goroutine trace\", \"stack\", string(buf[:n]))\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (c *KVMetadataPatchCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"max-versions\", Target: &c.flagMaxVersions, Default: -1, Usage: `The number of versions to keep. If not set, the backends configured max version is used.`})\n",
      "\tf.BoolPtrVar(&BoolPtrVar{Name: \"cas-required\", Target: &c.flagCASRequired, Usage: `If true the key will require the cas parameter to be set on all write requests. If false, the backends configuration will be used.`})\n",
      "\tf.DurationVar(&DurationVar{Name: \"delete-version-after\", Target: &c.flagDeleteVersionAfter, Default: -1, EnvVar: \"\", Completion: complete.PredictAnything, Usage: `Specifies the length of time before a version is deleted.\n",
      "\t\tIf not set, the backend's configured delete-version-after is used. Cannot be\n",
      "\t\tgreater than the backend's delete-version-after. The delete-version-after is\n",
      "\t\tspecified as a numeric string with a suffix like \"30s\" or\n",
      "\t\t\"3h25m19s\".`})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"custom-metadata\", Target: &c.flagCustomMetadata, Default: map[string]string{}, Usage: `Specifies arbitrary version-agnostic key=value metadata meant to describe a secret.\n",
      "\t\tThis can be specified multiple times to add multiple pieces of metadata.`})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"remove-custom-metadata\", Target: &c.flagRemoveCustomMetadata, Default: []string{}, Usage: \"Key to remove from custom metadata. To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /metadata/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func (c *UIConfig) DeleteHeader(ctx context.Context, header string) error {\n",
      "\tc.l.Lock()\n",
      "\tdefer c.l.Unlock()\n",
      "\tconfig, err := c.get(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tconfig.Headers.Del(header)\n",
      "\treturn c.save(ctx, config)\n",
      "}\n",
      "func (s *gRPCSystemViewClient) NewPluginClient(ctx context.Context, config pluginutil.PluginClientConfig) (pluginutil.PluginClient, error) {\n",
      "\treturn nil, fmt.Errorf(\"cannot call NewPluginClient from a plugin backend\")\n",
      "}\n",
      "func (c *SecretsEnableCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"description\", Target: &c.flagDescription, Completion: complete.PredictAnything, Usage: \"Human-friendly description for the purpose of this engine.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"path\", Target: &c.flagPath, Default: \"\", Completion: complete.PredictAnything, Usage: \"Place where the secrets engine will be accessible. This must be \" + \"unique cross all secrets engines. This defaults to the \\\"type\\\" of the \" + \"secrets engine.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"default-lease-ttl\", Target: &c.flagDefaultLeaseTTL, Completion: complete.PredictAnything, Usage: \"The default lease TTL for this secrets engine. If unspecified, \" + \"this defaults to the Vault server's globally configured default lease \" + \"TTL.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"max-lease-ttl\", Target: &c.flagMaxLeaseTTL, Completion: complete.PredictAnything, Usage: \"The maximum lease TTL for this secrets engine. If unspecified, \" + \"this defaults to the Vault server's globally configured maximum lease \" + \"TTL.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACRequestKeys, Target: &c.flagAuditNonHMACRequestKeys, Usage: \"Key that will not be HMAC'd by audit devices in the request data object. \" + \"To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACResponseKeys, Target: &c.flagAuditNonHMACResponseKeys, Usage: \"Key that will not be HMAC'd by audit devices in the response data object. \" + \"To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameListingVisibility, Target: &c.flagListingVisibility, Usage: \"Determines the visibility of the mount in the UI-specific listing endpoint.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNamePassthroughRequestHeaders, Target: &c.flagPassthroughRequestHeaders, Usage: \"Request header value that will be sent to the plugins. To specify multiple \" + \"values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedResponseHeaders, Target: &c.flagAllowedResponseHeaders, Usage: \"Response header value that plugins will be allowed to set. To specify multiple \" + \"values, specify this flag multiple times.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"force-no-cache\", Target: &c.flagForceNoCache, Default: false, Usage: \"Force the secrets engine to disable caching. If unspecified, this \" + \"defaults to the Vault server's globally configured cache settings. \" + \"This does not affect caching of the underlying encrypted data storage.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"plugin-name\", Target: &c.flagPluginName, Completion: c.PredictVaultPlugins(api.PluginTypeSecrets, api.PluginTypeDatabase), Usage: \"Name of the secrets engine plugin. This plugin name must already \" + \"exist in Vault's plugin catalog.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNamePluginVersion, Target: &c.flagPluginVersion, Default: \"\", Usage: \"Select the semantic version of the plugin to enable.\"})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"options\", Target: &c.flagOptions, Completion: complete.PredictAnything, Usage: \"Key-value pair provided as key=value for the mount options. \" + \"This can be specified multiple times.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"local\", Target: &c.flagLocal, Default: false, Usage: \"Mark the secrets engine as local-only. Local engines are not \" + \"replicated or removed by replication.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"seal-wrap\", Target: &c.flagSealWrap, Default: false, Usage: \"Enable seal wrapping of critical values in the secrets engine.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"external-entropy-access\", Target: &c.flagExternalEntropyAccess, Default: false, Usage: \"Enable secrets engine to access Vault's external entropy source.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Default: 0, Usage: \"Select the version of the engine to run. Not supported by all engines.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedManagedKeys, Target: &c.flagAllowedManagedKeys, Usage: \"Managed key name(s) that the mount in question is allowed to access. \" + \"Note that multiple keys may be specified by providing this option multiple times, \" + \"each time with 1 key.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameIdentityTokenKey, Target: &c.flagIdentityTokenKey, Default: \"default\", Usage: \"Select the key used to sign plugin identity tokens.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (c *PluginRuntimeDeregisterCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault plugin runtime deregister [options] NAME\n",
      "\n",
      "  Deregister an existing plugin runtime in the catalog with the given name. If\n",
      "  any registered plugin references the plugin runtime, an error is returned. If\n",
      "  the plugin runtime does not exist, an error is returned. The -type flag\n",
      "  currently only accepts \"container\".\n",
      "\n",
      "  Deregister a plugin runtime:\n",
      "\n",
      "      $ vault plugin runtime deregister -type=container my-plugin-runtime\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (d *defaultSeal) SetBarrierConfig(ctx context.Context, config *SealConfig) error {\n",
      "\tif err := d.checkCore(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\td.config.Store((*SealConfig)(nil))\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tconfig.Type = d.BarrierSealConfigType().String()\n",
      "\tif d.core.isRaftUnseal() {\n",
      "\t\td.config.Store(config.Clone())\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\terr := d.core.SetPhysicalBarrierSealConfig(ctx, config)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\td.SetCachedBarrierConfig(config.Clone())\n",
      "\treturn nil\n",
      "}\n",
      "func NewEntryFormatter(name string, config FormatterConfig, salter Salter, logger hclog.Logger, opt ...Option) (*EntryFormatter, error) {\n",
      "\tconst op = \"audit.NewEntryFormatter\"\n",
      "\tname = strings.TrimSpace(name)\n",
      "\tif name == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"%s: name is required: %w\", op, event.ErrInvalidParameter)\n",
      "\t}\n",
      "\tif salter == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"%s: cannot create a new audit formatter with nil salter: %w\", op, event.ErrInvalidParameter)\n",
      "\t}\n",
      "\tif logger == nil || reflect.ValueOf(logger).IsNil() {\n",
      "\t\treturn nil, fmt.Errorf(\"%s: cannot create a new audit formatter with nil logger: %w\", op, event.ErrInvalidParameter)\n",
      "\t}\n",
      "\tif err := config.RequiredFormat.validate(); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"%s: format not valid: %w\", op, err)\n",
      "\t}\n",
      "\topts, err := getOpts(opt...)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"%s: error applying options: %w\", op, err)\n",
      "\t}\n",
      "\treturn &EntryFormatter{config: config, salter: salter, logger: logger, headerFormatter: opts.withHeaderFormatter, name: name, prefix: opts.withPrefix}, nil\n",
      "}\n",
      "func (c *OperatorInitCommand) consulAuto(client *api.Client, req *api.InitRequest) int {\n",
      "\toriginalAddr := client.Address()\n",
      "\tdefer client.SetAddress(originalAddr)\n",
      "\tconsulClient, err := consulapi.NewClient(consulapi.DefaultConfig())\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Failed to create Consul client:%v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\taddr := client.Address()\n",
      "\tclientURL, err := url.Parse(addr)\n",
      "\tif err != nil || clientURL == nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Failed to parse Vault address %s: %s\", addr, err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tvar uninitedVaults []string\n",
      "\tvar initedVault string\n",
      "\tservices, _, err := consulClient.Catalog().Service(c.flagConsulService, \"\", &consulapi.QueryOptions{AllowStale: true})\n",
      "\tif err == nil {\n",
      "\t\tfor _, service := range services {\n",
      "\t\t\tvaultAddr := (&url.URL{Scheme: clientURL.Scheme, Host: fmt.Sprintf(\"%s:%d\", service.ServiceAddress, service.ServicePort)}).String()\n",
      "\t\t\tclient.SetAddress(vaultAddr)\n",
      "\t\t\tinited, err := client.Sys().InitStatus()\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Error checking init status of %q: %s\", vaultAddr, err))\n",
      "\t\t\t}\n",
      "\t\t\tif inited {\n",
      "\t\t\t\tinitedVault = vaultAddr\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t\tuninitedVaults = append(uninitedVaults, vaultAddr)\n",
      "\t\t}\n",
      "\t}\n",
      "\texport := \"export\"\n",
      "\tquote := \"\\\"\"\n",
      "\tif runtime.GOOS == \"windows\" {\n",
      "\t\texport = \"set\"\n",
      "\t\tquote = \"\"\n",
      "\t}\n",
      "\tif initedVault != \"\" {\n",
      "\t\tvaultURL, err := url.Parse(initedVault)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to parse Vault address %q: %s\", initedVault, err))\n",
      "\t\t\treturn 2\n",
      "\t\t}\n",
      "\t\tvaultAddr := vaultURL.String()\n",
      "\t\tc.UI.Output(wrapAtLength(fmt.Sprintf(\"Discovered an initialized Vault node at %q with Consul service name \"+\"%q. Set the following environment variable to target the discovered \"+\"Vault server:\", vaultURL.String(), c.flagConsulService)))\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"    $ %s VAULT_ADDR=%s%s%s\", export, quote, vaultAddr, quote))\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\treturn 0\n",
      "\t}\n",
      "\tswitch len(uninitedVaults) {\n",
      "\tcase 0:\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"No Vault nodes registered as %q in Consul\", c.flagConsulService))\n",
      "\t\treturn 2\n",
      "\tcase 1:\n",
      "\t\tvaultURL, err := url.Parse(uninitedVaults[0])\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to parse Vault address %q: %s\", initedVault, err))\n",
      "\t\t\treturn 2\n",
      "\t\t}\n",
      "\t\tvaultAddr := vaultURL.String()\n",
      "\t\tclient.SetAddress(vaultAddr)\n",
      "\t\tc.UI.Output(wrapAtLength(fmt.Sprintf(\"Discovered an initialized Vault node at %q with Consul service name \"+\"%q. Set the following environment variable to target the discovered \"+\"Vault server:\", vaultURL.String(), c.flagConsulService)))\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\tc.UI.Output(fmt.Sprintf(\"    $ %s VAULT_ADDR=%s%s%s\", export, quote, vaultAddr, quote))\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\tc.UI.Output(\"Attempting to initialize it...\")\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\treturn c.init(client, req)\n",
      "\tdefault:\n",
      "\t\tc.UI.Output(wrapAtLength(fmt.Sprintf(\"Discovered %d uninitialized Vault servers with Consul service name \"+\"%q. To initialize these Vaults, set any one of the following \"+\"environment variables and run \\\"vault operator init\\\":\", len(uninitedVaults), c.flagConsulService)))\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\tfor _, node := range uninitedVaults {\n",
      "\t\t\tvaultURL, err := url.Parse(node)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.UI.Error(fmt.Sprintf(\"Failed to parse Vault address %q: %s\", initedVault, err))\n",
      "\t\t\t\treturn 2\n",
      "\t\t\t}\n",
      "\t\t\tvaultAddr := vaultURL.String()\n",
      "\t\t\tc.UI.Output(fmt.Sprintf(\"    $ %s VAULT_ADDR=%s%s%s\", export, quote, vaultAddr, quote))\n",
      "\t\t}\n",
      "\t\tc.UI.Output(\"\")\n",
      "\t\treturn 0\n",
      "\t}\n",
      "}\n",
      "func (b *LoginMFABackend) loginMFAMethodExistenceCheck(eConfig *mfa.MFAEnforcementConfig) error {\n",
      "\tvar aggErr *multierror.Error\n",
      "\tfor _, confID := range eConfig.MFAMethodIDs {\n",
      "\t\tconfig, memErr := b.MemDBMFAConfigByID(confID)\n",
      "\t\tif memErr != nil {\n",
      "\t\t\taggErr = multierror.Append(aggErr, memErr)\n",
      "\t\t\treturn aggErr.ErrorOrNil()\n",
      "\t\t}\n",
      "\t\tif config == nil {\n",
      "\t\t\taggErr = multierror.Append(aggErr, fmt.Errorf(\"found an MFA method ID in enforcement config, but failed to find the MFA method config method ID %s\", confID))\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn aggErr.ErrorOrNil()\n",
      "}\n",
      "func (i *IdentityStore) handleMFALoginEnforcementUpdate(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\tvar err error\n",
      "\tvar eConfig *mfa.MFAEnforcementConfig\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tname := d.Get(\"name\").(string)\n",
      "\tif name == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing enforcement name\"), nil\n",
      "\t}\n",
      "\tb := i.mfaBackend\n",
      "\tb.mfaLock.Lock()\n",
      "\tdefer b.mfaLock.Unlock()\n",
      "\teConfig, err = b.MemDBMFALoginEnforcementConfigByNameAndNamespace(name, ns.ID)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif eConfig == nil {\n",
      "\t\tconfigID, err := uuid.GenerateUUID()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to generate an identifier for MFA login enforcement config: %w\", err)\n",
      "\t\t}\n",
      "\t\teConfig = &mfa.MFAEnforcementConfig{Name: name, NamespaceID: ns.ID, ID: configID}\n",
      "\t}\n",
      "\tmfaMethodIds, ok := d.GetOk(\"mfa_method_ids\")\n",
      "\tif !ok {\n",
      "\t\treturn logical.ErrorResponse(\"missing method ids\"), nil\n",
      "\t}\n",
      "\tfor _, mmid := range mfaMethodIds.([]string) {\n",
      "\t\tconfig, err := b.mfaConfigReadByMethodID(mmid)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif config == nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"one of the provided method ids doesn't exist\"), nil\n",
      "\t\t}\n",
      "\t\tmfaNs, err := i.namespacer.NamespaceByID(ctx, config[\"namespace_id\"].(string))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"failed to retrieve config namespace\"), nil\n",
      "\t\t}\n",
      "\t\tif ns.ID != mfaNs.ID && !ns.HasParent(mfaNs) {\n",
      "\t\t\treturn logical.ErrorResponse(\"one of the provided method ids is in an incompatible namespace and can't be used\"), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\teConfig.MFAMethodIDs = mfaMethodIds.([]string)\n",
      "\toneOfLastFour := false\n",
      "\tauthMethodAccessors, ok := d.GetOk(\"auth_method_accessors\")\n",
      "\tif ok {\n",
      "\t\tfor _, accessor := range authMethodAccessors.([]string) {\n",
      "\t\t\tfound, err := b.validateAuthEntriesForAccessorOrType(ctx, ns, func(entry *MountEntry) bool {\n",
      "\t\t\t\treturn accessor == entry.Accessor\n",
      "\t\t\t})\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif !found {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"one of the auth method accessors provided is invalid\"), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\teConfig.AuthMethodAccessors = authMethodAccessors.([]string)\n",
      "\t\toneOfLastFour = true\n",
      "\t}\n",
      "\tauthMethodTypes, ok := d.GetOk(\"auth_method_types\")\n",
      "\tif ok {\n",
      "\t\tfor _, authType := range authMethodTypes.([]string) {\n",
      "\t\t\tfound, err := b.validateAuthEntriesForAccessorOrType(ctx, ns, func(entry *MountEntry) bool {\n",
      "\t\t\t\treturn authType == entry.Type\n",
      "\t\t\t})\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif !found {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"one of the auth method types provided is invalid\"), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\teConfig.AuthMethodTypes = authMethodTypes.([]string)\n",
      "\t\toneOfLastFour = true\n",
      "\t}\n",
      "\tidentityGroupIds, ok := d.GetOk(\"identity_group_ids\")\n",
      "\tif ok {\n",
      "\t\tfor _, groupId := range identityGroupIds.([]string) {\n",
      "\t\t\tgroup, err := i.MemDBGroupByID(groupId, true)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif group == nil {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"one of the provided group ids doesn't exist\"), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\teConfig.IdentityGroupIds = identityGroupIds.([]string)\n",
      "\t\toneOfLastFour = true\n",
      "\t}\n",
      "\tidentityEntityIds, ok := d.GetOk(\"identity_entity_ids\")\n",
      "\tif ok {\n",
      "\t\tfor _, entityId := range identityEntityIds.([]string) {\n",
      "\t\t\tentity, err := i.MemDBEntityByID(entityId, true)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tif entity == nil {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"one of the provided entity ids doesn't exist\"), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\teConfig.IdentityEntityIDs = identityEntityIds.([]string)\n",
      "\t\toneOfLastFour = true\n",
      "\t}\n",
      "\tif !oneOfLastFour {\n",
      "\t\treturn logical.ErrorResponse(\"One of auth_method_accessors, auth_method_types, identity_group_ids, identity_entity_ids must be specified\"), nil\n",
      "\t}\n",
      "\terr = b.putMFALoginEnforcementConfig(ctx, eConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn nil, b.MemDBUpsertMFALoginEnforcementConfig(ctx, eConfig)\n",
      "}\n",
      "func (sc *storageContext) getRevocationConfig() (*crlConfig, error) {\n",
      "\tentry, err := sc.Storage.Get(sc.Context, \"config/crl\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar result crlConfig\n",
      "\tif entry == nil {\n",
      "\t\tresult = defaultCrlConfig\n",
      "\t\treturn &result, nil\n",
      "\t}\n",
      "\tif err = entry.DecodeJSON(&result); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif result.Version == 0 {\n",
      "\t\tresult.OcspDisable = defaultCrlConfig.OcspDisable\n",
      "\t\tresult.OcspExpiry = defaultCrlConfig.OcspExpiry\n",
      "\t\tresult.AutoRebuild = defaultCrlConfig.AutoRebuild\n",
      "\t\tresult.AutoRebuildGracePeriod = defaultCrlConfig.AutoRebuildGracePeriod\n",
      "\t\tresult.Version = 1\n",
      "\t}\n",
      "\tif result.Version == 1 {\n",
      "\t\tif result.DeltaRebuildInterval == \"\" {\n",
      "\t\t\tresult.DeltaRebuildInterval = defaultCrlConfig.DeltaRebuildInterval\n",
      "\t\t}\n",
      "\t\tresult.Version = 2\n",
      "\t}\n",
      "\tif result.Expiry == \"\" {\n",
      "\t\tresult.Expiry = defaultCrlConfig.Expiry\n",
      "\t}\n",
      "\tisLocalMount := sc.Backend.System().LocalMount()\n",
      "\tif (!constants.IsEnterprise || isLocalMount) && (result.UnifiedCRLOnExistingPaths || result.UnifiedCRL || result.UseGlobalQueue) {\n",
      "\t\tsc.Backend.Logger().Warn(\"Not running Vault Enterprise or using a local mount, \" + \"disabling unified_crl, unified_crl_on_existing_paths and cross_cluster_revocation config flags.\")\n",
      "\t\tresult.UnifiedCRLOnExistingPaths = false\n",
      "\t\tresult.UnifiedCRL = false\n",
      "\t\tresult.UseGlobalQueue = false\n",
      "\t}\n",
      "\treturn &result, nil\n",
      "}\n",
      "func (a *acmeState) writeConfig(sc *storageContext, config *acmeConfigEntry) (*acmeConfigEntry, error) {\n",
      "\ta._config.Lock()\n",
      "\tdefer a._config.Unlock()\n",
      "\tif err := sc.setAcmeConfig(config); err != nil {\n",
      "\t\ta.markConfigDirty()\n",
      "\t\treturn nil, fmt.Errorf(\"failed writing ACME config: %w\", err)\n",
      "\t}\n",
      "\tif config != nil {\n",
      "\t\ta.config = *config\n",
      "\t} else {\n",
      "\t\ta.config = defaultAcmeConfig\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "func (c *KVMetadataDeleteCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /metadata/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func ValidateTLSALPN01Challenge(domain string, token string, thumbprint string, config *acmeConfigEntry) (bool, error) {\n",
      "\tcfg := &tls.Config{NextProtos: []string{ALPNProtocol}, ServerName: domain, VerifyConnection: func(connState tls.ConnectionState) error {\n",
      "\t\tif connState.DidResume {\n",
      "\t\t\treturn fmt.Errorf(\"server under test incorrectly reported that handshake was resumed when no session cache was provided; refusing to continue\")\n",
      "\t\t}\n",
      "\t\tif connState.NegotiatedProtocol != ALPNProtocol {\n",
      "\t\t\treturn fmt.Errorf(\"server under test negotiated unexpected ALPN protocol %v\", connState.NegotiatedProtocol)\n",
      "\t\t}\n",
      "\t\tif len(connState.PeerCertificates) > 1 {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned multiple (%v) certificates when we expected only one\", len(connState.PeerCertificates))\n",
      "\t\t}\n",
      "\t\tcert := connState.PeerCertificates[0]\n",
      "\t\terr := cert.CheckSignature(cert.SignatureAlgorithm, cert.RawTBSCertificate, cert.Signature)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a non-self-signed certificate: %w\", err)\n",
      "\t\t}\n",
      "\t\tif !bytes.Equal(cert.RawSubject, cert.RawIssuer) {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a non-self-signed certificate: invalid subject (%v) <-> issuer (%v) match\", cert.Subject.String(), cert.Issuer.String())\n",
      "\t\t}\n",
      "\t\tif len(cert.DNSNames) != 1 || len(cert.EmailAddresses) > 0 || len(cert.IPAddresses) > 0 || len(cert.URIs) > 0 {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a certificate with incorrect SANs\")\n",
      "\t\t}\n",
      "\t\tif !strings.EqualFold(cert.DNSNames[0], domain) {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a certificate with unexpected identifier: %v\", cert.DNSNames[0])\n",
      "\t\t}\n",
      "\t\tvar foundACMEId bool\n",
      "\t\tfor _, ext := range cert.Extensions {\n",
      "\t\t\tif !ext.Id.Equal(OIDACMEIdentifier) {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tif foundACMEId {\n",
      "\t\t\t\treturn fmt.Errorf(\"server under test returned a certificate with multiple acmeIdentifier extensions\")\n",
      "\t\t\t}\n",
      "\t\t\tfoundACMEId = true\n",
      "\t\t\tif !ext.Critical {\n",
      "\t\t\t\treturn fmt.Errorf(\"server under test returned a certificate with an acmeIdentifier extension marked non-Critical\")\n",
      "\t\t\t}\n",
      "\t\t\tvar keyAuthz []byte\n",
      "\t\t\tremainder, err := asn1.Unmarshal(ext.Value, &keyAuthz)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"server under test returned a certificate with invalid acmeIdentifier extension value: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tif len(remainder) > 0 {\n",
      "\t\t\t\treturn fmt.Errorf(\"server under test returned a certificate with invalid acmeIdentifier extension value with additional trailing data\")\n",
      "\t\t\t}\n",
      "\t\t\tok, err := ValidateRawSHA256KeyAuthorization(keyAuthz, token, thumbprint)\n",
      "\t\t\tif !ok || err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"server under test returned a certificate with an invalid key authorization (%w)\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !foundACMEId {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a certificate without the required acmeIdentifier extension\")\n",
      "\t\t}\n",
      "\t\tvar index int = -1\n",
      "\t\tfor oidIndex, oid := range cert.UnhandledCriticalExtensions {\n",
      "\t\t\tif oid.Equal(OIDACMEIdentifier) {\n",
      "\t\t\t\tindex = oidIndex\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif index != -1 {\n",
      "\t\t\tcert.UnhandledCriticalExtensions = append(cert.UnhandledCriticalExtensions[0:index], cert.UnhandledCriticalExtensions[index+1:]...)\n",
      "\t\t}\n",
      "\t\tif len(cert.UnhandledCriticalExtensions) > 0 {\n",
      "\t\t\treturn fmt.Errorf(\"server under test returned a certificate with additional unknown critical extensions (%v)\", cert.UnhandledCriticalExtensions)\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}, ClientSessionCache: nil, RootCAs: x509.NewCertPool(), InsecureSkipVerify: true, MinVersion: tls.VersionTLS12, CipherSuites: []uint16{tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305}}\n",
      "\tdialer, err := buildDialerConfig(config)\n",
      "\tif err != nil {\n",
      "\t\treturn false, fmt.Errorf(\"failed to build dialer: %w\", err)\n",
      "\t}\n",
      "\taddress := fmt.Sprintf(\"%v:\"+ALPNPort, domain)\n",
      "\tconn, err := dialer.Dial(\"tcp\", address)\n",
      "\tif err != nil {\n",
      "\t\treturn false, fmt.Errorf(\"tls-alpn-01: failed to dial host: %w\", err)\n",
      "\t}\n",
      "\tclient := tls.Client(conn, cfg)\n",
      "\tdefer client.Close()\n",
      "\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n",
      "\tdefer cancel()\n",
      "\tif err := client.HandshakeContext(ctx); err != nil {\n",
      "\t\treturn false, fmt.Errorf(\"tls-alpn-01: failed to perform handshake: %w\", err)\n",
      "\t}\n",
      "\treturn true, nil\n",
      "}\n",
      "func (c *NamespacePatchCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"custom-metadata\", Target: &c.flagCustomMetadata, Default: map[string]string{}, Usage: \"Specifies arbitrary key=value metadata meant to describe a namespace.\" + \"This can be specified multiple times to add multiple pieces of metadata.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"remove-custom-metadata\", Target: &c.flagRemoveCustomMetadata, Default: []string{}, Usage: \"Key to remove from custom metadata. To specify multiple values, specify this flag multiple times.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (b *databaseBackend) selectPluginVersion(ctx context.Context, config *DatabaseConfig, data *framework.FieldData, op logical.Operation) (string, *logical.Response, error) {\n",
      "\tpinnedVersion, err := b.getPinnedVersion(ctx, config.PluginName)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", nil, err\n",
      "\t}\n",
      "\tpluginVersionRaw, ok := data.GetOk(\"plugin_version\")\n",
      "\tswitch {\n",
      "\tcase ok && pinnedVersion != \"\":\n",
      "\t\treturn \"\", logical.ErrorResponse(\"cannot specify plugin_version for plugin %q as it is pinned (v%s)\", config.PluginName, pinnedVersion), nil\n",
      "\tcase pinnedVersion != \"\":\n",
      "\t\treturn pinnedVersion, nil, nil\n",
      "\tcase ok:\n",
      "\t\tconfig.PluginVersion = pluginVersionRaw.(string)\n",
      "\t}\n",
      "\tvar builtinShadowed bool\n",
      "\tif unversionedPlugin, err := b.System().LookupPlugin(ctx, config.PluginName, consts.PluginTypeDatabase); err == nil && !unversionedPlugin.Builtin {\n",
      "\t\tbuiltinShadowed = true\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase config.PluginVersion != \"\":\n",
      "\t\tsemanticVersion, err := version.NewVersion(config.PluginVersion)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn \"\", logical.ErrorResponse(\"version %q is not a valid semantic version: %s\", config.PluginVersion, err), nil\n",
      "\t\t}\n",
      "\t\tconfig.PluginVersion = \"v\" + semanticVersion.String()\n",
      "\t\tif config.PluginVersion == versions.GetBuiltinVersion(consts.PluginTypeDatabase, config.PluginName) {\n",
      "\t\t\tif builtinShadowed {\n",
      "\t\t\t\treturn \"\", logical.ErrorResponse(\"database plugin %q, version %s not found, as it is\"+\" overridden by an unversioned plugin of the same name. Omit `plugin_version` to use the unversioned plugin\", config.PluginName, config.PluginVersion), nil\n",
      "\t\t\t}\n",
      "\t\t\tconfig.PluginVersion = \"\"\n",
      "\t\t}\n",
      "\tcase builtinShadowed:\n",
      "\tcase op == logical.CreateOperation:\n",
      "\t\tplugins, err := b.System().ListVersionedPlugins(ctx, consts.PluginTypeDatabase)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn \"\", nil, err\n",
      "\t\t}\n",
      "\t\tvar versionedCandidates []pluginutil.VersionedPlugin\n",
      "\t\tfor _, plugin := range plugins {\n",
      "\t\t\tif !plugin.Builtin && plugin.Name == config.PluginName && plugin.Version != \"\" {\n",
      "\t\t\t\tversionedCandidates = append(versionedCandidates, plugin)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif len(versionedCandidates) != 0 {\n",
      "\t\t\tsort.SliceStable(versionedCandidates, func(i, j int) bool {\n",
      "\t\t\t\treturn versionedCandidates[i].SemanticVersion.GreaterThan(versionedCandidates[j].SemanticVersion)\n",
      "\t\t\t})\n",
      "\t\t\tconfig.PluginVersion = \"v\" + versionedCandidates[0].SemanticVersion.String()\n",
      "\t\t\tb.logger.Debug(fmt.Sprintf(\"pinning %q database plugin version %q from candidates %v\", config.PluginName, config.PluginVersion, versionedCandidates))\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn config.PluginVersion, nil, nil\n",
      "}\n",
      "func NewTokenStore(ctx context.Context, logger log.Logger, core *Core, config *logical.BackendConfig) (*TokenStore, error) {\n",
      "\tview := core.systemBarrierView.SubView(tokenSubPath)\n",
      "\tt := &TokenStore{activeContext: ctx, core: core, batchTokenEncryptor: core.barrier, baseBarrierView: view, idBarrierView: view.SubView(idPrefix), accessorBarrierView: view.SubView(accessorPrefix), parentBarrierView: view.SubView(parentPrefix), rolesBarrierView: view.SubView(rolesPrefix), cubbyholeDestroyer: destroyCubbyhole, logger: logger, tokenLocks: locksutil.CreateLocks(), tokensPendingDeletion: &sync.Map{}, saltLock: sync.RWMutex{}, tidyLock: new(uint32), quitContext: core.activeContext, salts: make(map[string]*salt.Salt)}\n",
      "\tt.Backend = &framework.Backend{AuthRenew: t.authRenew, PathsSpecial: &logical.Paths{Root: []string{\"revoke-orphan\", \"accessors/\"}, LocalStorage: []string{idPrefix, accessorPrefix, parentPrefix, salt.DefaultLocation}}, BackendType: logical.TypeCredential}\n",
      "\tt.Backend.Paths = append(t.Backend.Paths, t.paths()...)\n",
      "\tt.Backend.Setup(ctx, config)\n",
      "\tif err := t.loadSSCTokensGenerationCounter(ctx); err != nil {\n",
      "\t\treturn t, err\n",
      "\t}\n",
      "\treturn t, nil\n",
      "}\n",
      "func (b *backend) doTidyRevocationStore(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tb.GetRevokeStorageLock().Lock()\n",
      "\tdefer b.GetRevokeStorageLock().Unlock()\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tissuerIDCertMap, err := fetchIssuerMapForRevocationChecking(sc)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\trebuildCRL := false\n",
      "\trevokedSerials, err := req.Storage.List(ctx, \"revoked/\")\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error fetching list of revoked certs: %w\", err)\n",
      "\t}\n",
      "\trevokedSerialsCount := len(revokedSerials)\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"revoked_cert_total_entries\"}, float32(revokedSerialsCount))\n",
      "\tfixedIssuers := 0\n",
      "\tvar revInfo revocationInfo\n",
      "\tfor i, serial := range revokedSerials {\n",
      "\t\tb.tidyStatusMessage(fmt.Sprintf(\"Tidying revoked certificates: checking certificate %d of %d\", i, len(revokedSerials)))\n",
      "\t\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"revoked_cert_current_entry\"}, float32(i))\n",
      "\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\treturn tidyCancelledError\n",
      "\t\t}\n",
      "\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\tb.GetRevokeStorageLock().Unlock()\n",
      "\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t\tb.GetRevokeStorageLock().Lock()\n",
      "\t\t}\n",
      "\t\trevokedEntry, err := req.Storage.Get(ctx, \"revoked/\"+serial)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"unable to fetch revoked cert with serial %q: %w\", serial, err)\n",
      "\t\t}\n",
      "\t\tif revokedEntry == nil {\n",
      "\t\t\tlogger.Warn(\"revoked entry is nil; tidying up since it is no longer useful for any server operations\", \"serial\", serial)\n",
      "\t\t\tif err := req.Storage.Delete(ctx, \"revoked/\"+serial); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting nil revoked entry with serial %s: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncRevokedCertCount()\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif revokedEntry.Value == nil || len(revokedEntry.Value) == 0 {\n",
      "\t\t\tlogger.Warn(\"revoked entry has nil value; tidying up since it is no longer useful for any server operations\", \"serial\", serial)\n",
      "\t\t\tif err := req.Storage.Delete(ctx, \"revoked/\"+serial); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting revoked entry with nil value with serial %s: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncRevokedCertCount()\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\terr = revokedEntry.DecodeJSON(&revInfo)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"error decoding revocation entry for serial %q: %w\", serial, err)\n",
      "\t\t}\n",
      "\t\trevokedCert, err := x509.ParseCertificate(revInfo.CertificateBytes)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"unable to parse stored revoked certificate with serial %q: %w\", serial, err)\n",
      "\t\t}\n",
      "\t\tvar storeCert bool\n",
      "\t\tif config.IssuerAssocs {\n",
      "\t\t\tif !isRevInfoIssuerValid(&revInfo, issuerIDCertMap) {\n",
      "\t\t\t\tb.tidyStatusIncMissingIssuerCertCount()\n",
      "\t\t\t\trevInfo.CertificateIssuer = issuing.IssuerID(\"\")\n",
      "\t\t\t\tstoreCert = true\n",
      "\t\t\t\tif associateRevokedCertWithIsssuer(&revInfo, revokedCert, issuerIDCertMap) {\n",
      "\t\t\t\t\tfixedIssuers += 1\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif config.RevokedCerts {\n",
      "\t\t\tif time.Since(revokedCert.NotAfter) > config.SafetyBuffer {\n",
      "\t\t\t\tif err := req.Storage.Delete(ctx, \"revoked/\"+serial); err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"error deleting serial %q from revoked list: %w\", serial, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif err := req.Storage.Delete(ctx, \"certs/\"+serial); err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"error deleting serial %q from store when tidying revoked: %w\", serial, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\trebuildCRL = true\n",
      "\t\t\t\tstoreCert = false\n",
      "\t\t\t\tb.tidyStatusIncRevokedCertCount()\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif storeCert {\n",
      "\t\t\trevokedEntry, err = logical.StorageEntryJSON(\"revoked/\"+serial, revInfo)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error building entry to persist changes to serial %v from revoked list: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\terr = req.Storage.Put(ctx, revokedEntry)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error persisting changes to serial %v from revoked list: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tb.tidyStatusLock.RLock()\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"revoked_cert_total_entries_remaining\"}, float32(uint(revokedSerialsCount)-b.tidyStatus.revokedCertDeletedCount))\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"revoked_cert_entries_incorrect_issuers\"}, float32(b.tidyStatus.missingIssuerCertCount))\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"revoked_cert_entries_fixed_issuers\"}, float32(fixedIssuers))\n",
      "\tb.tidyStatusLock.RUnlock()\n",
      "\tif rebuildCRL {\n",
      "\t\tconfig, err := sc.getRevocationConfig()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif !config.AutoRebuild {\n",
      "\t\t\twarnings, err := b.CrlBuilder().rebuild(sc, false)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tif len(warnings) > 0 {\n",
      "\t\t\t\tmsg := \"During rebuild of CRL for tidy, got the following warnings:\"\n",
      "\t\t\t\tfor index, warning := range warnings {\n",
      "\t\t\t\t\tmsg = fmt.Sprintf(\"%v\\n %d. %v\", msg, index+1, warning)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tb.Logger().Warn(msg)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func writeRevocationDeltaWALs(sc *storageContext, config *crlConfig, resp *logical.Response, failedWritingUnifiedCRL bool, hyphenSerial string, colonSerial string) error {\n",
      "\tif err := writeSpecificRevocationDeltaWALs(sc, hyphenSerial, colonSerial, localDeltaWALPath); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to write local delta WAL entry: %w\", err)\n",
      "\t}\n",
      "\tif config.UnifiedCRL && !failedWritingUnifiedCRL {\n",
      "\t\tif ignoredErr := writeSpecificRevocationDeltaWALs(sc, hyphenSerial, colonSerial, unifiedDeltaWALPath); ignoredErr != nil {\n",
      "\t\t\tsc.Backend.Logger().Error(\"Failed to write cross-cluster delta WAL entry, will re-attempt later\", \"serial_number\", colonSerial, \"error\", ignoredErr)\n",
      "\t\t\tsc.Backend.GetUnifiedTransferStatus().forceRun()\n",
      "\t\t\tresp.AddWarning(fmt.Sprintf(\"Failed to write cross-cluster delta WAL entry, will re-attempt later: %v\", ignoredErr))\n",
      "\t\t}\n",
      "\t} else if failedWritingUnifiedCRL {\n",
      "\t\tresp.AddWarning(\"Skipping cross-cluster delta WAL entry as cross-cluster revocation failed to write; will re-attempt later.\")\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *SecretsTuneCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACRequestKeys, Target: &c.flagAuditNonHMACRequestKeys, Usage: \"Key that will not be HMAC'd by audit devices in the request data \" + \"object. To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAuditNonHMACResponseKeys, Target: &c.flagAuditNonHMACResponseKeys, Usage: \"Key that will not be HMAC'd by audit devices in the response data \" + \"object. To specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"default-lease-ttl\", Target: &c.flagDefaultLeaseTTL, Default: 0, EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"The default lease TTL for this secrets engine. If unspecified, \" + \"this defaults to the Vault server's globally configured default lease \" + \"TTL, or a previously configured value for the secrets engine.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameDescription, Target: &c.flagDescription, Usage: \"Human-friendly description of this secret engine. This overrides the \" + \"current stored value, if any.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameListingVisibility, Target: &c.flagListingVisibility, Usage: \"Determines the visibility of the mount in the UI-specific listing \" + \"endpoint.\"})\n",
      "\tf.DurationVar(&DurationVar{Name: \"max-lease-ttl\", Target: &c.flagMaxLeaseTTL, Default: 0, EnvVar: \"\", Completion: complete.PredictAnything, Usage: \"The maximum lease TTL for this secrets engine. If unspecified, \" + \"this defaults to the Vault server's globally configured maximum lease \" + \"TTL, or a previously configured value for the secrets engine.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNamePassthroughRequestHeaders, Target: &c.flagPassthroughRequestHeaders, Usage: \"Request header value that will be sent to the plugin. To specify \" + \"multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedResponseHeaders, Target: &c.flagAllowedResponseHeaders, Usage: \"Response header value that plugins will be allowed to set. To \" + \"specify multiple values, specify this flag multiple times.\"})\n",
      "\tf.StringMapVar(&StringMapVar{Name: \"options\", Target: &c.flagOptions, Completion: complete.PredictAnything, Usage: \"Key-value pair provided as key=value for the mount options. \" + \"This can be specified multiple times.\"})\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Default: 0, Usage: \"Select the version of the engine to run. Not supported by all engines.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameAllowedManagedKeys, Target: &c.flagAllowedManagedKeys, Usage: \"Managed key name(s) that the mount in question is allowed to access. \" + \"Note that multiple keys may be specified by providing this option multiple times, \" + \"each time with 1 key.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNamePluginVersion, Target: &c.flagPluginVersion, Default: \"\", Usage: \"Select the semantic version of the plugin to run. The new version must be registered in \" + \"the plugin catalog, and will not start running until the plugin is reloaded.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: flagNameDelegatedAuthAccessors, Target: &c.flagDelegatedAuthAccessors, Usage: \"A list of permitted authentication accessors this backend can delegate authentication to. \" + \"Note that multiple values may be specified by providing this option multiple times, \" + \"each time with 1 accessor.\"})\n",
      "\tf.StringVar(&StringVar{Name: flagNameIdentityTokenKey, Target: &c.flagIdentityTokenKey, Default: \"default\", Usage: \"Select the key used to sign plugin identity tokens.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (c *Core) InitializedLocally(ctx context.Context) (bool, error) {\n",
      "\tinit, err := c.barrier.Initialized(ctx)\n",
      "\tif err != nil {\n",
      "\t\tc.logger.Error(\"barrier init check failed\", \"error\", err)\n",
      "\t\treturn false, err\n",
      "\t}\n",
      "\tif !init {\n",
      "\t\tc.logger.Info(\"security barrier not initialized\")\n",
      "\t\treturn false, nil\n",
      "\t}\n",
      "\tsealConf, err := c.seal.BarrierConfig(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn false, err\n",
      "\t}\n",
      "\tif sealConf == nil {\n",
      "\t\treturn false, fmt.Errorf(\"core: barrier reports initialized but no seal configuration found\")\n",
      "\t}\n",
      "\treturn true, nil\n",
      "}\n",
      "func NewTokenFileAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &tokenFileMethod{logger: conf.Logger, mountPath: \"auth/token\"}\n",
      "\ttokenFilePathRaw, ok := conf.Config[\"token_file_path\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'token_file_path' value\")\n",
      "\t}\n",
      "\ta.tokenFilePath, ok = tokenFilePathRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'token_file_path' config value to string\")\n",
      "\t}\n",
      "\tif a.tokenFilePath == \"\" {\n",
      "\t\treturn nil, errors.New(\"'token_file_path' value is empty\")\n",
      "\t}\n",
      "\treturn a, nil\n",
      "}\n",
      "func (b *backend) getRootConfig(ctx context.Context, s logical.Storage, clientType string, logger hclog.Logger) (*aws.Config, error) {\n",
      "\tcredsConfig := &awsutil.CredentialsConfig{}\n",
      "\tvar endpoint string\n",
      "\tvar maxRetries int = aws.UseServiceDefaultRetries\n",
      "\tentry, err := s.Get(ctx, \"config/root\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif entry != nil {\n",
      "\t\tvar config rootConfig\n",
      "\t\tif err := entry.DecodeJSON(&config); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error reading root configuration: %w\", err)\n",
      "\t\t}\n",
      "\t\tcredsConfig.AccessKey = config.AccessKey\n",
      "\t\tcredsConfig.SecretKey = config.SecretKey\n",
      "\t\tcredsConfig.Region = config.Region\n",
      "\t\tmaxRetries = config.MaxRetries\n",
      "\t\tswitch {\n",
      "\t\tcase clientType == \"iam\" && config.IAMEndpoint != \"\":\n",
      "\t\t\tendpoint = *aws.String(config.IAMEndpoint)\n",
      "\t\tcase clientType == \"sts\" && config.STSEndpoint != \"\":\n",
      "\t\t\tendpoint = *aws.String(config.STSEndpoint)\n",
      "\t\t}\n",
      "\t\tif config.IdentityTokenAudience != \"\" {\n",
      "\t\t\tns, err := namespace.FromContext(ctx)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to get namespace from context: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tfetcher := &PluginIdentityTokenFetcher{sys: b.System(), logger: b.Logger(), ns: ns, audience: config.IdentityTokenAudience, ttl: config.IdentityTokenTTL}\n",
      "\t\t\tsessionSuffix := strconv.FormatInt(time.Now().UnixNano(), 10)\n",
      "\t\t\tcredsConfig.RoleSessionName = fmt.Sprintf(\"vault-aws-secrets-%s\", sessionSuffix)\n",
      "\t\t\tcredsConfig.WebIdentityTokenFetcher = fetcher\n",
      "\t\t\tcredsConfig.RoleARN = config.RoleARN\n",
      "\t\t}\n",
      "\t}\n",
      "\tif credsConfig.Region == \"\" {\n",
      "\t\tcredsConfig.Region = os.Getenv(\"AWS_REGION\")\n",
      "\t\tif credsConfig.Region == \"\" {\n",
      "\t\t\tcredsConfig.Region = os.Getenv(\"AWS_DEFAULT_REGION\")\n",
      "\t\t\tif credsConfig.Region == \"\" {\n",
      "\t\t\t\tcredsConfig.Region = \"us-east-1\"\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tcredsConfig.HTTPClient = cleanhttp.DefaultClient()\n",
      "\tcredsConfig.Logger = logger\n",
      "\tcreds, err := credsConfig.GenerateCredentialChain()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn &aws.Config{Credentials: creds, Region: aws.String(credsConfig.Region), Endpoint: &endpoint, HTTPClient: cleanhttp.DefaultClient(), MaxRetries: aws.Int(maxRetries)}, nil\n",
      "}\n",
      "func runListeners(c *ServerCommand, coreConfig *vault.CoreConfig, config *server.Config, configSR sr.ServiceRegistration) error {\n",
      "\tif sd := coreConfig.GetServiceRegistration(); sd != nil {\n",
      "\t\tif err := configSR.Run(c.ShutdownCh, c.WaitGroup, coreConfig.RedirectAddr); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"Error running service_registration of type %s: %s\", config.ServiceRegistration.Type, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func AddPersistentStorageToLeaseCache(ctx context.Context, leaseCache *cache.LeaseCache, persistConfig *PersistConfig, logger log.Logger) (func() error, string, error) {\n",
      "\tif persistConfig == nil {\n",
      "\t\treturn nil, \"\", errors.New(\"persist config was nil\")\n",
      "\t}\n",
      "\tif persistConfig.Path == \"\" {\n",
      "\t\treturn nil, \"\", errors.New(\"must specify persistent cache path\")\n",
      "\t}\n",
      "\tvar aad string\n",
      "\tvar err error\n",
      "\tswitch persistConfig.Type {\n",
      "\tcase \"kubernetes\":\n",
      "\t\taad, err = getServiceAccountJWT(persistConfig.ServiceAccountTokenFile)\n",
      "\t\tif err != nil {\n",
      "\t\t\ttokenFileName := persistConfig.ServiceAccountTokenFile\n",
      "\t\t\tif len(tokenFileName) == 0 {\n",
      "\t\t\t\ttokenFileName = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n",
      "\t\t\t}\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"failed to read service account token from %s: %w\", tokenFileName, err)\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\treturn nil, \"\", fmt.Errorf(\"persistent key protection type %q not supported\", persistConfig.Type)\n",
      "\t}\n",
      "\tdbFileExists, err := cacheboltdb.DBFileExists(persistConfig.Path)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, \"\", fmt.Errorf(\"failed to check if bolt file exists at path %s: %w\", persistConfig.Path, err)\n",
      "\t}\n",
      "\tif dbFileExists {\n",
      "\t\tps, err := cacheboltdb.NewBoltStorage(&cacheboltdb.BoltStorageConfig{Path: persistConfig.Path, Logger: logger.Named(\"cacheboltdb\")})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error opening persistent cache %v\", err)\n",
      "\t\t}\n",
      "\t\ttoken, err := ps.GetRetrievalToken()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error getting retrieval token from persistent cache: %w\", err)\n",
      "\t\t}\n",
      "\t\tif err := ps.Close(); err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"failed to close persistent cache file after getting retrieval token: %w\", err)\n",
      "\t\t}\n",
      "\t\tkm, err := keymanager.NewPassthroughKeyManager(ctx, token)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"failed to configure persistence encryption for cache: %w\", err)\n",
      "\t\t}\n",
      "\t\tps, err = cacheboltdb.NewBoltStorage(&cacheboltdb.BoltStorageConfig{Path: persistConfig.Path, Logger: logger.Named(\"cacheboltdb\"), Wrapper: km.Wrapper(), AAD: aad})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error opening persistent cache with wrapper: %w\", err)\n",
      "\t\t}\n",
      "\t\tif err := leaseCache.Restore(ctx, ps); err != nil {\n",
      "\t\t\tlogger.Error(fmt.Sprintf(\"error restoring in-memory cache from persisted file: %v\", err))\n",
      "\t\t\tif persistConfig.ExitOnErr {\n",
      "\t\t\t\treturn nil, \"\", fmt.Errorf(\"exiting with error as exit_on_err is set to true\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tlogger.Info(\"loaded memcache from persistent storage\")\n",
      "\t\toldTokenBytes, err := ps.GetAutoAuthToken(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlogger.Error(fmt.Sprintf(\"error in fetching previous auto-auth token: %v\", err))\n",
      "\t\t\tif persistConfig.ExitOnErr {\n",
      "\t\t\t\treturn nil, \"\", fmt.Errorf(\"exiting with error as exit_on_err is set to true\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tvar previousToken string\n",
      "\t\tif len(oldTokenBytes) > 0 {\n",
      "\t\t\toldToken, err := cachememdb.Deserialize(oldTokenBytes)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlogger.Error(fmt.Sprintf(\"error in deserializing previous auto-auth token cache entryn: %v\", err))\n",
      "\t\t\t\tif persistConfig.ExitOnErr {\n",
      "\t\t\t\t\treturn nil, \"\", fmt.Errorf(\"exiting with error as exit_on_err is set to true\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tpreviousToken = oldToken.Token\n",
      "\t\t}\n",
      "\t\tif persistConfig.KeepAfterImport {\n",
      "\t\t\tleaseCache.SetPersistentStorage(ps)\n",
      "\t\t\treturn ps.Close, previousToken, nil\n",
      "\t\t} else {\n",
      "\t\t\tif err := ps.Close(); err != nil {\n",
      "\t\t\t\tlogger.Warn(fmt.Sprintf(\"failed to close persistent cache file: %s\", err))\n",
      "\t\t\t}\n",
      "\t\t\tdbFile := filepath.Join(persistConfig.Path, cacheboltdb.DatabaseFileName)\n",
      "\t\t\tif err := os.Remove(dbFile); err != nil {\n",
      "\t\t\t\tlogger.Error(fmt.Sprintf(\"failed to remove persistent storage file %s: %v\", dbFile, err))\n",
      "\t\t\t\tif persistConfig.ExitOnErr {\n",
      "\t\t\t\t\treturn nil, \"\", fmt.Errorf(\"exiting with error as exit_on_err is set to true\")\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\treturn nil, previousToken, nil\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tkm, err := keymanager.NewPassthroughKeyManager(ctx, nil)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"failed to configure persistence encryption for cache: %w\", err)\n",
      "\t\t}\n",
      "\t\tps, err := cacheboltdb.NewBoltStorage(&cacheboltdb.BoltStorageConfig{Path: persistConfig.Path, Logger: logger.Named(\"cacheboltdb\"), Wrapper: km.Wrapper(), AAD: aad})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error creating persistent cache: %w\", err)\n",
      "\t\t}\n",
      "\t\tlogger.Info(\"configured persistent storage\", \"path\", persistConfig.Path)\n",
      "\t\ttoken, err := km.RetrievalToken(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error getting persistence key: %w\", err)\n",
      "\t\t}\n",
      "\t\tif err := ps.StoreRetrievalToken(token); err != nil {\n",
      "\t\t\treturn nil, \"\", fmt.Errorf(\"error setting key in persistent cache: %w\", err)\n",
      "\t\t}\n",
      "\t\tleaseCache.SetPersistentStorage(ps)\n",
      "\t\treturn ps.Close, \"\", nil\n",
      "\t}\n",
      "}\n",
      "func (f *FSM) Restore(r io.ReadCloser) error {\n",
      "\tdefer metrics.MeasureSince([]string{\"raft_storage\", \"fsm\", \"restore_snapshot\"}, time.Now())\n",
      "\tif f.noopRestore {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tsnapshotInstaller, ok := r.(*boltSnapshotInstaller)\n",
      "\tif !ok {\n",
      "\t\twrapper, ok := r.(raft.ReadCloserWrapper)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn fmt.Errorf(\"expected ReadCloserWrapper object, got: %T\", r)\n",
      "\t\t}\n",
      "\t\tsnapshotInstallerRaw := wrapper.WrappedReadCloser()\n",
      "\t\tsnapshotInstaller, ok = snapshotInstallerRaw.(*boltSnapshotInstaller)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn fmt.Errorf(\"expected snapshot installer object, got: %T\", snapshotInstallerRaw)\n",
      "\t\t}\n",
      "\t}\n",
      "\tf.l.Lock()\n",
      "\tdefer f.l.Unlock()\n",
      "\tlnConfig, err := f.localNodeConfig()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := f.db.Close(); err != nil {\n",
      "\t\tf.logger.Error(\"failed to close database file\", \"error\", err)\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tdbPath := filepath.Join(f.path, databaseFilename)\n",
      "\tf.logger.Info(\"installing snapshot to FSM\")\n",
      "\tvar retErr *multierror.Error\n",
      "\tif err := snapshotInstaller.Install(dbPath); err != nil {\n",
      "\t\tf.logger.Error(\"failed to install snapshot\", \"error\", err)\n",
      "\t\tretErr = multierror.Append(retErr, fmt.Errorf(\"failed to install snapshot database: %w\", err))\n",
      "\t} else {\n",
      "\t\tf.logger.Info(\"snapshot installed\")\n",
      "\t}\n",
      "\tif err := f.openDBFile(dbPath); err != nil {\n",
      "\t\tf.logger.Error(\"failed to open new database file\", \"error\", err)\n",
      "\t\tretErr = multierror.Append(retErr, fmt.Errorf(\"failed to open new bolt file: %w\", err))\n",
      "\t}\n",
      "\tif lnConfig != nil {\n",
      "\t\tif err := f.persistDesiredSuffrage(lnConfig); err != nil {\n",
      "\t\t\tf.logger.Error(\"failed to persist local node config from before the restore\", \"error\", err)\n",
      "\t\t\tretErr = multierror.Append(retErr, fmt.Errorf(\"failed to persist local node config from before the restore: %w\", err))\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn retErr.ErrorOrNil()\n",
      "}\n",
      "func (ace *ACMEChallengeEngine) _verifyChallenge(sc *storageContext, id string, config *acmeConfigEntry) (bool, time.Time, error) {\n",
      "\tnow := time.Now()\n",
      "\tbackoffTime := now.Add(1 * time.Second)\n",
      "\tpath := acmeValidationPrefix + id\n",
      "\tchallengeEntry, err := sc.Storage.Get(sc.Context, path)\n",
      "\tif err != nil {\n",
      "\t\treturn true, backoffTime, fmt.Errorf(\"error loading challenge %v: %w\", id, err)\n",
      "\t}\n",
      "\tif challengeEntry == nil {\n",
      "\t\treturn ace._verifyChallengeCleanup(sc, nil, id)\n",
      "\t}\n",
      "\tvar cv *ChallengeValidation\n",
      "\tif err := challengeEntry.DecodeJSON(&cv); err != nil {\n",
      "\t\treturn true, backoffTime, fmt.Errorf(\"error decoding challenge %v: %w\", id, err)\n",
      "\t}\n",
      "\tif now.Before(cv.RetryAfter) {\n",
      "\t\treturn true, cv.RetryAfter, fmt.Errorf(\"retrying challenge %v too soon\", id)\n",
      "\t}\n",
      "\tauthzPath := getAuthorizationPath(cv.Account, cv.Authorization)\n",
      "\tauthz, err := loadAuthorizationAtPath(sc, authzPath)\n",
      "\tif err != nil {\n",
      "\t\treturn true, backoffTime, fmt.Errorf(\"error loading authorization %v/%v for challenge %v: %w\", cv.Account, cv.Authorization, id, err)\n",
      "\t}\n",
      "\tif authz.Status != ACMEAuthorizationPending {\n",
      "\t\terr = nil\n",
      "\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t}\n",
      "\tvar challenge *ACMEChallenge\n",
      "\tfor _, authzChallenge := range authz.Challenges {\n",
      "\t\tif authzChallenge.Type == cv.ChallengeType {\n",
      "\t\t\tchallenge = authzChallenge\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t}\n",
      "\tif challenge == nil {\n",
      "\t\terr = fmt.Errorf(\"no challenge of type %v in authorization %v/%v for challenge %v\", cv.ChallengeType, cv.Account, cv.Authorization, id)\n",
      "\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t}\n",
      "\tif challenge.Status != ACMEChallengePending && challenge.Status != ACMEChallengeProcessing {\n",
      "\t\terr = fmt.Errorf(\"challenge is in invalid state %v in authorization %v/%v for challenge %v\", challenge.Status, cv.Account, cv.Authorization, id)\n",
      "\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t}\n",
      "\tvar valid bool\n",
      "\tswitch challenge.Type {\n",
      "\tcase ACMEHTTPChallenge:\n",
      "\t\tif authz.Identifier.Type != ACMEDNSIdentifier && authz.Identifier.Type != ACMEIPIdentifier {\n",
      "\t\t\terr = fmt.Errorf(\"unsupported identifier type for authorization %v/%v in challenge %v: %v\", cv.Account, cv.Authorization, id, authz.Identifier.Type)\n",
      "\t\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t\t}\n",
      "\t\tif authz.Wildcard {\n",
      "\t\t\terr = fmt.Errorf(\"unable to validate wildcard authorization %v/%v in challenge %v via http-01 challenge\", cv.Account, cv.Authorization, id)\n",
      "\t\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t\t}\n",
      "\t\tvalid, err = ValidateHTTP01Challenge(authz.Identifier.Value, cv.Token, cv.Thumbprint, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\terr = fmt.Errorf(\"%w: error validating http-01 challenge %v: %v; %v\", ErrIncorrectResponse, id, err, ChallengeAttemptFailedMsg)\n",
      "\t\t\treturn ace._verifyChallengeRetry(sc, cv, authzPath, authz, challenge, err, id)\n",
      "\t\t}\n",
      "\tcase ACMEDNSChallenge:\n",
      "\t\tif authz.Identifier.Type != ACMEDNSIdentifier {\n",
      "\t\t\terr = fmt.Errorf(\"unsupported identifier type for authorization %v/%v in challenge %v: %v\", cv.Account, cv.Authorization, id, authz.Identifier.Type)\n",
      "\t\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t\t}\n",
      "\t\tvalid, err = ValidateDNS01Challenge(authz.Identifier.Value, cv.Token, cv.Thumbprint, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\terr = fmt.Errorf(\"%w: error validating dns-01 challenge %v: %v; %v\", ErrIncorrectResponse, id, err, ChallengeAttemptFailedMsg)\n",
      "\t\t\treturn ace._verifyChallengeRetry(sc, cv, authzPath, authz, challenge, err, id)\n",
      "\t\t}\n",
      "\tcase ACMEALPNChallenge:\n",
      "\t\tif authz.Identifier.Type != ACMEDNSIdentifier {\n",
      "\t\t\terr = fmt.Errorf(\"unsupported identifier type for authorization %v/%v in challenge %v: %v\", cv.Account, cv.Authorization, id, authz.Identifier.Type)\n",
      "\t\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t\t}\n",
      "\t\tif authz.Wildcard {\n",
      "\t\t\terr = fmt.Errorf(\"unable to validate wildcard authorization %v/%v in challenge %v via tls-alpn-01 challenge\", cv.Account, cv.Authorization, id)\n",
      "\t\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t\t}\n",
      "\t\tvalid, err = ValidateTLSALPN01Challenge(authz.Identifier.Value, cv.Token, cv.Thumbprint, config)\n",
      "\t\tif err != nil {\n",
      "\t\t\terr = fmt.Errorf(\"%w: error validating tls-alpn-01 challenge %v: %s\", ErrIncorrectResponse, id, err.Error())\n",
      "\t\t\treturn ace._verifyChallengeRetry(sc, cv, authzPath, authz, challenge, err, id)\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\terr = fmt.Errorf(\"unsupported ACME challenge type %v for challenge %v\", cv.ChallengeType, id)\n",
      "\t\treturn ace._verifyChallengeCleanup(sc, err, id)\n",
      "\t}\n",
      "\tif !valid {\n",
      "\t\terr = fmt.Errorf(\"%w: challenge failed with no additional information\", ErrIncorrectResponse)\n",
      "\t\treturn ace._verifyChallengeRetry(sc, cv, authzPath, authz, challenge, err, id)\n",
      "\t}\n",
      "\texpires := now.Add(15 * 24 * time.Hour)\n",
      "\tchallenge.Status = ACMEChallengeValid\n",
      "\tchallenge.Validated = now.Format(time.RFC3339)\n",
      "\tchallenge.Error = nil\n",
      "\tauthz.Status = ACMEAuthorizationValid\n",
      "\tauthz.Expires = expires.Format(time.RFC3339)\n",
      "\tif err := saveAuthorizationAtPath(sc, authzPath, authz); err != nil {\n",
      "\t\terr = fmt.Errorf(\"error saving updated (validated) authorization %v/%v for challenge %v: %w\", cv.Account, cv.Authorization, id, err)\n",
      "\t\treturn ace._verifyChallengeRetry(sc, cv, authzPath, authz, challenge, err, id)\n",
      "\t}\n",
      "\treturn ace._verifyChallengeCleanup(sc, nil, id)\n",
      "}\n",
      "func (c *OperatorRaftJoinCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"auto-join-scheme\", Target: &c.flagAutoJoinScheme, Completion: complete.PredictNothing, Default: \"https\", Usage: \"An optional URI protocol scheme used for addresses discovered via auto-join.\"})\n",
      "\tf.UintVar(&UintVar{Name: \"auto-join-port\", Target: &c.flagAutoJoinPort, Completion: complete.PredictNothing, Default: 8200, Usage: \"An optional port used for addresses discovered via auto-join.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"leader-ca-cert\", Target: &c.flagLeaderCACert, Completion: complete.PredictNothing, Usage: \"CA cert to use when verifying the Raft leader certificate.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"leader-client-cert\", Target: &c.flagLeaderClientCert, Completion: complete.PredictNothing, Usage: \"Client cert to use when authenticating with the Raft leader.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"leader-client-key\", Target: &c.flagLeaderClientKey, Completion: complete.PredictNothing, Usage: \"Client key to use when authenticating with the Raft leader.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"retry\", Target: &c.flagRetry, Default: false, Usage: \"Continuously retry joining the Raft cluster upon failures.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"non-voter\", Target: &c.flagNonVoter, Default: false, Usage: \"(Enterprise-only) This flag is used to make the server not participate in the Raft quorum, and have it only receive the data replication stream. This can be used to add read scalability to a cluster in cases where a high volume of reads to servers are needed.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (b *backend) pathConfigRotateRootUpdate(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tb.configMutex.Lock()\n",
      "\tdefer b.configMutex.Unlock()\n",
      "\tclientConf, err := b.nonLockedClientConfigEntry(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif clientConf == nil {\n",
      "\t\treturn logical.ErrorResponse(`can't update client config because it's unset`), nil\n",
      "\t}\n",
      "\tif clientConf.AccessKey == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"can't update access_key because it's unset\"), nil\n",
      "\t}\n",
      "\tif clientConf.SecretKey == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"can't update secret_key because it's unset\"), nil\n",
      "\t}\n",
      "\tstaticCreds := &credentials.StaticProvider{Value: credentials.Value{AccessKeyID: clientConf.AccessKey, SecretAccessKey: clientConf.SecretKey}}\n",
      "\tvar iamEndpoint *string\n",
      "\tif clientConf.IAMEndpoint != \"\" {\n",
      "\t\tiamEndpoint = aws.String(clientConf.IAMEndpoint)\n",
      "\t}\n",
      "\tregion, err := awsutil.GetRegion(\"\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error retrieving region: %w\", err)\n",
      "\t}\n",
      "\tawsConfig := &aws.Config{Credentials: credentials.NewCredentials(staticCreds), Endpoint: iamEndpoint, Region: aws.String(region), HTTPClient: cleanhttp.DefaultClient()}\n",
      "\tsess, err := session.NewSession(awsConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tiamClient := getIAMClient(sess)\n",
      "\tvar getUserInput iam.GetUserInput\n",
      "\tgetUserRes, err := iamClient.GetUserWithContext(ctx, &getUserInput)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error calling GetUser: %w\", err)\n",
      "\t}\n",
      "\tif getUserRes == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil response from GetUser\")\n",
      "\t}\n",
      "\tif getUserRes.User == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil user returned from GetUser\")\n",
      "\t}\n",
      "\tif getUserRes.User.UserName == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil UserName returned from GetUser\")\n",
      "\t}\n",
      "\tcreateAccessKeyInput := iam.CreateAccessKeyInput{UserName: getUserRes.User.UserName}\n",
      "\tcreateAccessKeyRes, err := iamClient.CreateAccessKeyWithContext(ctx, &createAccessKeyInput)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error calling CreateAccessKey: %w\", err)\n",
      "\t}\n",
      "\tif createAccessKeyRes.AccessKey == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil response from CreateAccessKey\")\n",
      "\t}\n",
      "\tif createAccessKeyRes.AccessKey.AccessKeyId == nil || createAccessKeyRes.AccessKey.SecretAccessKey == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil AccessKeyId or SecretAccessKey returned from CreateAccessKey\")\n",
      "\t}\n",
      "\tstoredNewConf := false\n",
      "\tvar errs error\n",
      "\tdefer func() {\n",
      "\t\tif storedNewConf {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tdeleteAccessKeyInput := iam.DeleteAccessKeyInput{AccessKeyId: createAccessKeyRes.AccessKey.AccessKeyId, UserName: getUserRes.User.UserName}\n",
      "\t\tif _, err := iamClient.DeleteAccessKeyWithContext(ctx, &deleteAccessKeyInput); err != nil {\n",
      "\t\t\terrs = multierror.Append(errs, fmt.Errorf(\"error deleting newly created but unstored access key ID %s: %s\", *createAccessKeyRes.AccessKey.AccessKeyId, err))\n",
      "\t\t}\n",
      "\t}()\n",
      "\toldAccessKey := clientConf.AccessKey\n",
      "\tclientConf.AccessKey = *createAccessKeyRes.AccessKey.AccessKeyId\n",
      "\tclientConf.SecretKey = *createAccessKeyRes.AccessKey.SecretAccessKey\n",
      "\tnewEntry, err := b.configClientToEntry(clientConf)\n",
      "\tif err != nil {\n",
      "\t\terrs = multierror.Append(errs, fmt.Errorf(\"error generating new client config JSON: %w\", err))\n",
      "\t\treturn nil, errs\n",
      "\t}\n",
      "\tif err := req.Storage.Put(ctx, newEntry); err != nil {\n",
      "\t\terrs = multierror.Append(errs, fmt.Errorf(\"error saving new client config: %w\", err))\n",
      "\t\treturn nil, errs\n",
      "\t}\n",
      "\tstoredNewConf = true\n",
      "\tb.IAMClientsMap = make(map[string]map[string]*iam.IAM)\n",
      "\tb.EC2ClientsMap = make(map[string]map[string]*ec2.EC2)\n",
      "\tdeleteAccessKeyInput := iam.DeleteAccessKeyInput{AccessKeyId: aws.String(oldAccessKey), UserName: getUserRes.User.UserName}\n",
      "\tif _, err = iamClient.DeleteAccessKeyWithContext(ctx, &deleteAccessKeyInput); err != nil {\n",
      "\t\terrs = multierror.Append(errs, fmt.Errorf(\"error deleting old access key ID %s: %w\", oldAccessKey, err))\n",
      "\t\treturn nil, errs\n",
      "\t}\n",
      "\treturn &logical.Response{Data: map[string]interface{}{\"access_key\": clientConf.AccessKey}}, nil\n",
      "}\n",
      "func (i *IdentityStore) handleLoginMFAGenerateCommon(ctx context.Context, req *logical.Request, methodID, entityID string) (*logical.Response, error) {\n",
      "\tif methodID == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing method ID\"), nil\n",
      "\t}\n",
      "\tif entityID == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing entityID\"), nil\n",
      "\t}\n",
      "\tmConfig, err := i.mfaBackend.MemDBMFAConfigByID(methodID)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif mConfig == nil {\n",
      "\t\treturn logical.ErrorResponse(fmt.Sprintf(\"configuration for method ID %q does not exist\", methodID)), nil\n",
      "\t}\n",
      "\tif mConfig.ID == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"configuration for method ID %q does not contain an identifier\", methodID)\n",
      "\t}\n",
      "\tentity, err := i.MemDBEntityByID(entityID, true)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to find entity with ID %q: error: %w\", entityID, err)\n",
      "\t}\n",
      "\tif entity == nil {\n",
      "\t\treturn logical.ErrorResponse(\"invalid entity ID\"), nil\n",
      "\t}\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn logical.ErrorResponse(\"failed to retrieve the namespace\"), nil\n",
      "\t}\n",
      "\tif ns.ID != entity.NamespaceID {\n",
      "\t\treturn logical.ErrorResponse(\"entity namespace ID does not match the current namespace ID\"), nil\n",
      "\t}\n",
      "\tentityNS, err := i.namespacer.NamespaceByID(ctx, entity.NamespaceID)\n",
      "\tif err != nil {\n",
      "\t\treturn logical.ErrorResponse(\"entity namespace not found\"), nil\n",
      "\t}\n",
      "\tconfigNS, err := i.namespacer.NamespaceByID(ctx, mConfig.NamespaceID)\n",
      "\tif err != nil {\n",
      "\t\treturn logical.ErrorResponse(\"methodID namespace not found\"), nil\n",
      "\t}\n",
      "\tif configNS.ID != entityNS.ID && !entityNS.HasParent(configNS) {\n",
      "\t\treturn logical.ErrorResponse(fmt.Sprintf(\"entity namespace %s outside of the config namespace %s\", entityNS.Path, configNS.Path)), nil\n",
      "\t}\n",
      "\tswitch mConfig.Type {\n",
      "\tcase mfaMethodTypeTOTP:\n",
      "\t\treturn i.mfaBackend.handleMFAGenerateTOTP(ctx, mConfig, entityID)\n",
      "\tdefault:\n",
      "\t\treturn logical.ErrorResponse(fmt.Sprintf(\"generate not available for MFA type %q\", mConfig.Type)), nil\n",
      "\t}\n",
      "}\n",
      "func (b *SystemBackend) handleStorageRaftAutopilotConfigRead() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\t\traftBackend := b.Core.getRaftBackend()\n",
      "\t\tif raftBackend == nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"raft storage is not in use\"), logical.ErrInvalidRequest\n",
      "\t\t}\n",
      "\t\tconfig := raftBackend.AutopilotConfig()\n",
      "\t\tif config == nil {\n",
      "\t\t\treturn nil, nil\n",
      "\t\t}\n",
      "\t\treturn &logical.Response{Data: map[string]interface{}{\"cleanup_dead_servers\": config.CleanupDeadServers, \"last_contact_threshold\": config.LastContactThreshold.String(), \"dead_server_last_contact_threshold\": config.DeadServerLastContactThreshold.String(), \"max_trailing_logs\": config.MaxTrailingLogs, \"min_quorum\": config.MinQuorum, \"server_stabilization_time\": config.ServerStabilizationTime.String(), \"disable_upgrade_migration\": config.DisableUpgradeMigration}}, nil\n",
      "\t}\n",
      "}\n",
      "func pathRoles(b *backend) *framework.Path {\n",
      "\treturn &framework.Path{Pattern: \"roles/\" + framework.GenericNameWithAtRegex(\"name\"), DisplayAttrs: &framework.DisplayAttributes{OperationPrefix: operationPrefixAWS, OperationSuffix: \"role\"}, Fields: map[string]*framework.FieldSchema{\"name\": {Type: framework.TypeString, Description: \"Name of the role\", DisplayAttrs: &framework.DisplayAttributes{Name: \"Role Name\"}}, \"credential_type\": {Type: framework.TypeString, Description: fmt.Sprintf(\"Type of credential to retrieve. Must be one of %s, %s, %s, or %s\", assumedRoleCred, iamUserCred, federationTokenCred, sessionTokenCred)}, \"role_arns\": {Type: framework.TypeCommaStringSlice, Description: \"ARNs of AWS roles allowed to be assumed. Only valid when credential_type is \" + assumedRoleCred, DisplayAttrs: &framework.DisplayAttributes{Name: \"Role ARNs\"}}, \"policy_arns\": {Type: framework.TypeCommaStringSlice, Description: fmt.Sprintf(`ARNs of AWS policies. Behavior varies by credential_type. When credential_type is\n",
      "%s, then it will attach the specified policies to the generated IAM user.\n",
      "When credential_type is %s or %s, the policies will be passed as the\n",
      "PolicyArns parameter, acting as a filter on permissions available.`, iamUserCred, assumedRoleCred, federationTokenCred), DisplayAttrs: &framework.DisplayAttributes{Name: \"Policy ARNs\"}}, \"policy_document\": {Type: framework.TypeString, Description: `JSON-encoded IAM policy document. Behavior varies by credential_type. When credential_type is\n",
      "iam_user, then it will attach the contents of the policy_document to the IAM\n",
      "user generated. When credential_type is assumed_role or federation_token, this\n",
      "will be passed in as the Policy parameter to the AssumeRole or\n",
      "GetFederationToken API call, acting as a filter on permissions available.`}, \"iam_groups\": {Type: framework.TypeCommaStringSlice, Description: `Names of IAM groups that generated IAM users will be added to. For a credential\n",
      "type of assumed_role or federation_token, the policies sent to the\n",
      "corresponding AWS call (sts:AssumeRole or sts:GetFederation) will be the\n",
      "policies from each group in iam_groups combined with the policy_document\n",
      "and policy_arns parameters.`, DisplayAttrs: &framework.DisplayAttributes{Name: \"IAM Groups\", Value: \"group1,group2\"}}, \"iam_tags\": {Type: framework.TypeKVPairs, Description: `IAM tags to be set for any users created by this role. These must be presented\n",
      "as Key-Value pairs. This can be represented as a map or a list of equal sign\n",
      "delimited key pairs.`, DisplayAttrs: &framework.DisplayAttributes{Name: \"IAM Tags\", Value: \"[key1=value1, key2=value2]\"}}, \"default_sts_ttl\": {Type: framework.TypeDurationSecond, Description: fmt.Sprintf(\"Default TTL for %s, %s, and %s credential types when no TTL is explicitly requested with the credentials\", assumedRoleCred, federationTokenCred, sessionTokenCred), DisplayAttrs: &framework.DisplayAttributes{Name: \"Default STS TTL\"}}, \"max_sts_ttl\": {Type: framework.TypeDurationSecond, Description: fmt.Sprintf(\"Max allowed TTL for %s, %s, and %s credential types\", assumedRoleCred, federationTokenCred, sessionTokenCred), DisplayAttrs: &framework.DisplayAttributes{Name: \"Max STS TTL\"}}, \"permissions_boundary_arn\": {Type: framework.TypeString, Description: \"ARN of an IAM policy to attach as a permissions boundary on IAM user credentials; only valid when credential_type is\" + iamUserCred, DisplayAttrs: &framework.DisplayAttributes{Name: \"Permissions Boundary ARN\"}}, \"arn\": {Type: framework.TypeString, Description: `Use role_arns or policy_arns instead.`, Deprecated: true}, \"policy\": {Type: framework.TypeString, Description: \"Use policy_document instead.\", Deprecated: true}, \"user_path\": {Type: framework.TypeString, Description: \"Path for IAM User. Only valid when credential_type is \" + iamUserCred, DisplayAttrs: &framework.DisplayAttributes{Name: \"User Path\", Value: \"/\"}, Default: \"/\"}, \"mfa_serial_number\": {Type: framework.TypeString, Description: fmt.Sprintf(`Identification number or ARN of the MFA device associated with the root config user. Only valid\n",
      "when credential_type is %s. This is only required when the IAM user has an MFA device configured.`, sessionTokenCred), DisplayAttrs: &framework.DisplayAttributes{Name: \"MFA Device Serial Number\"}}}, Callbacks: map[logical.Operation]framework.OperationFunc{logical.DeleteOperation: b.pathRolesDelete, logical.ReadOperation: b.pathRolesRead, logical.UpdateOperation: b.pathRolesWrite}, HelpSynopsis: pathRolesHelpSyn, HelpDescription: pathRolesHelpDesc}\n",
      "}\n",
      "func (c *Core) migrateSealConfig(ctx context.Context) error {\n",
      "\texistBarrierSealConfig, existRecoverySealConfig, err := c.PhysicalSealConfigs(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to read existing seal configuration during migration: %v\", err)\n",
      "\t}\n",
      "\tvar bc, rc *SealConfig\n",
      "\tswitch {\n",
      "\tcase c.migrationInfo.seal.RecoveryKeySupported() && c.seal.RecoveryKeySupported():\n",
      "\t\tbc, rc = existBarrierSealConfig, existRecoverySealConfig\n",
      "\tcase c.migrationInfo.seal.RecoveryKeySupported():\n",
      "\t\tbc = existRecoverySealConfig.Clone()\n",
      "\t\tbc.StoredShares = 1\n",
      "\tcase c.seal.RecoveryKeySupported():\n",
      "\t\tbc = &SealConfig{Type: c.seal.BarrierSealConfigType().String(), SecretShares: 1, SecretThreshold: 1, StoredShares: 1}\n",
      "\t\trc = existBarrierSealConfig.Clone()\n",
      "\t\trc.StoredShares = 0\n",
      "\t}\n",
      "\tif err := c.seal.SetBarrierConfig(ctx, bc); err != nil {\n",
      "\t\treturn fmt.Errorf(\"error storing barrier config after migration: %w\", err)\n",
      "\t}\n",
      "\tif c.seal.RecoveryKeySupported() {\n",
      "\t\tif err := c.seal.SetRecoveryConfig(ctx, rc); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"error storing recovery config after migration: %w\", err)\n",
      "\t\t}\n",
      "\t} else if err := c.physical.Delete(ctx, recoverySealConfigPlaintextPath); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to delete old recovery seal configuration during migration: %w\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *KVRollbackCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"version\", Target: &c.flagVersion, Usage: `Specifies the version number that should be made current again.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /data/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBMFAConfigByIDInTxn(txn *memdb.Txn, mConfigID string) (*mfa.Config, error) {\n",
      "\tif mConfigID == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing config id\")\n",
      "\t}\n",
      "\tif txn == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"txn is nil\")\n",
      "\t}\n",
      "\tmConfigRaw, err := txn.First(b.methodTable, \"id\", mConfigID)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errwrap.Wrapf(\"failed to fetch MFA config from memdb using id: {{err}}\", err)\n",
      "\t}\n",
      "\tif mConfigRaw == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tmConfig, ok := mConfigRaw.(*mfa.Config)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to declare the type of fetched MFA config\")\n",
      "\t}\n",
      "\treturn mConfig.Clone()\n",
      "}\n",
      "func (c *LoginCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringVar(&StringVar{Name: \"method\", Target: &c.flagMethod, Default: \"token\", Completion: c.PredictVaultAvailableAuths(), Usage: \"Type of authentication to use such as \\\"userpass\\\" or \" + \"\\\"ldap\\\". Note this corresponds to the TYPE, not the enabled path. \" + \"Use -path to specify the path where the authentication is enabled.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"path\", Target: &c.flagPath, Default: \"\", Completion: c.PredictVaultAuths(), Usage: \"Remote path in Vault where the auth method is enabled. \" + \"This defaults to the TYPE of method (e.g. userpass -> userpass/).\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"no-store\", Target: &c.flagNoStore, Default: false, Usage: \"Do not persist the token to the token helper (usually the \" + \"local filesystem) after authentication for use in future requests. \" + \"The token will only be displayed in the command output.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"no-print\", Target: &c.flagNoPrint, Default: false, Usage: \"Do not display the token. The token will be still be stored to the \" + \"configured token helper.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"token-only\", Target: &c.flagTokenOnly, Default: false, Usage: \"Output only the token with no verification. This flag is a \" + \"shortcut for \\\"-field=token -no-store\\\". Setting those flags to other \" + \"values will have no affect.\"})\n",
      "\treturn set\n",
      "}\n",
      "func (a *ActivityLog) SetConfig(ctx context.Context, config activityConfig) {\n",
      "\ta.l.Lock()\n",
      "\tdefer a.l.Unlock()\n",
      "\ta.fragmentLock.Lock()\n",
      "\toriginalEnabled := a.enabled\n",
      "\tswitch config.Enabled {\n",
      "\tcase \"enable\":\n",
      "\t\ta.enabled = true\n",
      "\tcase \"default\":\n",
      "\t\ta.enabled = activityLogEnabledDefault\n",
      "\tcase \"disable\":\n",
      "\t\ta.enabled = false\n",
      "\t}\n",
      "\tif a.enabled != originalEnabled {\n",
      "\t\ta.logger.Info(\"activity log enable changed\", \"original\", originalEnabled, \"current\", a.enabled)\n",
      "\t}\n",
      "\tif !a.enabled && a.currentSegment.startTimestamp != 0 {\n",
      "\t\ta.logger.Trace(\"deleting current segment\")\n",
      "\t\ta.deleteDone = make(chan struct{})\n",
      "\t\tgo a.deleteLogWorker(a.core.activeContext, a.currentSegment.startTimestamp, a.deleteDone)\n",
      "\t\ta.resetCurrentLog()\n",
      "\t}\n",
      "\tforceSave := false\n",
      "\tif a.enabled && a.currentSegment.startTimestamp == 0 {\n",
      "\t\ta.startNewCurrentLogLocked(a.clock.Now().UTC())\n",
      "\t\tforceSave = true\n",
      "\t}\n",
      "\ta.fragmentLock.Unlock()\n",
      "\tif forceSave {\n",
      "\t\ta.saveCurrentSegmentInternal(ctx, true)\n",
      "\t}\n",
      "\ta.defaultReportMonths = config.DefaultReportMonths\n",
      "\ta.retentionMonths = config.RetentionMonths\n",
      "\tif a.retentionMonths < a.configOverrides.MinimumRetentionMonths {\n",
      "\t\ta.retentionMonths = a.configOverrides.MinimumRetentionMonths\n",
      "\t}\n",
      "\tgo a.retentionWorker(ctx, a.clock.Now(), a.retentionMonths)\n",
      "}\n",
      "func (f *BoltSnapshotStore) getMetaFromDB(id string) (*raft.SnapshotMeta, error) {\n",
      "\tif len(id) == 0 {\n",
      "\t\treturn nil, errors.New(\"can not open empty snapshot ID\")\n",
      "\t}\n",
      "\tfilename := filepath.Join(f.path, id, databaseFilename)\n",
      "\tboltDB, err := bolt.Open(filename, 0o600, &bolt.Options{Timeout: 1 * time.Second})\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdefer boltDB.Close()\n",
      "\tmeta := &raft.SnapshotMeta{Version: 1, ID: id}\n",
      "\terr = boltDB.View(func(tx *bolt.Tx) error {\n",
      "\t\tb := tx.Bucket(configBucketName)\n",
      "\t\tval := b.Get(latestIndexKey)\n",
      "\t\tif val != nil {\n",
      "\t\t\tvar snapshotIndexes IndexValue\n",
      "\t\t\terr := proto.Unmarshal(val, &snapshotIndexes)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tmeta.Index = snapshotIndexes.Index\n",
      "\t\t\tmeta.Term = snapshotIndexes.Term\n",
      "\t\t}\n",
      "\t\tval = b.Get(latestConfigKey)\n",
      "\t\tif val != nil {\n",
      "\t\t\tvar config ConfigurationValue\n",
      "\t\t\terr := proto.Unmarshal(val, &config)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tmeta.ConfigurationIndex, meta.Configuration = protoConfigurationToRaftConfiguration(&config)\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t})\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn meta, nil\n",
      "}\n",
      "func (c *LeaseRevokeCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault lease revoke [options] ID\n",
      "\n",
      "  Revokes secrets by their lease ID. This command can revoke a single secret\n",
      "  or multiple secrets based on a path-matched prefix.\n",
      "\n",
      "  The default behavior when not using -force is to revoke asynchronously; Vault\n",
      "  will queue the revocation and keep trying if it fails (including across\n",
      "  restarts). The -sync flag can be used to force a synchronous operation, but\n",
      "  it is then up to the caller to retry on failure. Force mode always operates\n",
      "  synchronously.\n",
      "\n",
      "  Revoke a single lease:\n",
      "\n",
      "      $ vault lease revoke database/creds/readonly/2f6a614c...\n",
      "\n",
      "  Revoke all leases for a role:\n",
      "\n",
      "      $ vault lease revoke -prefix aws/creds/deploy\n",
      "\n",
      "  Force delete leases from Vault even if secret engine revocation fails:\n",
      "\n",
      "      $ vault lease revoke -force -prefix consul/creds\n",
      "\n",
      "  For a full list of examples and paths, please see the documentation that\n",
      "  corresponds to the secret engine in use.\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (c *KVDeleteCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"versions\", Target: &c.flagVersions, Default: nil, Usage: `Specifies the version numbers to delete.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /data/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func (c *Client) clone(cloneHeaders bool) (*Client, error) {\n",
      "\tconfig := c.config\n",
      "\tnewConfig := &Config{Address: config.Address, HttpClient: config.HttpClient, MinRetryWait: config.MinRetryWait, MaxRetryWait: config.MaxRetryWait, MaxRetries: config.MaxRetries, Timeout: config.Timeout, Backoff: config.Backoff, CheckRetry: config.CheckRetry, Logger: config.Logger, Limiter: config.Limiter, AgentAddress: config.AgentAddress, SRVLookup: config.SRVLookup, CloneHeaders: config.CloneHeaders, CloneToken: config.CloneToken, ReadYourWrites: config.ReadYourWrites}\n",
      "\tif config.CloneTLSConfig {\n",
      "\t\tnewConfig.clientTLSConfig = config.clientTLSConfig\n",
      "\t}\n",
      "\tclient, err := NewClient(newConfig)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif cloneHeaders {\n",
      "\t\tclient.SetHeaders(c.headersInternal().Clone())\n",
      "\t}\n",
      "\tif config.CloneToken {\n",
      "\t\tclient.SetToken(c.token)\n",
      "\t}\n",
      "\tclient.replicationStateStore = c.replicationStateStore\n",
      "\treturn client, nil\n",
      "}\n",
      "func (h *EnableAcmeIssuance) Evaluate(e *Executor) (results []*Result, err error) {\n",
      "\tif h.UnsupportedVersion {\n",
      "\t\tret := Result{Status: ResultInvalidVersion, Endpoint: h.AcmeConfigFetcher.Path, Message: \"This health check requires Vault 1.14+ but an earlier version of Vault Server was contacted, preventing this health check from running.\"}\n",
      "\t\treturn []*Result{&ret}, nil\n",
      "\t}\n",
      "\tif h.AcmeConfigFetcher.IsSecretPermissionsError() {\n",
      "\t\tmsg := \"Without this information, this health check is unable to function.\"\n",
      "\t\treturn craftInsufficientPermissionResult(e, h.AcmeConfigFetcher.Path, msg), nil\n",
      "\t}\n",
      "\tacmeEnabled, err := isAcmeEnabled(h.AcmeConfigFetcher)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif !acmeEnabled {\n",
      "\t\tif h.TotalIssuers == 0 {\n",
      "\t\t\tret := Result{Status: ResultNotApplicable, Endpoint: h.AcmeConfigFetcher.Path, Message: \"No issuers in mount, ACME is not required.\"}\n",
      "\t\t\treturn []*Result{&ret}, nil\n",
      "\t\t}\n",
      "\t\tif h.TotalIssuers == h.RootIssuers {\n",
      "\t\t\tret := Result{Status: ResultNotApplicable, Endpoint: h.AcmeConfigFetcher.Path, Message: \"Mount contains only root issuers, ACME is not required.\"}\n",
      "\t\t\treturn []*Result{&ret}, nil\n",
      "\t\t}\n",
      "\t\tret := Result{Status: ResultInformational, Endpoint: h.AcmeConfigFetcher.Path, Message: \"Consider enabling ACME support to support a self-rotating PKI infrastructure.\"}\n",
      "\t\treturn []*Result{&ret}, nil\n",
      "\t}\n",
      "\tif h.ClusterConfigFetcher.IsSecretPermissionsError() {\n",
      "\t\tmsg := \"Without this information, this health check is unable to function.\"\n",
      "\t\treturn craftInsufficientPermissionResult(e, h.ClusterConfigFetcher.Path, msg), nil\n",
      "\t}\n",
      "\tlocalPathIssue := verifyLocalPathUrl(h)\n",
      "\tif localPathIssue != nil {\n",
      "\t\tret := Result{Status: ResultWarning, Endpoint: h.ClusterConfigFetcher.Path, Message: \"ACME enabled in config but not functional: \" + localPathIssue.Error()}\n",
      "\t\treturn []*Result{&ret}, nil\n",
      "\t}\n",
      "\tret := Result{Status: ResultOK, Endpoint: h.ClusterConfigFetcher.Path, Message: \"ACME enabled and successfully connected to the ACME directory.\"}\n",
      "\treturn []*Result{&ret}, nil\n",
      "}\n",
      "func (b *backend) doTidyCertStore(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tserials, err := req.Storage.List(ctx, \"certs/\")\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error fetching list of certs: %w\", err)\n",
      "\t}\n",
      "\tserialCount := len(serials)\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"cert_store_total_entries\"}, float32(serialCount))\n",
      "\tfor i, serial := range serials {\n",
      "\t\tb.tidyStatusMessage(fmt.Sprintf(\"Tidying certificate store: checking entry %d of %d\", i, serialCount))\n",
      "\t\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"cert_store_current_entry\"}, float32(i))\n",
      "\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\treturn tidyCancelledError\n",
      "\t\t}\n",
      "\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t}\n",
      "\t\tcertEntry, err := req.Storage.Get(ctx, \"certs/\"+serial)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"error fetching certificate %q: %w\", serial, err)\n",
      "\t\t}\n",
      "\t\tif certEntry == nil {\n",
      "\t\t\tlogger.Warn(\"certificate entry is nil; tidying up since it is no longer useful for any server operations\", \"serial\", serial)\n",
      "\t\t\tif err := req.Storage.Delete(ctx, \"certs/\"+serial); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting nil entry with serial %s: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncCertStoreCount()\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif certEntry.Value == nil || len(certEntry.Value) == 0 {\n",
      "\t\t\tlogger.Warn(\"certificate entry has no value; tidying up since it is no longer useful for any server operations\", \"serial\", serial)\n",
      "\t\t\tif err := req.Storage.Delete(ctx, \"certs/\"+serial); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting entry with nil value with serial %s: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncCertStoreCount()\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tcert, err := x509.ParseCertificate(certEntry.Value)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"unable to parse stored certificate with serial %q: %w\", serial, err)\n",
      "\t\t}\n",
      "\t\tif time.Since(cert.NotAfter) > config.SafetyBuffer {\n",
      "\t\t\tif err := req.Storage.Delete(ctx, \"certs/\"+serial); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting serial %q from storage: %w\", serial, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncCertStoreCount()\n",
      "\t\t}\n",
      "\t}\n",
      "\tb.tidyStatusLock.RLock()\n",
      "\tmetrics.SetGauge([]string{\"secrets\", \"pki\", \"tidy\", \"cert_store_total_entries_remaining\"}, float32(uint(serialCount)-b.tidyStatus.certStoreDeletedCount))\n",
      "\tb.tidyStatusLock.RUnlock()\n",
      "\treturn nil\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBMFALoginEnforcementConfigByNameAndNamespace(name, namespaceId string) (*mfa.MFAEnforcementConfig, error) {\n",
      "\tif name == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing config name\")\n",
      "\t}\n",
      "\ttxn := b.db.Txn(false)\n",
      "\tdefer txn.Abort()\n",
      "\teConfigRaw, err := txn.First(memDBMFALoginEnforcementsTable, \"nameAndNamespace\", name, namespaceId)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to fetch MFA login enforcement config from memdb using name: %w\", err)\n",
      "\t}\n",
      "\tif eConfigRaw == nil {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\teConfig, ok := eConfigRaw.(*mfa.MFAEnforcementConfig)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"invalid type for MFA login enforcement config in memdb\")\n",
      "\t}\n",
      "\treturn eConfig.Clone()\n",
      "}\n",
      "func (c *Core) GenerateRootUpdate(ctx context.Context, key []byte, nonce string, strategy GenerateRootStrategy) (*GenerateRootResult, error) {\n",
      "\tmin, max := c.barrier.KeyLength()\n",
      "\tmax += shamir.ShareOverhead\n",
      "\tif len(key) < min {\n",
      "\t\treturn nil, &ErrInvalidKey{fmt.Sprintf(\"key is shorter than minimum %d bytes\", min)}\n",
      "\t}\n",
      "\tif len(key) > max {\n",
      "\t\treturn nil, &ErrInvalidKey{fmt.Sprintf(\"key is longer than maximum %d bytes\", max)}\n",
      "\t}\n",
      "\tvar config *SealConfig\n",
      "\tvar err error\n",
      "\tif c.seal.RecoveryKeySupported() {\n",
      "\t\tconfig, err = c.seal.RecoveryConfig(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tconfig, err = c.seal.BarrierConfig(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\treturn nil, ErrNotInit\n",
      "\t}\n",
      "\tc.stateLock.RLock()\n",
      "\tdefer c.stateLock.RUnlock()\n",
      "\tif c.Sealed() && !c.recoveryMode {\n",
      "\t\treturn nil, consts.ErrSealed\n",
      "\t}\n",
      "\tbarrierSealed, err := c.barrier.Sealed()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errors.New(\"unable to check barrier seal status\")\n",
      "\t}\n",
      "\tif !barrierSealed && c.recoveryMode {\n",
      "\t\treturn nil, errors.New(\"attempt to generate recovery token when already unsealed\")\n",
      "\t}\n",
      "\tif c.standby && !c.recoveryMode {\n",
      "\t\treturn nil, consts.ErrStandby\n",
      "\t}\n",
      "\tc.generateRootLock.Lock()\n",
      "\tdefer c.generateRootLock.Unlock()\n",
      "\tif c.generateRootConfig == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"no root generation in progress\")\n",
      "\t}\n",
      "\tif nonce != c.generateRootConfig.Nonce {\n",
      "\t\treturn nil, fmt.Errorf(\"incorrect nonce supplied; nonce for this root generation operation is %q\", c.generateRootConfig.Nonce)\n",
      "\t}\n",
      "\tif strategy != c.generateRootConfig.Strategy {\n",
      "\t\treturn nil, fmt.Errorf(\"incorrect strategy supplied; a generate root operation of another type is already in progress\")\n",
      "\t}\n",
      "\tfor _, existing := range c.generateRootProgress {\n",
      "\t\tif bytes.Equal(existing, key) {\n",
      "\t\t\treturn nil, fmt.Errorf(\"given key has already been provided during this generation operation\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tc.generateRootProgress = append(c.generateRootProgress, key)\n",
      "\tprogress := len(c.generateRootProgress)\n",
      "\tif len(c.generateRootProgress) < config.SecretThreshold {\n",
      "\t\tif c.logger.IsDebug() {\n",
      "\t\t\tc.logger.Debug(\"cannot generate root, not enough keys\", \"keys\", progress, \"threshold\", config.SecretThreshold)\n",
      "\t\t}\n",
      "\t\treturn &GenerateRootResult{Progress: progress, Required: config.SecretThreshold, PGPFingerprint: c.generateRootConfig.PGPFingerprint}, nil\n",
      "\t}\n",
      "\tvar combinedKey []byte\n",
      "\tif config.SecretThreshold == 1 {\n",
      "\t\tcombinedKey = c.generateRootProgress[0]\n",
      "\t\tc.generateRootProgress = nil\n",
      "\t} else {\n",
      "\t\tcombinedKey, err = shamir.Combine(c.generateRootProgress)\n",
      "\t\tc.generateRootProgress = nil\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to compute root key: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := strategy.authenticate(ctx, c, combinedKey); err != nil {\n",
      "\t\tc.logger.Error(\"root generation aborted\", \"error\", err.Error())\n",
      "\t\treturn nil, fmt.Errorf(\"root generation aborted: %w\", err)\n",
      "\t}\n",
      "\ttoken, cleanupFunc, err := strategy.generate(ctx, c)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar encodedToken string\n",
      "\tswitch {\n",
      "\tcase len(c.generateRootConfig.OTP) > 0:\n",
      "\t\tencodedToken, err = roottoken.EncodeToken(token, c.generateRootConfig.OTP)\n",
      "\tcase len(c.generateRootConfig.PGPKey) > 0:\n",
      "\t\tvar tokenBytesArr [][]byte\n",
      "\t\t_, tokenBytesArr, err = pgpkeys.EncryptShares([][]byte{[]byte(token)}, []string{c.generateRootConfig.PGPKey})\n",
      "\t\tencodedToken = base64.StdEncoding.EncodeToString(tokenBytesArr[0])\n",
      "\tdefault:\n",
      "\t\terr = fmt.Errorf(\"unreachable condition\")\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\tcleanupFunc()\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tresults := &GenerateRootResult{Progress: progress, Required: config.SecretThreshold, EncodedToken: encodedToken, PGPFingerprint: c.generateRootConfig.PGPFingerprint}\n",
      "\tswitch strategy.(type) {\n",
      "\tcase generateStandardRootToken:\n",
      "\t\tc.logger.Info(\"root generation finished\", \"nonce\", c.generateRootConfig.Nonce)\n",
      "\tcase *generateRecoveryToken:\n",
      "\t\tc.logger.Info(\"recovery token generation finished\", \"nonce\", c.generateRootConfig.Nonce)\n",
      "\tdefault:\n",
      "\t\tc.logger.Info(\"dr operation token generation finished\", \"nonce\", c.generateRootConfig.Nonce)\n",
      "\t}\n",
      "\tc.generateRootProgress = nil\n",
      "\tc.generateRootConfig = nil\n",
      "\treturn results, nil\n",
      "}\n",
      "func NewMySQLClient(conf map[string]string, logger log.Logger) (*sql.DB, error) {\n",
      "\tvar err error\n",
      "\tusername, ok := conf[\"username\"]\n",
      "\tif !ok || username == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing username\")\n",
      "\t}\n",
      "\tpassword, ok := conf[\"password\"]\n",
      "\tif !ok || password == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing password\")\n",
      "\t}\n",
      "\taddress, ok := conf[\"address\"]\n",
      "\tif !ok {\n",
      "\t\taddress = \"127.0.0.1:3306\"\n",
      "\t}\n",
      "\tmaxIdleConnStr, ok := conf[\"max_idle_connections\"]\n",
      "\tvar maxIdleConnInt int\n",
      "\tif ok {\n",
      "\t\tmaxIdleConnInt, err = strconv.Atoi(maxIdleConnStr)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed parsing max_idle_connections parameter: %w\", err)\n",
      "\t\t}\n",
      "\t\tif logger.IsDebug() {\n",
      "\t\t\tlogger.Debug(\"max_idle_connections set\", \"max_idle_connections\", maxIdleConnInt)\n",
      "\t\t}\n",
      "\t}\n",
      "\tmaxConnLifeStr, ok := conf[\"max_connection_lifetime\"]\n",
      "\tvar maxConnLifeInt int\n",
      "\tif ok {\n",
      "\t\tmaxConnLifeInt, err = strconv.Atoi(maxConnLifeStr)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed parsing max_connection_lifetime parameter: %w\", err)\n",
      "\t\t}\n",
      "\t\tif logger.IsDebug() {\n",
      "\t\t\tlogger.Debug(\"max_connection_lifetime set\", \"max_connection_lifetime\", maxConnLifeInt)\n",
      "\t\t}\n",
      "\t}\n",
      "\tmaxParStr, ok := conf[\"max_parallel\"]\n",
      "\tvar maxParInt int\n",
      "\tif ok {\n",
      "\t\tmaxParInt, err = strconv.Atoi(maxParStr)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed parsing max_parallel parameter: %w\", err)\n",
      "\t\t}\n",
      "\t\tif logger.IsDebug() {\n",
      "\t\t\tlogger.Debug(\"max_parallel set\", \"max_parallel\", maxParInt)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tmaxParInt = physical.DefaultParallelOperations\n",
      "\t}\n",
      "\tdsnParams := url.Values{}\n",
      "\ttlsCaFile, tlsOk := conf[\"tls_ca_file\"]\n",
      "\tif tlsOk {\n",
      "\t\tif err := setupMySQLTLSConfig(tlsCaFile); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed register TLS config: %w\", err)\n",
      "\t\t}\n",
      "\t\tdsnParams.Add(\"tls\", mysqlTLSKey)\n",
      "\t}\n",
      "\tptAllowed, ptOk := conf[\"plaintext_connection_allowed\"]\n",
      "\tif !(ptOk && strings.ToLower(ptAllowed) == \"true\") && !tlsOk {\n",
      "\t\tlogger.Warn(\"No TLS specified, credentials will be sent in plaintext. To mute this warning add 'plaintext_connection_allowed' with a true value to your MySQL configuration in your config file.\")\n",
      "\t}\n",
      "\tdsn := username + \":\" + password + \"@tcp(\" + address + \")/?\" + dsnParams.Encode()\n",
      "\tdb, err := sql.Open(\"mysql\", dsn)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to connect to mysql: %w\", err)\n",
      "\t}\n",
      "\tdb.SetMaxOpenConns(maxParInt)\n",
      "\tif maxIdleConnInt != 0 {\n",
      "\t\tdb.SetMaxIdleConns(maxIdleConnInt)\n",
      "\t}\n",
      "\tif maxConnLifeInt != 0 {\n",
      "\t\tdb.SetConnMaxLifetime(time.Duration(maxConnLifeInt) * time.Second)\n",
      "\t}\n",
      "\treturn db, err\n",
      "}\n",
      "func (b *backend) pathRevokeIssuer(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tb.issuersLock.Lock()\n",
      "\tdefer b.issuersLock.Unlock()\n",
      "\tif b.UseLegacyBundleCaStorage() {\n",
      "\t\treturn logical.ErrorResponse(\"cannot revoke issuer until migration has completed\"), nil\n",
      "\t}\n",
      "\tissuerName := GetIssuerRef(data)\n",
      "\tif len(issuerName) == 0 {\n",
      "\t\treturn logical.ErrorResponse(\"missing issuer reference\"), nil\n",
      "\t}\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tref, err := sc.resolveIssuerReference(issuerName)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif ref == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"unable to resolve issuer id for reference: \" + issuerName), nil\n",
      "\t}\n",
      "\tissuer, err := sc.fetchIssuerById(ref)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif issuer.Revoked {\n",
      "\t\treturn respondReadIssuer(issuer)\n",
      "\t}\n",
      "\tissuer.Revoked = true\n",
      "\tif issuer.Usage.HasUsage(issuing.IssuanceUsage) {\n",
      "\t\tissuer.Usage.ToggleUsage(issuing.IssuanceUsage)\n",
      "\t}\n",
      "\tcurrTime := time.Now()\n",
      "\tissuer.RevocationTime = currTime.Unix()\n",
      "\tissuer.RevocationTimeUTC = currTime.UTC()\n",
      "\terr = sc.writeIssuer(issuer)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tcertEntry, err := fetchCertBySerial(sc, \"certs/\", issuer.SerialNumber)\n",
      "\tif err == nil && certEntry != nil {\n",
      "\t\tstorageCert, err := x509.ParseCertificate(certEntry.Value)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing stored certificate value: %w\", err)\n",
      "\t\t}\n",
      "\t\tissuerCert, err := issuer.GetCertificate()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing issuer certificate value: %w\", err)\n",
      "\t\t}\n",
      "\t\tif bytes.Equal(issuerCert.Raw, storageCert.Raw) {\n",
      "\t\t\trevInfo := revocationInfo{CertificateBytes: issuerCert.Raw, RevocationTime: issuer.RevocationTime, RevocationTimeUTC: issuer.RevocationTimeUTC}\n",
      "\t\t\trevEntry, err := logical.StorageEntryJSON(revokedPath+normalizeSerial(issuer.SerialNumber), revInfo)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"error creating revocation entry for issuer: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\terr = req.Storage.Put(ctx, revEntry)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"error saving revoked issuer to new location: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\twarnings, crlErr := b.CrlBuilder().rebuild(sc, false)\n",
      "\tif crlErr != nil {\n",
      "\t\tswitch crlErr.(type) {\n",
      "\t\tcase errutil.UserError:\n",
      "\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"Error during CRL building: %s\", crlErr)), nil\n",
      "\t\tdefault:\n",
      "\t\t\treturn nil, fmt.Errorf(\"error encountered during CRL building: %w\", crlErr)\n",
      "\t\t}\n",
      "\t}\n",
      "\tresponse, err := respondReadIssuer(issuer)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tfor index, warning := range warnings {\n",
      "\t\tresponse.AddWarning(fmt.Sprintf(\"Warning %d during CRL rebuild: %v\", index+1, warning))\n",
      "\t}\n",
      "\tourCert, err := issuer.GetCertificate()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tallIssuers, err := sc.listIssuers()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tisSelfSigned := false\n",
      "\thaveOtherIssuer := false\n",
      "\tfor _, candidateID := range allIssuers {\n",
      "\t\tcandidate, err := sc.fetchIssuerById(candidateID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tcandidateCert, err := candidate.GetCertificate()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif err := ourCert.CheckSignatureFrom(candidateCert); err == nil {\n",
      "\t\t\tif candidate.ID == issuer.ID {\n",
      "\t\t\t\tisSelfSigned = true\n",
      "\t\t\t} else {\n",
      "\t\t\t\thaveOtherIssuer = true\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif isSelfSigned && haveOtherIssuer {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t}\n",
      "\tif isSelfSigned {\n",
      "\t\tresponse.AddWarning(\"This issuer is a self-signed (potentially root) certificate. This means it may not be considered revoked if there is not an external, cross-signed variant of this certificate. This issuer's serial number will not appear on its own CRL.\")\n",
      "\t}\n",
      "\tif !haveOtherIssuer {\n",
      "\t\tresponse.AddWarning(\"This issuer lacks another parent issuer within the mount. This means it will not appear on any other CRLs and may not be considered revoked by clients. Consider adding this issuer to its issuer's CRL as well if it is not self-signed.\")\n",
      "\t}\n",
      "\tconfig, err := sc.getIssuersConfig()\n",
      "\tif err == nil && config != nil && config.DefaultIssuerId == issuer.ID {\n",
      "\t\tresponse.AddWarning(\"This issuer is currently configured as the default issuer for this mount; operations such as certificate issuance may not work until a new default issuer is selected.\")\n",
      "\t}\n",
      "\treturn response, nil\n",
      "}\n",
      "func (m MockDatabaseV4) Init(ctx context.Context, config map[string]interface{}, verifyConnection bool) (saveConfig map[string]interface{}, err error) {\n",
      "\tlog.Default().Info(\"Init called\", \"config\", config, \"verifyConnection\", verifyConnection)\n",
      "\treturn config, nil\n",
      "}\n",
      "func (c *Core) newCredentialBackend(ctx context.Context, entry *MountEntry, sysView logical.SystemView, view logical.Storage) (logical.Backend, error) {\n",
      "\tt := entry.Type\n",
      "\tif alias, ok := credentialAliases[t]; ok {\n",
      "\t\tt = alias\n",
      "\t}\n",
      "\tpluginVersion, err := c.resolveMountEntryVersion(ctx, consts.PluginTypeCredential, entry)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar runningSha string\n",
      "\tfactory, ok := c.credentialBackends[t]\n",
      "\tif !ok {\n",
      "\t\tplug, err := c.pluginCatalog.Get(ctx, t, consts.PluginTypeCredential, pluginVersion)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif plug == nil {\n",
      "\t\t\terrContext := t\n",
      "\t\t\tif pluginVersion != \"\" {\n",
      "\t\t\t\terrContext += fmt.Sprintf(\", version=%s\", pluginVersion)\n",
      "\t\t\t}\n",
      "\t\t\treturn nil, fmt.Errorf(\"%w: %s\", plugincatalog.ErrPluginNotFound, errContext)\n",
      "\t\t}\n",
      "\t\tif len(plug.Sha256) > 0 {\n",
      "\t\t\trunningSha = hex.EncodeToString(plug.Sha256)\n",
      "\t\t}\n",
      "\t\tfactory = plugin.Factory\n",
      "\t\tif !plug.Builtin {\n",
      "\t\t\tfactory = wrapFactoryCheckPerms(c, plugin.Factory)\n",
      "\t\t}\n",
      "\t}\n",
      "\tconf := make(map[string]string)\n",
      "\tfor k, v := range entry.Options {\n",
      "\t\tconf[k] = v\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase entry.Type == \"plugin\":\n",
      "\t\tconf[\"plugin_name\"] = entry.Config.PluginName\n",
      "\tdefault:\n",
      "\t\tconf[\"plugin_name\"] = t\n",
      "\t}\n",
      "\tconf[\"plugin_type\"] = consts.PluginTypeCredential.String()\n",
      "\tconf[\"plugin_version\"] = pluginVersion\n",
      "\tauthLogger := c.baseLogger.Named(fmt.Sprintf(\"auth.%s.%s\", t, entry.Accessor))\n",
      "\tc.AddLogger(authLogger)\n",
      "\tpluginEventSender, err := c.events.WithPlugin(entry.namespace, &logical.EventPluginInfo{MountClass: consts.PluginTypeCredential.String(), MountAccessor: entry.Accessor, MountPath: entry.Path, Plugin: entry.Type, PluginVersion: pluginVersion, Version: entry.Options[\"version\"]})\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfig := &logical.BackendConfig{StorageView: view, Logger: authLogger, Config: conf, System: sysView, BackendUUID: entry.BackendAwareUUID, EventsSender: pluginEventSender}\n",
      "\tbackend, err := factory(ctx, config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif backend != nil {\n",
      "\t\tentry.RunningVersion = pluginVersion\n",
      "\t\tentry.RunningSha256 = runningSha\n",
      "\t\tif entry.RunningVersion == \"\" && entry.RunningSha256 == \"\" {\n",
      "\t\t\tentry.RunningVersion = versions.GetBuiltinVersion(consts.PluginTypeCredential, entry.Type)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn backend, nil\n",
      "}\n",
      "func (b *backend) doTidyMoveCABundle(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tif b.System().ReplicationState().HasState(consts.ReplicationDRSecondary|consts.ReplicationPerformanceStandby) || (!b.System().LocalMount() && b.System().ReplicationState().HasState(consts.ReplicationPerformanceSecondary)) {\n",
      "\t\tb.Logger().Debug(\"skipping moving the legacy CA bundle as we're not on the primary or secondary with a local mount\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif b.UseLegacyBundleCaStorage() {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\t_, bundle, err := getLegacyCertBundle(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to fetch the legacy CA bundle: %w\", err)\n",
      "\t}\n",
      "\tif bundle == nil {\n",
      "\t\tb.Logger().Debug(\"No legacy CA bundle available; nothing to do.\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tlog, err := getLegacyBundleMigrationLog(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to fetch the legacy bundle migration log: %w\", err)\n",
      "\t}\n",
      "\tif log == nil {\n",
      "\t\treturn fmt.Errorf(\"refusing to tidy with an empty legacy migration log but present CA bundle: %w\", err)\n",
      "\t}\n",
      "\tif time.Since(log.Created) <= config.IssuerSafetyBuffer {\n",
      "\t\tb.Logger().Debug(\"Migration was created too recently to remove the legacy bundle; refusing to move legacy CA bundle to backup location.\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tentry, err := logical.StorageEntryJSON(legacyCertBundleBackupPath, bundle)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to create new backup storage entry: %w\", err)\n",
      "\t}\n",
      "\terr = req.Storage.Put(ctx, entry)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to write new backup legacy CA bundle: %w\", err)\n",
      "\t}\n",
      "\terr = req.Storage.Delete(ctx, legacyCertBundlePath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to remove old legacy CA bundle path: %w\", err)\n",
      "\t}\n",
      "\tb.Logger().Info(\"legacy CA bundle successfully moved to backup location\")\n",
      "\treturn nil\n",
      "}\n",
      "func parseHAStorage(result *Config, list *ast.ObjectList, name string) error {\n",
      "\tif len(list.Items) > 1 {\n",
      "\t\treturn fmt.Errorf(\"only one %q block is permitted\", name)\n",
      "\t}\n",
      "\titem := list.Items[0]\n",
      "\tkey := name\n",
      "\tif len(item.Keys) > 0 {\n",
      "\t\tkey = item.Keys[0].Token.Value().(string)\n",
      "\t}\n",
      "\tvar config map[string]interface{}\n",
      "\tif err := hcl.DecodeObject(&config, item.Val); err != nil {\n",
      "\t\treturn multierror.Prefix(err, fmt.Sprintf(\"%s.%s:\", name, key))\n",
      "\t}\n",
      "\tm := make(map[string]string)\n",
      "\tfor key, val := range config {\n",
      "\t\tvalStr, ok := val.(string)\n",
      "\t\tif ok {\n",
      "\t\t\tm[key] = valStr\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tvalBytes, err := json.Marshal(val)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tm[key] = string(valBytes)\n",
      "\t}\n",
      "\tvar redirectAddr string\n",
      "\tif v, ok := m[\"redirect_addr\"]; ok {\n",
      "\t\tredirectAddr = v\n",
      "\t\tdelete(m, \"redirect_addr\")\n",
      "\t} else if v, ok := m[\"advertise_addr\"]; ok {\n",
      "\t\tredirectAddr = v\n",
      "\t\tdelete(m, \"advertise_addr\")\n",
      "\t}\n",
      "\tvar clusterAddr string\n",
      "\tif v, ok := m[\"cluster_addr\"]; ok {\n",
      "\t\tclusterAddr = v\n",
      "\t\tdelete(m, \"cluster_addr\")\n",
      "\t}\n",
      "\tvar disableClustering bool\n",
      "\tvar err error\n",
      "\tif v, ok := m[\"disable_clustering\"]; ok {\n",
      "\t\tdisableClustering, err = strconv.ParseBool(v)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn multierror.Prefix(err, fmt.Sprintf(\"%s.%s:\", name, key))\n",
      "\t\t}\n",
      "\t\tdelete(m, \"disable_clustering\")\n",
      "\t}\n",
      "\tif result.APIAddr != \"\" {\n",
      "\t\tredirectAddr = result.APIAddr\n",
      "\t}\n",
      "\tif result.ClusterAddr != \"\" {\n",
      "\t\tclusterAddr = result.ClusterAddr\n",
      "\t}\n",
      "\tif result.DisableClusteringRaw != nil {\n",
      "\t\tdisableClustering = result.DisableClustering\n",
      "\t}\n",
      "\tresult.HAStorage = &Storage{RedirectAddr: redirectAddr, ClusterAddr: clusterAddr, DisableClustering: disableClustering, Type: strings.ToLower(key), Config: m}\n",
      "\treturn nil\n",
      "}\n",
      "func (cb *CrlBuilder) writeConfig(sc *storageContext, config *crlConfig) (*crlConfig, error) {\n",
      "\tcb._config.Lock()\n",
      "\tdefer cb._config.Unlock()\n",
      "\tif err := sc.setRevocationConfig(config); err != nil {\n",
      "\t\tcb.markConfigDirty()\n",
      "\t\treturn nil, fmt.Errorf(\"failed writing CRL config: %w\", err)\n",
      "\t}\n",
      "\tpreviousConfig := cb.config\n",
      "\tif config != nil {\n",
      "\t\tcb.config = *config\n",
      "\t} else {\n",
      "\t\tcb.config = defaultCrlConfig\n",
      "\t}\n",
      "\ttriggerChangeNotification := true\n",
      "\tif !cb.haveInitializedConfig {\n",
      "\t\tcb.haveInitializedConfig = true\n",
      "\t\ttriggerChangeNotification = false\n",
      "\t}\n",
      "\tif triggerChangeNotification {\n",
      "\t\tcb.notifyOnConfigChange(sc, previousConfig, cb.config)\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "func NewMantaBackend(conf map[string]string, logger log.Logger) (physical.Backend, error) {\n",
      "\tuser := os.Getenv(\"MANTA_USER\")\n",
      "\tif user == \"\" {\n",
      "\t\tuser = conf[\"user\"]\n",
      "\t}\n",
      "\tkeyId := os.Getenv(\"MANTA_KEY_ID\")\n",
      "\tif keyId == \"\" {\n",
      "\t\tkeyId = conf[\"key_id\"]\n",
      "\t}\n",
      "\turl := os.Getenv(\"MANTA_URL\")\n",
      "\tif url == \"\" {\n",
      "\t\turl = conf[\"url\"]\n",
      "\t} else {\n",
      "\t\turl = \"https://us-east.manta.joyent.com\"\n",
      "\t}\n",
      "\tsubuser := os.Getenv(\"MANTA_SUBUSER\")\n",
      "\tif subuser == \"\" {\n",
      "\t\tif confUser, ok := conf[\"subuser\"]; ok {\n",
      "\t\t\tsubuser = confUser\n",
      "\t\t}\n",
      "\t}\n",
      "\tinput := authentication.SSHAgentSignerInput{KeyID: keyId, AccountName: user, Username: subuser}\n",
      "\tsigner, err := authentication.NewSSHAgentSigner(input)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"Error Creating SSH Agent Signer: %w\", err)\n",
      "\t}\n",
      "\tmaxParStr, ok := conf[\"max_parallel\"]\n",
      "\tvar maxParInt int\n",
      "\tif ok {\n",
      "\t\tmaxParInt, err = strconv.Atoi(maxParStr)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed parsing max_parallel parameter: %w\", err)\n",
      "\t\t}\n",
      "\t\tif logger.IsDebug() {\n",
      "\t\t\tlogger.Debug(\"max_parallel set\", \"max_parallel\", maxParInt)\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig := &triton.ClientConfig{MantaURL: url, AccountName: user, Signers: []authentication.Signer{signer}}\n",
      "\tclient, err := storage.NewClient(config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed initialising Storage client: %w\", err)\n",
      "\t}\n",
      "\treturn &MantaBackend{client: client, directory: conf[\"directory\"], logger: logger, permitPool: physical.NewPermitPool(maxParInt)}, nil\n",
      "}\n",
      "func (c *KVPatchCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault kv patch [options] KEY [DATA]\n",
      "\n",
      "  *NOTE*: This is only supported for KV v2 engine mounts.\n",
      "\n",
      "  Writes the data to the corresponding path in the key-value store. The data can be of\n",
      "  any type.\n",
      "\n",
      "      $ vault kv patch -mount=secret foo bar=baz\n",
      "\n",
      "  The deprecated path-like syntax can also be used, but this should be avoided, \n",
      "  as the fact that it is not actually the full API path to \n",
      "  the secret (secret/data/foo) can cause confusion: \n",
      "  \n",
      "      $ vault kv patch secret/foo bar=baz\n",
      "\n",
      "  The data can also be consumed from a file on disk by prefixing with the \"@\"\n",
      "  symbol. For example:\n",
      "\n",
      "      $ vault kv patch -mount=secret foo @data.json\n",
      "\n",
      "  Or it can be read from stdin using the \"-\" symbol:\n",
      "\n",
      "      $ echo \"abcd1234\" | vault kv patch -mount=secret foo bar=-\n",
      "\n",
      "  To perform a Check-And-Set operation, specify the -cas flag with the\n",
      "  appropriate version number corresponding to the key you want to perform\n",
      "  the CAS operation on:\n",
      "\n",
      "      $ vault kv patch -mount=secret -cas=1 foo bar=baz\n",
      "\n",
      "  By default, this operation will attempt an HTTP PATCH operation. If your\n",
      "  policy does not allow that, it will fall back to a read/local update/write approach.\n",
      "  If you wish to specify which method this command should use, you may do so\n",
      "  with the -method flag. When -method=patch is specified, only an HTTP PATCH\n",
      "  operation will be tried. If it fails, the entire command will fail.\n",
      "\n",
      "      $ vault kv patch -mount=secret -method=patch foo bar=baz\n",
      "\n",
      "  When -method=rw is specified, only a read/local update/write approach will be tried.\n",
      "  This was the default behavior previous to Vault 1.9.\n",
      "\n",
      "      $ vault kv patch -mount=secret -method=rw foo bar=baz\n",
      "\n",
      "  To remove data from the corresponding path in the key-value store, kv patch can be used.\n",
      "\n",
      "      $ vault kv patch -mount=secret -remove-data=bar foo\n",
      "\n",
      "  Additional flags and more advanced use cases are detailed below.\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (b *LoginMFABackend) loadMFAMethodConfigs(ctx context.Context, ns *namespace.Namespace) error {\n",
      "\tb.mfaLogger.Trace(\"loading login MFA configurations\")\n",
      "\tbarrierView, err := b.Core.barrierViewForNamespace(ns.ID)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"error getting namespace view, namespaceid %s, error %w\", ns.ID, err)\n",
      "\t}\n",
      "\texisting, err := barrierView.List(ctx, loginMFAConfigPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list MFA configurations for namespace path %s and prefix %s: %w\", ns.Path, loginMFAConfigPrefix, err)\n",
      "\t}\n",
      "\tb.mfaLogger.Trace(\"methods collected\", \"num_existing\", len(existing))\n",
      "\tfor _, key := range existing {\n",
      "\t\tb.mfaLogger.Trace(\"loading method\", \"method\", key)\n",
      "\t\tmConfig, err := b.getMFAConfig(ctx, loginMFAConfigPrefix+key, barrierView)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif mConfig == nil {\n",
      "\t\t\tb.mfaLogger.Trace(\"failed to find the config related to a method\", \"namespace\", ns.Path, \"prefix\", loginMFAConfigPrefix, \"method\", key)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\terr = b.MemDBUpsertMFAConfig(ctx, mConfig)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to load configuration ID %s prefix %s in MemDB: %w\", mConfig.ID, loginMFAConfigPrefix, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tb.mfaLogger.Trace(\"configurations restored\", \"namespace\", ns.Path, \"prefix\", loginMFAConfigPrefix)\n",
      "\treturn nil\n",
      "}\n",
      "func (c *OperatorInitCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault operator init [options]\n",
      "\n",
      "  Initializes a Vault server. Initialization is the process by which Vault's\n",
      "  storage backend is prepared to receive data. Since Vault servers share the\n",
      "  same storage backend in HA mode, you only need to initialize one Vault to\n",
      "  initialize the storage backend.\n",
      "\n",
      "  During initialization, Vault generates an in-memory root key and applies\n",
      "  Shamir's secret sharing algorithm to disassemble that root key into a\n",
      "  configuration number of key shares such that a configurable subset of those\n",
      "  key shares must come together to regenerate the root key. These keys are\n",
      "  often called \"unseal keys\" in Vault's documentation.\n",
      "\n",
      "  This command cannot be run against an already-initialized Vault cluster.\n",
      "\n",
      "  Start initialization with the default options:\n",
      "\n",
      "      $ vault operator init\n",
      "\n",
      "  Initialize, but encrypt the unseal keys with pgp keys:\n",
      "\n",
      "      $ vault operator init \\\n",
      "          -key-shares=3 \\\n",
      "          -key-threshold=2 \\\n",
      "          -pgp-keys=\"keybase:hashicorp,keybase:jefferai,keybase:sethvargo\"\n",
      "\n",
      "  Encrypt the initial root token using a pgp key:\n",
      "\n",
      "      $ vault operator init -root-token-pgp-key=\"keybase:hashicorp\"\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func revokeCert(sc *storageContext, config *crlConfig, cert *x509.Certificate) (*logical.Response, error) {\n",
      "\tif sc.Backend.System().Tainted() {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tcolonSerial := serialFromCert(cert)\n",
      "\thyphenSerial := normalizeSerial(colonSerial)\n",
      "\tissuerIDCertMap, err := fetchIssuerMapForRevocationChecking(sc)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tfor issuer, certificate := range issuerIDCertMap {\n",
      "\t\tif colonSerial == serialFromCert(certificate) {\n",
      "\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"adding issuer (id: %v) to its own CRL is not allowed\", issuer)), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tcurRevInfo, err := sc.fetchRevocationInfo(colonSerial)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif curRevInfo != nil {\n",
      "\t\tresp := &logical.Response{Data: map[string]interface{}{\"revocation_time\": curRevInfo.RevocationTime, \"state\": \"revoked\"}}\n",
      "\t\tif !curRevInfo.RevocationTimeUTC.IsZero() {\n",
      "\t\t\tresp.Data[\"revocation_time_rfc3339\"] = curRevInfo.RevocationTimeUTC.Format(time.RFC3339Nano)\n",
      "\t\t}\n",
      "\t\treturn resp, nil\n",
      "\t}\n",
      "\tif cert.NotAfter.Before(time.Now().Add(2 * time.Second)) {\n",
      "\t\tresponse := &logical.Response{}\n",
      "\t\tresponse.AddWarning(fmt.Sprintf(\"certificate with serial %s already expired; refusing to add to CRL\", colonSerial))\n",
      "\t\treturn response, nil\n",
      "\t}\n",
      "\tcurrTime := time.Now()\n",
      "\trevInfo := revocationInfo{CertificateBytes: cert.Raw, RevocationTime: currTime.Unix(), RevocationTimeUTC: currTime.UTC()}\n",
      "\tassociateRevokedCertWithIsssuer(&revInfo, cert, issuerIDCertMap)\n",
      "\trevEntry, err := logical.StorageEntryJSON(revokedPath+hyphenSerial, revInfo)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error creating revocation entry: %w\", err)\n",
      "\t}\n",
      "\tcertCounter := sc.Backend.GetCertificateCounter()\n",
      "\tcertsCounted := certCounter.IsInitialized()\n",
      "\terr = sc.Storage.Put(sc.Context, revEntry)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error saving revoked certificate to new location: %w\", err)\n",
      "\t}\n",
      "\tcertCounter.IncrementTotalRevokedCertificatesCount(certsCounted, revEntry.Key)\n",
      "\tresp := &logical.Response{Data: map[string]interface{}{\"revocation_time\": revInfo.RevocationTime, \"revocation_time_rfc3339\": revInfo.RevocationTimeUTC.Format(time.RFC3339Nano), \"state\": \"revoked\"}}\n",
      "\tfailedWritingUnifiedCRL := false\n",
      "\tif config.UnifiedCRL {\n",
      "\t\tentry := &unifiedRevocationEntry{SerialNumber: colonSerial, CertExpiration: cert.NotAfter, RevocationTimeUTC: revInfo.RevocationTimeUTC, CertificateIssuer: revInfo.CertificateIssuer}\n",
      "\t\tignoreErr := writeUnifiedRevocationEntry(sc, entry)\n",
      "\t\tif ignoreErr != nil {\n",
      "\t\t\tsc.Backend.Logger().Error(\"Failed to write unified revocation entry, will re-attempt later\", \"serial_number\", colonSerial, \"error\", ignoreErr)\n",
      "\t\t\tsc.Backend.GetUnifiedTransferStatus().forceRun()\n",
      "\t\t\tresp.AddWarning(fmt.Sprintf(\"Failed to write unified revocation entry, will re-attempt later: %v\", err))\n",
      "\t\t\tfailedWritingUnifiedCRL = true\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !config.AutoRebuild {\n",
      "\t\twarnings, crlErr := sc.Backend.CrlBuilder().rebuild(sc, false)\n",
      "\t\tif crlErr != nil {\n",
      "\t\t\tswitch crlErr.(type) {\n",
      "\t\t\tcase errutil.UserError:\n",
      "\t\t\t\treturn logical.ErrorResponse(fmt.Sprintf(\"Error during CRL building: %s\", crlErr)), nil\n",
      "\t\t\tdefault:\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"error encountered during CRL building: %w\", crlErr)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor index, warning := range warnings {\n",
      "\t\t\tresp.AddWarning(fmt.Sprintf(\"Warning %d during CRL rebuild: %v\", index+1, warning))\n",
      "\t\t}\n",
      "\t} else if config.EnableDelta {\n",
      "\t\tif err := writeRevocationDeltaWALs(sc, config, resp, failedWritingUnifiedCRL, hyphenSerial, colonSerial); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to write WAL entries for Delta CRLs: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn resp, nil\n",
      "}\n",
      "func (c *Core) configureCredentialsBackends(backends map[string]logical.Factory, logger log.Logger) {\n",
      "\tcredentialBackends := make(map[string]logical.Factory, len(backends))\n",
      "\tfor k, f := range backends {\n",
      "\t\tcredentialBackends[k] = f\n",
      "\t}\n",
      "\tcredentialBackends[mountTypeToken] = func(ctx context.Context, config *logical.BackendConfig) (logical.Backend, error) {\n",
      "\t\ttsLogger := logger.Named(\"token\")\n",
      "\t\tc.AddLogger(tsLogger)\n",
      "\t\treturn NewTokenStore(ctx, tsLogger, c, config)\n",
      "\t}\n",
      "\tc.credentialBackends = credentialBackends\n",
      "\tc.addExtraCredentialBackends()\n",
      "}\n",
      "func (c *ServerCommand) configureSeals(ctx context.Context, config *server.Config, backend physical.Backend, infoKeys []string, info map[string]string) (*SetSealResponse, io.Reader, error) {\n",
      "\texistingSealGenerationInfo, err := vault.PhysicalSealGenInfo(ctx, backend)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, fmt.Errorf(\"Error getting seal generation info: %v\", err)\n",
      "\t}\n",
      "\thasPartialPaths, err := hasPartiallyWrappedPaths(ctx, backend)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, fmt.Errorf(\"Cannot determine if there are partially seal wrapped entries in storage: %v\", err)\n",
      "\t}\n",
      "\tsetSealResponse, err := setSeal(c, config, infoKeys, info, existingSealGenerationInfo, hasPartialPaths)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tif setSealResponse.sealConfigWarning != nil {\n",
      "\t\tc.UI.Warn(fmt.Sprintf(\"Warnings during seal configuration: %v\", setSealResponse.sealConfigWarning))\n",
      "\t}\n",
      "\tif setSealResponse.barrierSeal == nil {\n",
      "\t\treturn nil, nil, errors.New(\"Could not create barrier seal! Most likely proper Seal configuration information was not set, but no error was generated.\")\n",
      "\t}\n",
      "\tentropyAugLogger := c.logger.Named(\"entropy-augmentation\")\n",
      "\tvar entropySources []*configutil.EntropySourcerInfo\n",
      "\tfor _, sealWrapper := range setSealResponse.barrierSeal.GetAccess().GetEnabledSealWrappersByPriority() {\n",
      "\t\tif s, ok := sealWrapper.Wrapper.(entropy.Sourcer); ok {\n",
      "\t\t\tentropySources = append(entropySources, &configutil.EntropySourcerInfo{Sourcer: s, Name: sealWrapper.Name})\n",
      "\t\t}\n",
      "\t}\n",
      "\tsecureRandomReader, err := configutil.CreateSecureRandomReaderFunc(config.SharedConfig, entropySources, entropyAugLogger)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\treturn setSealResponse, secureRandomReader, nil\n",
      "}\n",
      "func newInsecureOcspTransport(extraCas []*x509.Certificate) *http.Transport {\n",
      "\trootCAs, _ := x509.SystemCertPool()\n",
      "\tif rootCAs == nil {\n",
      "\t\trootCAs = x509.NewCertPool()\n",
      "\t}\n",
      "\tfor _, c := range extraCas {\n",
      "\t\trootCAs.AddCert(c)\n",
      "\t}\n",
      "\tconfig := &tls.Config{RootCAs: rootCAs}\n",
      "\treturn &http.Transport{MaxIdleConns: 10, IdleConnTimeout: 30 * time.Minute, Proxy: http.ProxyFromEnvironment, DialContext: (&net.Dialer{Timeout: 30 * time.Second, KeepAlive: 30 * time.Second}).DialContext, TLSClientConfig: config}\n",
      "}\n",
      "func (i *IdentityStore) mergeEntity(ctx context.Context, txn *memdb.Txn, toEntity *identity.Entity, fromEntityIDs, conflictingAliasIDsToKeep []string, force, grabLock, mergePolicies, persist, forceMergeAliases bool) (error, error, []aliasClashInformation) {\n",
      "\tif grabLock {\n",
      "\t\ti.lock.Lock()\n",
      "\t\tdefer i.lock.Unlock()\n",
      "\t}\n",
      "\tif toEntity == nil {\n",
      "\t\treturn errors.New(\"entity id to merge to is invalid\"), nil, nil\n",
      "\t}\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err, nil\n",
      "\t}\n",
      "\tif toEntity.NamespaceID != ns.ID {\n",
      "\t\treturn errors.New(\"entity id to merge into does not belong to the request's namespace\"), nil, nil\n",
      "\t}\n",
      "\tif len(fromEntityIDs) > 1 && len(conflictingAliasIDsToKeep) > 1 {\n",
      "\t\treturn errors.New(\"aliases conflicts cannot be resolved with multiple from entity ids - merge one entity at a time\"), nil, nil\n",
      "\t}\n",
      "\tsanitizedFromEntityIDs := strutil.RemoveDuplicates(fromEntityIDs, false)\n",
      "\tfromEntityAccessors := make(map[string]string)\n",
      "\taliasesInvolvedInClashes := make([]aliasClashInformation, 0)\n",
      "\tvar aliasClashError error\n",
      "\tfor _, fromEntityID := range sanitizedFromEntityIDs {\n",
      "\t\tif fromEntityID == toEntity.ID {\n",
      "\t\t\treturn errors.New(\"to_entity_id should not be present in from_entity_ids\"), nil, nil\n",
      "\t\t}\n",
      "\t\tfromEntity, err := i.MemDBEntityByID(fromEntityID, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t\tif fromEntity == nil {\n",
      "\t\t\tif forceMergeAliases {\n",
      "\t\t\t\treturn fmt.Errorf(\"fromEntity %s was not found in memdb as part of an automated entity merge into %s; storage/memdb may be in a bad state\", fromEntityID, toEntity.ID), nil, nil\n",
      "\t\t\t}\n",
      "\t\t\treturn errors.New(\"entity id to merge from is invalid\"), nil, nil\n",
      "\t\t}\n",
      "\t\tif fromEntity.NamespaceID != toEntity.NamespaceID {\n",
      "\t\t\treturn errors.New(\"entity id to merge from does not belong to this namespace\"), nil, nil\n",
      "\t\t}\n",
      "\t\tif !forceMergeAliases && len(conflictingAliasIDsToKeep) == 0 {\n",
      "\t\t\tfor _, toAlias := range toEntity.Aliases {\n",
      "\t\t\t\tfor _, fromAlias := range fromEntity.Aliases {\n",
      "\t\t\t\t\tid, mountAccessorInAnotherFromEntity := fromEntityAccessors[fromAlias.MountAccessor]\n",
      "\t\t\t\t\tif mountAccessorInAnotherFromEntity && (id != fromEntityID) {\n",
      "\t\t\t\t\t\treturn fmt.Errorf(\"mount accessor %s found in multiple fromEntities, merge should be done with one fromEntity at a time\", fromAlias.MountAccessor), nil, nil\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tfromEntityAccessors[fromAlias.MountAccessor] = fromEntityID\n",
      "\t\t\t\t\tif toAlias.MountAccessor == fromAlias.MountAccessor {\n",
      "\t\t\t\t\t\tif aliasClashError == nil {\n",
      "\t\t\t\t\t\t\taliasClashError = multierror.Append(aliasClashError, fmt.Errorf(\"toEntity and at least one fromEntity have aliases with the same mount accessor, repeat the merge request specifying exactly one fromEntity, clashes: \"))\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\taliasClashError = multierror.Append(aliasClashError, fmt.Errorf(\"mountAccessor: %s, toEntity ID: %s, fromEntity ID: %s, conflicting toEntity alias ID: %s, conflicting fromEntity alias ID: %s\", toAlias.MountAccessor, toEntity.ID, fromEntityID, toAlias.ID, fromAlias.ID))\n",
      "\t\t\t\t\t\tvar toAliasMountType string\n",
      "\t\t\t\t\t\tvar toAliasMountPath string\n",
      "\t\t\t\t\t\tmountValidationRespToAlias := i.router.ValidateMountByAccessor(toAlias.MountAccessor)\n",
      "\t\t\t\t\t\tif mountValidationRespToAlias != nil {\n",
      "\t\t\t\t\t\t\ttoAliasMountType = mountValidationRespToAlias.MountType\n",
      "\t\t\t\t\t\t\ttoAliasMountPath = mountValidationRespToAlias.MountPath\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tvar fromAliasMountType string\n",
      "\t\t\t\t\t\tvar fromAliasMountPath string\n",
      "\t\t\t\t\t\tmountValidationRespFromAlias := i.router.ValidateMountByAccessor(fromAlias.MountAccessor)\n",
      "\t\t\t\t\t\tif mountValidationRespFromAlias != nil {\n",
      "\t\t\t\t\t\t\tfromAliasMountType = mountValidationRespFromAlias.MountType\n",
      "\t\t\t\t\t\t\tfromAliasMountPath = mountValidationRespFromAlias.MountPath\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\taliasesInvolvedInClashes = append(aliasesInvolvedInClashes, aliasClashInformation{Entity: toEntity.Name, EntityId: toEntity.ID, Alias: toAlias.Name, Mount: toAliasMountType, MountPath: toAliasMountPath})\n",
      "\t\t\t\t\t\taliasesInvolvedInClashes = append(aliasesInvolvedInClashes, aliasClashInformation{Entity: fromEntity.Name, EntityId: fromEntityID, Alias: fromAlias.Name, Mount: fromAliasMountType, MountPath: fromAliasMountPath})\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tfor configID, configSecret := range fromEntity.MFASecrets {\n",
      "\t\t\t_, ok := toEntity.MFASecrets[configID]\n",
      "\t\t\tif ok && !force {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"conflicting MFA config ID %q in entity ID %q\", configID, fromEntity.ID), nil\n",
      "\t\t\t} else {\n",
      "\t\t\t\tif toEntity.MFASecrets == nil {\n",
      "\t\t\t\t\ttoEntity.MFASecrets = make(map[string]*mfa.Secret)\n",
      "\t\t\t\t}\n",
      "\t\t\t\ttoEntity.MFASecrets[configID] = configSecret\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif aliasClashError != nil {\n",
      "\t\treturn aliasClashError, nil, aliasesInvolvedInClashes\n",
      "\t}\n",
      "\tisPerfSecondaryOrStandby := i.localNode.ReplicationState().HasState(consts.ReplicationPerformanceSecondary) || i.localNode.HAState() == consts.PerfStandby\n",
      "\tvar fromEntityGroups []*identity.Group\n",
      "\ttoEntityAccessors := make(map[string][]string)\n",
      "\tfor _, alias := range toEntity.Aliases {\n",
      "\t\tif accessors, ok := toEntityAccessors[alias.MountAccessor]; !ok {\n",
      "\t\t\tif accessors == nil {\n",
      "\t\t\t\ttoEntityAccessors[alias.MountAccessor] = []string{alias.ID}\n",
      "\t\t\t} else {\n",
      "\t\t\t\ttoEntityAccessors[alias.MountAccessor] = append(accessors, alias.ID)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor _, fromEntityID := range sanitizedFromEntityIDs {\n",
      "\t\tif fromEntityID == toEntity.ID {\n",
      "\t\t\treturn errors.New(\"to_entity_id should not be present in from_entity_ids\"), nil, nil\n",
      "\t\t}\n",
      "\t\tfromEntity, err := i.MemDBEntityByID(fromEntityID, true)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t\tif fromEntity == nil {\n",
      "\t\t\tif forceMergeAliases {\n",
      "\t\t\t\treturn fmt.Errorf(\"fromEntity %s was not found in memdb as part of an automated entity merge into %s; storage/memdb may be in a bad state\", fromEntityID, toEntity.ID), nil, nil\n",
      "\t\t\t}\n",
      "\t\t\treturn errors.New(\"entity id to merge from is invalid\"), nil, nil\n",
      "\t\t}\n",
      "\t\tif fromEntity.NamespaceID != toEntity.NamespaceID {\n",
      "\t\t\treturn errors.New(\"entity id to merge from does not belong to this namespace\"), nil, nil\n",
      "\t\t}\n",
      "\t\tfor _, fromAlias := range fromEntity.Aliases {\n",
      "\t\t\tif toAliasIds, ok := toEntityAccessors[fromAlias.MountAccessor]; ok {\n",
      "\t\t\t\tfor _, toAliasId := range toAliasIds {\n",
      "\t\t\t\t\tif forceMergeAliases {\n",
      "\t\t\t\t\t\ti.logger.Info(\"Deleting to_entity alias during entity merge\", \"to_entity\", toEntity.ID, \"deleted_alias\", toAliasId)\n",
      "\t\t\t\t\t\terr := i.MemDBDeleteAliasByIDInTxn(txn, toAliasId, false)\n",
      "\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"aborting entity merge - failed to delete orphaned alias %q during merge into entity %q: %w\", toAliasId, toEntity.ID, err), nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t} else if strutil.StrListContains(conflictingAliasIDsToKeep, toAliasId) {\n",
      "\t\t\t\t\t\ti.logger.Info(\"Deleting from_entity alias during entity merge\", \"from_entity\", fromEntityID, \"deleted_alias\", fromAlias.ID)\n",
      "\t\t\t\t\t\terr := i.MemDBDeleteAliasByIDInTxn(txn, fromAlias.ID, false)\n",
      "\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"aborting entity merge - failed to delete orphaned alias %q during merge into entity %q: %w\", fromAlias.ID, toEntity.ID, err), nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t} else if strutil.StrListContains(conflictingAliasIDsToKeep, fromAlias.ID) {\n",
      "\t\t\t\t\t\ti.logger.Info(\"Deleting to_entity alias during entity merge\", \"to_entity\", toEntity.ID, \"deleted_alias\", toAliasId)\n",
      "\t\t\t\t\t\terr := i.MemDBDeleteAliasByIDInTxn(txn, toAliasId, false)\n",
      "\t\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"aborting entity merge - failed to delete orphaned alias %q during merge into entity %q: %w\", toAliasId, toEntity.ID, err), nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\treturn fmt.Errorf(\"conflicting mount accessors in following alias IDs and neither were present in conflicting_alias_ids_to_keep: %s, %s\", fromAlias.ID, toAliasId), nil, nil\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tfromAlias.CanonicalID = toEntity.ID\n",
      "\t\t\tfromAlias.MergedFromCanonicalIDs = append(fromAlias.MergedFromCanonicalIDs, fromEntity.ID)\n",
      "\t\t\terr = i.MemDBUpsertAliasInTxn(txn, fromAlias, false)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to update alias during merge: %w\", err), nil\n",
      "\t\t\t}\n",
      "\t\t\ttoEntity.Aliases = append(toEntity.Aliases, fromAlias)\n",
      "\t\t}\n",
      "\t\tif mergePolicies {\n",
      "\t\t\ttoEntity.Policies = strutil.RemoveDuplicates(strutil.MergeSlices(toEntity.Policies, fromEntity.Policies), false)\n",
      "\t\t}\n",
      "\t\ttoEntity.MergedEntityIDs = append(toEntity.MergedEntityIDs, fromEntity.MergedEntityIDs...)\n",
      "\t\ttoEntity.MergedEntityIDs = append(toEntity.MergedEntityIDs, fromEntity.ID)\n",
      "\t\tgroups, err := i.MemDBGroupsByMemberEntityIDInTxn(txn, fromEntity.ID, true, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t\tfor _, group := range groups {\n",
      "\t\t\tgroup.MemberEntityIDs = strutil.StrListDelete(group.MemberEntityIDs, fromEntity.ID)\n",
      "\t\t\terr = i.UpsertGroupInTxn(ctx, txn, group, persist && !isPerfSecondaryOrStandby)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err, nil\n",
      "\t\t\t}\n",
      "\t\t\tfromEntityGroups = append(fromEntityGroups, group)\n",
      "\t\t}\n",
      "\t\terr = i.MemDBDeleteEntityByIDInTxn(txn, fromEntity.ID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t\tif persist && !isPerfSecondaryOrStandby {\n",
      "\t\t\terr = i.entityPacker.DeleteItem(ctx, fromEntity.ID)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err, nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\terr = i.MemDBUpsertEntityInTxn(txn, toEntity)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err, nil\n",
      "\t}\n",
      "\tfor _, group := range fromEntityGroups {\n",
      "\t\tgroup.MemberEntityIDs = append(group.MemberEntityIDs, toEntity.ID)\n",
      "\t\terr = i.UpsertGroupInTxn(ctx, txn, group, persist && !isPerfSecondaryOrStandby)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tif persist && !isPerfSecondaryOrStandby {\n",
      "\t\ttoEntityAsAny, err := ptypes.MarshalAny(toEntity)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t\titem := &storagepacker.Item{ID: toEntity.ID, Message: toEntityAsAny}\n",
      "\t\terr = i.entityPacker.PutItem(ctx, item)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil, nil, nil\n",
      "}\n",
      "func NewAliCloudAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &alicloudMethod{logger: conf.Logger, mountPath: conf.MountPath, credsFound: make(chan struct{}), stopCh: make(chan struct{})}\n",
      "\tif roleRaw, ok := conf.Config[\"role\"]; !ok {\n",
      "\t\treturn nil, errors.New(\"'role' is required but is not provided\")\n",
      "\t} else {\n",
      "\t\tif a.role, ok = roleRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif regionRaw, ok := conf.Config[\"region\"]; !ok {\n",
      "\t\treturn nil, errors.New(\"'region' is required but is not provided\")\n",
      "\t} else {\n",
      "\t\tif a.region, ok = regionRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'region' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tcredCheckFreqSec := defaultCredCheckFreqSeconds\n",
      "\tif checkFreqRaw, ok := conf.Config[\"credential_poll_interval\"]; ok {\n",
      "\t\tif credFreq, ok := checkFreqRaw.(int); ok && credFreq > 0 {\n",
      "\t\t\tcredCheckFreqSec = credFreq\n",
      "\t\t} else {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'credential_poll_interval' config value to positive int\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tcredConfig := &providers.Configuration{}\n",
      "\tif accessKeyRaw, ok := conf.Config[\"access_key\"]; ok {\n",
      "\t\tif credConfig.AccessKeyID, ok = accessKeyRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'access_key' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif accessSecretRaw, ok := conf.Config[\"access_secret\"]; ok {\n",
      "\t\tif credConfig.AccessKeySecret, ok = accessSecretRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'access_secret' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif accessTokenRaw, ok := conf.Config[\"access_token\"]; ok {\n",
      "\t\tif credConfig.AccessKeyStsToken, ok = accessTokenRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'access_token' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif roleArnRaw, ok := conf.Config[\"role_arn\"]; ok {\n",
      "\t\tif credConfig.RoleArn, ok = roleArnRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'role_arn' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif roleSessionNameRaw, ok := conf.Config[\"role_session_name\"]; ok {\n",
      "\t\tif credConfig.RoleSessionName, ok = roleSessionNameRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'role_session_name' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif roleSessionExpirationRaw, ok := conf.Config[\"role_session_expiration\"]; ok {\n",
      "\t\tif roleSessionExpiration, ok := roleSessionExpirationRaw.(int); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'role_session_expiration' config value to int\")\n",
      "\t\t} else {\n",
      "\t\t\tcredConfig.RoleSessionExpiration = &roleSessionExpiration\n",
      "\t\t}\n",
      "\t}\n",
      "\tif privateKeyRaw, ok := conf.Config[\"private_key\"]; ok {\n",
      "\t\tif credConfig.PrivateKey, ok = privateKeyRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'private_key' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif publicKeyIdRaw, ok := conf.Config[\"public_key_id\"]; ok {\n",
      "\t\tif credConfig.PublicKeyID, ok = publicKeyIdRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'public_key_id' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif sessionExpirationRaw, ok := conf.Config[\"session_expiration\"]; ok {\n",
      "\t\tif sessionExpiration, ok := sessionExpirationRaw.(int); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'session_expiration' config value to int\")\n",
      "\t\t} else {\n",
      "\t\t\tcredConfig.SessionExpiration = &sessionExpiration\n",
      "\t\t}\n",
      "\t}\n",
      "\tif roleNameRaw, ok := conf.Config[\"role_name\"]; ok {\n",
      "\t\tif credConfig.RoleName, ok = roleNameRaw.(string); !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'role_name' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tcredentialChain := []providers.Provider{providers.NewEnvCredentialProvider(), providers.NewConfigurationCredentialProvider(credConfig), providers.NewInstanceMetadataProvider()}\n",
      "\tcredProvider := providers.NewChainProvider(credentialChain)\n",
      "\tlastCreds, err := credProvider.Retrieve()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\ta.lastCreds = lastCreds\n",
      "\tgo a.pollForCreds(credProvider, credCheckFreqSec)\n",
      "\treturn a, nil\n",
      "}\n",
      "func (c *ProxyCommand) applyConfigOverrides(f *FlagSets, config *proxyConfig.Config) {\n",
      "\tif config.Vault == nil {\n",
      "\t\tconfig.Vault = &proxyConfig.Vault{}\n",
      "\t}\n",
      "\tf.applyLogConfigOverrides(config.SharedConfig)\n",
      "\tf.Visit(func(fl *flag.Flag) {\n",
      "\t\tif fl.Name == flagNameProxyExitAfterAuth {\n",
      "\t\t\tconfig.ExitAfterAuth = c.flagExitAfterAuth\n",
      "\t\t}\n",
      "\t})\n",
      "\tc.setStringFlag(f, config.Vault.Address, &StringVar{Name: flagNameAddress, Target: &c.flagAddress, Default: \"https://127.0.0.1:8200\", EnvVar: api.EnvVaultAddress})\n",
      "\tconfig.Vault.Address = c.flagAddress\n",
      "\tc.setStringFlag(f, config.Vault.CACert, &StringVar{Name: flagNameCACert, Target: &c.flagCACert, Default: \"\", EnvVar: api.EnvVaultCACert})\n",
      "\tconfig.Vault.CACert = c.flagCACert\n",
      "\tc.setStringFlag(f, config.Vault.CAPath, &StringVar{Name: flagNameCAPath, Target: &c.flagCAPath, Default: \"\", EnvVar: api.EnvVaultCAPath})\n",
      "\tconfig.Vault.CAPath = c.flagCAPath\n",
      "\tc.setStringFlag(f, config.Vault.ClientCert, &StringVar{Name: flagNameClientCert, Target: &c.flagClientCert, Default: \"\", EnvVar: api.EnvVaultClientCert})\n",
      "\tconfig.Vault.ClientCert = c.flagClientCert\n",
      "\tc.setStringFlag(f, config.Vault.ClientKey, &StringVar{Name: flagNameClientKey, Target: &c.flagClientKey, Default: \"\", EnvVar: api.EnvVaultClientKey})\n",
      "\tconfig.Vault.ClientKey = c.flagClientKey\n",
      "\tc.setBoolFlag(f, config.Vault.TLSSkipVerify, &BoolVar{Name: flagNameTLSSkipVerify, Target: &c.flagTLSSkipVerify, Default: false, EnvVar: api.EnvVaultSkipVerify})\n",
      "\tconfig.Vault.TLSSkipVerify = c.flagTLSSkipVerify\n",
      "\tc.setStringFlag(f, config.Vault.TLSServerName, &StringVar{Name: flagTLSServerName, Target: &c.flagTLSServerName, Default: \"\", EnvVar: api.EnvVaultTLSServerName})\n",
      "\tconfig.Vault.TLSServerName = c.flagTLSServerName\n",
      "}\n",
      "func (c *OperatorDiagnoseCommand) Flags() *FlagSets {\n",
      "\tset := NewFlagSets(c.UI)\n",
      "\tf := set.NewFlagSet(\"Command Options\")\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"config\", Target: &c.flagConfigs, Completion: complete.PredictOr(complete.PredictFiles(\"*.hcl\"), complete.PredictFiles(\"*.json\"), complete.PredictDirs(\"*\")), Usage: \"Path to a Vault configuration file or directory of configuration \" + \"files. This flag can be specified multiple times to load multiple \" + \"configurations. If the path is a directory, all files which end in \" + \".hcl or .json are loaded.\"})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"skip\", Target: &c.flagSkips, Usage: \"Skip the health checks named as arguments. May be 'listener', 'storage', or 'autounseal'.\"})\n",
      "\tf.BoolVar(&BoolVar{Name: \"debug\", Target: &c.flagDebug, Default: false, Usage: \"Dump all information collected by Diagnose.\"})\n",
      "\tf.StringVar(&StringVar{Name: \"format\", Target: &c.flagFormat, Usage: \"The output format\"})\n",
      "\treturn set\n",
      "}\n",
      "func (h *CLIHandler) Help() string {\n",
      "\thelp := `\n",
      "Usage: vault login -method=github [CONFIG K=V...]\n",
      "\n",
      "  The GitHub auth method allows users to authenticate using a GitHub\n",
      "  personal access token. Users can generate a personal access token from the\n",
      "  settings page on their GitHub account.\n",
      "\n",
      "  Authenticate using a GitHub token:\n",
      "\n",
      "      $ vault login -method=github token=abcd1234\n",
      "\n",
      "Configuration:\n",
      "\n",
      "  mount=<string>\n",
      "      Path where the GitHub credential method is mounted. This is usually\n",
      "      provided via the -path flag in the \"vault login\" command, but it can be\n",
      "      specified here as well. If specified here, it takes precedence over the\n",
      "      value for -path. The default value is \"github\".\n",
      "\n",
      "  token=<string>\n",
      "      GitHub personal access token to use for authentication. If not provided,\n",
      "      Vault will prompt for the value.\n",
      "`\n",
      "\treturn strings.TrimSpace(help)\n",
      "}\n",
      "func (c *SSHCommand) handleTypeOTP(username, ip, port string, sshArgs []string) int {\n",
      "\tsecret, cred, err := c.generateCredential(username, ip)\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"failed to generate credential: %s\", err))\n",
      "\t\treturn 2\n",
      "\t}\n",
      "\tif c.flagNoExec {\n",
      "\t\tif c.flagField != \"\" {\n",
      "\t\t\treturn PrintRawField(c.UI, secret, c.flagField)\n",
      "\t\t}\n",
      "\t\treturn OutputSecret(c.UI, secret)\n",
      "\t}\n",
      "\tvar cmd *exec.Cmd\n",
      "\targs := make([]string, 0)\n",
      "\tenv := os.Environ()\n",
      "\tsshCmd := c.flagSSHExecutable\n",
      "\tsshpassPath, err := exec.LookPath(\"sshpass\")\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Warn(wrapAtLength(\"Vault could not locate \\\"sshpass\\\". The OTP code for the session is \" + \"displayed below. Enter this code in the SSH password prompt. If you \" + \"install sshpass, Vault can automatically perform this step for you.\"))\n",
      "\t\tc.UI.Output(\"OTP for the session is: \" + cred.Key)\n",
      "\t} else {\n",
      "\t\tsshCmd = sshpassPath\n",
      "\t\targs = append(args, \"-e\", c.flagSSHExecutable)\n",
      "\t\tenv = append(env, fmt.Sprintf(\"SSHPASS=%s\", string(cred.Key)))\n",
      "\t}\n",
      "\tif c.flagUserKnownHostsFile != \"\" {\n",
      "\t\targs = append(args, \"-o UserKnownHostsFile=\"+c.flagUserKnownHostsFile)\n",
      "\t}\n",
      "\tif port == \"\" {\n",
      "\t\targs = append(args, \"-p\", cred.Port)\n",
      "\t}\n",
      "\targs = append(args, \"-o StrictHostKeyChecking=\"+c.flagStrictHostKeyChecking)\n",
      "\targs = append(args, sshArgs...)\n",
      "\tcmd = exec.Command(sshCmd, args...)\n",
      "\tcmd.Env = env\n",
      "\tcmd.Stdin = os.Stdin\n",
      "\tcmd.Stdout = os.Stdout\n",
      "\tcmd.Stderr = os.Stderr\n",
      "\terr = cmd.Run()\n",
      "\tif err != nil {\n",
      "\t\texitCode := 2\n",
      "\t\tif exitError, ok := err.(*exec.ExitError); ok {\n",
      "\t\t\tif exitError.Success() {\n",
      "\t\t\t\treturn 0\n",
      "\t\t\t}\n",
      "\t\t\tif ws, ok := exitError.Sys().(syscall.WaitStatus); ok {\n",
      "\t\t\t\texitCode = ws.ExitStatus()\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"failed to run ssh command: %s\", err))\n",
      "\t\treturn exitCode\n",
      "\t}\n",
      "\tif err := c.client.Sys().Revoke(secret.LeaseID); err != nil {\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"failed to revoke key: %s\", err))\n",
      "\t\treturn 2\n",
      "\t}\n",
      "\treturn 0\n",
      "}\n",
      "func (b *SystemBackend) handleQuotasConfigRead() framework.OperationFunc {\n",
      "\treturn func(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\t\tconfig := b.Core.quotaManager.Config()\n",
      "\t\treturn &logical.Response{Data: map[string]interface{}{\"enable_rate_limit_audit_logging\": config.EnableRateLimitAuditLogging, \"enable_rate_limit_response_headers\": config.EnableRateLimitResponseHeaders, \"rate_limit_exempt_paths\": config.RateLimitExemptPaths, \"absolute_rate_limit_exempt_paths\": config.AbsoluteRateLimitExemptPaths}}, nil\n",
      "\t}\n",
      "}\n",
      "func (b *backend) pathStaticRolesWrite(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tconfig := staticRoleEntry{}\n",
      "\tisCreate := req.Operation == logical.CreateOperation\n",
      "\tif rawRoleName, ok := data.GetOk(paramRoleName); ok {\n",
      "\t\tconfig.Name = rawRoleName.(string)\n",
      "\t\tif err := b.validateRoleName(config.Name); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\treturn logical.ErrorResponse(\"missing %q parameter\", paramRoleName), nil\n",
      "\t}\n",
      "\tentry, err := req.Storage.Get(ctx, formatRoleStoragePath(config.Name))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"couldn't check storage for pre-existing role: %w\", err)\n",
      "\t}\n",
      "\tif entry != nil {\n",
      "\t\terr = entry.DecodeJSON(&config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"couldn't convert existing role into config struct: %w\", err)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tisCreate = true\n",
      "\t}\n",
      "\tif rawUsername, ok := data.GetOk(paramUsername); ok {\n",
      "\t\tconfig.Username = rawUsername.(string)\n",
      "\t\tif err := b.validateIAMUserExists(ctx, req.Storage, &config, isCreate); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t} else if isCreate {\n",
      "\t\treturn logical.ErrorResponse(\"missing %q parameter\", paramUsername), nil\n",
      "\t}\n",
      "\tif rawRotationPeriod, ok := data.GetOk(paramRotationPeriod); ok {\n",
      "\t\tconfig.RotationPeriod = time.Duration(rawRotationPeriod.(int)) * time.Second\n",
      "\t\tif err := b.validateRotationPeriod(config.RotationPeriod); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t} else if isCreate {\n",
      "\t\treturn logical.ErrorResponse(\"missing %q parameter\", paramRotationPeriod), nil\n",
      "\t}\n",
      "\tb.roleMutex.Lock()\n",
      "\tdefer b.roleMutex.Unlock()\n",
      "\tnewRole, err := logical.StorageEntryJSON(formatRoleStoragePath(config.Name), config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to marshal object to JSON: %w\", err)\n",
      "\t}\n",
      "\terr = req.Storage.Put(ctx, newRole)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to save object in storage: %w\", err)\n",
      "\t}\n",
      "\texistingCreds, err := req.Storage.Get(ctx, formatCredsStoragePath(config.Name))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"unable to verify if credentials already exist for role %q: %w\", config.Name, err)\n",
      "\t}\n",
      "\tif existingCreds == nil {\n",
      "\t\terr := b.createCredential(ctx, req.Storage, config, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to create new credentials for role %q: %w\", config.Name, err)\n",
      "\t\t}\n",
      "\t\terr = b.credRotationQueue.Push(&queue.Item{Key: config.Name, Value: config, Priority: time.Now().Add(config.RotationPeriod).Unix()})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to add item into the rotation queue for role %q: %w\", config.Name, err)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\ti, err := b.credRotationQueue.PopByKey(config.Name)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"expected an item with name %q, but got an error: %w\", config.Name, err)\n",
      "\t\t}\n",
      "\t\ti.Value = config\n",
      "\t\ti.Priority = time.Now().Add(config.RotationPeriod).Unix()\n",
      "\t\terr = b.credRotationQueue.Push(i)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to add updated item into the rotation queue for role %q: %w\", config.Name, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn &logical.Response{Data: formatResponse(config)}, nil\n",
      "}\n",
      "func (b *Backend) Setup(ctx context.Context, config *logical.BackendConfig) error {\n",
      "\tb.logger = config.Logger\n",
      "\tb.system = config.System\n",
      "\tb.events = config.EventsSender\n",
      "\treturn nil\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBUpsertMFALoginEnforcementConfig(ctx context.Context, eConfig *mfa.MFAEnforcementConfig) error {\n",
      "\tif eConfig == nil {\n",
      "\t\treturn fmt.Errorf(\"config is nil\")\n",
      "\t}\n",
      "\ttxn := b.db.Txn(true)\n",
      "\tdefer txn.Abort()\n",
      "\teConfigRaw, err := txn.First(memDBMFALoginEnforcementsTable, \"nameAndNamespace\", eConfig.Name, eConfig.NamespaceID)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to lookup MFA login enforcement config from MemDB using name: %w\", err)\n",
      "\t}\n",
      "\tif eConfigRaw != nil {\n",
      "\t\terr = txn.Delete(memDBMFALoginEnforcementsTable, eConfigRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to delete MFA login enforcement config from MemDB: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := txn.Insert(memDBMFALoginEnforcementsTable, eConfig); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to update MFA login enforcement config in MemDB: %w\", err)\n",
      "\t}\n",
      "\ttxn.Commit()\n",
      "\treturn nil\n",
      "}\n",
      "func (b *MFABackend) MemDBUpsertMFAConfigInTxn(txn *memdb.Txn, mConfig *mfa.Config) error {\n",
      "\tif txn == nil {\n",
      "\t\treturn fmt.Errorf(\"nil txn\")\n",
      "\t}\n",
      "\tif mConfig == nil {\n",
      "\t\treturn fmt.Errorf(\"config is nil\")\n",
      "\t}\n",
      "\tmConfigRaw, err := txn.First(b.methodTable, \"id\", mConfig.ID)\n",
      "\tif err != nil {\n",
      "\t\treturn errwrap.Wrapf(\"failed to lookup MFA config from MemDB using id: {{err}}\", err)\n",
      "\t}\n",
      "\tif mConfigRaw != nil {\n",
      "\t\terr = txn.Delete(b.methodTable, mConfigRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errwrap.Wrapf(\"failed to delete MFA config from MemDB: {{err}}\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err := txn.Insert(b.methodTable, mConfig); err != nil {\n",
      "\t\treturn errwrap.Wrapf(\"failed to update MFA config into MemDB: {{err}}\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (b *backend) doTidyAcme(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tb.acmeAccountLock.Lock()\n",
      "\tdefer b.acmeAccountLock.Unlock()\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tthumbprints, err := sc.Storage.List(ctx, acmeThumbprintPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tb.tidyStatusLock.Lock()\n",
      "\tb.tidyStatus.acmeAccountsCount = uint(len(thumbprints))\n",
      "\tb.tidyStatusLock.Unlock()\n",
      "\tfor _, thumbprint := range thumbprints {\n",
      "\t\terr := b.tidyAcmeAccountByThumbprint(b.GetAcmeState(), sc, thumbprint, config.SafetyBuffer, config.AcmeAccountSafetyBuffer)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlogger.Warn(\"error tidying account %v: %v\", thumbprint, err.Error())\n",
      "\t\t}\n",
      "\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\treturn tidyCancelledError\n",
      "\t\t}\n",
      "\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\tb.acmeAccountLock.Unlock()\n",
      "\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t\tb.acmeAccountLock.Lock()\n",
      "\t\t}\n",
      "\t}\n",
      "\teabIds, err := b.GetAcmeState().ListEabIds(sc)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed listing EAB ids: %w\", err)\n",
      "\t}\n",
      "\tfor _, eabId := range eabIds {\n",
      "\t\teab, err := b.GetAcmeState().LoadEab(sc, eabId)\n",
      "\t\tif err != nil {\n",
      "\t\t\tif errors.Is(err, ErrStorageItemNotFound) {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\teabExpiration := eab.CreatedOn.Add(config.AcmeAccountSafetyBuffer)\n",
      "\t\tif time.Now().After(eabExpiration) {\n",
      "\t\t\t_, err := b.GetAcmeState().DeleteEab(sc, eabId)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"failed to tidy eab %s: %w\", eabId, err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\treturn tidyCancelledError\n",
      "\t\t}\n",
      "\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\tb.acmeAccountLock.Unlock()\n",
      "\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t\tb.acmeAccountLock.Lock()\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func toClientTLSConfig(certificatePEM string, privateKeyPEM string, caChainPEMs []string, tlsMinVersion uint16, serverName string, insecureSkipVerify bool) (*tls.Config, error) {\n",
      "\tif certificatePEM != \"\" && privateKeyPEM == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"found certificate for client-side TLS authentication but no private key\")\n",
      "\t} else if certificatePEM == \"\" && privateKeyPEM != \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"found private key for client-side TLS authentication but no certificate\")\n",
      "\t}\n",
      "\tvar certificates []tls.Certificate\n",
      "\tif certificatePEM != \"\" {\n",
      "\t\tcertificate, err := tls.X509KeyPair([]byte(certificatePEM), []byte(privateKeyPEM))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to parse certificate and private key pair: %w\", err)\n",
      "\t\t}\n",
      "\t\tcertificates = append(certificates, certificate)\n",
      "\t}\n",
      "\tvar rootCAs *x509.CertPool\n",
      "\tif len(caChainPEMs) > 0 {\n",
      "\t\trootCAs = x509.NewCertPool()\n",
      "\t\tfor _, caBlock := range caChainPEMs {\n",
      "\t\t\tok := rootCAs.AppendCertsFromPEM([]byte(caBlock))\n",
      "\t\t\tif !ok {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to add CA certificate to certificate pool: it may be malformed or empty\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig := &tls.Config{Certificates: certificates, RootCAs: rootCAs, ServerName: serverName, InsecureSkipVerify: insecureSkipVerify, MinVersion: tlsMinVersion}\n",
      "\treturn config, nil\n",
      "}\n",
      "func SetupPluginCatalog(ctx context.Context, in *PluginCatalogInput) (*PluginCatalog, error) {\n",
      "\tlogger := in.Logger\n",
      "\tcatalog := &PluginCatalog{builtinRegistry: in.BuiltinRegistry, catalogView: in.CatalogView, directory: in.PluginDirectory, tmpdir: in.Tmpdir, logger: logger, mlockPlugins: in.EnableMlock, wrapper: logical.StaticSystemView{VersionString: version.GetVersion().Version}, runtimeCatalog: in.PluginRuntimeCatalog}\n",
      "\terr := catalog.upgradePlugins(ctx, logger)\n",
      "\tif err != nil {\n",
      "\t\tlogger.Error(\"error while upgrading plugin storage\", \"error\", err)\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif legacy, _ := strconv.ParseBool(os.Getenv(pluginutil.PluginUseLegacyEnvLayering)); legacy {\n",
      "\t\tconflicts := false\n",
      "\t\tosKeys := envKeys(os.Environ())\n",
      "\t\tplugins, err := catalog.collectAllPlugins(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tfor _, plugin := range plugins {\n",
      "\t\t\tpluginKeys := envKeys(plugin.Env)\n",
      "\t\t\tfor k := range pluginKeys {\n",
      "\t\t\t\tif _, ok := osKeys[k]; ok {\n",
      "\t\t\t\t\tconflicts = true\n",
      "\t\t\t\t\tlogger.Warn(\"conflict between system and plugin environment variable\", \"type\", plugin.Type, \"name\", plugin.Name, \"version\", plugin.Version, \"variable\", k)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif conflicts {\n",
      "\t\t\tlogger.Warn(\"conflicts found between system and plugin environment variables, \"+\"system environment variables will take precedence until flag is disabled\", pluginutil.PluginUseLegacyEnvLayering, os.Getenv(pluginutil.PluginUseLegacyEnvLayering))\n",
      "\t\t} else {\n",
      "\t\t\tlogger.Info(\"no conflicts found between system and plugin environment variables\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tlogger.Info(\"successfully setup plugin catalog\", \"plugin-directory\", catalog.directory)\n",
      "\tif catalog.tmpdir != \"\" {\n",
      "\t\tlogger.Debug(\"plugin temporary directory configured\", \"tmpdir\", catalog.tmpdir)\n",
      "\t}\n",
      "\treturn catalog, nil\n",
      "}\n",
      "func (b *LoginMFABackend) mfaLoginEnforcementList(ctx context.Context) ([]string, map[string]interface{}, error) {\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tws := memdb.NewWatchSet()\n",
      "\ttxn := b.db.Txn(false)\n",
      "\titer, err := txn.Get(memDBMFALoginEnforcementsTable, \"namespace\", ns.ID)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, fmt.Errorf(\"failed to fetch iterator for login enforcement configs in memdb: %w\", err)\n",
      "\t}\n",
      "\tws.Add(iter.WatchCh())\n",
      "\tvar keys []string\n",
      "\tenforcementInfo := map[string]interface{}{}\n",
      "\tfor {\n",
      "\t\tselect {\n",
      "\t\tcase <-ctx.Done():\n",
      "\t\t\treturn keys, enforcementInfo, nil\n",
      "\t\tdefault:\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\traw := iter.Next()\n",
      "\t\tif raw == nil {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\tconfig := raw.(*mfa.MFAEnforcementConfig)\n",
      "\t\tkeys = append(keys, config.Name)\n",
      "\t\tconfigInfoEntry, err := b.mfaLoginEnforcementConfigToMap(config)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, fmt.Errorf(\"failed to convert enforcement to map: %w\", err)\n",
      "\t\t}\n",
      "\t\tenforcementInfo[config.Name] = configInfoEntry\n",
      "\t}\n",
      "\treturn keys, enforcementInfo, nil\n",
      "}\n",
      "func (b *backendGRPCPluginServer) Setup(ctx context.Context, args *pb.SetupArgs) (*pb.SetupReply, error) {\n",
      "\tvar err error\n",
      "\tid := singleImplementationID\n",
      "\tif b.multiplexingSupport {\n",
      "\t\tid, err = pluginutil.GetMultiplexIDFromContext(ctx)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn &pb.SetupReply{}, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tbrokeredClient, err := b.broker.Dial(args.BrokerID)\n",
      "\tif err != nil {\n",
      "\t\treturn &pb.SetupReply{}, err\n",
      "\t}\n",
      "\tstorage := newGRPCStorageClient(brokeredClient)\n",
      "\tsysView := newGRPCSystemView(brokeredClient)\n",
      "\tevents := newGRPCEventsClient(brokeredClient)\n",
      "\tconfig := &logical.BackendConfig{StorageView: storage, Logger: b.logger, System: sysView, Config: args.Config, BackendUUID: args.BackendUUID, EventsSender: events}\n",
      "\tbackend, err := b.factory(ctx, config)\n",
      "\tif err != nil {\n",
      "\t\treturn &pb.SetupReply{Err: pb.ErrToString(err)}, nil\n",
      "\t}\n",
      "\tb.instancesLock.Lock()\n",
      "\tdefer b.instancesLock.Unlock()\n",
      "\tb.instances[id] = backendInstance{brokeredClient: brokeredClient, backend: backend}\n",
      "\treturn &pb.SetupReply{}, nil\n",
      "}\n",
      "func (s *Server) Run(ctx context.Context, incomingVaultToken chan string) error {\n",
      "\tlatestToken := new(string)\n",
      "\ts.logger.Info(\"starting exec server\")\n",
      "\tdefer func() {\n",
      "\t\ts.logger.Info(\"exec server stopped\")\n",
      "\t}()\n",
      "\tif len(s.config.AgentConfig.EnvTemplates) == 0 || s.config.AgentConfig.Exec == nil {\n",
      "\t\ts.logger.Info(\"no env templates or exec config, exiting\")\n",
      "\t\t<-ctx.Done()\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tmanagerConfig := ctmanager.ManagerConfig{AgentConfig: s.config.AgentConfig, Namespace: s.config.Namespace, LogLevel: s.config.LogLevel, LogWriter: s.config.LogWriter}\n",
      "\trunnerConfig, err := ctmanager.NewConfig(managerConfig, s.config.AgentConfig.EnvTemplates)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"template server failed to generate runner config: %w\", err)\n",
      "\t}\n",
      "\ts.runner, err = manager.NewRunner(runnerConfig, true)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"template server failed to create: %w\", err)\n",
      "\t}\n",
      "\ts.runner.SetOutStream(io.Discard)\n",
      "\ts.numberOfTemplates = len(s.runner.TemplateConfigMapping())\n",
      "\tvar debounceTimer *time.Timer\n",
      "\trestartChildProcessErrCh := make(chan error)\n",
      "\trestartBackoff := backoff.NewBackoff(math.MaxInt, consts.DefaultMinBackoff, consts.DefaultMaxBackoff)\n",
      "\tfor {\n",
      "\t\tselect {\n",
      "\t\tcase <-ctx.Done():\n",
      "\t\t\ts.runner.Stop()\n",
      "\t\t\ts.childProcessLock.Lock()\n",
      "\t\t\tif s.childProcess != nil {\n",
      "\t\t\t\ts.childProcess.Stop()\n",
      "\t\t\t}\n",
      "\t\t\ts.childProcessState = childProcessStateStopped\n",
      "\t\t\ts.close()\n",
      "\t\t\ts.childProcessLock.Unlock()\n",
      "\t\t\treturn nil\n",
      "\t\tcase token := <-incomingVaultToken:\n",
      "\t\t\tif token != *latestToken {\n",
      "\t\t\t\ts.logger.Info(\"exec server received new token\")\n",
      "\t\t\t\ts.runner.Stop()\n",
      "\t\t\t\t*latestToken = token\n",
      "\t\t\t\tnewTokenConfig := ctconfig.Config{Vault: &ctconfig.VaultConfig{Token: latestToken, ClientUserAgent: pointerutil.StringPtr(useragent.AgentTemplatingString())}}\n",
      "\t\t\t\trunnerConfig = runnerConfig.Merge(&newTokenConfig)\n",
      "\t\t\t\ts.runner, err = manager.NewRunner(runnerConfig, true)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\ts.logger.Error(\"template server failed with new Vault token\", \"error\", err)\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\ts.runner.SetOutStream(io.Discard)\n",
      "\t\t\t\tgo s.runner.Start()\n",
      "\t\t\t}\n",
      "\t\tcase err := <-s.runner.ErrCh:\n",
      "\t\t\ts.logger.Error(\"template server error\", \"error\", err.Error())\n",
      "\t\t\ts.runner.StopImmediately()\n",
      "\t\t\tif s.config.AgentConfig.TemplateConfig != nil && s.config.AgentConfig.TemplateConfig.ExitOnRetryFailure {\n",
      "\t\t\t\treturn fmt.Errorf(\"template server: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tsleep, err := restartBackoff.Next()\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\ts.logger.Error(\"template server: reached maximum number restart attempts\")\n",
      "\t\t\t\trestartBackoff.Reset()\n",
      "\t\t\t}\n",
      "\t\t\ts.logger.Warn(fmt.Sprintf(\"template server restart: retry attempt after %s\", sleep))\n",
      "\t\t\ttime.Sleep(sleep)\n",
      "\t\t\ts.runner, err = manager.NewRunner(runnerConfig, true)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"template server failed to create: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tgo s.runner.Start()\n",
      "\t\tcase <-s.runner.TemplateRenderedCh():\n",
      "\t\t\ts.logger.Trace(\"template rendered\")\n",
      "\t\t\tevents := s.runner.RenderEvents()\n",
      "\t\t\tif len(events) < s.numberOfTemplates {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tdoneRendering := true\n",
      "\t\t\tvar renderedEnvVars []string\n",
      "\t\t\tfor _, event := range events {\n",
      "\t\t\t\tif event.LastWouldRender.IsZero() {\n",
      "\t\t\t\t\tdoneRendering = false\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tfor _, tcfg := range event.TemplateConfigs {\n",
      "\t\t\t\t\t\tenvVar := fmt.Sprintf(\"%s=%s\", *tcfg.MapToEnvironmentVariable, event.Contents)\n",
      "\t\t\t\t\t\trenderedEnvVars = append(renderedEnvVars, envVar)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif !doneRendering {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tsort.Strings(renderedEnvVars)\n",
      "\t\t\ts.logger.Trace(\"done rendering templates\")\n",
      "\t\t\tif slices.Equal(s.lastRenderedEnvVars, renderedEnvVars) {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\ts.lastRenderedEnvVars = renderedEnvVars\n",
      "\t\t\ts.logger.Debug(\"detected a change in the environment variables: restarting the child process\")\n",
      "\t\t\tif debounceTimer != nil {\n",
      "\t\t\t\tdebounceTimer.Stop()\n",
      "\t\t\t}\n",
      "\t\t\tdebounceTimer = time.AfterFunc(2*time.Second, func() {\n",
      "\t\t\t\tif err := s.restartChildProcess(renderedEnvVars); err != nil {\n",
      "\t\t\t\t\trestartChildProcessErrCh <- fmt.Errorf(\"unable to restart the child process: %w\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t})\n",
      "\t\tcase err := <-restartChildProcessErrCh:\n",
      "\t\t\treturn err\n",
      "\t\tcase exitCode := <-s.childProcessExitCh:\n",
      "\t\t\treturn &ProcessExitError{ExitCode: exitCode}\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (vpm *VaultPkiMount) UpdateRole(roleName string, config map[string]interface{}) error {\n",
      "\tdefaults := map[string]interface{}{}\n",
      "\t_, err := vpm.GetActiveNode().Logical().WriteWithContext(context.Background(), vpm.mount+\"/roles/\"+roleName, mergeWithDefaults(config, defaults))\n",
      "\treturn err\n",
      "}\n",
      "func (c *ServerCommand) reloadSeals(ctx context.Context, core *vault.Core, config *server.Config) (*SetSealResponse, error) {\n",
      "\tif len(config.Seals) == 1 && config.Seals[0].Disabled {\n",
      "\t\treturn nil, errors.New(\"moving from autoseal to shamir requires seal migration\")\n",
      "\t}\n",
      "\tif core.SealAccess().BarrierSealConfigType() == vault.SealConfigTypeShamir {\n",
      "\t\treturn nil, errors.New(\"moving from shamir to autoseal requires seal migration\")\n",
      "\t}\n",
      "\tinfoKeysReload := make([]string, 0)\n",
      "\tinfoReload := make(map[string]string)\n",
      "\tsetSealResponse, secureRandomReader, err := c.configureSeals(ctx, config, core.PhysicalAccess(), infoKeysReload, infoReload)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif setSealResponse.sealConfigError != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tnewGen := setSealResponse.barrierSeal.GetAccess().GetSealGenerationInfo()\n",
      "\terr = core.SetSeals(setSealResponse.barrierSeal, secureRandomReader, !newGen.IsRewrapped() || setSealResponse.hasPartiallyWrappedPaths)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error setting seal: %s\", err)\n",
      "\t}\n",
      "\tif err := core.SetPhysicalSealGenInfo(ctx, newGen); err != nil {\n",
      "\t\tc.logger.Warn(\"could not update seal information in storage\", \"err\", err)\n",
      "\t}\n",
      "\treturn setSealResponse, nil\n",
      "}\n",
      "func NewAzureAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\ta := &azureMethod{logger: conf.Logger, mountPath: conf.MountPath}\n",
      "\troleRaw, ok := conf.Config[\"role\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role' value\")\n",
      "\t}\n",
      "\ta.role, ok = roleRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t}\n",
      "\tresourceRaw, ok := conf.Config[\"resource\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'resource' value\")\n",
      "\t}\n",
      "\ta.resource, ok = resourceRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'resource' config value to string\")\n",
      "\t}\n",
      "\tobjectIDRaw, ok := conf.Config[\"object_id\"]\n",
      "\tif ok {\n",
      "\t\ta.objectID, ok = objectIDRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'object_id' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tclientIDRaw, ok := conf.Config[\"client_id\"]\n",
      "\tif ok {\n",
      "\t\ta.clientID, ok = clientIDRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'client_id' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tscopeRaw, ok := conf.Config[\"scope\"]\n",
      "\tif ok {\n",
      "\t\ta.scope, ok = scopeRaw.(string)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, errors.New(\"could not convert 'scope' config value to string\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif a.scope == \"\" {\n",
      "\t\ta.scope = fmt.Sprintf(\"%s/.default\", a.resource)\n",
      "\t}\n",
      "\tauthenticateFromEnvironmentRaw, ok := conf.Config[\"authenticate_from_environment\"]\n",
      "\tif ok {\n",
      "\t\tauthenticateFromEnvironment, err := parseutil.ParseBool(authenticateFromEnvironmentRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"could not convert 'authenticate_from_environment' config value to bool: %w\", err)\n",
      "\t\t}\n",
      "\t\ta.authenticateFromEnvironment = authenticateFromEnvironment\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase a.role == \"\":\n",
      "\t\treturn nil, errors.New(\"'role' value is empty\")\n",
      "\tcase a.resource == \"\":\n",
      "\t\treturn nil, errors.New(\"'resource' value is empty\")\n",
      "\tcase a.objectID != \"\" && a.clientID != \"\":\n",
      "\t\treturn nil, errors.New(\"only one of 'object_id' or 'client_id' may be provided\")\n",
      "\t}\n",
      "\treturn a, nil\n",
      "}\n",
      "func (b *backend) acmeRevocationByPoP(acmeCtx *acmeContext, userCtx *jwsCtx, cert *x509.Certificate, config *crlConfig) (*logical.Response, error) {\n",
      "\tgivenPublic, ok := userCtx.Key.Key.(crypto.PublicKey)\n",
      "\tif !ok {\n",
      "\t\treturn nil, fmt.Errorf(\"unable to revoke certificate: unable to parse message header's JWS key of type (%T): %w\", userCtx.Key.Key, ErrMalformed)\n",
      "\t}\n",
      "\tif err := validatePublicKeyMatchesCert(givenPublic, cert); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"unable to revoke certificate: unable to verify proof of possession of private key provided by proxy: %v: %w\", err, ErrMalformed)\n",
      "\t}\n",
      "\tb.GetRevokeStorageLock().Lock()\n",
      "\tdefer b.GetRevokeStorageLock().Unlock()\n",
      "\treturn revokeCert(acmeCtx.sc, config, cert)\n",
      "}\n",
      "func (c *Core) buildMfaEnforcementResponse(eConfig *mfa.MFAEnforcementConfig) (*logical.MFAConstraintAny, error) {\n",
      "\tmfaAny := &logical.MFAConstraintAny{Any: []*logical.MFAMethodID{}}\n",
      "\tfor _, methodID := range eConfig.MFAMethodIDs {\n",
      "\t\tmConfig, err := c.loginMFABackend.MemDBMFAConfigByID(methodID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to get methodID %s from MFA config table, error: %v\", methodID, err)\n",
      "\t\t}\n",
      "\t\tvar duoUsePasscode bool\n",
      "\t\tif mConfig.Type == mfaMethodTypeDuo {\n",
      "\t\t\tduoConf, ok := mConfig.Config.(*mfa.Config_DuoConfig)\n",
      "\t\t\tif !ok {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"invalid MFA configuration type\")\n",
      "\t\t\t}\n",
      "\t\t\tduoUsePasscode = duoConf.DuoConfig.UsePasscode\n",
      "\t\t}\n",
      "\t\tmfaMethod := &logical.MFAMethodID{Type: mConfig.Type, ID: methodID, UsesPasscode: mConfig.Type == mfaMethodTypeTOTP || duoUsePasscode, Name: mConfig.Name}\n",
      "\t\tmfaAny.Any = append(mfaAny.Any, mfaMethod)\n",
      "\t}\n",
      "\treturn mfaAny, nil\n",
      "}\n",
      "func (b *LoginMFABackend) deleteMFAConfigByMethodID(ctx context.Context, configID, methodType, tableName, prefix string) error {\n",
      "\tvar err error\n",
      "\tif configID == \"\" {\n",
      "\t\treturn fmt.Errorf(\"missing config id\")\n",
      "\t}\n",
      "\tb.mfaLock.Lock()\n",
      "\tdefer b.mfaLock.Unlock()\n",
      "\teConfigIter, err := b.MemDBMFALoginEnforcementConfigIterator()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tfor eConfigRaw := eConfigIter.Next(); eConfigRaw != nil; eConfigRaw = eConfigIter.Next() {\n",
      "\t\teConfig := eConfigRaw.(*mfa.MFAEnforcementConfig)\n",
      "\t\tif strutil.StrListContains(eConfig.MFAMethodIDs, configID) {\n",
      "\t\t\treturn fmt.Errorf(\"methodID is still used by an enforcement configuration with ID: %s\", eConfig.ID)\n",
      "\t\t}\n",
      "\t}\n",
      "\tentryIndex := prefix + configID\n",
      "\terr = b.Core.systemBarrierView.Delete(ctx, entryIndex)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\ttxn := b.db.Txn(true)\n",
      "\tdefer txn.Abort()\n",
      "\tmConfig, err := b.MemDBMFAConfigByIDInTxn(txn, configID)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif mConfig == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif mConfig.Type != methodType {\n",
      "\t\treturn fmt.Errorf(\"method type does not match the MFA config type\")\n",
      "\t}\n",
      "\tmfaNs, err := b.Core.NamespaceByID(ctx, mConfig.NamespaceID)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tns, err := namespace.FromContext(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif ns.ID != mfaNs.ID {\n",
      "\t\treturn fmt.Errorf(\"request namespace does not match method namespace\")\n",
      "\t}\n",
      "\tif mConfig.Type == \"totp\" && mConfig.ID != \"\" {\n",
      "\t\tif err := logical.ClearView(ctx, NewBarrierView(b.Core.barrier, fmt.Sprintf(\"%s%s\", mfaTOTPKeysPrefix, mConfig.ID))); err != nil {\n",
      "\t\t\tb.mfaLogger.Warn(\"unable to clear TOTP keys\", \"method\", mConfig.Name, \"error\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\terr = b.MemDBDeleteMFAConfigByIDInTxn(txn, configID)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\ttxn.Commit()\n",
      "\treturn nil\n",
      "}\n",
      "func (b *SystemBackend) handlePluginCatalogUpdate(ctx context.Context, _ *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\tpluginName := d.Get(\"name\").(string)\n",
      "\tif pluginName == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing plugin name\"), nil\n",
      "\t}\n",
      "\tpluginTypeStr := d.Get(\"type\").(string)\n",
      "\tif pluginTypeStr == \"\" {\n",
      "\t\tpluginTypeStr = \"unknown\"\n",
      "\t}\n",
      "\tpluginType, err := consts.ParsePluginType(pluginTypeStr)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tpluginVersion, builtin, err := getVersion(d)\n",
      "\tif err != nil {\n",
      "\t\treturn logical.ErrorResponse(err.Error()), nil\n",
      "\t}\n",
      "\tif builtin {\n",
      "\t\treturn logical.ErrorResponse(\"version %q is not allowed because 'builtin' is a reserved metadata identifier\", pluginVersion), nil\n",
      "\t}\n",
      "\tsha256 := d.Get(\"sha256\").(string)\n",
      "\tif sha256 == \"\" {\n",
      "\t\tsha256 = d.Get(\"sha_256\").(string)\n",
      "\t\tif sha256 == \"\" {\n",
      "\t\t\treturn logical.ErrorResponse(\"missing SHA-256 value\"), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tcommand := d.Get(\"command\").(string)\n",
      "\tociImage := d.Get(\"oci_image\").(string)\n",
      "\tif command == \"\" && ociImage == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"must provide at least one of command or oci_image\"), nil\n",
      "\t}\n",
      "\tif ociImage == \"\" {\n",
      "\t\tif err = b.Core.CheckPluginPerms(command); err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tpluginRuntime := d.Get(\"runtime\").(string)\n",
      "\tif ociImage != \"\" {\n",
      "\t\tif runtime.GOOS != \"linux\" {\n",
      "\t\t\treturn logical.ErrorResponse(\"specifying oci_image is currently only supported on Linux\"), nil\n",
      "\t\t}\n",
      "\t\tif pluginRuntime != \"\" {\n",
      "\t\t\t_, err := b.Core.pluginRuntimeCatalog.Get(ctx, pluginRuntime, consts.PluginRuntimeTypeContainer)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn logical.ErrorResponse(\"specified plugin runtime %q, but failed to retrieve config: %w\", pluginRuntime, err), nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\targs := d.Get(\"args\").([]string)\n",
      "\tparts := strings.Split(command, \" \")\n",
      "\tif len(parts) == 0 && ociImage == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing command value\"), nil\n",
      "\t} else if len(parts) > 1 && len(args) > 0 {\n",
      "\t\treturn logical.ErrorResponse(\"must not specify args in command and args field\"), nil\n",
      "\t} else if len(parts) >= 1 {\n",
      "\t\tcommand = parts[0]\n",
      "\t\tif len(parts) > 1 {\n",
      "\t\t\targs = parts[1:]\n",
      "\t\t}\n",
      "\t}\n",
      "\tenv := d.Get(\"env\").([]string)\n",
      "\tsha256Bytes, err := hex.DecodeString(sha256)\n",
      "\tif err != nil {\n",
      "\t\treturn logical.ErrorResponse(\"Could not decode SHA256 value from Hex %s: %s\", sha256, err), err\n",
      "\t}\n",
      "\terr = b.Core.pluginCatalog.Set(ctx, pluginutil.SetPluginInput{Name: pluginName, Type: pluginType, Version: pluginVersion, OCIImage: ociImage, Runtime: pluginRuntime, Command: command, Args: args, Env: env, Sha256: sha256Bytes})\n",
      "\tif err != nil {\n",
      "\t\tif errors.Is(err, plugincatalog.ErrPluginNotFound) || errors.Is(err, plugincatalog.ErrPluginVersionMismatch) || errors.Is(err, plugincatalog.ErrPluginUnableToRun) {\n",
      "\t\t\treturn logical.ErrorResponse(err.Error()), nil\n",
      "\t\t}\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn nil, nil\n",
      "}\n",
      "func (b *backend) pathAcmeWrite(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tconfig, err := b.GetAcmeState().getConfigWithForcedUpdate(sc)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif enabledRaw, ok := d.GetOk(\"enabled\"); ok {\n",
      "\t\tconfig.Enabled = enabledRaw.(bool)\n",
      "\t}\n",
      "\tif allowedRolesRaw, ok := d.GetOk(\"allowed_roles\"); ok {\n",
      "\t\tconfig.AllowedRoles = allowedRolesRaw.([]string)\n",
      "\t\tif len(config.AllowedRoles) == 0 {\n",
      "\t\t\treturn nil, fmt.Errorf(\"allowed_roles must take a non-zero length value; specify '*' as the value to allow anything or specify enabled=false to disable ACME entirely\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif allowRoleExtKeyUsageRaw, ok := d.GetOk(\"allow_role_ext_key_usage\"); ok {\n",
      "\t\tconfig.AllowRoleExtKeyUsage = allowRoleExtKeyUsageRaw.(bool)\n",
      "\t}\n",
      "\tif defaultDirectoryPolicyRaw, ok := d.GetOk(\"default_directory_policy\"); ok {\n",
      "\t\tconfig.DefaultDirectoryPolicy = defaultDirectoryPolicyRaw.(string)\n",
      "\t}\n",
      "\tif allowedIssuersRaw, ok := d.GetOk(\"allowed_issuers\"); ok {\n",
      "\t\tconfig.AllowedIssuers = allowedIssuersRaw.([]string)\n",
      "\t\tif len(config.AllowedIssuers) == 0 {\n",
      "\t\t\treturn nil, fmt.Errorf(\"allowed_issuers must take a non-zero length value; specify '*' as the value to allow anything or specify enabled=false to disable ACME entirely\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif dnsResolverRaw, ok := d.GetOk(\"dns_resolver\"); ok {\n",
      "\t\tconfig.DNSResolver = dnsResolverRaw.(string)\n",
      "\t\tif config.DNSResolver != \"\" {\n",
      "\t\t\taddr, _, err := net.SplitHostPort(config.DNSResolver)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to parse DNS resolver address: %w\", err)\n",
      "\t\t\t}\n",
      "\t\t\tif addr == \"\" {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to parse DNS resolver address: got empty address\")\n",
      "\t\t\t}\n",
      "\t\t\tif net.ParseIP(addr) == nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed to parse DNS resolver address: expected IPv4/IPv6 address, likely got hostname\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif eabPolicyRaw, ok := d.GetOk(\"eab_policy\"); ok {\n",
      "\t\teabPolicy, err := getEabPolicyByString(eabPolicyRaw.(string))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"invalid eab policy name provided, valid values are '%s', '%s', '%s'\", eabPolicyNotRequired, eabPolicyNewAccountRequired, eabPolicyAlwaysRequired)\n",
      "\t\t}\n",
      "\t\tconfig.EabPolicyName = eabPolicy.Name\n",
      "\t}\n",
      "\tdefaultDirectoryPolicyType, extraInfo, err := getDefaultDirectoryPolicyType(config.DefaultDirectoryPolicy)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"invalid default_directory_policy: %w\", err)\n",
      "\t}\n",
      "\tdefaultDirectoryRoleName := \"\"\n",
      "\tswitch defaultDirectoryPolicyType {\n",
      "\tcase Forbid:\n",
      "\tcase SignVerbatim:\n",
      "\tcase ExternalPolicy:\n",
      "\t\tif !constants.IsEnterprise {\n",
      "\t\t\treturn nil, fmt.Errorf(\"external-policy is only available in enterprise versions of Vault\")\n",
      "\t\t}\n",
      "\tcase Role:\n",
      "\t\tdefaultDirectoryRoleName = extraInfo\n",
      "\t\t_, err := getAndValidateAcmeRole(sc, defaultDirectoryRoleName)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"default directory policy role %v is not a valid ACME role: %w\", defaultDirectoryRoleName, err)\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\treturn nil, fmt.Errorf(\"validation for the type of policy defined by %v is undefined\", config.DefaultDirectoryPolicy)\n",
      "\t}\n",
      "\tallowAnyRole := len(config.AllowedRoles) == 1 && config.AllowedRoles[0] == \"*\"\n",
      "\tfoundDefault := false\n",
      "\tif !allowAnyRole {\n",
      "\t\tfor index, name := range config.AllowedRoles {\n",
      "\t\t\tif name == \"*\" {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"cannot use '*' as role name at index %d\", index)\n",
      "\t\t\t}\n",
      "\t\t\t_, err := getAndValidateAcmeRole(sc, name)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"allowed_role %v is not a valid acme role: %w\", name, err)\n",
      "\t\t\t}\n",
      "\t\t\tif defaultDirectoryPolicyType == Role && name == defaultDirectoryRoleName {\n",
      "\t\t\t\tfoundDefault = true\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !foundDefault && defaultDirectoryPolicyType == Role {\n",
      "\t\t\treturn nil, fmt.Errorf(\"default directory policy %v was not specified in allowed_roles: %v\", config.DefaultDirectoryPolicy, config.AllowedRoles)\n",
      "\t\t}\n",
      "\t}\n",
      "\tallowAnyIssuer := len(config.AllowedIssuers) == 1 && config.AllowedIssuers[0] == \"*\"\n",
      "\tif !allowAnyIssuer {\n",
      "\t\tfor index, name := range config.AllowedIssuers {\n",
      "\t\t\tif name == \"*\" {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"cannot use '*' as issuer name at index %d\", index)\n",
      "\t\t\t}\n",
      "\t\t\t_, err := sc.resolveIssuerReference(name)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"failed validating allowed_issuers: unable to fetch issuer: %v: %w\", name, err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.Enabled {\n",
      "\t\t_, err = getBasePathFromClusterConfig(sc)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar warnings []string\n",
      "\tisPublicAcmeDisabledByEnv, err := isPublicACMEDisabledByEnv()\n",
      "\tif err != nil {\n",
      "\t\twarnings = append(warnings, err.Error())\n",
      "\t}\n",
      "\tif isPublicAcmeDisabledByEnv && config.Enabled {\n",
      "\t\teabPolicy := getEabPolicyByName(config.EabPolicyName)\n",
      "\t\tif !eabPolicy.OverrideEnvDisablingPublicAcme() {\n",
      "\t\t\tresp := logical.ErrorResponse(\"%s env var is enabled, ACME EAB policy needs to be '%s' with ACME enabled\", disableAcmeEnvVar, eabPolicyAlwaysRequired)\n",
      "\t\t\tresp.Warnings = warnings\n",
      "\t\t\treturn resp, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tif _, err := b.GetAcmeState().writeConfig(sc, config); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed persisting: %w\", err)\n",
      "\t}\n",
      "\treturn genResponseFromAcmeConfig(config, warnings), nil\n",
      "}\n",
      "func (c *Core) setupRaftActiveNode(ctx context.Context) error {\n",
      "\traftBackend := c.getRaftBackend()\n",
      "\tif raftBackend == nil {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tc.logger.Info(\"starting raft active node\")\n",
      "\traftBackend.SetEffectiveSDKVersion(c.effectiveSDKVersion)\n",
      "\tc.pendingRaftPeers = &sync.Map{}\n",
      "\tif err := c.checkRaftTLSKeyUpgrades(ctx); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := c.monitorUndoLogs(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\traftBackend.StartRaftWalVerifier(ctx)\n",
      "\tif err := c.startPeriodicRaftTLSRotate(ctx); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tautopilotConfig, err := c.loadAutopilotConfiguration(ctx)\n",
      "\tif err != nil {\n",
      "\t\tc.logger.Error(\"failed to load autopilot config from storage when setting up cluster; continuing since autopilot falls back to default config\", \"error\", err)\n",
      "\t}\n",
      "\tdisableAutopilot := c.disableAutopilot\n",
      "\traftBackend.SetupAutopilot(c.activeContext, autopilotConfig, c.raftFollowerStates, disableAutopilot)\n",
      "\treturn nil\n",
      "}\n",
      "func (b *LoginMFABackend) sanitizeMFACredsWithLoginEnforcementMethodIDs(ctx context.Context, mfaCredsMap logical.MFACreds, mfaMethodIDs []string) (logical.MFACreds, error) {\n",
      "\tsanitizedMfaCreds := make(logical.MFACreds, 0)\n",
      "\tvar multiError *multierror.Error\n",
      "\tfor _, methodID := range mfaMethodIDs {\n",
      "\t\tval, ok := mfaCredsMap[methodID]\n",
      "\t\tif ok {\n",
      "\t\t\tsanitizedMfaCreds[methodID] = val\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tmConfig, err := b.MemDBMFAConfigByID(methodID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif mConfig == nil {\n",
      "\t\t\tmultiError = multierror.Append(multiError, fmt.Errorf(\"failed to find MFA config for method ID %s\", methodID))\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tconfigNS, err := NamespaceByID(ctx, mConfig.NamespaceID, b.Core)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif configNS != nil {\n",
      "\t\t\tval, ok = mfaCredsMap[configNS.Path+mConfig.Name]\n",
      "\t\t\tif ok {\n",
      "\t\t\t\tsanitizedMfaCreds[mConfig.ID] = val\n",
      "\t\t\t} else {\n",
      "\t\t\t\tmultiError = multierror.Append(multiError, fmt.Errorf(\"failed to find MFA credentials associated with an MFA method ID %v, method name %v\", methodID, configNS.Path+mConfig.Name))\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tmultiError = multierror.Append(multiError, fmt.Errorf(\"failed to find the namespace associated with an MFA method ID %v\", mConfig.ID))\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(sanitizedMfaCreds) > 0 {\n",
      "\t\treturn sanitizedMfaCreds, nil\n",
      "\t}\n",
      "\treturn sanitizedMfaCreds, multiError\n",
      "}\n",
      "func (b *LoginMFABackend) MemDBMFAConfigByID(mConfigID string) (*mfa.Config, error) {\n",
      "\tif mConfigID == \"\" {\n",
      "\t\treturn nil, fmt.Errorf(\"missing config id\")\n",
      "\t}\n",
      "\ttxn := b.db.Txn(false)\n",
      "\treturn b.MemDBMFAConfigByIDInTxn(txn, mConfigID)\n",
      "}\n",
      "func (b *backend) pathConnectionUpdate(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\turi := data.Get(\"connection_uri\").(string)\n",
      "\tif uri == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing connection_uri\"), nil\n",
      "\t}\n",
      "\tusername := data.Get(\"username\").(string)\n",
      "\tif username == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing username\"), nil\n",
      "\t}\n",
      "\tpassword := data.Get(\"password\").(string)\n",
      "\tif password == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"missing password\"), nil\n",
      "\t}\n",
      "\tusernameTemplate := data.Get(\"username_template\").(string)\n",
      "\tif usernameTemplate != \"\" {\n",
      "\t\tup, err := template.NewTemplate(template.Template(usernameTemplate))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"unable to initialize username template: %w\", err), nil\n",
      "\t\t}\n",
      "\t\t_, err = up.Generate(UsernameMetadata{})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.ErrorResponse(\"invalid username template: %w\", err), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tpasswordPolicy := data.Get(\"password_policy\").(string)\n",
      "\tverifyConnection := data.Get(\"verify_connection\").(bool)\n",
      "\tif verifyConnection {\n",
      "\t\tclient, err := rabbithole.NewClient(uri, username, password)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to create client: %w\", err)\n",
      "\t\t}\n",
      "\t\tif _, err = client.ListUsers(); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to validate the connection: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig := connectionConfig{URI: uri, Username: username, Password: password, PasswordPolicy: passwordPolicy, UsernameTemplate: usernameTemplate}\n",
      "\terr := writeConfig(ctx, req.Storage, config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tb.resetClient(ctx)\n",
      "\treturn nil, nil\n",
      "}\n",
      "func (c *PluginCatalog) getBackendRunningVersion(ctx context.Context, pluginRunner *pluginutil.PluginRunner) (logical.PluginVersion, error) {\n",
      "\tmerr := &multierror.Error{}\n",
      "\tconfig := pluginutil.PluginClientConfig{Name: pluginRunner.Name, PluginSets: backendplugin.PluginSet, HandshakeConfig: backendplugin.HandshakeConfig, Logger: log.NewNullLogger(), IsMetadataMode: false, AutoMTLS: true, Wrapper: c.wrapper}\n",
      "\tvar client logical.Backend\n",
      "\tc.logger.Debug(\"attempting to load backend plugin\", \"name\", pluginRunner.Name)\n",
      "\tpc, err := c.newPluginClient(ctx, pluginRunner, config)\n",
      "\tif err == nil {\n",
      "\t\tkey, err := makeExternalPluginsKey(pluginRunner)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn logical.EmptyPluginVersion, err\n",
      "\t\t}\n",
      "\t\tdefer func() {\n",
      "\t\t\terr = c.cleanupExternalPlugin(key, pc.id, pluginRunner.BinaryReference())\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.logger.Error(\"error closing plugin client\", \"error\", err)\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t\tclient, err = backendplugin.Dispense(pc.ClientProtocol, pc)\n",
      "\t\tif err == nil {\n",
      "\t\t\tc.logger.Debug(\"successfully dispensed v5 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\t\t\terr = client.Setup(ctx, &logical.BackendConfig{})\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn logical.EmptyPluginVersion, nil\n",
      "\t\t\t}\n",
      "\t\t\tif versioner, ok := client.(logical.PluginVersioner); ok {\n",
      "\t\t\t\treturn versioner.PluginVersion(), nil\n",
      "\t\t\t}\n",
      "\t\t\treturn logical.EmptyPluginVersion, nil\n",
      "\t\t}\n",
      "\t\tmerr = multierror.Append(merr, err)\n",
      "\t}\n",
      "\tc.logger.Debug(\"failed to dispense v5 backend plugin\", \"name\", pluginRunner.Name, \"error\", err)\n",
      "\tconfig.AutoMTLS = false\n",
      "\tconfig.IsMetadataMode = true\n",
      "\tclient, err = backendplugin.NewPluginClient(ctx, c.wrapper, pluginRunner, log.NewNullLogger(), true)\n",
      "\tif err != nil {\n",
      "\t\tmerr = multierror.Append(merr, err)\n",
      "\t\tc.logger.Debug(\"failed to dispense v4 backend plugin\", \"name\", pluginRunner.Name, \"error\", err)\n",
      "\t\tif pluginRunner.OCIImage != \"\" {\n",
      "\t\t\treturn logical.EmptyPluginVersion, fmt.Errorf(\"%w: %w\", ErrPluginUnableToRun, merr.ErrorOrNil())\n",
      "\t\t}\n",
      "\t\treturn logical.EmptyPluginVersion, merr.ErrorOrNil()\n",
      "\t}\n",
      "\tc.logger.Debug(\"successfully dispensed v4 backend plugin\", \"name\", pluginRunner.Name)\n",
      "\tdefer client.Cleanup(ctx)\n",
      "\terr = client.Setup(ctx, &logical.BackendConfig{})\n",
      "\tif err != nil {\n",
      "\t\treturn logical.EmptyPluginVersion, err\n",
      "\t}\n",
      "\tif versioner, ok := client.(logical.PluginVersioner); ok {\n",
      "\t\treturn versioner.PluginVersion(), nil\n",
      "\t}\n",
      "\treturn logical.EmptyPluginVersion, nil\n",
      "}\n",
      "func configureDevTLS(c *ServerCommand) (func(), *server.Config, string, error) {\n",
      "\tvar devStorageType string\n",
      "\tswitch {\n",
      "\tcase c.flagDevConsul:\n",
      "\t\tdevStorageType = \"consul\"\n",
      "\tcase c.flagDevHA && c.flagDevTransactional:\n",
      "\t\tdevStorageType = \"inmem_transactional_ha\"\n",
      "\tcase !c.flagDevHA && c.flagDevTransactional:\n",
      "\t\tdevStorageType = \"inmem_transactional\"\n",
      "\tcase c.flagDevHA && !c.flagDevTransactional:\n",
      "\t\tdevStorageType = \"inmem_ha\"\n",
      "\tdefault:\n",
      "\t\tdevStorageType = \"inmem\"\n",
      "\t}\n",
      "\tvar certDir string\n",
      "\tvar err error\n",
      "\tvar config *server.Config\n",
      "\tvar f func()\n",
      "\tif c.flagDevTLS {\n",
      "\t\tif c.flagDevTLSCertDir != \"\" {\n",
      "\t\t\tif _, err = os.Stat(c.flagDevTLSCertDir); err != nil {\n",
      "\t\t\t\treturn nil, nil, \"\", err\n",
      "\t\t\t}\n",
      "\t\t\tcertDir = c.flagDevTLSCertDir\n",
      "\t\t} else {\n",
      "\t\t\tif certDir, err = os.MkdirTemp(\"\", \"vault-tls\"); err != nil {\n",
      "\t\t\t\treturn nil, nil, certDir, err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\textraSANs := c.flagDevTLSSANs\n",
      "\t\thost, _, err := net.SplitHostPort(c.flagDevListenAddr)\n",
      "\t\tif err == nil {\n",
      "\t\t\tif host != \"\" && host != \"127.0.0.1\" {\n",
      "\t\t\t\textraSANs = append(extraSANs, host)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tconfig, err = server.DevTLSConfig(devStorageType, certDir, extraSANs)\n",
      "\t\tf = func() {\n",
      "\t\t\tif err := os.Remove(fmt.Sprintf(\"%s/%s\", certDir, server.VaultDevCAFilename)); err != nil {\n",
      "\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif err := os.Remove(fmt.Sprintf(\"%s/%s\", certDir, server.VaultDevCertFilename)); err != nil {\n",
      "\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif err := os.Remove(fmt.Sprintf(\"%s/%s\", certDir, server.VaultDevKeyFilename)); err != nil {\n",
      "\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tif c.flagDevTLSCertDir == \"\" {\n",
      "\t\t\t\tif err := os.Remove(certDir); err != nil {\n",
      "\t\t\t\t\tc.UI.Error(err.Error())\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tconfig, err = server.DevConfig(devStorageType)\n",
      "\t}\n",
      "\treturn f, config, certDir, err\n",
      "}\n",
      "func NewJWTAuthMethod(conf *auth.AuthConfig) (auth.AuthMethod, error) {\n",
      "\tif conf == nil {\n",
      "\t\treturn nil, errors.New(\"empty config\")\n",
      "\t}\n",
      "\tif conf.Config == nil {\n",
      "\t\treturn nil, errors.New(\"empty config data\")\n",
      "\t}\n",
      "\tj := &jwtMethod{logger: conf.Logger, mountPath: conf.MountPath, removeJWTAfterReading: true, credsFound: make(chan struct{}), watchCh: make(chan string), stopCh: make(chan struct{}), doneCh: make(chan struct{}), credSuccessGate: make(chan struct{}), once: new(sync.Once), latestToken: new(atomic.Value)}\n",
      "\tj.latestToken.Store(\"\")\n",
      "\tpathRaw, ok := conf.Config[\"path\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'path' value\")\n",
      "\t}\n",
      "\tj.path, ok = pathRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'path' config value to string\")\n",
      "\t}\n",
      "\troleRaw, ok := conf.Config[\"role\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"missing 'role' value\")\n",
      "\t}\n",
      "\tj.role, ok = roleRaw.(string)\n",
      "\tif !ok {\n",
      "\t\treturn nil, errors.New(\"could not convert 'role' config value to string\")\n",
      "\t}\n",
      "\tif removeJWTAfterReadingRaw, ok := conf.Config[\"remove_jwt_after_reading\"]; ok {\n",
      "\t\tremoveJWTAfterReading, err := parseutil.ParseBool(removeJWTAfterReadingRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'remove_jwt_after_reading' value: %w\", err)\n",
      "\t\t}\n",
      "\t\tj.removeJWTAfterReading = removeJWTAfterReading\n",
      "\t}\n",
      "\tif removeJWTFollowsSymlinksRaw, ok := conf.Config[\"remove_jwt_follows_symlinks\"]; ok {\n",
      "\t\tremoveJWTFollowsSymlinks, err := parseutil.ParseBool(removeJWTFollowsSymlinksRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'remove_jwt_follows_symlinks' value: %w\", err)\n",
      "\t\t}\n",
      "\t\tj.removeJWTFollowsSymlinks = removeJWTFollowsSymlinks\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase j.path == \"\":\n",
      "\t\treturn nil, errors.New(\"'path' value is empty\")\n",
      "\tcase j.role == \"\":\n",
      "\t\treturn nil, errors.New(\"'role' value is empty\")\n",
      "\t}\n",
      "\treadPeriod := 1 * time.Minute\n",
      "\tif jwtReadPeriodRaw, ok := conf.Config[\"jwt_read_period\"]; ok {\n",
      "\t\tjwtReadPeriod, err := parseutil.ParseDurationSecond(jwtReadPeriodRaw)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"error parsing 'jwt_read_period' value: %w\", err)\n",
      "\t\t}\n",
      "\t\treadPeriod = jwtReadPeriod\n",
      "\t} else {\n",
      "\t\tif j.removeJWTAfterReading {\n",
      "\t\t\treadPeriod = 500 * time.Millisecond\n",
      "\t\t}\n",
      "\t}\n",
      "\tj.ticker = time.NewTicker(readPeriod)\n",
      "\tgo j.runWatcher()\n",
      "\tj.logger.Info(\"jwt auth method created\", \"path\", j.path)\n",
      "\treturn j, nil\n",
      "}\n",
      "func (b *backend) doTidyExpiredIssuers(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tif b.System().ReplicationState().HasState(consts.ReplicationDRSecondary|consts.ReplicationPerformanceStandby) || (!b.System().LocalMount() && b.System().ReplicationState().HasState(consts.ReplicationPerformanceSecondary)) {\n",
      "\t\tb.Logger().Debug(\"skipping expired issuer tidy as we're not on the primary or secondary with a local mount\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif b.UseLegacyBundleCaStorage() {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tb.issuersLock.Lock()\n",
      "\tdefer b.issuersLock.Unlock()\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tissuerIDCertMap, err := fetchIssuerMapForRevocationChecking(sc)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tiConfig, err := sc.getIssuersConfig()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\trebuildChainsAndCRL := false\n",
      "\tfor issuer, cert := range issuerIDCertMap {\n",
      "\t\tif time.Since(cert.NotAfter) <= config.IssuerSafetyBuffer {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tentry, err := sc.fetchIssuerById(issuer)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\tmsg := \"[Tidy on mount: %v] Issuer %v has expired by %v and is being removed.\"\n",
      "\t\tidAndName := fmt.Sprintf(\"[id:%v/name:%v]\", entry.ID, entry.Name)\n",
      "\t\tmsg = fmt.Sprintf(msg, b.backendUUID, idAndName, config.IssuerSafetyBuffer)\n",
      "\t\tif iConfig.DefaultIssuerId == issuer {\n",
      "\t\t\tmsg = \"[Tidy on mount: %v] Issuer %v has expired and would be removed via tidy, but won't be, as it is currently the default issuer.\"\n",
      "\t\t\tmsg = fmt.Sprintf(msg, b.backendUUID, idAndName)\n",
      "\t\t\tb.Logger().Warn(msg)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tb.Logger().Info(msg, \"serial_number\", entry.SerialNumber, \"key_id\", entry.KeyID, \"certificate\", entry.Certificate)\n",
      "\t\twasDefault, err := sc.deleteIssuer(issuer)\n",
      "\t\tif err != nil {\n",
      "\t\t\tb.Logger().Error(fmt.Sprintf(\"failed to remove %v: %v\", idAndName, err))\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif wasDefault {\n",
      "\t\t\tb.Logger().Warn(fmt.Sprintf(\"expired issuer %v was default; it is strongly encouraged to choose a new default issuer for backwards compatibility\", idAndName))\n",
      "\t\t}\n",
      "\t\trebuildChainsAndCRL = true\n",
      "\t}\n",
      "\tif rebuildChainsAndCRL {\n",
      "\t\tif err := sc.rebuildIssuersChains(nil); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tb.GetRevokeStorageLock().Lock()\n",
      "\t\tdefer b.GetRevokeStorageLock().Unlock()\n",
      "\t\twarnings, err := b.CrlBuilder().rebuild(sc, false)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif len(warnings) > 0 {\n",
      "\t\t\tmsg := \"During rebuild of CRL for tidy, got the following warnings:\"\n",
      "\t\t\tfor index, warning := range warnings {\n",
      "\t\t\t\tmsg = fmt.Sprintf(\"%v\\n %d. %v\", msg, index+1, warning)\n",
      "\t\t\t}\n",
      "\t\t\tb.Logger().Warn(msg)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *KVPutCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: vault kv put [options] KEY [DATA]\n",
      "\n",
      "  Writes the data to the given path in the key-value store. The data can be of\n",
      "  any type.\n",
      "\n",
      "      $ vault kv put -mount=secret foo bar=baz\n",
      "\n",
      "  The deprecated path-like syntax can also be used, but this should be avoided \n",
      "  for KV v2, as the fact that it is not actually the full API path to \n",
      "  the secret (secret/data/foo) can cause confusion: \n",
      "  \n",
      "      $ vault kv put secret/foo bar=baz\n",
      "\n",
      "  The data can also be consumed from a file on disk by prefixing with the \"@\"\n",
      "  symbol. For example:\n",
      "\n",
      "      $ vault kv put -mount=secret foo @data.json\n",
      "\n",
      "  Or it can be read from stdin using the \"-\" symbol:\n",
      "\n",
      "      $ echo \"abcd1234\" | vault kv put -mount=secret foo bar=-\n",
      "\n",
      "  To perform a Check-And-Set operation, specify the -cas flag with the\n",
      "  appropriate version number corresponding to the key you want to perform\n",
      "  the CAS operation on:\n",
      "\n",
      "      $ vault kv put -mount=secret -cas=1 foo bar=baz\n",
      "\n",
      "  Additional flags and more advanced use cases are detailed below.\n",
      "\n",
      "` + c.Flags().Help()\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (sd *SignedData) SignWithoutAttr(ee *x509.Certificate, pkey crypto.PrivateKey, config SignerInfoConfig) error {\n",
      "\tvar signature []byte\n",
      "\tsd.sd.DigestAlgorithmIdentifiers = append(sd.sd.DigestAlgorithmIdentifiers, pkix.AlgorithmIdentifier{Algorithm: sd.digestOid})\n",
      "\thash, err := getHashForOID(sd.digestOid)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\th := hash.New()\n",
      "\th.Write(sd.data)\n",
      "\tsd.messageDigest = h.Sum(nil)\n",
      "\tswitch pkey := pkey.(type) {\n",
      "\tcase *dsa.PrivateKey:\n",
      "\t\tr, s, err := dsa.Sign(rand.Reader, pkey, sd.messageDigest)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tsignature, err = asn1.Marshal(dsaSignature{r, s})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\tkey, ok := pkey.(crypto.Signer)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn errors.New(\"pkcs7: private key does not implement crypto.Signer\")\n",
      "\t\t}\n",
      "\t\tsignature, err = key.Sign(rand.Reader, sd.messageDigest, hash)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar ias issuerAndSerial\n",
      "\tias.SerialNumber = ee.SerialNumber\n",
      "\tias.IssuerName = asn1.RawValue{FullBytes: ee.RawIssuer}\n",
      "\tif sd.encryptionOid == nil {\n",
      "\t\tsd.encryptionOid, err = getOIDForEncryptionAlgorithm(pkey, sd.digestOid)\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tsigner := signerInfo{DigestAlgorithm: pkix.AlgorithmIdentifier{Algorithm: sd.digestOid}, DigestEncryptionAlgorithm: pkix.AlgorithmIdentifier{Algorithm: sd.encryptionOid}, IssuerAndSerialNumber: ias, EncryptedDigest: signature, Version: 1}\n",
      "\tsd.certs = append(sd.certs, ee)\n",
      "\tsd.sd.SignerInfos = append(sd.sd.SignerInfos, signer)\n",
      "\treturn nil\n",
      "}\n",
      "func (c *OperatorRaftAutopilotGetConfigCommand) Run(args []string) int {\n",
      "\tf := c.Flags()\n",
      "\tif err := f.Parse(args); err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\targs = f.Args()\n",
      "\tswitch len(args) {\n",
      "\tcase 0:\n",
      "\tdefault:\n",
      "\t\tc.UI.Error(fmt.Sprintf(\"Incorrect arguments (expected 0, got %d)\", len(args)))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tclient, err := c.Client()\n",
      "\tif err != nil {\n",
      "\t\tc.UI.Error(err.Error())\n",
      "\t\treturn 2\n",
      "\t}\n",
      "\tvar config *api.AutopilotConfig\n",
      "\tswitch {\n",
      "\tcase c.flagDRToken != \"\":\n",
      "\t\tconfig, err = client.Sys().RaftAutopilotConfigurationWithDRToken(c.flagDRToken)\n",
      "\tdefault:\n",
      "\t\tconfig, err = client.Sys().RaftAutopilotConfiguration()\n",
      "\t}\n",
      "\tif config == nil {\n",
      "\t\treturn 0\n",
      "\t}\n",
      "\tif Format(c.UI) != \"table\" {\n",
      "\t\treturn OutputData(c.UI, config)\n",
      "\t}\n",
      "\tentries := []string{\"Key | Value\"}\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %t\", \"Cleanup Dead Servers\", config.CleanupDeadServers))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %s\", \"Last Contact Threshold\", config.LastContactThreshold.String()))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %s\", \"Dead Server Last Contact Threshold\", config.DeadServerLastContactThreshold.String()))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %s\", \"Server Stabilization Time\", config.ServerStabilizationTime.String()))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %d\", \"Min Quorum\", config.MinQuorum))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %d\", \"Max Trailing Logs\", config.MaxTrailingLogs))\n",
      "\tentries = append(entries, fmt.Sprintf(\"%s | %t\", \"Disable Upgrade Migration\", config.DisableUpgradeMigration))\n",
      "\treturn OutputData(c.UI, entries)\n",
      "}\n",
      "func (c *AgentCommand) applyConfigOverrides(f *FlagSets, config *agentConfig.Config) {\n",
      "\tif config.Vault == nil {\n",
      "\t\tconfig.Vault = &agentConfig.Vault{}\n",
      "\t}\n",
      "\tf.applyLogConfigOverrides(config.SharedConfig)\n",
      "\tf.Visit(func(fl *flag.Flag) {\n",
      "\t\tif fl.Name == flagNameAgentExitAfterAuth {\n",
      "\t\t\tconfig.ExitAfterAuth = c.flagExitAfterAuth\n",
      "\t\t}\n",
      "\t})\n",
      "\tc.setStringFlag(f, config.Vault.Address, &StringVar{Name: flagNameAddress, Target: &c.flagAddress, Default: \"https://127.0.0.1:8200\", EnvVar: api.EnvVaultAddress})\n",
      "\tconfig.Vault.Address = c.flagAddress\n",
      "\tc.setStringFlag(f, config.Vault.CACert, &StringVar{Name: flagNameCACert, Target: &c.flagCACert, Default: \"\", EnvVar: api.EnvVaultCACert})\n",
      "\tconfig.Vault.CACert = c.flagCACert\n",
      "\tc.setStringFlag(f, config.Vault.CAPath, &StringVar{Name: flagNameCAPath, Target: &c.flagCAPath, Default: \"\", EnvVar: api.EnvVaultCAPath})\n",
      "\tconfig.Vault.CAPath = c.flagCAPath\n",
      "\tc.setStringFlag(f, config.Vault.ClientCert, &StringVar{Name: flagNameClientCert, Target: &c.flagClientCert, Default: \"\", EnvVar: api.EnvVaultClientCert})\n",
      "\tconfig.Vault.ClientCert = c.flagClientCert\n",
      "\tc.setStringFlag(f, config.Vault.ClientKey, &StringVar{Name: flagNameClientKey, Target: &c.flagClientKey, Default: \"\", EnvVar: api.EnvVaultClientKey})\n",
      "\tconfig.Vault.ClientKey = c.flagClientKey\n",
      "\tc.setBoolFlag(f, config.Vault.TLSSkipVerify, &BoolVar{Name: flagNameTLSSkipVerify, Target: &c.flagTLSSkipVerify, Default: false, EnvVar: api.EnvVaultSkipVerify})\n",
      "\tconfig.Vault.TLSSkipVerify = c.flagTLSSkipVerify\n",
      "\tc.setStringFlag(f, config.Vault.TLSServerName, &StringVar{Name: flagTLSServerName, Target: &c.flagTLSServerName, Default: \"\", EnvVar: api.EnvVaultTLSServerName})\n",
      "\tconfig.Vault.TLSServerName = c.flagTLSServerName\n",
      "}\n",
      "func (c *KVUndeleteCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"versions\", Target: &c.flagVersions, Default: nil, Usage: `Specifies the version numbers to undelete.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified,\n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is\n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount\n",
      "\t\tpath and secret path, with /data/ automatically appended between KV\n",
      "\t\tv2 secrets.`})\n",
      "\treturn set\n",
      "}\n",
      "func (rc runConfig) generateCmd(ctx context.Context) (cmd *exec.Cmd, clientTLSConfig *tls.Config, err error) {\n",
      "\tcmd = exec.Command(rc.command, rc.args...)\n",
      "\tenv := rc.env\n",
      "\tif rc.mlockEnabled() {\n",
      "\t\tenv = append(env, fmt.Sprintf(\"%s=%s\", PluginMlockEnabled, \"true\"))\n",
      "\t}\n",
      "\tversion, err := rc.Wrapper.VaultVersion(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tenv = append(env, fmt.Sprintf(\"%s=%s\", PluginVaultVersionEnv, version))\n",
      "\tif rc.IsMetadataMode {\n",
      "\t\trc.Logger = rc.Logger.With(\"metadata\", \"true\")\n",
      "\t}\n",
      "\tmetadataEnv := fmt.Sprintf(\"%s=%t\", PluginMetadataModeEnv, rc.IsMetadataMode)\n",
      "\tenv = append(env, metadataEnv)\n",
      "\tautomtlsEnv := fmt.Sprintf(\"%s=%t\", PluginAutoMTLSEnv, rc.AutoMTLS)\n",
      "\tenv = append(env, automtlsEnv)\n",
      "\tif !rc.AutoMTLS && !rc.IsMetadataMode {\n",
      "\t\tcertBytes, key, err := generateCert()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tclientTLSConfig, err = createClientTLSConfig(certBytes, key)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\twrapToken, err := wrapServerConfig(ctx, rc.Wrapper, certBytes, key)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, nil, err\n",
      "\t\t}\n",
      "\t\tenv = append(env, fmt.Sprintf(\"%s=%s\", PluginUnwrapTokenEnv, wrapToken))\n",
      "\t}\n",
      "\tif rc.image == \"\" {\n",
      "\t\tif legacy, _ := strconv.ParseBool(os.Getenv(PluginUseLegacyEnvLayering)); legacy {\n",
      "\t\t\tcmd.Env = append(env, os.Environ()...)\n",
      "\t\t} else {\n",
      "\t\t\tcmd.Env = append(os.Environ(), env...)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tcmd.Env = env\n",
      "\t}\n",
      "\treturn cmd, clientTLSConfig, nil\n",
      "}\n",
      "func loadConfig(path string) (*defaultConfig, error) {\n",
      "\tif path == \"\" {\n",
      "\t\tpath = defaultConfigPath\n",
      "\t}\n",
      "\tif v := os.Getenv(configPathEnv); v != \"\" {\n",
      "\t\tpath = v\n",
      "\t}\n",
      "\tpath, err := homedir.Expand(path)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error expanding config path %q: %w\", path, err)\n",
      "\t}\n",
      "\tcontents, err := os.ReadFile(path)\n",
      "\tif err != nil && !os.IsNotExist(err) {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconf, err := parseConfig(string(contents))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error parsing config file at %q: %w; ensure that the file is valid; Ansible Vault is known to conflict with it\", path, err)\n",
      "\t}\n",
      "\treturn conf, nil\n",
      "}\n",
      "func (b *backend) doTidyCrossRevocationStore(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tif b.System().ReplicationState().HasState(consts.ReplicationDRSecondary|consts.ReplicationPerformanceStandby) || (!b.System().LocalMount() && b.System().ReplicationState().HasState(consts.ReplicationPerformanceSecondary)) {\n",
      "\t\tb.Logger().Debug(\"skipping cross-cluster revoked certificate store tidy as we're not on the primary or secondary with a local mount\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tclusters, err := sc.Storage.List(sc.Context, unifiedRevocationReadPathPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list cross-cluster revoked certificate store participating clusters: %w\", err)\n",
      "\t}\n",
      "\tb.GetRevokeStorageLock().Lock()\n",
      "\tdefer b.GetRevokeStorageLock().Unlock()\n",
      "\tfor cIndex, cluster := range clusters {\n",
      "\t\tif cluster[len(cluster)-1] == '/' {\n",
      "\t\t\tcluster = cluster[0 : len(cluster)-1]\n",
      "\t\t}\n",
      "\t\tcPath := unifiedRevocationReadPathPrefix + cluster + \"/\"\n",
      "\t\tserials, err := sc.Storage.List(sc.Context, cPath)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to list cross-cluster revoked certificate store entries for cluster %v (%v): %w\", cluster, cIndex, err)\n",
      "\t\t}\n",
      "\t\tfor _, serial := range serials {\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\t\tb.GetRevokeStorageLock().Unlock()\n",
      "\t\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t\t\tb.GetRevokeStorageLock().Lock()\n",
      "\t\t\t}\n",
      "\t\t\tePath := cPath + serial\n",
      "\t\t\tentry, err := sc.Storage.Get(sc.Context, ePath)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error reading cross-cluster revocation entry (%v) to tidy: %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tif entry == nil || entry.Value == nil {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tvar details unifiedRevocationEntry\n",
      "\t\t\tif err := entry.DecodeJSON(&details); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error decoding cross-cluster revocation entry (%v) to tidy: %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tif time.Since(details.CertExpiration) <= config.SafetyBuffer {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tif err := sc.Storage.Delete(sc.Context, ePath); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting revocation request (%v): %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncCrossRevCertCount()\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (b *backend) doTidyRevocationQueue(ctx context.Context, req *logical.Request, logger hclog.Logger, config *tidyConfig) error {\n",
      "\tif b.System().ReplicationState().HasState(consts.ReplicationDRSecondary|consts.ReplicationPerformanceStandby) || (!b.System().LocalMount() && b.System().ReplicationState().HasState(consts.ReplicationPerformanceSecondary)) {\n",
      "\t\tb.Logger().Debug(\"skipping cross-cluster revocation queue tidy as we're not on the primary or secondary with a local mount\")\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tsc := b.makeStorageContext(ctx, req.Storage)\n",
      "\tclusters, err := sc.Storage.List(sc.Context, crossRevocationPrefix)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to list cross-cluster revocation queue participating clusters: %w\", err)\n",
      "\t}\n",
      "\tb.GetRevokeStorageLock().Lock()\n",
      "\tdefer b.GetRevokeStorageLock().Unlock()\n",
      "\tfor cIndex, cluster := range clusters {\n",
      "\t\tif cluster[len(cluster)-1] == '/' {\n",
      "\t\t\tcluster = cluster[0 : len(cluster)-1]\n",
      "\t\t}\n",
      "\t\tcPath := crossRevocationPrefix + cluster + \"/\"\n",
      "\t\tserials, err := sc.Storage.List(sc.Context, cPath)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to list cross-cluster revocation queue entries for cluster %v (%v): %w\", cluster, cIndex, err)\n",
      "\t\t}\n",
      "\t\tfor _, serial := range serials {\n",
      "\t\t\tif atomic.CompareAndSwapUint32(b.tidyCancelCAS, 1, 0) {\n",
      "\t\t\t\treturn tidyCancelledError\n",
      "\t\t\t}\n",
      "\t\t\tif config.PauseDuration > (0 * time.Second) {\n",
      "\t\t\t\tb.GetRevokeStorageLock().Unlock()\n",
      "\t\t\t\ttime.Sleep(config.PauseDuration)\n",
      "\t\t\t\tb.GetRevokeStorageLock().Lock()\n",
      "\t\t\t}\n",
      "\t\t\tif serial[len(serial)-1] == '/' {\n",
      "\t\t\t\tconfirmedPath := cPath + serial + \"confirmed\"\n",
      "\t\t\t\tremovalEntry, err := sc.Storage.Get(sc.Context, confirmedPath)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"error reading revocation confirmation (%v) during tidy: %w\", confirmedPath, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif removalEntry == nil {\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tfor _, subCluster := range clusters {\n",
      "\t\t\t\t\tif subCluster[len(subCluster)-1] == '/' {\n",
      "\t\t\t\t\t\tsubCluster = subCluster[0 : len(subCluster)-1]\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treqPath := subCluster + \"/\" + serial[0:len(serial)-1]\n",
      "\t\t\t\t\tif err := sc.Storage.Delete(sc.Context, reqPath); err != nil {\n",
      "\t\t\t\t\t\treturn fmt.Errorf(\"failed to remove confirmed revocation request on candidate cluster (%v): %w\", reqPath, err)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif err := sc.Storage.Delete(sc.Context, confirmedPath); err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"failed to remove confirmed revocation confirmation (%v): %w\", confirmedPath, err)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tePath := cPath + serial\n",
      "\t\t\tentry, err := sc.Storage.Get(sc.Context, ePath)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error reading revocation request (%v) to tidy: %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tif entry == nil || entry.Value == nil {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tvar revRequest revocationRequest\n",
      "\t\t\tif err := entry.DecodeJSON(&revRequest); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error reading revocation request (%v) to tidy: %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tif time.Since(revRequest.RequestedAt) <= config.QueueSafetyBuffer {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tif err := sc.Storage.Delete(sc.Context, ePath); err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"error deleting revocation request (%v): %w\", ePath, err)\n",
      "\t\t\t}\n",
      "\t\t\tb.tidyStatusIncRevQueueCount()\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (b *backend) pathConfigRotateRootUpdate(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {\n",
      "\tclient, err := b.clientIAM(ctx, req.Storage)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif client == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil IAM client\")\n",
      "\t}\n",
      "\tb.clientMutex.Lock()\n",
      "\tdefer b.clientMutex.Unlock()\n",
      "\trawRootConfig, err := req.Storage.Get(ctx, \"config/root\")\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif rawRootConfig == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"no configuration found for config/root\")\n",
      "\t}\n",
      "\tvar config rootConfig\n",
      "\tif err := rawRootConfig.DecodeJSON(&config); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error reading root configuration: %w\", err)\n",
      "\t}\n",
      "\tif config.AccessKey == \"\" || config.SecretKey == \"\" {\n",
      "\t\treturn logical.ErrorResponse(\"Cannot call config/rotate-root when either access_key or secret_key is empty\"), nil\n",
      "\t}\n",
      "\tvar getUserInput iam.GetUserInput\n",
      "\tgetUserRes, err := client.GetUserWithContext(ctx, &getUserInput)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error calling GetUser: %w\", err)\n",
      "\t}\n",
      "\tif getUserRes == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil response from GetUser\")\n",
      "\t}\n",
      "\tif getUserRes.User == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil user returned from GetUser\")\n",
      "\t}\n",
      "\tif getUserRes.User.UserName == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil UserName returned from GetUser\")\n",
      "\t}\n",
      "\tcreateAccessKeyInput := iam.CreateAccessKeyInput{UserName: getUserRes.User.UserName}\n",
      "\tcreateAccessKeyRes, err := client.CreateAccessKeyWithContext(ctx, &createAccessKeyInput)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error calling CreateAccessKey: %w\", err)\n",
      "\t}\n",
      "\tif createAccessKeyRes.AccessKey == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil response from CreateAccessKey\")\n",
      "\t}\n",
      "\tif createAccessKeyRes.AccessKey.AccessKeyId == nil || createAccessKeyRes.AccessKey.SecretAccessKey == nil {\n",
      "\t\treturn nil, fmt.Errorf(\"nil AccessKeyId or SecretAccessKey returned from CreateAccessKey\")\n",
      "\t}\n",
      "\toldAccessKey := config.AccessKey\n",
      "\tconfig.AccessKey = *createAccessKeyRes.AccessKey.AccessKeyId\n",
      "\tconfig.SecretKey = *createAccessKeyRes.AccessKey.SecretAccessKey\n",
      "\tnewEntry, err := logical.StorageEntryJSON(\"config/root\", config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error generating new config/root JSON: %w\", err)\n",
      "\t}\n",
      "\tif err := req.Storage.Put(ctx, newEntry); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error saving new config/root: %w\", err)\n",
      "\t}\n",
      "\tb.iamClient = nil\n",
      "\tb.stsClient = nil\n",
      "\tdeleteAccessKeyInput := iam.DeleteAccessKeyInput{AccessKeyId: aws.String(oldAccessKey), UserName: getUserRes.User.UserName}\n",
      "\t_, err = client.DeleteAccessKeyWithContext(ctx, &deleteAccessKeyInput)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"error deleting old access key: %w\", err)\n",
      "\t}\n",
      "\treturn &logical.Response{Data: map[string]interface{}{\"access_key\": config.AccessKey}}, nil\n",
      "}\n",
      "func setSeal(c *ServerCommand, config *server.Config, infoKeys []string, info map[string]string, existingSealGenerationInfo *vaultseal.SealGenerationInfo, hasPartiallyWrappedPaths bool) (*SetSealResponse, error) {\n",
      "\tif c.flagDevAutoSeal {\n",
      "\t\taccess, _ := vaultseal.NewTestSeal(nil)\n",
      "\t\tbarrierSeal := vault.NewAutoSeal(access)\n",
      "\t\treturn &SetSealResponse{barrierSeal: barrierSeal}, nil\n",
      "\t}\n",
      "\tswitch len(config.Seals) {\n",
      "\tcase 0:\n",
      "\t\tconfig.Seals = append(config.Seals, &configutil.KMS{Type: vault.SealConfigTypeShamir.String(), Priority: 1, Name: \"shamir\"})\n",
      "\tdefault:\n",
      "\t\tallSealsDisabled := true\n",
      "\t\tfor _, c := range config.Seals {\n",
      "\t\t\tif !c.Disabled {\n",
      "\t\t\t\tallSealsDisabled = false\n",
      "\t\t\t} else if c.Type == vault.SealConfigTypeShamir.String() {\n",
      "\t\t\t\treturn nil, errors.New(\"shamir seals cannot be set disabled (they should simply not be set)\")\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif allSealsDisabled {\n",
      "\t\t\tconfig.Seals = append(config.Seals, &configutil.KMS{Type: vault.SealConfigTypeShamir.String(), Priority: 1, Name: \"shamir\"})\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar sealConfigError error\n",
      "\tvar sealConfigWarning error\n",
      "\trecordSealConfigError := func(err error) {\n",
      "\t\tsealConfigError = errors.Join(sealConfigError, err)\n",
      "\t}\n",
      "\trecordSealConfigWarning := func(err error) {\n",
      "\t\tsealConfigWarning = errors.Join(sealConfigWarning, err)\n",
      "\t}\n",
      "\tenabledSealWrappers := make([]*vaultseal.SealWrapper, 0)\n",
      "\tdisabledSealWrappers := make([]*vaultseal.SealWrapper, 0)\n",
      "\tallSealKmsConfigs := make([]*configutil.KMS, 0)\n",
      "\ttype infoKeysAndMap struct {\n",
      "\t\tkeys\t[]string\n",
      "\t\ttheMap\tmap[string]string\n",
      "\t}\n",
      "\tsealWrapperInfoKeysMap := make(map[string]infoKeysAndMap)\n",
      "\tconfiguredSeals := 0\n",
      "\tfor _, configSeal := range config.Seals {\n",
      "\t\tsealTypeEnvVarName := \"VAULT_SEAL_TYPE\"\n",
      "\t\tif configSeal.Priority > 1 {\n",
      "\t\t\tsealTypeEnvVarName = sealTypeEnvVarName + \"_\" + configSeal.Name\n",
      "\t\t}\n",
      "\t\tif !configSeal.Disabled && os.Getenv(sealTypeEnvVarName) != \"\" {\n",
      "\t\t\tsealType := os.Getenv(sealTypeEnvVarName)\n",
      "\t\t\tconfigSeal.Type = sealType\n",
      "\t\t}\n",
      "\t\tsealLogger := c.logger.ResetNamed(fmt.Sprintf(\"seal.%s\", configSeal.Type))\n",
      "\t\tc.allLoggers = append(c.allLoggers, sealLogger)\n",
      "\t\tallSealKmsConfigs = append(allSealKmsConfigs, configSeal)\n",
      "\t\tvar wrapperInfoKeys []string\n",
      "\t\twrapperInfoMap := map[string]string{}\n",
      "\t\twrapper, wrapperConfigError := configutil.ConfigureWrapper(configSeal, &wrapperInfoKeys, &wrapperInfoMap, sealLogger)\n",
      "\t\tif wrapperConfigError == nil {\n",
      "\t\t\tif wrapper == nil {\n",
      "\t\t\t\twrapper = aeadwrapper.NewShamirWrapper()\n",
      "\t\t\t}\n",
      "\t\t\tconfiguredSeals++\n",
      "\t\t} else if server.IsMultisealSupported() {\n",
      "\t\t\trecordSealConfigWarning(fmt.Errorf(\"error configuring seal: %v\", wrapperConfigError))\n",
      "\t\t} else {\n",
      "\t\t\tif !errwrap.ContainsType(wrapperConfigError, new(logical.KeyNotFoundError)) {\n",
      "\t\t\t\treturn nil, fmt.Errorf(\"error parsing Seal configuration: %s\", wrapperConfigError)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tsealLogger.Error(\"error configuring seal\", \"name\", configSeal.Name, \"err\", wrapperConfigError)\n",
      "\t\t\t\trecordSealConfigError(wrapperConfigError)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tsealWrapper := vaultseal.NewSealWrapper(wrapper, configSeal.Priority, configSeal.Name, configSeal.Type, configSeal.Disabled, wrapperConfigError == nil)\n",
      "\t\tif configSeal.Disabled {\n",
      "\t\t\tdisabledSealWrappers = append(disabledSealWrappers, sealWrapper)\n",
      "\t\t} else {\n",
      "\t\t\tenabledSealWrappers = append(enabledSealWrappers, sealWrapper)\n",
      "\t\t}\n",
      "\t\tsealWrapperInfoKeysMap[sealWrapper.Name] = infoKeysAndMap{keys: wrapperInfoKeys, theMap: wrapperInfoMap}\n",
      "\t}\n",
      "\tif len(enabledSealWrappers) == 0 && len(disabledSealWrappers) == 0 && sealConfigWarning != nil {\n",
      "\t\trecordSealConfigError(sealConfigWarning)\n",
      "\t\tsealConfigWarning = nil\n",
      "\t}\n",
      "\tappendWrapperInfoKeys := func(prefix string, sealWrappers []*vaultseal.SealWrapper) {\n",
      "\t\tif len(sealWrappers) == 0 {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tuseName := false\n",
      "\t\tif len(sealWrappers) > 1 {\n",
      "\t\t\tuseName = true\n",
      "\t\t}\n",
      "\t\tfor _, sealWrapper := range sealWrappers {\n",
      "\t\t\tif useName {\n",
      "\t\t\t\tprefix = fmt.Sprintf(\"%s %s \", prefix, sealWrapper.Name)\n",
      "\t\t\t}\n",
      "\t\t\tfor _, k := range sealWrapperInfoKeysMap[sealWrapper.Name].keys {\n",
      "\t\t\t\tinfoKeys = append(infoKeys, prefix+k)\n",
      "\t\t\t\tinfo[prefix+k] = sealWrapperInfoKeysMap[sealWrapper.Name].theMap[k]\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tappendWrapperInfoKeys(\"\", enabledSealWrappers)\n",
      "\tappendWrapperInfoKeys(\"Old\", disabledSealWrappers)\n",
      "\tsealGenerationInfo, err := c.computeSealGenerationInfo(existingSealGenerationInfo, allSealKmsConfigs, hasPartiallyWrappedPaths)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tcontainsShamir := func(sealWrappers []*vaultseal.SealWrapper) bool {\n",
      "\t\tfor _, si := range sealWrappers {\n",
      "\t\t\tif vault.SealConfigTypeShamir.IsSameAs(si.SealConfigType) {\n",
      "\t\t\t\treturn true\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tvar barrierSeal vault.Seal\n",
      "\tvar unwrapSeal vault.Seal\n",
      "\tsealLogger := c.logger\n",
      "\tswitch {\n",
      "\tcase len(enabledSealWrappers) == 0:\n",
      "\t\treturn nil, errors.Join(sealConfigWarning, errors.New(\"no enabled Seals in configuration\"))\n",
      "\tcase configuredSeals == 0:\n",
      "\t\treturn nil, errors.Join(sealConfigWarning, errors.New(\"no seals were successfully initialized\"))\n",
      "\tcase len(enabledSealWrappers) == 1 && containsShamir(enabledSealWrappers):\n",
      "\t\ta, err := vaultseal.NewAccess(sealLogger, sealGenerationInfo, enabledSealWrappers)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tbarrierSeal = vault.NewDefaultSeal(a)\n",
      "\t\tif len(disabledSealWrappers) > 0 {\n",
      "\t\t\ta, err = vaultseal.NewAccess(sealLogger, sealGenerationInfo, disabledSealWrappers)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tunwrapSeal = vault.NewAutoSeal(a)\n",
      "\t\t} else if sealGenerationInfo.Generation == 1 {\n",
      "\t\t\tsealGenerationInfo.SetRewrapped(true)\n",
      "\t\t}\n",
      "\tcase len(disabledSealWrappers) == 1 && containsShamir(disabledSealWrappers):\n",
      "\t\ta, err := vaultseal.NewAccess(sealLogger, sealGenerationInfo, enabledSealWrappers)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tbarrierSeal = vault.NewAutoSeal(a)\n",
      "\t\ta, err = vaultseal.NewAccess(sealLogger, sealGenerationInfo, disabledSealWrappers)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tunwrapSeal = vault.NewDefaultSeal(a)\n",
      "\tcase server.IsMultisealSupported():\n",
      "\t\tallSealWrappers := append(enabledSealWrappers, disabledSealWrappers...)\n",
      "\t\ta, err := vaultseal.NewAccess(sealLogger, sealGenerationInfo, allSealWrappers)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tbarrierSeal = vault.NewAutoSeal(a)\n",
      "\t\tif configuredSeals < len(enabledSealWrappers) {\n",
      "\t\t\tc.UI.Warn(\"WARNING: running with fewer than all configured seals during unseal.  Will not be fully highly available until errors are corrected and Vault restarted.\")\n",
      "\t\t}\n",
      "\tcase len(enabledSealWrappers) == 1:\n",
      "\t\ta, err := vaultseal.NewAccess(sealLogger, sealGenerationInfo, enabledSealWrappers)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tbarrierSeal = vault.NewAutoSeal(a)\n",
      "\t\tif len(disabledSealWrappers) > 0 {\n",
      "\t\t\ta, err = vaultseal.NewAccess(sealLogger, sealGenerationInfo, disabledSealWrappers)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn nil, err\n",
      "\t\t\t}\n",
      "\t\t\tunwrapSeal = vault.NewAutoSeal(a)\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\treturn nil, errors.Join(sealConfigWarning, errors.New(\"error: more than one enabled seal found\"))\n",
      "\t}\n",
      "\treturn &SetSealResponse{barrierSeal: barrierSeal, unwrapSeal: unwrapSeal, sealConfigError: sealConfigError, sealConfigWarning: sealConfigWarning, hasPartiallyWrappedPaths: hasPartiallyWrappedPaths}, nil\n",
      "}\n",
      "func (c *KVPatchCommand) Flags() *FlagSets {\n",
      "\tset := c.flagSet(FlagSetHTTP | FlagSetOutputField | FlagSetOutputFormat)\n",
      "\tf := set.NewFlagSet(\"Common Options\")\n",
      "\tf.IntVar(&IntVar{Name: \"cas\", Target: &c.flagCAS, Default: 0, Usage: `Specifies to use a Check-And-Set operation. If set to 0 or not\n",
      "\t\tset, the patch will be allowed. If the index is non-zero the patch will\n",
      "\t\tonly be allowed if the keys current version matches the version\n",
      "\t\tspecified in the cas parameter.`})\n",
      "\tf.StringVar(&StringVar{Name: \"method\", Target: &c.flagMethod, Usage: `Specifies which method of patching to use. If set to \"patch\", then\n",
      "\t\tan HTTP PATCH request will be issued. If set to \"rw\", then a read will be\n",
      "\t\tperformed, then a local update, followed by a remote update.`})\n",
      "\tf.StringVar(&StringVar{Name: \"mount\", Target: &c.flagMount, Default: \"\", Usage: `Specifies the path where the KV backend is mounted. If specified, \n",
      "\t\tthe next argument will be interpreted as the secret path. If this flag is \n",
      "\t\tnot specified, the next argument will be interpreted as the combined mount \n",
      "\t\tpath and secret path, with /data/ automatically appended between KV \n",
      "\t\tv2 secrets.`})\n",
      "\tf.StringSliceVar(&StringSliceVar{Name: \"remove-data\", Target: &c.flagRemoveData, Default: []string{}, Usage: \"Key to remove from data. To specify multiple values, specify this flag multiple times.\"})\n",
      "\treturn set\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (b *AESGCMBarrier) Unseal(ctx context.Context, key []byte) error {\n",
      "\tb.l.Lock()\n",
      "\tdefer b.l.Unlock()\n",
      "\tif !b.sealed {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tgcm, err := b.aeadFromKey(key)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tout, err := b.backend.Get(ctx, keyringPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to check for keyring: %w\", err)\n",
      "\t}\n",
      "\tif out != nil {\n",
      "\t\tterm := binary.BigEndian.Uint32(out.Value[:4])\n",
      "\t\tif term != initialKeyTerm {\n",
      "\t\t\treturn errors.New(\"term mis-match\")\n",
      "\t\t}\n",
      "\t\tplain, err := b.decrypt(keyringPath, gcm, out.Value)\n",
      "\t\tdefer memzero(plain)\n",
      "\t\tif err != nil {\n",
      "\t\t\tif strings.Contains(err.Error(), \"message authentication failed\") {\n",
      "\t\t\t\treturn ErrBarrierInvalidKey\n",
      "\t\t\t}\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\terr = b.recoverKeyring(plain)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"keyring deserialization failed: %w\", err)\n",
      "\t\t}\n",
      "\t\tb.sealed = false\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tout, err = b.backend.Get(ctx, barrierInitPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to check for initialization: %w\", err)\n",
      "\t}\n",
      "\tif out == nil {\n",
      "\t\treturn ErrBarrierNotInit\n",
      "\t}\n",
      "\tterm := binary.BigEndian.Uint32(out.Value[:4])\n",
      "\tif term != initialKeyTerm {\n",
      "\t\treturn errors.New(\"term mis-match\")\n",
      "\t}\n",
      "\tplain, err := b.decrypt(barrierInitPath, gcm, out.Value)\n",
      "\tif err != nil {\n",
      "\t\tif strings.Contains(err.Error(), \"message authentication failed\") {\n",
      "\t\t\treturn ErrBarrierInvalidKey\n",
      "\t\t}\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tdefer memzero(plain)\n",
      "\tvar init barrierInit\n",
      "\tif err := jsonutil.DecodeJSON(plain, &init); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to unmarshal barrier init file\")\n",
      "\t}\n",
      "\tkeyringNew := NewKeyring()\n",
      "\tkeyring := keyringNew.SetRootKey(key)\n",
      "\tdefer keyringNew.Zeroize(false)\n",
      "\tkeyring, err = keyring.AddKey(&Key{Term: 1, Version: 1, Value: init.Key})\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to create keyring: %w\", err)\n",
      "\t}\n",
      "\tif err := b.persistKeyring(ctx, keyring); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := b.backend.Delete(ctx, barrierInitPath); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to delete barrier init file: %w\", err)\n",
      "\t}\n",
      "\tb.keyring = keyring\n",
      "\tb.sealed = false\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Core) migrateMultiSealConfig(ctx context.Context) error {\n",
      "\tbarrierSealConfig, err := c.PhysicalBarrierSealConfig(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to read existing seal configuration during multi seal migration: %v\", err)\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase c.seal.BarrierSealConfigType().IsSameAs(barrierSealConfig.Type):\n",
      "\t\treturn nil\n",
      "\tcase c.seal.BarrierSealConfigType() == SealConfigTypeMultiseal:\n",
      "\tcase SealConfigTypeMultiseal.IsSameAs(barrierSealConfig.Type):\n",
      "\tdefault:\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif err := c.seal.SetBarrierConfig(ctx, barrierSealConfig); err != nil {\n",
      "\t\treturn fmt.Errorf(\"error storing barrier config during multi seal migration: %w\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func kvPreflightVersionRequest(client *api.Client, path string) (string, int, error) {\n",
      "\tcurrentWrappingLookupFunc := client.CurrentWrappingLookupFunc()\n",
      "\tclient.SetWrappingLookupFunc(nil)\n",
      "\tdefer client.SetWrappingLookupFunc(currentWrappingLookupFunc)\n",
      "\tcurrentOutputCurlString := client.OutputCurlString()\n",
      "\tclient.SetOutputCurlString(false)\n",
      "\tdefer client.SetOutputCurlString(currentOutputCurlString)\n",
      "\tcurrentOutputPolicy := client.OutputPolicy()\n",
      "\tclient.SetOutputPolicy(false)\n",
      "\tdefer client.SetOutputPolicy(currentOutputPolicy)\n",
      "\tr := client.NewRequest(\"GET\", \"/v1/sys/internal/ui/mounts/\"+path)\n",
      "\tresp, err := client.RawRequest(r)\n",
      "\tif resp != nil {\n",
      "\t\tdefer resp.Body.Close()\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\tif resp != nil {\n",
      "\t\t\tif resp.StatusCode == 404 {\n",
      "\t\t\t\treturn \"\", 1, nil\n",
      "\t\t\t}\n",
      "\t\t\tif (currentOutputCurlString || currentOutputPolicy) && resp.StatusCode == 403 {\n",
      "\t\t\t\terr = fmt.Errorf(`This output flag requires the success of a preflight request \n",
      "to determine the version of a KV secrets engine. Please \n",
      "re-run this command with a token with read access to %s. \n",
      "Note that if the path you are trying to reach is a KV v2 path, your token's policy must \n",
      "allow read access to that path in the format 'mount-path/data/foo', not just 'mount-path/foo'.`, path)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn \"\", 0, err\n",
      "\t}\n",
      "\tsecret, err := api.ParseSecret(resp.Body)\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", 0, err\n",
      "\t}\n",
      "\tif secret == nil {\n",
      "\t\treturn \"\", 0, errors.New(\"nil response from pre-flight request\")\n",
      "\t}\n",
      "\tvar mountPath string\n",
      "\tif mountPathRaw, ok := secret.Data[\"path\"]; ok {\n",
      "\t\tmountPath = mountPathRaw.(string)\n",
      "\t}\n",
      "\toptions := secret.Data[\"options\"]\n",
      "\tif options == nil {\n",
      "\t\treturn mountPath, 1, nil\n",
      "\t}\n",
      "\tversionRaw := options.(map[string]interface{})[\"version\"]\n",
      "\tif versionRaw == nil {\n",
      "\t\treturn mountPath, 1, nil\n",
      "\t}\n",
      "\tversion := versionRaw.(string)\n",
      "\tswitch version {\n",
      "\tcase \"\", \"1\":\n",
      "\t\treturn mountPath, 1, nil\n",
      "\tcase \"2\":\n",
      "\t\treturn mountPath, 2, nil\n",
      "\t}\n",
      "\treturn mountPath, 1, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "hashicorp/consul 11 27562\n",
      "11\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "tmrts/go-patterns 1 23606\n",
      "1\n",
      "======================CLASS=======================\n",
      "hashicorp/packer 1 14780\n",
      "1\n",
      "======================CLASS=======================\n",
      "func (p *Parser) decodeHCPRegistry(block *hcl.Block, cfg *PackerConfig) (*HCPPackerRegistryBlock, hcl.Diagnostics) {\n",
      "\tpar := &HCPPackerRegistryBlock{}\n",
      "\tbody := block.Body\n",
      "\tvar b struct {\n",
      "\t\tSlug\t\tstring\t\t\t`hcl:\"bucket_name,optional\"`\n",
      "\t\tDescription\tstring\t\t\t`hcl:\"description,optional\"`\n",
      "\t\tLabels\t\tmap[string]string\t`hcl:\"labels,optional\"`\n",
      "\t\tBucketLabels\tmap[string]string\t`hcl:\"bucket_labels,optional\"`\n",
      "\t\tBuildLabels\tmap[string]string\t`hcl:\"build_labels,optional\"`\n",
      "\t\tConfig\t\thcl.Body\t\t`hcl:\",remain\"`\n",
      "\t}\n",
      "\tectx := cfg.EvalContext(BuildContext, nil)\n",
      "\tdiags := gohcl.DecodeBody(body, ectx, &b)\n",
      "\tif diags.HasErrors() {\n",
      "\t\treturn nil, diags\n",
      "\t}\n",
      "\tif len(b.Description) > 255 {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(buildHCPPackerRegistryLabel + \".description should have a maximum length of 255 characters\"), Subject: block.DefRange.Ptr()})\n",
      "\t\treturn nil, diags\n",
      "\t}\n",
      "\tif !bucketNameRegexp.MatchString(b.Slug) {\n",
      "\t\tdiags = diags.Append(&hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"%s.bucket_name can only contain between 3 and 36 ASCII letters, numbers and hyphens\", buildHCPPackerRegistryLabel), Subject: block.DefRange.Ptr()})\n",
      "\t}\n",
      "\tpar.Slug = b.Slug\n",
      "\tpar.Description = b.Description\n",
      "\tif len(b.Labels) > 0 && len(b.BucketLabels) > 0 {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"%s.labels and %[1]s.bucket_labels are mutually exclusive; please use the recommended argument %[1]s.bucket_labels\", buildHCPPackerRegistryLabel), Subject: block.DefRange.Ptr()})\n",
      "\t\treturn nil, diags\n",
      "\t}\n",
      "\tif len(b.Labels) > 0 {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagWarning, Summary: fmt.Sprintf(\"the argument %s.labels has been deprecated and will be removed in the next minor release; please use %[1]s.bucket_labels\", buildHCPPackerRegistryLabel)})\n",
      "\t\tb.BucketLabels = b.Labels\n",
      "\t}\n",
      "\tpar.BucketLabels = b.BucketLabels\n",
      "\tpar.BuildLabels = b.BuildLabels\n",
      "\treturn par, diags\n",
      "}\n",
      "func (*ValidateCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: packer validate [options] TEMPLATE\n",
      "\n",
      "  Checks the template is valid by parsing the template and also\n",
      "  checking the configuration with the various builders, provisioners, etc.\n",
      "\n",
      "  If it is not valid, the errors will be shown and the command will exit\n",
      "  with a non-zero exit status. If it is valid, it will exit with a zero\n",
      "  exit status.\n",
      "\n",
      "Options:\n",
      "\n",
      "  -syntax-only                  Only check syntax. Do not verify config of the template.\n",
      "  -except=foo,bar,baz           Validate all builds other than these.\n",
      "  -only=foo,bar,baz             Validate only these builds.\n",
      "  -machine-readable             Produce machine-readable output.\n",
      "  -var 'key=value'              Variable for templates, can be used multiple times.\n",
      "  -var-file=path                JSON or HCL2 file containing user variables, can be used multiple times.\n",
      "  -no-warn-undeclared-var       Disable warnings for user variable files containing undeclared variables.\n",
      "  -evaluate-datasources         Evaluate data sources during validation (HCL2 only, may incur costs); Defaults to false. \n",
      "`\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (p *Parser) Parse(filename string, varFiles []string, argVars map[string]string) (*PackerConfig, hcl.Diagnostics) {\n",
      "\tvar files []*hcl.File\n",
      "\tvar diags hcl.Diagnostics\n",
      "\tif filename != \"\" {\n",
      "\t\thclFiles, jsonFiles, moreDiags := GetHCL2Files(filename, hcl2FileExt, hcl2JsonFileExt)\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t\tif moreDiags.HasErrors() {\n",
      "\t\t\treturn nil, diags\n",
      "\t\t}\n",
      "\t\tif len(hclFiles)+len(jsonFiles) == 0 {\n",
      "\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Could not find any config file in \" + filename, Detail: \"A config file must be suffixed with `.pkr.hcl` or \" + \"`.pkr.json`. A folder can be referenced.\"})\n",
      "\t\t}\n",
      "\t\tfor _, filename := range hclFiles {\n",
      "\t\t\tf, moreDiags := p.ParseHCLFile(filename)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tfiles = append(files, f)\n",
      "\t\t}\n",
      "\t\tfor _, filename := range jsonFiles {\n",
      "\t\t\tf, moreDiags := p.ParseJSONFile(filename)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tfiles = append(files, f)\n",
      "\t\t}\n",
      "\t\tif diags.HasErrors() {\n",
      "\t\t\treturn nil, diags\n",
      "\t\t}\n",
      "\t}\n",
      "\tbasedir := filename\n",
      "\tif isDir, err := isDir(basedir); err == nil && !isDir {\n",
      "\t\tbasedir = filepath.Dir(basedir)\n",
      "\t}\n",
      "\twd, err := os.Getwd()\n",
      "\tif err != nil {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Could not find current working directory\", Detail: err.Error()})\n",
      "\t}\n",
      "\tcfg := &PackerConfig{Basedir: basedir, Cwd: wd, CorePackerVersionString: p.CorePackerVersionString, HCPVars: map[string]cty.Value{}, ValidationOptions: p.ValidationOptions, parser: p, files: files}\n",
      "\tfor _, file := range files {\n",
      "\t\tcoreVersionConstraints, moreDiags := sniffCoreVersionRequirements(file.Body)\n",
      "\t\tcfg.Packer.VersionConstraints = append(cfg.Packer.VersionConstraints, coreVersionConstraints...)\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t}\n",
      "\tversionDiags := cfg.CheckCoreVersionRequirements(p.CorePackerVersion)\n",
      "\tdiags = append(diags, versionDiags...)\n",
      "\tif versionDiags.HasErrors() {\n",
      "\t\treturn cfg, diags\n",
      "\t}\n",
      "\t{\n",
      "\t\tfor _, file := range files {\n",
      "\t\t\tdiags = append(diags, cfg.decodeRequiredPluginsBlock(file)...)\n",
      "\t\t}\n",
      "\t}\n",
      "\t{\n",
      "\t\tfor _, file := range files {\n",
      "\t\t\tdiags = append(diags, cfg.decodeInputVariables(file)...)\n",
      "\t\t}\n",
      "\t\tfor _, file := range files {\n",
      "\t\t\tmorediags := p.decodeDatasources(file, cfg)\n",
      "\t\t\tdiags = append(diags, morediags...)\n",
      "\t\t}\n",
      "\t\tfor _, file := range files {\n",
      "\t\t\tmoreLocals, morediags := parseLocalVariableBlocks(file)\n",
      "\t\t\tdiags = append(diags, morediags...)\n",
      "\t\t\tcfg.LocalBlocks = append(cfg.LocalBlocks, moreLocals...)\n",
      "\t\t}\n",
      "\t}\n",
      "\t{\n",
      "\t\thclVarFiles, jsonVarFiles, moreDiags := GetHCL2Files(filename, hcl2AutoVarFileExt, hcl2AutoVarJsonFileExt)\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t\tfor _, file := range varFiles {\n",
      "\t\t\tswitch filepath.Ext(file) {\n",
      "\t\t\tcase \".hcl\":\n",
      "\t\t\t\thclVarFiles = append(hclVarFiles, file)\n",
      "\t\t\tcase \".json\":\n",
      "\t\t\t\tjsonVarFiles = append(jsonVarFiles, file)\n",
      "\t\t\tdefault:\n",
      "\t\t\t\tdiags = append(moreDiags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Could not guess format of \" + file, Detail: \"A var file must be suffixed with `.hcl` or `.json`.\"})\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tvar varFiles []*hcl.File\n",
      "\t\tfor _, filename := range hclVarFiles {\n",
      "\t\t\tf, moreDiags := p.ParseHCLFile(filename)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tvarFiles = append(varFiles, f)\n",
      "\t\t}\n",
      "\t\tfor _, filename := range jsonVarFiles {\n",
      "\t\t\tf, moreDiags := p.ParseJSONFile(filename)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tvarFiles = append(varFiles, f)\n",
      "\t\t}\n",
      "\t\tdiags = append(diags, cfg.collectInputVariableValues(os.Environ(), varFiles, argVars)...)\n",
      "\t}\n",
      "\treturn cfg, diags\n",
      "}\n",
      "func (cfg *PackerConfig) recursivelyEvaluateDatasources(ref DatasourceRef, dependencies map[DatasourceRef][]DatasourceRef, skipExecution bool, depth int) (map[DatasourceRef][]DatasourceRef, hcl.Diagnostics) {\n",
      "\tvar diags hcl.Diagnostics\n",
      "\tvar moreDiags hcl.Diagnostics\n",
      "\tif depth > 10 {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Max datasource recursion depth exceeded.\", Detail: \"An error occured while recursively evaluating data \" + \"sources. Either your data source depends on more than ten \" + \"other data sources, or your data sources have a cyclic \" + \"dependency. Please simplify your config to continue. \", Subject: &(cfg.Datasources[ref]).block.DefRange})\n",
      "\t\treturn dependencies, diags\n",
      "\t}\n",
      "\tds := cfg.Datasources[ref]\n",
      "\tfor _, dep := range dependencies[ref] {\n",
      "\t\tif _, ok := dependencies[dep]; ok {\n",
      "\t\t\tdepth += 1\n",
      "\t\t\tdependencies, moreDiags = cfg.recursivelyEvaluateDatasources(dep, dependencies, skipExecution, depth)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\t\treturn dependencies, diags\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tdatasource, startDiags := cfg.startDatasource(ds)\n",
      "\tif startDiags.HasErrors() {\n",
      "\t\tdiags = append(diags, startDiags...)\n",
      "\t\treturn dependencies, diags\n",
      "\t}\n",
      "\tif skipExecution {\n",
      "\t\tplaceholderValue := cty.UnknownVal(hcldec.ImpliedType(datasource.OutputSpec()))\n",
      "\t\tds.value = placeholderValue\n",
      "\t\tcfg.Datasources[ref] = ds\n",
      "\t\treturn dependencies, diags\n",
      "\t}\n",
      "\topts, _ := decodeHCL2Spec(ds.block.Body, cfg.EvalContext(DatasourceContext, nil), datasource)\n",
      "\tsp := packer.CheckpointReporter.AddSpan(ref.Type, \"datasource\", opts)\n",
      "\trealValue, err := datasource.Execute()\n",
      "\tsp.End(err)\n",
      "\tif err != nil {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Summary: err.Error(), Subject: &cfg.Datasources[ref].block.DefRange, Severity: hcl.DiagError})\n",
      "\t\treturn dependencies, diags\n",
      "\t}\n",
      "\tds.value = realValue\n",
      "\tcfg.Datasources[ref] = ds\n",
      "\tdelete(dependencies, ref)\n",
      "\treturn dependencies, diags\n",
      "}\n",
      "func loadConfig() (*config, error) {\n",
      "\tpluginDir, err := packer.PluginFolder()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tvar config config\n",
      "\tconfig.Plugins = &packer.PluginConfig{PluginMinPort: 10000, PluginMaxPort: 25000, PluginDirectory: pluginDir, Builders: packer.MapOfBuilder{}, Provisioners: packer.MapOfProvisioner{}, PostProcessors: packer.MapOfPostProcessor{}, DataSources: packer.MapOfDatasource{}}\n",
      "\tif err := config.discoverInternalComponents(); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfigFilePath := os.Getenv(\"PACKER_CONFIG\")\n",
      "\tif configFilePath == \"\" {\n",
      "\t\tvar err error\n",
      "\t\tlog.Print(\"[INFO] PACKER_CONFIG env var not set; checking the default config file path\")\n",
      "\t\tconfigFilePath, err = pathing.ConfigFile()\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Printf(\"Error detecting default config file path: %s\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif configFilePath == \"\" {\n",
      "\t\treturn &config, nil\n",
      "\t}\n",
      "\tlog.Printf(\"[INFO] PACKER_CONFIG env var set; attempting to open config file: %s\", configFilePath)\n",
      "\tf, err := os.Open(configFilePath)\n",
      "\tif err != nil {\n",
      "\t\tif !os.IsNotExist(err) {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[WARN] Config file doesn't exist: %s\", configFilePath)\n",
      "\t\treturn &config, nil\n",
      "\t}\n",
      "\tdefer f.Close()\n",
      "\tif err := decodeConfig(f, &config); err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tconfig.LoadExternalComponentsFromConfig()\n",
      "\treturn &config, nil\n",
      "}\n",
      "func ConfigValueFromHCL2(v cty.Value) interface{} {\n",
      "\tif !v.IsKnown() {\n",
      "\t\treturn hcl2helper.UnknownVariableValue\n",
      "\t}\n",
      "\tif v.IsNull() {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tswitch v.Type() {\n",
      "\tcase cty.Bool:\n",
      "\t\treturn v.True()\n",
      "\tcase cty.String:\n",
      "\t\treturn v.AsString()\n",
      "\tcase cty.Number:\n",
      "\t\tf := v.AsBigFloat()\n",
      "\t\tif i, acc := f.Int64(); acc == big.Exact {\n",
      "\t\t\tconst MaxInt = int(^uint(0) >> 1)\n",
      "\t\t\tconst MinInt = -MaxInt - 1\n",
      "\t\t\tif i <= int64(MaxInt) && i >= int64(MinInt) {\n",
      "\t\t\t\treturn int(i)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tf64, _ := f.Float64()\n",
      "\t\treturn f64\n",
      "\t}\n",
      "\tif v.Type().IsListType() || v.Type().IsSetType() || v.Type().IsTupleType() {\n",
      "\t\tl := make([]interface{}, 0, v.LengthInt())\n",
      "\t\tit := v.ElementIterator()\n",
      "\t\tfor it.Next() {\n",
      "\t\t\t_, ev := it.Element()\n",
      "\t\t\tl = append(l, ConfigValueFromHCL2(ev))\n",
      "\t\t}\n",
      "\t\treturn l\n",
      "\t}\n",
      "\tif v.Type().IsMapType() || v.Type().IsObjectType() {\n",
      "\t\tl := make(map[string]interface{})\n",
      "\t\tit := v.ElementIterator()\n",
      "\t\tfor it.Next() {\n",
      "\t\t\tek, ev := it.Element()\n",
      "\t\t\tcv := ConfigValueFromHCL2(ev)\n",
      "\t\t\tif cv != nil {\n",
      "\t\t\t\tl[ek.AsString()] = cv\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\treturn l\n",
      "\t}\n",
      "\tpanic(fmt.Errorf(\"can't convert %#v to config value\", v))\n",
      "}\n",
      "func (*InitCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: packer init [options] TEMPLATE\n",
      "\n",
      "  Install all the missing plugins required in a Packer config. Note that Packer\n",
      "  does not have a state.\n",
      "\n",
      "  This is the first command that should be executed when working with a new\n",
      "  or existing template.\n",
      "\n",
      "  This command is always safe to run multiple times. Though subsequent runs may\n",
      "  give errors, this command will never delete anything.\n",
      "\n",
      "Options:\n",
      "  -upgrade                     On top of installing missing plugins, update\n",
      "                               installed plugins to the latest available\n",
      "                               version, if there is a new higher one. Note that\n",
      "                               this still takes into consideration the version\n",
      "                               constraint of the config.\n",
      "  -force                       Forces reinstallation of plugins, even if already\n",
      "                               installed.\n",
      "`\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func (g *Getter) Get(what string, opts plugingetter.GetOptions) (io.ReadCloser, error) {\n",
      "\tif opts.PluginRequirement.Identifier.Hostname != defaultHostname {\n",
      "\t\ts := opts.PluginRequirement.Identifier.String() + \" doesn't appear to be a valid \" + defaultHostname + \" source address; check source and try again.\"\n",
      "\t\treturn nil, errors.New(s)\n",
      "\t}\n",
      "\tctx := context.TODO()\n",
      "\tif g.Client == nil {\n",
      "\t\tvar tc *http.Client\n",
      "\t\tif tk := os.Getenv(ghTokenAccessor); tk != \"\" {\n",
      "\t\t\tlog.Printf(\"[DEBUG] github-getter: using %s\", ghTokenAccessor)\n",
      "\t\t\tts := oauth2.StaticTokenSource(&oauth2.Token{AccessToken: tk})\n",
      "\t\t\ttc = &http.Client{Transport: &HostSpecificTokenAuthTransport{TokenSources: map[string]oauth2.TokenSource{\"api.github.com\": ts}}}\n",
      "\t\t} else {\n",
      "\t\t\tlog.Printf(\"[WARNING] github-getter: no GitHub token set, if you intend to install plugins often, please set the %s env var\", ghTokenAccessor)\n",
      "\t\t}\n",
      "\t\tg.Client = github.NewClient(tc)\n",
      "\t\tg.Client.UserAgent = defaultUserAgent\n",
      "\t\tif g.UserAgent != \"\" {\n",
      "\t\t\tg.Client.UserAgent = g.UserAgent\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar req *http.Request\n",
      "\tvar err error\n",
      "\ttransform := func(in io.ReadCloser) (io.ReadCloser, error) {\n",
      "\t\treturn in, nil\n",
      "\t}\n",
      "\tswitch what {\n",
      "\tcase \"releases\":\n",
      "\t\tu := filepath.ToSlash(\"/repos/\" + opts.PluginRequirement.Identifier.RealRelativePath() + \"/git/matching-refs/tags\")\n",
      "\t\treq, err = g.Client.NewRequest(\"GET\", u, nil)\n",
      "\t\ttransform = transformVersionStream\n",
      "\tcase \"sha256\":\n",
      "\t\tu := filepath.ToSlash(\"https://github.com/\" + opts.PluginRequirement.Identifier.RealRelativePath() + \"/releases/download/\" + opts.Version() + \"/\" + opts.PluginRequirement.FilenamePrefix() + opts.Version() + \"_SHA256SUMS\")\n",
      "\t\treq, err = g.Client.NewRequest(\"GET\", u, nil)\n",
      "\t\ttransform = transformChecksumStream()\n",
      "\tcase \"zip\":\n",
      "\t\tu := filepath.ToSlash(\"https://github.com/\" + opts.PluginRequirement.Identifier.RealRelativePath() + \"/releases/download/\" + opts.Version() + \"/\" + opts.ExpectedZipFilename())\n",
      "\t\treq, err = g.Client.NewRequest(\"GET\", u, nil)\n",
      "\tdefault:\n",
      "\t\treturn nil, fmt.Errorf(\"%q not implemented\", what)\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tlog.Printf(\"[DEBUG] github-getter: getting %q\", req.URL)\n",
      "\tresp, err := g.Client.BareDo(ctx, req)\n",
      "\tif err != nil {\n",
      "\t\tif resp != nil {\n",
      "\t\t\tresp.Body.Close()\n",
      "\t\t}\n",
      "\t\tswitch err := err.(type) {\n",
      "\t\tcase *github.RateLimitError:\n",
      "\t\t\treturn nil, &plugingetter.RateLimitError{SetableEnvVar: ghTokenAccessor, Err: err, ResetTime: err.Rate.Reset.Time}\n",
      "\t\tdefault:\n",
      "\t\t\tlog.Printf(\"[TRACE] failed requesting: %T. %v\", err, err)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn transform(resp.Body)\n",
      "}\n",
      "func (c *PluginConfig) Client(path string, args ...string) *PluginClient {\n",
      "\toriginalPath := path\n",
      "\tif strings.Contains(path, PACKERSPACE) {\n",
      "\t\tparts := strings.Split(path, PACKERSPACE)\n",
      "\t\tpath = parts[0]\n",
      "\t\targs = parts[1:]\n",
      "\t}\n",
      "\tpath, err := exec.LookPath(path)\n",
      "\tif err != nil {\n",
      "\t\tlog.Printf(\"[INFO] exec.LookPath: %s : %v. Checking same directory as executable.\", path, err)\n",
      "\t\texePath, err := os.Executable()\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Printf(\"Couldn't get current exe path: %s\", err)\n",
      "\t\t} else {\n",
      "\t\t\tlog.Printf(\"Current exe path: %s\", exePath)\n",
      "\t\t\tpath = filepath.Join(filepath.Dir(exePath), filepath.Base(originalPath))\n",
      "\t\t}\n",
      "\t}\n",
      "\tif path == \"\" {\n",
      "\t\tpath = originalPath\n",
      "\t}\n",
      "\tif strings.Contains(originalPath, PACKERSPACE) {\n",
      "\t\tlog.Printf(\"[INFO] Starting internal plugin %s\", args[len(args)-1])\n",
      "\t} else {\n",
      "\t\tlog.Printf(\"[INFO] Starting external plugin %s %s\", path, strings.Join(args, \" \"))\n",
      "\t}\n",
      "\tvar config PluginClientConfig\n",
      "\tconfig.Cmd = exec.Command(path, args...)\n",
      "\tconfig.Managed = true\n",
      "\tconfig.MinPort = c.PluginMinPort\n",
      "\tconfig.MaxPort = c.PluginMaxPort\n",
      "\treturn NewClient(&config)\n",
      "}\n",
      "func (p *Parser) decodeBuildConfig(block *hcl.Block, cfg *PackerConfig) (*BuildBlock, hcl.Diagnostics) {\n",
      "\tvar b struct {\n",
      "\t\tName\t\tstring\t\t`hcl:\"name,optional\"`\n",
      "\t\tDescription\tstring\t\t`hcl:\"description,optional\"`\n",
      "\t\tFromSources\t[]string\t`hcl:\"sources,optional\"`\n",
      "\t\tConfig\t\thcl.Body\t`hcl:\",remain\"`\n",
      "\t}\n",
      "\tbody := block.Body\n",
      "\tdiags := gohcl.DecodeBody(body, cfg.EvalContext(LocalContext, nil), &b)\n",
      "\tif diags.HasErrors() {\n",
      "\t\treturn nil, diags\n",
      "\t}\n",
      "\tbuild := &BuildBlock{HCL2Ref: newHCL2Ref(block, b.Config)}\n",
      "\tbuild.Name = b.Name\n",
      "\tbuild.Description = b.Description\n",
      "\tbuild.HCL2Ref.DefRange = block.DefRange\n",
      "\tectx := cfg.EvalContext(BuildContext, nil)\n",
      "\tectx.Variables[buildAccessor] = cty.ObjectVal(map[string]cty.Value{\"name\": cty.StringVal(b.Name)})\n",
      "\thadSource := false\n",
      "\tfor _, buildFrom := range b.FromSources {\n",
      "\t\thadSource = true\n",
      "\t\tref := sourceRefFromString(buildFrom)\n",
      "\t\tif ref == NoSource || !hclsyntax.ValidIdentifier(ref.Type) || !hclsyntax.ValidIdentifier(ref.Name) {\n",
      "\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Invalid \" + sourceLabel + \" reference\", Detail: \"A \" + sourceLabel + \" type is made of three parts that are\" + \"split by a dot `.`; each part must start with a letter and \" + \"may contain only letters, digits, underscores, and dashes.\" + \"A valid source reference looks like: `source.type.name`\", Subject: block.DefRange.Ptr()})\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tbuild.Sources = append(build.Sources, SourceUseBlock{SourceRef: ref})\n",
      "\t}\n",
      "\tbody = b.Config\n",
      "\tcontent, moreDiags := body.Content(buildSchema)\n",
      "\tdiags = append(diags, moreDiags...)\n",
      "\tif diags.HasErrors() {\n",
      "\t\treturn nil, diags\n",
      "\t}\n",
      "\tfor _, block := range content.Blocks {\n",
      "\t\tswitch block.Type {\n",
      "\t\tcase buildHCPPackerRegistryLabel:\n",
      "\t\t\tif build.HCPPackerRegistry != nil {\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"Only one \" + buildHCPPackerRegistryLabel + \" is allowed\"), Subject: block.DefRange.Ptr()})\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\thcpPackerRegistry, moreDiags := p.decodeHCPRegistry(block, cfg)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tbuild.HCPPackerRegistry = hcpPackerRegistry\n",
      "\t\tcase sourceLabel:\n",
      "\t\t\thadSource = true\n",
      "\t\t\tref, moreDiags := p.decodeBuildSource(block)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tbuild.Sources = append(build.Sources, ref)\n",
      "\t\tcase buildProvisionerLabel:\n",
      "\t\t\tp, moreDiags := p.decodeProvisioner(block, ectx)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tbuild.ProvisionerBlocks = append(build.ProvisionerBlocks, p)\n",
      "\t\tcase buildErrorCleanupProvisionerLabel:\n",
      "\t\t\tif build.ErrorCleanupProvisionerBlock != nil {\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"Only one \" + buildErrorCleanupProvisionerLabel + \" is allowed\"), Subject: block.DefRange.Ptr()})\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tp, moreDiags := p.decodeProvisioner(block, ectx)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tbuild.ErrorCleanupProvisionerBlock = p\n",
      "\t\tcase buildPostProcessorLabel:\n",
      "\t\t\tpp, moreDiags := p.decodePostProcessor(block, ectx)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tbuild.PostProcessorsLists = append(build.PostProcessorsLists, []*PostProcessorBlock{pp})\n",
      "\t\tcase buildPostProcessorsLabel:\n",
      "\t\t\tcontent, moreDiags := block.Body.Content(postProcessorsSchema)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\terrored := false\n",
      "\t\t\tpostProcessors := []*PostProcessorBlock{}\n",
      "\t\t\tfor _, block := range content.Blocks {\n",
      "\t\t\t\tpp, moreDiags := p.decodePostProcessor(block, ectx)\n",
      "\t\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\t\tif moreDiags.HasErrors() {\n",
      "\t\t\t\t\terrored = true\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t\tpostProcessors = append(postProcessors, pp)\n",
      "\t\t\t}\n",
      "\t\t\tif errored == false {\n",
      "\t\t\t\tbuild.PostProcessorsLists = append(build.PostProcessorsLists, postProcessors)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !hadSource {\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Summary: \"missing source reference\", Detail: \"a build block must reference at least one source to be built\", Severity: hcl.DiagError, Subject: block.DefRange.Ptr()})\n",
      "\t}\n",
      "\treturn build, diags\n",
      "}\n",
      "func (c *PluginsCommand) Help() string {\n",
      "\thelpText := `\n",
      "Usage: packer plugins <subcommand> [options] [args]\n",
      "  This command groups subcommands for interacting with Packer plugins.\n",
      "\n",
      "Related but not under the \"plugins\" command :\n",
      "\n",
      "- \"packer init <path>\" will install all plugins required by a config.\n",
      "`\n",
      "\treturn strings.TrimSpace(helpText)\n",
      "}\n",
      "func transposeTemplatingCalls(s []byte) []byte {\n",
      "\tfuncErrors := &multierror.Error{ErrorFormat: func(es []error) string {\n",
      "\t\tif len(es) == 1 {\n",
      "\t\t\treturn fmt.Sprintf(\"# 1 error occurred upgrading the following block:\\n\\t# %s\\n\", es[0])\n",
      "\t\t}\n",
      "\t\tpoints := make([]string, len(es))\n",
      "\t\tfor i, err := range es {\n",
      "\t\t\tif i == len(es)-1 {\n",
      "\t\t\t\tpoints[i] = fmt.Sprintf(\"# %s\", err)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tpoints[i] = fmt.Sprintf(\"# %s\\n\", err)\n",
      "\t\t}\n",
      "\t\treturn fmt.Sprintf(\"# %d errors occurred upgrading the following block:\\n\\t%s\", len(es), strings.Join(points, \"\\n\\t\"))\n",
      "\t}}\n",
      "\tfuncMap := texttemplate.FuncMap{\"aws_secretsmanager\": func(a ...string) string {\n",
      "\t\tif len(a) == 2 {\n",
      "\t\t\tfor key, config := range amazonSecretsManagerMap {\n",
      "\t\t\t\tnameOk := config[\"name\"] == a[0]\n",
      "\t\t\t\tkeyOk := config[\"key\"] == a[1]\n",
      "\t\t\t\tif nameOk && keyOk {\n",
      "\t\t\t\t\treturn fmt.Sprintf(\"${data.amazon-secretsmanager.%s.value}\", key)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tid := fmt.Sprintf(\"autogenerated_%d\", len(amazonSecretsManagerMap)+1)\n",
      "\t\t\tamazonSecretsManagerMap[id] = map[string]interface{}{\"name\": a[0], \"key\": a[1]}\n",
      "\t\t\treturn fmt.Sprintf(\"${data.amazon-secretsmanager.%s.value}\", id)\n",
      "\t\t}\n",
      "\t\tfor key, config := range amazonSecretsManagerMap {\n",
      "\t\t\tnameOk := config[\"name\"] == a[0]\n",
      "\t\t\tif nameOk {\n",
      "\t\t\t\treturn fmt.Sprintf(\"${data.amazon-secretsmanager.%s.value}\", key)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tid := fmt.Sprintf(\"autogenerated_%d\", len(amazonSecretsManagerMap)+1)\n",
      "\t\tamazonSecretsManagerMap[id] = map[string]interface{}{\"name\": a[0]}\n",
      "\t\treturn fmt.Sprintf(\"${data.amazon-secretsmanager.%s.value}\", id)\n",
      "\t}, \"timestamp\": func() string {\n",
      "\t\ttimestamp = true\n",
      "\t\treturn \"${local.timestamp}\"\n",
      "\t}, \"isotime\": func(a ...string) string {\n",
      "\t\tif len(a) == 0 {\n",
      "\t\t\treturn \"${timestamp()}\"\n",
      "\t\t}\n",
      "\t\tisotime = true\n",
      "\t\treturn fmt.Sprintf(\"${legacy_isotime(\\\"%s\\\")}\", a[0])\n",
      "\t}, \"strftime\": func(a ...string) string {\n",
      "\t\tif len(a) == 0 {\n",
      "\t\t\treturn \"${timestamp()}\"\n",
      "\t\t}\n",
      "\t\tstrftime = true\n",
      "\t\treturn fmt.Sprintf(\"${legacy_strftime(\\\"%s\\\")}\", a[0])\n",
      "\t}, \"user\": func(in string) string {\n",
      "\t\tif _, ok := localsVariableMap[in]; ok {\n",
      "\t\t\treturn fmt.Sprintf(\"${local.%s}\", in)\n",
      "\t\t}\n",
      "\t\treturn fmt.Sprintf(\"${var.%s}\", in)\n",
      "\t}, \"env\": func(in string) string {\n",
      "\t\treturn fmt.Sprintf(\"${env(%q)}\", in)\n",
      "\t}, \"build\": func(a string) string {\n",
      "\t\treturn fmt.Sprintf(\"${build.%s}\", a)\n",
      "\t}, \"data\": func(a string) string {\n",
      "\t\treturn fmt.Sprintf(\"${data.%s}\", a)\n",
      "\t}, \"template_dir\": func() string {\n",
      "\t\treturn \"${path.root}\"\n",
      "\t}, \"pwd\": func() string {\n",
      "\t\treturn \"${path.cwd}\"\n",
      "\t}, \"packer_version\": func() string {\n",
      "\t\treturn \"${packer.version}\"\n",
      "\t}, \"uuid\": func() string {\n",
      "\t\treturn \"${uuidv4()}\"\n",
      "\t}, \"lower\": func(a string) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"lower\", \"`lower(var.example)`\", \"https://www.packer.io/docs/templates/hcl_templates/functions/string/lower\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ lower `%s` }}\", a), nil\n",
      "\t}, \"upper\": func(a string) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"upper\", \"`upper(var.example)`\", \"https://www.packer.io/docs/templates/hcl_templates/functions/string/upper\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ upper `%s` }}\", a), nil\n",
      "\t}, \"split\": func(a, b string, n int) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"split\", \"`split(separator, string)`\", \"https://www.packer.io/docs/templates/hcl_templates/functions/string/split\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ split `%s` `%s` %d }}\", a, b, n), nil\n",
      "\t}, \"replace\": func(a, b string, n int, c string) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"replace\", \"`replace(string, substring, replacement)` or `regex_replace(string, substring, replacement)`\", \"https://www.packer.io/docs/templates/hcl_templates/functions/string/replace or https://www.packer.io/docs/templates/hcl_templates/functions/string/regex_replace\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ replace `%s` `%s` `%s` %d }}\", a, b, c, n), nil\n",
      "\t}, \"replace_all\": func(a, b, c string) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"replace_all\", \"`replace(string, substring, replacement)` or `regex_replace(string, substring, replacement)`\", \"https://www.packer.io/docs/templates/hcl_templates/functions/string/replace or https://www.packer.io/docs/templates/hcl_templates/functions/string/regex_replace\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ replace_all `%s` `%s` `%s` }}\", a, b, c), nil\n",
      "\t}, \"clean_resource_name\": func(a string) (string, error) {\n",
      "\t\tfuncErrors = multierror.Append(funcErrors, UnhandleableArgumentError{\"clean_resource_name\", \"use custom validation rules, `replace(string, substring, replacement)` or `regex_replace(string, substring, replacement)`\", \"https://packer.io/docs/templates/hcl_templates/variables#custom-validation-rules\" + \" , https://www.packer.io/docs/templates/hcl_templates/functions/string/replace\" + \" or https://www.packer.io/docs/templates/hcl_templates/functions/string/regex_replace\"})\n",
      "\t\treturn fmt.Sprintf(\"{{ clean_resource_name `%s` }}\", a), nil\n",
      "\t}, \"build_name\": func() string {\n",
      "\t\treturn \"${build.name}\"\n",
      "\t}, \"build_type\": func() string {\n",
      "\t\treturn \"${build.type}\"\n",
      "\t}}\n",
      "\ttpl, err := texttemplate.New(\"hcl2_upgrade\").Funcs(funcMap).Parse(string(s))\n",
      "\tif err != nil {\n",
      "\t\tif strings.Contains(err.Error(), \"unexpected \\\"\\\\\\\\\\\" in operand\") {\n",
      "\t\t\tq := fixQuoting(string(s))\n",
      "\t\t\tunquoted := []byte(q)\n",
      "\t\t\ttpl, err = texttemplate.New(\"hcl2_upgrade\").Funcs(funcMap).Parse(string(unquoted))\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fallbackReturn(err, unquoted)\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\treturn fallbackReturn(err, s)\n",
      "\t\t}\n",
      "\t}\n",
      "\tretempl := &bytes.Buffer{}\n",
      "\tif err := reTemplate(tpl.Root, retempl, funcMap); err != nil {\n",
      "\t\treturn fallbackReturn(err, s)\n",
      "\t}\n",
      "\ttpl, err = texttemplate.New(\"hcl2_upgrade\").Funcs(funcMap).Parse(retempl.String())\n",
      "\tstr := &bytes.Buffer{}\n",
      "\tif err := tpl.Execute(str, nil); err != nil {\n",
      "\t\treturn fallbackReturn(err, s)\n",
      "\t}\n",
      "\tout := str.Bytes()\n",
      "\tif funcErrors.Len() > 0 {\n",
      "\t\treturn append([]byte(fmt.Sprintf(\"\\n%s\", funcErrors)), out...)\n",
      "\t}\n",
      "\treturn out\n",
      "}\n",
      "func (FixerPowerShellEscapes) Synopsis() string {\n",
      "\treturn `Removes PowerShell escapes from user env vars and elevated username and password strings`\n",
      "}\n",
      "func New(cfg packer.Handler, ui sdkpacker.Ui) (Registry, hcl.Diagnostics) {\n",
      "\tif !IsHCPEnabled(cfg) {\n",
      "\t\treturn &nullRegistry{}, nil\n",
      "\t}\n",
      "\tswitch config := cfg.(type) {\n",
      "\tcase *hcl2template.PackerConfig:\n",
      "\t\treturn NewHCLRegistry(config, ui)\n",
      "\tcase *packer.Core:\n",
      "\t\treturn NewJSONRegistry(config, ui)\n",
      "\t}\n",
      "\treturn nil, hcl.Diagnostics{&hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Unknown Config type\", Detail: \"The config type %s does not match a Packer-known template type. \" + \"This is a Packer error and should be brought up to the Packer \" + \"team via a GitHub Issue.\"}}\n",
      "}\n",
      "func (p *Provisioner) uploadEnvVars(flattenedEnvVars string) (err error) {\n",
      "\tctx := context.TODO()\n",
      "\tenvVarReader := strings.NewReader(flattenedEnvVars)\n",
      "\tlog.Printf(\"Uploading env vars to %s\", p.config.RemoteEnvVarPath)\n",
      "\terr = retry.Config{StartTimeout: p.config.StartRetryTimeout}.Run(ctx, func(context.Context) error {\n",
      "\t\tif err := p.communicator.Upload(p.config.RemoteEnvVarPath, envVarReader, nil); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"Error uploading ps script containing env vars: %s\", err)\n",
      "\t\t}\n",
      "\t\treturn err\n",
      "\t})\n",
      "\treturn\n",
      "}\n",
      "func (c *Core) generateCoreBuildProvisioner(rawP *template.Provisioner, rawName string) (CoreBuildProvisioner, error) {\n",
      "\tcbp := CoreBuildProvisioner{}\n",
      "\tif !c.components.PluginConfig.Provisioners.Has(rawP.Type) {\n",
      "\t\terr := fmt.Errorf(\"The provisioner %s is unknown by Packer, and is likely part of a plugin that is not installed.\\n\"+\"You may find the needed plugin along with installation instructions documented on the Packer integrations page.\\n\\n\"+\"https://developer.hashicorp.com/packer/integrations?filter=%s\", rawP.Type, strings.Split(rawP.Type, \"-\")[0])\n",
      "\t\tif sugg := didyoumean.NameSuggestion(rawP.Type, c.components.PluginConfig.Provisioners.List()); sugg != \"\" {\n",
      "\t\t\terr = fmt.Errorf(\"Did you mean to use %q?\", sugg)\n",
      "\t\t}\n",
      "\t\treturn cbp, err\n",
      "\t}\n",
      "\tprovisioner, err := c.components.PluginConfig.Provisioners.Start(rawP.Type)\n",
      "\tif err != nil {\n",
      "\t\treturn cbp, fmt.Errorf(\"error initializing provisioner '%s': %s\", rawP.Type, err)\n",
      "\t}\n",
      "\tif provisioner == nil {\n",
      "\t\treturn cbp, fmt.Errorf(\"provisioner failed to be started and did not error: %s\", rawP.Type)\n",
      "\t}\n",
      "\tconfig := make([]interface{}, 1, 2)\n",
      "\tconfig[0] = rawP.Config\n",
      "\tif rawP.Override != nil {\n",
      "\t\tif override, ok := rawP.Override[rawName]; ok {\n",
      "\t\t\tconfig = append(config, override)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif rawP.PauseBefore != 0 {\n",
      "\t\tprovisioner = &PausedProvisioner{PauseBefore: rawP.PauseBefore, Provisioner: provisioner}\n",
      "\t} else if rawP.Timeout != 0 {\n",
      "\t\tprovisioner = &TimeoutProvisioner{Timeout: rawP.Timeout, Provisioner: provisioner}\n",
      "\t}\n",
      "\tmaxRetries := 0\n",
      "\tif rawP.MaxRetries != \"\" {\n",
      "\t\trenderedMaxRetries, err := interpolate.Render(rawP.MaxRetries, c.Context())\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn cbp, fmt.Errorf(\"failed to interpolate `max_retries`: %s\", err.Error())\n",
      "\t\t}\n",
      "\t\tmaxRetries, err = strconv.Atoi(renderedMaxRetries)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn cbp, fmt.Errorf(\"`max_retries` must be a valid integer: %s\", err.Error())\n",
      "\t\t}\n",
      "\t}\n",
      "\tif maxRetries != 0 {\n",
      "\t\tprovisioner = &RetriedProvisioner{MaxRetries: maxRetries, Provisioner: provisioner}\n",
      "\t}\n",
      "\tcbp = CoreBuildProvisioner{PType: rawP.Type, Provisioner: provisioner, config: config}\n",
      "\treturn cbp, nil\n",
      "}\n",
      "func (rlerr *RateLimitError) Error() string {\n",
      "\ts := fmt.Sprintf(\"Plugin host rate limited the plugin getter. Try again in %s.\\n\", time.Until(rlerr.ResetTime))\n",
      "\tif rlerr.SetableEnvVar != \"\" {\n",
      "\t\ts += fmt.Sprintf(\"HINT: Set the %s env var with a token to get more requests.\\n\", rlerr.SetableEnvVar)\n",
      "\t}\n",
      "\ts += rlerr.Err.Error()\n",
      "\treturn s\n",
      "}\n",
      "func (c *PluginClient) Start() (net.Addr, error) {\n",
      "\tc.l.Lock()\n",
      "\tdefer c.l.Unlock()\n",
      "\tif c.address != nil {\n",
      "\t\treturn c.address, nil\n",
      "\t}\n",
      "\tc.doneLogging = make(chan struct{})\n",
      "\tenv := []string{fmt.Sprintf(\"%s=%s\", pluginsdk.MagicCookieKey, pluginsdk.MagicCookieValue), fmt.Sprintf(\"PACKER_PLUGIN_MIN_PORT=%d\", c.config.MinPort), fmt.Sprintf(\"PACKER_PLUGIN_MAX_PORT=%d\", c.config.MaxPort)}\n",
      "\tstdout_r, stdout_w := io.Pipe()\n",
      "\tstderr_r, stderr_w := io.Pipe()\n",
      "\tcmd := c.config.Cmd\n",
      "\tcmd.Env = append(cmd.Env, os.Environ()...)\n",
      "\tcmd.Env = append(cmd.Env, env...)\n",
      "\tcmd.Stdin = os.Stdin\n",
      "\tcmd.Stderr = stderr_w\n",
      "\tcmd.Stdout = stdout_w\n",
      "\tlog.Printf(\"Starting plugin: %s %#v\", cmd.Path, cmd.Args)\n",
      "\terr := cmd.Start()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\tr := recover()\n",
      "\t\tif err != nil || r != nil {\n",
      "\t\t\tcmd.Process.Kill()\n",
      "\t\t}\n",
      "\t\tif r != nil {\n",
      "\t\t\tpanic(r)\n",
      "\t\t}\n",
      "\t}()\n",
      "\texitCh := make(chan struct{})\n",
      "\tgo func() {\n",
      "\t\tdefer stderr_w.Close()\n",
      "\t\tdefer stdout_w.Close()\n",
      "\t\tcmd.Wait()\n",
      "\t\tlog.Printf(\"%s: plugin process exited\\n\", cmd.Path)\n",
      "\t\tos.Stderr.Sync()\n",
      "\t\tclose(exitCh)\n",
      "\t\tc.l.Lock()\n",
      "\t\tdefer c.l.Unlock()\n",
      "\t\tc.exited = true\n",
      "\t}()\n",
      "\tgo c.logStderr(stderr_r)\n",
      "\tlinesCh := make(chan []byte)\n",
      "\tgo func() {\n",
      "\t\tdefer close(linesCh)\n",
      "\t\tbuf := bufio.NewReader(stdout_r)\n",
      "\t\tfor {\n",
      "\t\t\tline, err := buf.ReadBytes('\\n')\n",
      "\t\t\tif line != nil {\n",
      "\t\t\t\tlinesCh <- line\n",
      "\t\t\t}\n",
      "\t\t\tif err == io.EOF {\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}()\n",
      "\tdefer func() {\n",
      "\t\tgo func() {\n",
      "\t\t\tfor range linesCh {\n",
      "\t\t\t}\n",
      "\t\t}()\n",
      "\t}()\n",
      "\ttimeout := time.After(c.config.StartTimeout)\n",
      "\tlog.Printf(\"Waiting for RPC address for: %s\", cmd.Path)\n",
      "\tselect {\n",
      "\tcase <-timeout:\n",
      "\t\terr = errors.New(\"timeout while waiting for plugin to start\")\n",
      "\tcase <-exitCh:\n",
      "\t\terr = errors.New(\"plugin exited before we could connect\")\n",
      "\tcase lineBytes := <-linesCh:\n",
      "\t\tline := strings.TrimSpace(string(lineBytes))\n",
      "\t\tparts := strings.SplitN(line, \"|\", 4)\n",
      "\t\tif len(parts) == 3 {\n",
      "\t\t\terr = fmt.Errorf(\"The protocol of this plugin (protocol version 4 \" + \"and lower) was deprecated, please use a newer version of this plugin.\" + \"Or use an older version of Packer (pre 1.7) with this plugin.\")\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif len(parts) < 4 {\n",
      "\t\t\terr = fmt.Errorf(\"Unrecognized remote plugin message: %s\", line)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tpluginMajorAPIVersion, pluginMinorAPIVersion, network, netAddr := parts[0], parts[1], parts[2], parts[3]\n",
      "\t\tif pluginMajorAPIVersion != pluginsdk.APIVersionMajor {\n",
      "\t\t\terr = fmt.Errorf(\"Incompatible API MAJOR version with plugin. \"+\"plugin MINOR API version: %s, Ours: %s\", pluginMajorAPIVersion, pluginsdk.APIVersionMajor)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tif pluginMinorAPIVersion > pluginsdk.APIVersionMinor {\n",
      "\t\t\terr = fmt.Errorf(\"Incompatible API MINOR version with plugin. \"+\"plugin MINOR API version: %s, Ours: %s. Please upgrade Packer.\", pluginMinorAPIVersion, pluginsdk.APIVersionMinor)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tswitch network {\n",
      "\t\tcase \"tcp\":\n",
      "\t\t\tc.address, err = net.ResolveTCPAddr(\"tcp\", netAddr)\n",
      "\t\tcase \"unix\":\n",
      "\t\t\tc.address, err = net.ResolveUnixAddr(\"unix\", netAddr)\n",
      "\t\tdefault:\n",
      "\t\t\treturn nil, fmt.Errorf(\"Unknown address type: %s\", network)\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"Received %s RPC address for %s: addr is %s\", network, cmd.Path, c.address)\n",
      "\t}\n",
      "\treturn c.address, err\n",
      "}\n",
      "func (m *Meta) Core(tpl *template.Template, cla *MetaArgs) (*packer.Core, error) {\n",
      "\tconfig := *m.CoreConfig\n",
      "\tconfig.Template = tpl\n",
      "\tfj := &kvflag.FlagJSON{}\n",
      "\tfor _, file := range cla.VarFiles {\n",
      "\t\terr := fj.Set(file)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif cla.Vars == nil {\n",
      "\t\tcla.Vars = map[string]string{}\n",
      "\t}\n",
      "\tfor k, v := range *fj {\n",
      "\t\tif _, exists := cla.Vars[k]; !exists {\n",
      "\t\t\tcla.Vars[k] = v\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig.Variables = cla.Vars\n",
      "\tcore := packer.NewCore(&config)\n",
      "\treturn core, nil\n",
      "}\n",
      "func (cfg *PackerConfig) collectInputVariableValues(env []string, files []*hcl.File, argv map[string]string) hcl.Diagnostics {\n",
      "\tvar diags hcl.Diagnostics\n",
      "\tvariables := cfg.InputVariables\n",
      "\tfor _, raw := range env {\n",
      "\t\tif !strings.HasPrefix(raw, VarEnvPrefix) {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\traw = raw[len(VarEnvPrefix):]\n",
      "\t\teq := strings.Index(raw, \"=\")\n",
      "\t\tif eq == -1 {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tname := raw[:eq]\n",
      "\t\tvalue := raw[eq+1:]\n",
      "\t\tvariable, found := variables[name]\n",
      "\t\tif !found {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tfakeFilename := fmt.Sprintf(\"<value for var.%s from env>\", name)\n",
      "\t\texpr, moreDiags := expressionFromVariableDefinition(fakeFilename, value, variable.Type)\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t\tif moreDiags.HasErrors() {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tval, valDiags := expr.Value(nil)\n",
      "\t\tdiags = append(diags, valDiags...)\n",
      "\t\tif variable.Type != cty.NilType {\n",
      "\t\t\tvar err error\n",
      "\t\t\tval, err = convert.Convert(val, variable.Type)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Invalid value for variable\", Detail: fmt.Sprintf(\"The value for %s is not compatible with the variable's type constraint: %s.\", name, err), Subject: expr.Range().Ptr()})\n",
      "\t\t\t\tval = cty.DynamicVal\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tvariable.Values = append(variable.Values, VariableAssignment{From: \"env\", Value: val, Expr: expr})\n",
      "\t}\n",
      "\tfor _, file := range files {\n",
      "\t\t{\n",
      "\t\t\tcontent, _, _ := file.Body.PartialContent(&hcl.BodySchema{Blocks: []hcl.BlockHeaderSchema{{Type: \"variable\", LabelNames: []string{\"name\"}}}})\n",
      "\t\t\tfor _, block := range content.Blocks {\n",
      "\t\t\t\tname := block.Labels[0]\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Variable declaration in a .pkrvar file\", Detail: fmt.Sprintf(\"A .pkrvar file is used to assign \"+\"values to variables that have already been declared \"+\"in .pkr files, not to declare new variables. To \"+\"declare variable %q, place this block in one of your\"+\" .pkr files, such as variables.pkr.hcl\\n\\nTo set a \"+\"value for this variable in %s, use the definition \"+\"syntax instead:\\n    %s = <value>\", name, block.TypeRange.Filename, name), Subject: &block.TypeRange})\n",
      "\t\t\t}\n",
      "\t\t\tif diags.HasErrors() {\n",
      "\t\t\t\treturn diags\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tattrs, moreDiags := file.Body.JustAttributes()\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t\tfor name, attr := range attrs {\n",
      "\t\t\tvariable, found := variables[name]\n",
      "\t\t\tif !found {\n",
      "\t\t\t\tif !cfg.ValidationOptions.WarnOnUndeclaredVar {\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\t}\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagWarning, Summary: \"Undefined variable\", Detail: fmt.Sprintf(\"The variable %[1]q was set but was not declared as an input variable.\"+\"\\nTo declare variable %[1]q place this block in one of your .pkr.hcl files, \"+\"such as variables.pkr.hcl\\n\\n\"+\"variable %[1]q {\\n\"+\"  type    = string\\n\"+\"  default = null\\n\"+\"}\", name), Context: attr.Range.Ptr()})\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tval, moreDiags := attr.Expr.Value(nil)\n",
      "\t\t\tdiags = append(diags, moreDiags...)\n",
      "\t\t\tif variable.Type != cty.NilType {\n",
      "\t\t\t\tvar err error\n",
      "\t\t\t\tval, err = convert.Convert(val, variable.Type)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Invalid value for variable\", Detail: fmt.Sprintf(\"The value for %s is not compatible with the variable's type constraint: %s.\", name, err), Subject: attr.Expr.Range().Ptr()})\n",
      "\t\t\t\t\tval = cty.DynamicVal\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tvariable.Values = append(variable.Values, VariableAssignment{From: \"varfile\", Value: val, Expr: attr.Expr})\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor name, value := range argv {\n",
      "\t\tvariable, found := variables[name]\n",
      "\t\tif !found {\n",
      "\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Undefined -var variable\", Detail: fmt.Sprintf(\"A %q variable was passed in the command \"+\"line but was not found in known variables. \"+\"To declare variable %q, place this block in one of your\"+\" .pkr files, such as variables.pkr.hcl\", name, name)})\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tfakeFilename := fmt.Sprintf(\"<value for var.%s from arguments>\", name)\n",
      "\t\texpr, moreDiags := expressionFromVariableDefinition(fakeFilename, value, variable.Type)\n",
      "\t\tdiags = append(diags, moreDiags...)\n",
      "\t\tif moreDiags.HasErrors() {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tval, valDiags := expr.Value(nil)\n",
      "\t\tdiags = append(diags, valDiags...)\n",
      "\t\tif variable.Type != cty.NilType {\n",
      "\t\t\tvar err error\n",
      "\t\t\tval, err = convert.Convert(val, variable.Type)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Invalid argument value for -var variable\", Detail: fmt.Sprintf(\"The received arg value for %s is not compatible with the variable's type constraint: %s.\", name, err)})\n",
      "\t\t\t\tval = cty.DynamicVal\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tvariable.Values = append(variable.Values, VariableAssignment{From: \"cmd\", Value: val, Expr: expr})\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "func (cfg *PackerConfig) DetectPluginBinaries() hcl.Diagnostics {\n",
      "\terr := cfg.parser.PluginConfig.Discover()\n",
      "\tif err != nil {\n",
      "\t\treturn (hcl.Diagnostics{}).Append(&hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Failed to discover installed plugins\", Detail: err.Error()})\n",
      "\t}\n",
      "\topts := plugingetter.ListInstallationsOptions{PluginDirectory: cfg.parser.PluginConfig.PluginDirectory, BinaryInstallationOptions: plugingetter.BinaryInstallationOptions{OS: runtime.GOOS, ARCH: runtime.GOARCH, APIVersionMajor: pluginsdk.APIVersionMajor, APIVersionMinor: pluginsdk.APIVersionMinor, Checksummers: []plugingetter.Checksummer{{Type: \"sha256\", Hash: sha256.New()}}, ReleasesOnly: cfg.parser.PluginConfig.ReleasesOnly}}\n",
      "\tif runtime.GOOS == \"windows\" && opts.Ext == \"\" {\n",
      "\t\topts.BinaryInstallationOptions.Ext = \".exe\"\n",
      "\t}\n",
      "\tpluginReqs, diags := cfg.PluginRequirements()\n",
      "\tif diags.HasErrors() {\n",
      "\t\treturn diags\n",
      "\t}\n",
      "\tuninstalledPlugins := map[string]string{}\n",
      "\tfor _, pluginRequirement := range pluginReqs {\n",
      "\t\tsortedInstalls, err := pluginRequirement.ListInstallations(opts)\n",
      "\t\tif err != nil {\n",
      "\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"Failed to list installation for %s\", pluginRequirement.Identifier), Detail: err.Error()})\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif len(sortedInstalls) == 0 {\n",
      "\t\t\tuninstalledPlugins[pluginRequirement.Identifier.String()] = pluginRequirement.VersionConstraints.String()\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"[TRACE] Found the following %q installations: %v\", pluginRequirement.Identifier, sortedInstalls)\n",
      "\t\tinstall := sortedInstalls[len(sortedInstalls)-1]\n",
      "\t\terr = cfg.parser.PluginConfig.DiscoverMultiPlugin(pluginRequirement.Accessor, install.BinaryPath)\n",
      "\t\tif err != nil {\n",
      "\t\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: fmt.Sprintf(\"Error discovering plugin %s\", pluginRequirement.Identifier), Detail: err.Error()})\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(uninstalledPlugins) > 0 {\n",
      "\t\tdetailMessage := &strings.Builder{}\n",
      "\t\tdetailMessage.WriteString(\"The following plugins are required, but not installed:\\n\\n\")\n",
      "\t\tfor pluginName, pluginVersion := range uninstalledPlugins {\n",
      "\t\t\tfmt.Fprintf(detailMessage, \"* %s %s\\n\", pluginName, pluginVersion)\n",
      "\t\t}\n",
      "\t\tdetailMessage.WriteString(\"\\nDid you run packer init for this project ?\")\n",
      "\t\tdiags = append(diags, &hcl.Diagnostic{Severity: hcl.DiagError, Summary: \"Missing plugins\", Detail: detailMessage.String()})\n",
      "\t}\n",
      "\treturn diags\n",
      "}\n",
      "func (c *InitCommand) RunContext(buildCtx context.Context, cla *InitArgs) int {\n",
      "\tpackerStarter, ret := c.GetConfig(&cla.MetaArgs)\n",
      "\tif ret != 0 {\n",
      "\t\treturn ret\n",
      "\t}\n",
      "\treqs, diags := packerStarter.PluginRequirements()\n",
      "\tret = writeDiags(c.Ui, nil, diags)\n",
      "\tif ret != 0 {\n",
      "\t\treturn ret\n",
      "\t}\n",
      "\tif len(reqs) == 0 {\n",
      "\t\tc.Ui.Message(`\n",
      "No plugins requirement found, make sure you reference a Packer config\n",
      "containing a packer.required_plugins block. See\n",
      "https://www.packer.io/docs/templates/hcl_templates/blocks/packer\n",
      "for more info.`)\n",
      "\t}\n",
      "\topts := plugingetter.ListInstallationsOptions{PluginDirectory: c.Meta.CoreConfig.Components.PluginConfig.PluginDirectory, BinaryInstallationOptions: plugingetter.BinaryInstallationOptions{OS: runtime.GOOS, ARCH: runtime.GOARCH, APIVersionMajor: pluginsdk.APIVersionMajor, APIVersionMinor: pluginsdk.APIVersionMinor, Checksummers: []plugingetter.Checksummer{{Type: \"sha256\", Hash: sha256.New()}}}}\n",
      "\tif runtime.GOOS == \"windows\" && opts.Ext == \"\" {\n",
      "\t\topts.BinaryInstallationOptions.Ext = \".exe\"\n",
      "\t}\n",
      "\tlog.Printf(\"[TRACE] init: %#v\", opts)\n",
      "\tgetters := []plugingetter.Getter{&github.Getter{UserAgent: \"packer-getter-github-\" + version.String()}}\n",
      "\tui := &packer.ColoredUi{Color: packer.UiColorCyan, Ui: c.Ui}\n",
      "\tfor _, pluginRequirement := range reqs {\n",
      "\t\tinstalls, err := pluginRequirement.ListInstallations(opts)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Ui.Error(err.Error())\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tif len(installs) > 0 {\n",
      "\t\t\tif !cla.Force && !cla.Upgrade {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tif cla.Force && !cla.Upgrade {\n",
      "\t\t\t\tpluginRequirement.VersionConstraints, _ = gversion.NewConstraint(fmt.Sprintf(\"=%s\", installs[len(installs)-1].Version))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tnewInstall, err := pluginRequirement.InstallLatest(plugingetter.InstallOptions{PluginDirectory: opts.PluginDirectory, BinaryInstallationOptions: opts.BinaryInstallationOptions, Getters: getters, Force: cla.Force})\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Ui.Error(fmt.Sprintf(\"Failed getting the %q plugin:\", pluginRequirement.Identifier))\n",
      "\t\t\tc.Ui.Error(err.Error())\n",
      "\t\t\tret = 1\n",
      "\t\t}\n",
      "\t\tif newInstall != nil {\n",
      "\t\t\tmsg := fmt.Sprintf(\"Installed plugin %s %s in %q\", pluginRequirement.Identifier, newInstall.Version, newInstall.BinaryPath)\n",
      "\t\t\tui.Say(msg)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn ret\n",
      "}\n",
      "func (*FormatCommand) Synopsis() string {\n",
      "\treturn \"Rewrites HCL2 config files to canonical format\"\n",
      "}\n",
      "func (c *PluginsRequiredCommand) RunContext(buildCtx context.Context, cla *PluginsRequiredArgs) int {\n",
      "\tpackerStarter, ret := c.GetConfig(&cla.MetaArgs)\n",
      "\tif ret != 0 {\n",
      "\t\treturn ret\n",
      "\t}\n",
      "\treqs, diags := packerStarter.PluginRequirements()\n",
      "\tret = writeDiags(c.Ui, nil, diags)\n",
      "\tif ret != 0 {\n",
      "\t\treturn ret\n",
      "\t}\n",
      "\topts := plugingetter.ListInstallationsOptions{PluginDirectory: c.Meta.CoreConfig.Components.PluginConfig.PluginDirectory, BinaryInstallationOptions: plugingetter.BinaryInstallationOptions{OS: runtime.GOOS, ARCH: runtime.GOARCH, APIVersionMajor: pluginsdk.APIVersionMajor, APIVersionMinor: pluginsdk.APIVersionMinor, Checksummers: []plugingetter.Checksummer{{Type: \"sha256\", Hash: sha256.New()}}}}\n",
      "\tfor _, pluginRequirement := range reqs {\n",
      "\t\ts := fmt.Sprintf(\"%s %s %q\", pluginRequirement.Accessor, pluginRequirement.Identifier.String(), pluginRequirement.VersionConstraints.String())\n",
      "\t\tinstalls, err := pluginRequirement.ListInstallations(opts)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Ui.Error(err.Error())\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t\tfor _, install := range installs {\n",
      "\t\t\ts += fmt.Sprintf(\" %s\", install.BinaryPath)\n",
      "\t\t}\n",
      "\t\tc.Ui.Message(s)\n",
      "\t}\n",
      "\tif len(reqs) == 0 {\n",
      "\t\tc.Ui.Message(`\n",
      "No plugins requirement found, make sure you reference a Packer config\n",
      "containing a packer.required_plugins block. See\n",
      "https://www.packer.io/docs/templates/hcl_templates/blocks/packer\n",
      "for more info.`)\n",
      "\t}\n",
      "\treturn 0\n",
      "}\n",
      "func (c *HCL2UpgradeCommand) RunContext(_ context.Context, cla *HCL2UpgradeArgs) int {\n",
      "\tvar output io.Writer\n",
      "\tif err := os.MkdirAll(filepath.Dir(cla.OutputFile), 0755); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Failed to create output directory: %v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif f, err := os.Create(cla.OutputFile); err == nil {\n",
      "\t\toutput = f\n",
      "\t\tdefer f.Close()\n",
      "\t} else {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Failed to create output file: %v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif cla.WithAnnotations {\n",
      "\t\tif _, err := output.Write([]byte(hcl2UpgradeFileHeader)); err != nil {\n",
      "\t\t\tc.Ui.Error(fmt.Sprintf(\"Failed to write to file: %v\", err))\n",
      "\t\t\treturn 1\n",
      "\t\t}\n",
      "\t}\n",
      "\thdl, ret := c.GetConfigFromJSON(&cla.MetaArgs)\n",
      "\tif ret != 0 {\n",
      "\t\tc.Ui.Error(\"Failed to get config from JSON\")\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tcore := hdl.(*packer.Core)\n",
      "\tif err := core.Initialize(packer.InitializeOptions{}); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following initialization error: %v\", err))\n",
      "\t}\n",
      "\ttpl := core.Template\n",
      "\tpackerBlock := &PackerParser{WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := packerBlock.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tvariables := &VariableParser{WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := variables.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following variables.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tlocals := &LocalsParser{LocalsOut: variables.localsOut, WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := locals.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following locals.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tbuilders := []*template.Builder{}\n",
      "\t{\n",
      "\t\tfor _, builder := range tpl.Builders {\n",
      "\t\t\tbuilders = append(builders, builder)\n",
      "\t\t}\n",
      "\t}\n",
      "\tsort.Slice(builders, func(i, j int) bool {\n",
      "\t\treturn builders[i].Type+builders[i].Name < builders[j].Type+builders[j].Name\n",
      "\t})\n",
      "\tamazonAmiDatasource := &AmazonAmiDatasourceParser{Builders: builders, WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := amazonAmiDatasource.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following amazonAmiDatasource.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tsources := &SourceParser{Builders: builders, BuilderPlugins: c.Meta.CoreConfig.Components.PluginConfig.Builders, WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := sources.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following sources.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tbuild := &BuildParser{Builders: builders, WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := build.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following build.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tamazonSecretsDatasource := &AmazonSecretsDatasourceParser{WithAnnotations: cla.WithAnnotations}\n",
      "\tif err := amazonSecretsDatasource.Parse(tpl); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Ignoring following amazonSecretsDatasource.Parse error: %v\", err))\n",
      "\t\tret = 1\n",
      "\t}\n",
      "\tout := &bytes.Buffer{}\n",
      "\tfor _, block := range []BlockParser{packerBlock, variables, amazonSecretsDatasource, amazonAmiDatasource, locals, sources, build} {\n",
      "\t\tblock.Write(out)\n",
      "\t}\n",
      "\tif _, err := output.Write(hclwrite.Format(out.Bytes())); err != nil {\n",
      "\t\tc.Ui.Error(fmt.Sprintf(\"Failed to write to file: %v\", err))\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tc.Ui.Say(fmt.Sprintf(\"Successfully created %s. Exit %d\", cla.OutputFile, ret))\n",
      "\treturn ret\n",
      "}\n",
      "func realMain() int {\n",
      "\tvar wrapConfig panicwrap.WrapConfig\n",
      "\twrapConfig.CookieKey = \"PACKER_WRAP_COOKIE\"\n",
      "\twrapConfig.CookieValue = \"49C22B1A-3A93-4C98-97FA-E07D18C787B5\"\n",
      "\tif inPlugin() || panicwrap.Wrapped(&wrapConfig) {\n",
      "\t\treturn wrappedMain()\n",
      "\t}\n",
      "\tUUID, _ := uuid.GenerateUUID()\n",
      "\tos.Setenv(\"PACKER_RUN_UUID\", UUID)\n",
      "\tlogWriter, err := logOutput()\n",
      "\tif err != nil {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"Couldn't setup log output: %s\", err)\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif logWriter == nil {\n",
      "\t\tlogWriter = io.Discard\n",
      "\t}\n",
      "\tpackersdk.LogSecretFilter.SetOutput(logWriter)\n",
      "\tlog.SetOutput(io.Discard)\n",
      "\tlogTempFile, err := tmp.File(\"packer-log\")\n",
      "\tif err != nil {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"Couldn't setup logging tempfile: %s\", err)\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tdefer os.Remove(logTempFile.Name())\n",
      "\tdefer logTempFile.Close()\n",
      "\tdoneCh := make(chan struct{})\n",
      "\toutR, outW := io.Pipe()\n",
      "\tgo copyOutput(outR, doneCh)\n",
      "\tif config, _ := loadConfig(); config != nil && !config.DisableCheckpoint {\n",
      "\t\tpacker.CheckpointReporter = packer.NewCheckpointReporter(config.DisableCheckpointSignature)\n",
      "\t}\n",
      "\twrapConfig.Handler = panicHandler(logTempFile)\n",
      "\twrapConfig.Writer = io.MultiWriter(logTempFile, &packersdk.LogSecretFilter)\n",
      "\twrapConfig.Stdout = outW\n",
      "\twrapConfig.DetectDuration = 500 * time.Millisecond\n",
      "\twrapConfig.ForwardSignals = []os.Signal{syscall.SIGTERM}\n",
      "\texitStatus, err := panicwrap.Wrap(&wrapConfig)\n",
      "\tif err != nil {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"Couldn't start Packer: %s\", err)\n",
      "\t\treturn 1\n",
      "\t}\n",
      "\tif exitStatus >= 0 {\n",
      "\t\toutW.Close()\n",
      "\t\t<-doneCh\n",
      "\t\treturn exitStatus\n",
      "\t}\n",
      "\tlogTempFile.Close()\n",
      "\treturn 0\n",
      "}\n",
      "func (h *ProvisionHook) Run(ctx context.Context, name string, ui packersdk.Ui, comm packersdk.Communicator, data interface{}) error {\n",
      "\tif len(h.Provisioners) == 0 {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif comm == nil {\n",
      "\t\treturn fmt.Errorf(\"No communicator found for provisioners! This is usually because the\\n\" + \"`communicator` config was set to \\\"none\\\". If you have any provisioners\\n\" + \"then a communicator is required. Please fix this to continue.\")\n",
      "\t}\n",
      "\tfor _, p := range h.Provisioners {\n",
      "\t\tts := CheckpointReporter.AddSpan(p.TypeName, \"provisioner\", p.Config)\n",
      "\t\tcast := CastDataToMap(data)\n",
      "\t\terr := p.Provisioner.Provision(ctx, ui, comm, cast)\n",
      "\t\tts.End(err)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func PluginFolder() (string, error) {\n",
      "\tif packerPluginPath := os.Getenv(\"PACKER_PLUGIN_PATH\"); packerPluginPath != \"\" {\n",
      "\t\treturn packerPluginPath, nil\n",
      "\t}\n",
      "\tcd, err := pathing.ConfigDir()\n",
      "\tif err != nil {\n",
      "\t\tlog.Printf(\"[ERR] Error loading config directory: %v\", err)\n",
      "\t\treturn \"\", err\n",
      "\t}\n",
      "\treturn filepath.Join(cd, \"plugins\"), nil\n",
      "}\n",
      "func (o *options) AddFlagSets(fs *flag.FlagSet) {\n",
      "\tfs.StringVar(&o.Type, \"type\", \"rsa\", `dsa | ecdsa | ed25519 | rsa\n",
      "Specifies the type of key to create. The possible values are 'dsa', 'ecdsa',\n",
      "'ed25519', or 'rsa'.\n",
      "`)\n",
      "\tfs.IntVar(&o.Bits, \"bits\", 0, `Specifies the number of bits in the key to create. By default maximum\n",
      "number will be picked. For RSA keys, the minimum size is 1024 bits and the\n",
      "default is 3072 bits. Generally, 3072 bits is considered sufficient. DSA\n",
      "keys must be exactly 1024 bits as specified by FIPS 186-2. For ECDSA keys,\n",
      "the bits flag determines the key length by selecting from one of three\n",
      "elliptic curve sizes: 256, 384 or 521 bits. Attempting to use bit lengths\n",
      "other than these three values for ECDSA keys will fail. Ed25519 keys have a\n",
      "fixed length and the bits flag will be ignored.\n",
      "`)\n",
      "\tdefaultPath := \"\"\n",
      "\tuser, err := user.Current()\n",
      "\tif err == nil {\n",
      "\t\tdefaultPath = filepath.Join(user.HomeDir, \".ssh\", \"tests\")\n",
      "\t}\n",
      "\tfs.StringVar(&o.Filename, \"filename\", defaultPath, `Specifies the filename of the key file.\n",
      "`)\n",
      "}\n",
      "rqlite/rqlite 3 14605\n",
      "3\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (s *Store) Open() (retErr error) {\n",
      "\tdefer func() {\n",
      "\t\tif retErr == nil {\n",
      "\t\t\ts.open.Set()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tif s.open.Is() {\n",
      "\t\treturn ErrOpen\n",
      "\t}\n",
      "\ts.openT = time.Now()\n",
      "\ts.logger.Printf(\"opening store with node ID %s, listening on %s\", s.raftID, s.ly.Addr().String())\n",
      "\ts.logger.Printf(\"ensuring data directory exists at %s\", s.raftDir)\n",
      "\tif err := os.MkdirAll(s.raftDir, 0755); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := os.MkdirAll(filepath.Dir(s.peersPath), 0755); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tdecMgmr, err := chunking.NewDechunkerManager(filepath.Dir(s.dbPath))\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\ts.dechunkManager = decMgmr\n",
      "\ts.cmdProc = NewCommandProcessor(s.logger, s.dechunkManager)\n",
      "\tparentDBDir := filepath.Dir(s.dbPath)\n",
      "\tif !dirExists(parentDBDir) {\n",
      "\t\ts.logger.Printf(\"creating directory for database at %s\", parentDBDir)\n",
      "\t\terr := os.MkdirAll(parentDBDir, 0755)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tnt := raft.NewNetworkTransport(NewTransport(s.ly), connectionPoolCount, connectionTimeout, nil)\n",
      "\ts.raftTn = NewNodeTransport(nt)\n",
      "\ts.numTrailingLogs = uint64(float64(s.SnapshotThreshold) * trailingScale)\n",
      "\tconfig := s.raftConfig()\n",
      "\tconfig.LocalID = raft.ServerID(s.raftID)\n",
      "\toldSnapshotDir := filepath.Join(s.raftDir, \"snapshots\")\n",
      "\tif err := snapshot.Upgrade(oldSnapshotDir, s.snapshotDir, s.logger); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to upgrade snapshots: %s\", err)\n",
      "\t}\n",
      "\tsnapshotStore, err := snapshot.NewStore(filepath.Join(s.snapshotDir))\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to create snapshot store: %s\", err)\n",
      "\t}\n",
      "\tsnapshotStore.LogReaping = s.hcLogLevel() < hclog.Warn\n",
      "\ts.snapshotStore = snapshotStore\n",
      "\tsnaps, err := s.snapshotStore.List()\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"list snapshots: %s\", err)\n",
      "\t}\n",
      "\ts.logger.Printf(\"%d preexisting snapshots present\", len(snaps))\n",
      "\ts.boltStore, err = rlog.New(filepath.Join(s.raftDir, raftDBPath), s.NoFreeListSync)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"new log store: %s\", err)\n",
      "\t}\n",
      "\ts.raftStable = s.boltStore\n",
      "\ts.raftLog, err = raft.NewLogCache(raftLogCacheSize, s.boltStore)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"new cached store: %s\", err)\n",
      "\t}\n",
      "\tif pathExists(s.peersPath) {\n",
      "\t\ts.logger.Printf(\"attempting node recovery using %s\", s.peersPath)\n",
      "\t\tconfig, err := raft.ReadConfigJSON(s.peersPath)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to read peers file: %s\", err.Error())\n",
      "\t\t}\n",
      "\t\tif err = RecoverNode(s.raftDir, s.logger, s.raftLog, s.boltStore, s.snapshotStore, s.raftTn, config); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to recover node: %s\", err.Error())\n",
      "\t\t}\n",
      "\t\tif err := os.Rename(s.peersPath, s.peersInfoPath); err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"failed to move %s after recovery: %s\", s.peersPath, err.Error())\n",
      "\t\t}\n",
      "\t\ts.logger.Printf(\"node recovered successfully using %s\", s.peersPath)\n",
      "\t\tstats.Add(numRecoveries, 1)\n",
      "\t}\n",
      "\ts.db, err = createOnDisk(s.dbPath, s.dbConf.FKConstraints, true)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to create on-disk database: %s\", err)\n",
      "\t}\n",
      "\tfor _, pattern := range []string{restoreScratchPattern, bootScatchPattern, backupScatchPattern, vacuumScatchPattern} {\n",
      "\t\tfor _, dir := range []string{s.raftDir, s.dbDir} {\n",
      "\t\t\tfiles, err := filepath.Glob(filepath.Join(dir, pattern))\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn fmt.Errorf(\"failed to locate temporary files for pattern %s: %s\", pattern, err.Error())\n",
      "\t\t\t}\n",
      "\t\t\tfor _, f := range files {\n",
      "\t\t\t\tif err := os.Remove(f); err != nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"failed to remove temporary file %s: %s\", f, err.Error())\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tra, err := raft.NewRaft(config, NewFSM(s), s.raftLog, s.raftStable, s.snapshotStore, s.raftTn)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"creating the raft system failed: %s\", err)\n",
      "\t}\n",
      "\ts.raft = ra\n",
      "\ts.observerChan = make(chan raft.Observation, observerChanLen)\n",
      "\ts.observer = raft.NewObserver(s.observerChan, false, func(o *raft.Observation) bool {\n",
      "\t\t_, isLeaderChange := o.Data.(raft.LeaderObservation)\n",
      "\t\t_, isFailedHeartBeat := o.Data.(raft.FailedHeartbeatObservation)\n",
      "\t\treturn isLeaderChange || isFailedHeartBeat\n",
      "\t})\n",
      "\ts.raft.RegisterObserver(s.observer)\n",
      "\ts.observerClose, s.observerDone = s.observe()\n",
      "\ts.snapshotWClose, s.snapshotWDone = s.runWALSnapshotting()\n",
      "\tif err := s.initVacuumTime(); err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to initialize auto-vacuum times: %s\", err.Error())\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func toggleFlag(op string, flag *bool) error {\n",
      "\tif op != \"on\" && op != \"off\" {\n",
      "\t\treturn fmt.Errorf(\"invalid option '%s'. Use 'on' or 'off' (default)\", op)\n",
      "\t}\n",
      "\t*flag = (op == \"on\")\n",
      "\treturn nil\n",
      "}\n",
      "func createClusterClient(cfg *Config, clstr *cluster.Service) (*cluster.Client, error) {\n",
      "\tvar dialerTLSConfig *tls.Config\n",
      "\tvar err error\n",
      "\tif cfg.NodeX509Cert != \"\" || cfg.NodeX509CACert != \"\" {\n",
      "\t\tdialerTLSConfig, err = rtls.CreateClientConfig(cfg.NodeX509Cert, cfg.NodeX509Key, cfg.NodeX509CACert, cfg.NodeVerifyServerName, cfg.NoNodeVerify)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to create TLS config for cluster dialer: %s\", err.Error())\n",
      "\t\t}\n",
      "\t}\n",
      "\tclstrDialer := tcp.NewDialer(cluster.MuxClusterHeader, dialerTLSConfig)\n",
      "\tclstrClient := cluster.NewClient(clstrDialer, cfg.ClusterConnectTimeout)\n",
      "\tif err := clstrClient.SetLocal(cfg.RaftAdv, clstr); err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to set cluster client local parameters: %s\", err.Error())\n",
      "\t}\n",
      "\treturn clstrClient, nil\n",
      "}\n",
      "func CreateClientConfig(certFile, keyFile, caCertFile, serverName string, noverify bool) (*tls.Config, error) {\n",
      "\tvar err error\n",
      "\tconfig := createBaseTLSConfig(serverName, noverify)\n",
      "\tif certFile != \"\" && keyFile != \"\" {\n",
      "\t\tconfig.Certificates = make([]tls.Certificate, 1)\n",
      "\t\tconfig.Certificates[0], err = tls.LoadX509KeyPair(certFile, keyFile)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif caCertFile != \"\" {\n",
      "\t\tasn1Data, err := os.ReadFile(caCertFile)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tconfig.RootCAs = x509.NewCertPool()\n",
      "\t\tok := config.RootCAs.AppendCertsFromPEM(asn1Data)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to load CA certificate(s) for server verification in %q\", caCertFile)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "func CreateServerConfig(certFile, keyFile, caCertFile string, mtls MTLSState) (*tls.Config, error) {\n",
      "\tvar err error\n",
      "\tconfig := createBaseTLSConfig(NoServerName, false)\n",
      "\tconfig.Certificates = make([]tls.Certificate, 1)\n",
      "\tconfig.Certificates[0], err = tls.LoadX509KeyPair(certFile, keyFile)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tif caCertFile != \"\" {\n",
      "\t\tasn1Data, err := os.ReadFile(caCertFile)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tconfig.ClientCAs = x509.NewCertPool()\n",
      "\t\tok := config.ClientCAs.AppendCertsFromPEM(asn1Data)\n",
      "\t\tif !ok {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to load CA certificate(s) for client verification in %q\", caCertFile)\n",
      "\t\t}\n",
      "\t}\n",
      "\tconfig.ClientAuth = tls.ClientAuthType(mtls)\n",
      "\treturn config, nil\n",
      "}\n",
      "func (s *Store) raftConfig() *raft.Config {\n",
      "\tconfig := raft.DefaultConfig()\n",
      "\tconfig.ShutdownOnRemove = s.ShutdownOnRemove\n",
      "\tconfig.LogLevel = s.RaftLogLevel\n",
      "\tif s.SnapshotThreshold != 0 {\n",
      "\t\tconfig.SnapshotThreshold = s.SnapshotThreshold\n",
      "\t\tconfig.TrailingLogs = s.numTrailingLogs\n",
      "\t}\n",
      "\tif s.SnapshotInterval != 0 {\n",
      "\t\tconfig.SnapshotInterval = s.SnapshotInterval\n",
      "\t}\n",
      "\tif s.LeaderLeaseTimeout != 0 {\n",
      "\t\tconfig.LeaderLeaseTimeout = s.LeaderLeaseTimeout\n",
      "\t}\n",
      "\tif s.HeartbeatTimeout != 0 {\n",
      "\t\tconfig.HeartbeatTimeout = s.HeartbeatTimeout\n",
      "\t}\n",
      "\tif s.ElectionTimeout != 0 {\n",
      "\t\tconfig.ElectionTimeout = s.ElectionTimeout\n",
      "\t}\n",
      "\topts := hclog.DefaultOptions\n",
      "\topts.Name = \"\"\n",
      "\topts.Level = s.hcLogLevel()\n",
      "\tconfig.Logger = hclog.FromStandardLogger(log.New(os.Stderr, \"[raft] \", log.LstdFlags), opts)\n",
      "\treturn config\n",
      "}\n",
      "func CreateRaftDialer(cert, key, caCert, serverName string, Insecure bool) (*tcp.Dialer, error) {\n",
      "\tvar dialerTLSConfig *tls.Config\n",
      "\tvar err error\n",
      "\tif cert != \"\" || key != \"\" {\n",
      "\t\tdialerTLSConfig, err = rtls.CreateClientConfig(cert, key, caCert, serverName, Insecure)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to create TLS config for Raft dialer: %s\", err.Error())\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn tcp.NewDialer(MuxRaftHeader, dialerTLSConfig), nil\n",
      "}\n",
      "func ParseFlags(name, desc string, build *BuildInfo) (*Config, error) {\n",
      "\tif flag.Parsed() {\n",
      "\t\treturn nil, fmt.Errorf(\"command-line flags already parsed\")\n",
      "\t}\n",
      "\tconfig := &Config{}\n",
      "\tshowVersion := false\n",
      "\tflag.StringVar(&config.NodeID, \"node-id\", \"\", \"Unique ID for node. If not set, set to advertised Raft address\")\n",
      "\tflag.StringVar(&config.HTTPAddr, HTTPAddrFlag, \"localhost:4001\", \"HTTP server bind address. To enable HTTPS, set X.509 certificate and key\")\n",
      "\tflag.StringVar(&config.HTTPAdv, HTTPAdvAddrFlag, \"\", \"Advertised HTTP address. If not set, same as HTTP server bind address\")\n",
      "\tflag.StringVar(&config.HTTPAllowOrigin, \"http-allow-origin\", \"\", \"Value to set for Access-Control-Allow-Origin HTTP header\")\n",
      "\tflag.StringVar(&config.HTTPx509CACert, \"http-ca-cert\", \"\", \"Path to X.509 CA certificate for HTTPS\")\n",
      "\tflag.StringVar(&config.HTTPx509Cert, HTTPx509CertFlag, \"\", \"Path to HTTPS X.509 certificate\")\n",
      "\tflag.StringVar(&config.HTTPx509Key, HTTPx509KeyFlag, \"\", \"Path to HTTPS X.509 private key\")\n",
      "\tflag.BoolVar(&config.HTTPVerifyClient, \"http-verify-client\", false, \"Enable mutual TLS for HTTPS\")\n",
      "\tflag.StringVar(&config.NodeX509CACert, \"node-ca-cert\", \"\", \"Path to X.509 CA certificate for node-to-node encryption\")\n",
      "\tflag.StringVar(&config.NodeX509Cert, NodeX509CertFlag, \"\", \"Path to X.509 certificate for node-to-node mutual authentication and encryption\")\n",
      "\tflag.StringVar(&config.NodeX509Key, NodeX509KeyFlag, \"\", \"Path to X.509 private key for node-to-node mutual authentication and encryption\")\n",
      "\tflag.BoolVar(&config.NoNodeVerify, \"node-no-verify\", false, \"Skip verification of any node-node certificate\")\n",
      "\tflag.BoolVar(&config.NodeVerifyClient, \"node-verify-client\", false, \"Enable mutual TLS for node-to-node communication\")\n",
      "\tflag.StringVar(&config.NodeVerifyServerName, \"node-verify-server-name\", \"\", \"Hostname to verify on certificate returned by a node\")\n",
      "\tflag.StringVar(&config.AuthFile, \"auth\", \"\", \"Path to authentication and authorization file. If not set, not enabled\")\n",
      "\tflag.StringVar(&config.AutoBackupFile, \"auto-backup\", \"\", \"Path to automatic backup configuration file. If not set, not enabled\")\n",
      "\tflag.StringVar(&config.AutoRestoreFile, \"auto-restore\", \"\", \"Path to automatic restore configuration file. If not set, not enabled\")\n",
      "\tflag.StringVar(&config.RaftAddr, RaftAddrFlag, \"localhost:4002\", \"Raft communication bind address\")\n",
      "\tflag.StringVar(&config.RaftAdv, RaftAdvAddrFlag, \"\", \"Advertised Raft communication address. If not set, same as Raft bind address\")\n",
      "\tflag.StringVar(&config.JoinAddrs, \"join\", \"\", \"Comma-delimited list of nodes, in host:port form, through which a cluster can be joined\")\n",
      "\tflag.IntVar(&config.JoinAttempts, \"join-attempts\", 5, \"Number of join attempts to make\")\n",
      "\tflag.DurationVar(&config.JoinInterval, \"join-interval\", 3*time.Second, \"Period between join attempts\")\n",
      "\tflag.StringVar(&config.JoinAs, \"join-as\", \"\", \"Username in authentication file to join as. If not set, joins anonymously\")\n",
      "\tflag.IntVar(&config.BootstrapExpect, \"bootstrap-expect\", 0, \"Minimum number of nodes required for a bootstrap\")\n",
      "\tflag.DurationVar(&config.BootstrapExpectTimeout, \"bootstrap-expect-timeout\", 120*time.Second, \"Maximum time for bootstrap process\")\n",
      "\tflag.StringVar(&config.DiscoMode, \"disco-mode\", \"\", \"Choose clustering discovery mode. If not set, no node discovery is performed\")\n",
      "\tflag.StringVar(&config.DiscoKey, \"disco-key\", \"rqlite\", \"Key prefix for cluster discovery service\")\n",
      "\tflag.StringVar(&config.DiscoConfig, \"disco-config\", \"\", \"Set discovery config, or path to cluster discovery config file\")\n",
      "\tflag.StringVar(&config.OnDiskPath, \"on-disk-path\", \"\", \"Path for SQLite on-disk database file. If not set, use a file in data directory\")\n",
      "\tflag.BoolVar(&config.FKConstraints, \"fk\", false, \"Enable SQLite foreign key constraints\")\n",
      "\tflag.BoolVar(&showVersion, \"version\", false, \"Show version information and exit\")\n",
      "\tflag.DurationVar(&config.AutoVacInterval, \"auto-vacuum-int\", 0, \"Period between automatic VACUUMs. It not set, not enabled\")\n",
      "\tflag.BoolVar(&config.RaftNonVoter, \"raft-non-voter\", false, \"Configure as non-voting node\")\n",
      "\tflag.DurationVar(&config.RaftHeartbeatTimeout, \"raft-timeout\", time.Second, \"Raft heartbeat timeout\")\n",
      "\tflag.DurationVar(&config.RaftElectionTimeout, \"raft-election-timeout\", time.Second, \"Raft election timeout\")\n",
      "\tflag.DurationVar(&config.RaftApplyTimeout, \"raft-apply-timeout\", 10*time.Second, \"Raft apply timeout\")\n",
      "\tflag.Uint64Var(&config.RaftSnapThreshold, \"raft-snap\", 8192, \"Number of outstanding log entries which triggers Raft snapshot\")\n",
      "\tflag.Uint64Var(&config.RaftSnapThresholdWALSize, \"raft-snap-wal-size\", 4*1024*1024, \"SQLite WAL file size in bytes which triggers Raft snapshot. Set to 0 to disable\")\n",
      "\tflag.DurationVar(&config.RaftSnapInterval, \"raft-snap-int\", 10*time.Second, \"Snapshot threshold check interval\")\n",
      "\tflag.DurationVar(&config.RaftLeaderLeaseTimeout, \"raft-leader-lease-timeout\", 0, \"Raft leader lease timeout. Use 0s for Raft default\")\n",
      "\tflag.BoolVar(&config.RaftStepdownOnShutdown, \"raft-shutdown-stepdown\", true, \"If leader, stepdown before shutting down. Enabled by default\")\n",
      "\tflag.BoolVar(&config.RaftShutdownOnRemove, \"raft-remove-shutdown\", false, \"Shutdown Raft if node removed from cluster\")\n",
      "\tflag.BoolVar(&config.RaftClusterRemoveOnShutdown, \"raft-cluster-remove-shutdown\", false, \"Node removes itself from cluster on graceful shutdown\")\n",
      "\tflag.StringVar(&config.RaftLogLevel, \"raft-log-level\", \"WARN\", \"Minimum log level for Raft module\")\n",
      "\tflag.DurationVar(&config.RaftReapNodeTimeout, \"raft-reap-node-timeout\", 0*time.Hour, \"Time after which a non-reachable voting node will be reaped. If not set, no reaping takes place\")\n",
      "\tflag.DurationVar(&config.RaftReapReadOnlyNodeTimeout, \"raft-reap-read-only-node-timeout\", 0*time.Hour, \"Time after which a non-reachable non-voting node will be reaped. If not set, no reaping takes place\")\n",
      "\tflag.DurationVar(&config.ClusterConnectTimeout, \"cluster-connect-timeout\", 30*time.Second, \"Timeout for initial connection to other nodes\")\n",
      "\tflag.IntVar(&config.WriteQueueCap, \"write-queue-capacity\", 1024, \"QueuedWrites queue capacity\")\n",
      "\tflag.IntVar(&config.WriteQueueBatchSz, \"write-queue-batch-size\", 128, \"QueuedWrites queue batch size\")\n",
      "\tflag.DurationVar(&config.WriteQueueTimeout, \"write-queue-timeout\", 50*time.Millisecond, \"QueuedWrites queue timeout\")\n",
      "\tflag.BoolVar(&config.WriteQueueTx, \"write-queue-tx\", false, \"Use a transaction when processing a queued write\")\n",
      "\tflag.StringVar(&config.CPUProfile, \"cpu-profile\", \"\", \"Path to file for CPU profiling information\")\n",
      "\tflag.StringVar(&config.MemProfile, \"mem-profile\", \"\", \"Path to file for memory profiling information\")\n",
      "\tflag.Usage = func() {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"\\n%s\\n\\n\", desc)\n",
      "\t\tfmt.Fprintf(os.Stderr, \"Usage: %s [flags] <data directory>\\n\", name)\n",
      "\t\tflag.PrintDefaults()\n",
      "\t}\n",
      "\tflag.Parse()\n",
      "\tif showVersion {\n",
      "\t\tmsg := fmt.Sprintf(\"%s %s %s %s %s sqlite%s (commit %s, branch %s, compiler %s)\", name, build.Version, runtime.GOOS, runtime.GOARCH, runtime.Version(), build.SQLiteVersion, build.Commit, build.Branch, runtime.Compiler)\n",
      "\t\terrorExit(0, msg)\n",
      "\t}\n",
      "\tflag.Visit(func(f *flag.Flag) {\n",
      "\t\tif f.Name == \"raft-reap-node-timeout\" || f.Name == \"raft-reap-read-only-node-timeout\" {\n",
      "\t\t\td, err := time.ParseDuration(f.Value.String())\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\terrorExit(1, fmt.Sprintf(\"failed to parse duration: %s\", err.Error()))\n",
      "\t\t\t}\n",
      "\t\t\tif d <= 0 {\n",
      "\t\t\t\terrorExit(1, fmt.Sprintf(\"-%s must be greater than 0\", f.Name))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t})\n",
      "\tif flag.NArg() < 1 {\n",
      "\t\terrorExit(1, \"no data directory set\")\n",
      "\t}\n",
      "\tconfig.DataPath = flag.Arg(0)\n",
      "\tif flag.NArg() > 1 {\n",
      "\t\tfmt.Fprintf(os.Stderr, \"arguments after data directory (%s) are not accepted (%s)\\n\", config.DataPath, flag.Args()[1:])\n",
      "\t\tos.Exit(1)\n",
      "\t}\n",
      "\tif err := config.Validate(); err != nil {\n",
      "\t\terrorExit(1, err.Error())\n",
      "\t}\n",
      "\treturn config, nil\n",
      "}\n",
      "Netflix/chaosmonkey 3 14258\n",
      "3\n",
      "======================CLASS=======================\n",
      "func doTerminate(d deps.Deps, group grp.InstanceGroup) error {\n",
      "\tleashed, err := d.MonkeyCfg.Leashed()\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"not terminating: could not determine leashed status\")\n",
      "\t}\n",
      "\tif d.Env.InTest() && !leashed {\n",
      "\t\treturn UnleashedInTestEnv{}\n",
      "\t}\n",
      "\tvar killer chaosmonkey.Terminator\n",
      "\tif leashed {\n",
      "\t\tkiller = leashedKiller{}\n",
      "\t} else {\n",
      "\t\tkiller = d.T\n",
      "\t}\n",
      "\tappName := group.App()\n",
      "\tappCfg, err := d.ConfGetter.Get(appName)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"not terminating: Could not retrieve config for app=%s\", appName)\n",
      "\t}\n",
      "\tif !appCfg.Enabled {\n",
      "\t\tlog.Printf(\"not terminating: enabled=false for app=%s\", appName)\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif appCfg.Whitelist != nil {\n",
      "\t\tlog.Printf(\"not terminating: app=%s has a whitelist which is no longer supported\", appName)\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tinstance, ok := PickRandomInstance(group, *appCfg, d.Dep)\n",
      "\tif !ok {\n",
      "\t\tlog.Printf(\"No eligible instances in group, nothing to terminate: %+v\", group)\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tlog.Printf(\"Picked: %s\", instance)\n",
      "\tloc, err := d.MonkeyCfg.Location()\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"not terminating: could not retrieve location\")\n",
      "\t}\n",
      "\ttrm := chaosmonkey.Termination{Instance: instance, Time: d.Cl.Now(), Leashed: leashed}\n",
      "\terr = d.Checker.Check(trm, *appCfg, d.MonkeyCfg.EndHour(), loc)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"not terminating: check for min time between terminations failed\")\n",
      "\t}\n",
      "\tfor _, tracker := range d.Trackers {\n",
      "\t\terr = tracker.Track(trm)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Wrap(err, \"not terminating: recording termination event failed\")\n",
      "\t\t}\n",
      "\t}\n",
      "\terr = killer.Execute(trm)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"termination failed\")\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (m *Monkey) BindPFlag(parameter string, flag *pflag.Flag) (err error) {\n",
      "\treturn m.v.BindPFlag(parameter, flag)\n",
      "}\n",
      "func Load(configPaths []string) (*Monkey, error) {\n",
      "\tm := &Monkey{v: viper.New()}\n",
      "\tm.setDefaults()\n",
      "\tm.setupEnvVarReader()\n",
      "\tfor _, dir := range configPaths {\n",
      "\t\tm.v.AddConfigPath(dir)\n",
      "\t}\n",
      "\tm.v.SetConfigType(\"toml\")\n",
      "\tm.v.SetConfigName(\"chaosmonkey\")\n",
      "\terr := m.v.ReadInConfig()\n",
      "\tif err != nil {\n",
      "\t\tif !os.IsNotExist(err) {\n",
      "\t\t\treturn nil, errors.Wrapf(err, \"failed to read config file\")\n",
      "\t\t}\n",
      "\t\tlog.Printf(\"no config file found, proceeding without one\")\n",
      "\t}\n",
      "\terr = m.configureRemote()\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn m, nil\n",
      "}\n",
      "func Usage() {\n",
      "\tusage := `\n",
      "Chaos Monkey\n",
      "\n",
      "Usage:\n",
      "\tchaosmonkey <command> ...\n",
      "\n",
      "command: migrate | schedule | terminate | fetch-schedule | outage | config  | email | eligible | intest\n",
      "\n",
      "Install\n",
      "-------\n",
      "Installs chaosmonkey with all the setup required, e.g setting up the cron, appling database migration etc.\n",
      "\n",
      "migrate\n",
      "-------\n",
      "Applies database migration to the database defined in the configuration file.\n",
      "\n",
      "schedule [--max-apps=<N>] [--apps=foo,bar,baz] [--no-record-schedule]\n",
      "--------------------------------------------------------------------\n",
      "Generates a schedule of terminations for the day and installs the\n",
      "terminations as local cron jobs that call \"chaosmonkey terminate ...\"\n",
      "\n",
      "--apps=foo,bar,baz     Optionally specify an explicit list of apps to schedule.\n",
      "                       This is primarily used for debugging.\n",
      "\n",
      "--max-apps=<N>         Optionally specify the maximum number of apps that Chaos Monkey\n",
      "\t\t\t\t\t   will schedule. This is primarily used for debugging.\n",
      "\n",
      "--no-record-schedule   Do not record the schedule with the database.\n",
      "                       This is primarily used for debugging.\n",
      "\n",
      "\n",
      "terminate <app> <account> [--region=<region>] [--stack=<stack>] [--cluster=<cluster>] [--leashed]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Terminates an instance from a given app and account.\n",
      "\n",
      "Optionally specify a region, stack, cluster.\n",
      "\n",
      "The --leashed flag forces chaosmonkey to run in leashed mode. When leashed,\n",
      "Chaos Monkey will check if an instance should be terminated, but will not\n",
      "actually terminate it.\n",
      "\n",
      "fetch-schedule\n",
      "--------------\n",
      "Queries the database to see if there is an existing schedule of\n",
      "terminations for today. If so, downloads the schedule and sets up cron jobs to\n",
      "implement the schedule.\n",
      "\n",
      "outage\n",
      "------\n",
      "Output \"true\" if there is an ongoing outage, otherwise \"false\". Used for debugging.\n",
      "\n",
      "\n",
      "config [<app>]\n",
      "------------\n",
      "Query Spinnaker for the config for a specific app and dump it to\n",
      "standard out. This is only used for debugging.\n",
      "\n",
      "If no app is specified, dump the Monkey-level configuration options to standard out.\n",
      "\n",
      "Examples:\n",
      "\n",
      "\tchaosmonkey config chaosguineapig\n",
      "\n",
      "\tchaosmonkey config\n",
      "\n",
      "eligible <app> <account> [--region=<region>] [--stack=<stack>] [--cluster=<cluster>]\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Dump a list of instance-ids that are eligible for termination for a given app, account,\n",
      "and optionally region, stack, and cluster.\n",
      "\n",
      "intest\n",
      "------\n",
      "\n",
      "Outputs \"true\" on standard out if running within a test environment, otherwise outputs \"false\"\n",
      "\n",
      "\n",
      "account <name>\n",
      "--------------\n",
      "\n",
      "Look up an cloud account ID by name.\n",
      "\n",
      "Example:\n",
      "\n",
      "\tchaosmonkey account test\n",
      "\n",
      "\n",
      "provider <name>\n",
      "---------------\n",
      "\n",
      "Look up the cloud provider by account name.\n",
      "\n",
      "Example:\n",
      "\n",
      "\tchaosmonkey provider test\n",
      "\n",
      "\n",
      "clusters <app> <account>\n",
      "------------------------\n",
      "\n",
      "List the clusters for a given app and account\n",
      "\n",
      "Example:\n",
      "\n",
      "\tchaosmonkey clusters chaosguineapig test\n",
      "\n",
      "\n",
      "regions <cluster> <account>\n",
      "---------------------------\n",
      "\n",
      "List the regions for a given cluster and account\n",
      "\n",
      "Example:\n",
      "\n",
      "\tchaosmonkey regions chaosguineapig test\n",
      "`\n",
      "\tfmt.Printf(usage)\n",
      "}\n",
      "func (s *Schedule) Populate(d deploy.Deployment, getter chaosmonkey.AppConfigGetter, chaosConfig *config.Monkey, apps []string) error {\n",
      "\tc := make(chan *deploy.App)\n",
      "\tif len(apps) == 0 {\n",
      "\t\tvar err error\n",
      "\t\tapps, err = d.AppNames()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn fmt.Errorf(\"could not retrieve list of apps: %v\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tgo d.Apps(c, apps)\n",
      "\ti := 0\n",
      "\tfor app := range c {\n",
      "\t\tif i >= chaosConfig.MaxApps() {\n",
      "\t\t\tbreak\n",
      "\t\t}\n",
      "\t\ti++\n",
      "\t\tcfg, err := getter.Get(app.Name())\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Printf(\"WARNING: Could not retrieve config for app=%s. %s\", app.Name(), err)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tdoScheduleApp(s, app, *cfg, chaosConfig)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "CodisLabs/codis 5 13027\n",
      "5\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func NewBackendConn(addr string, database int, config *Config) *BackendConn {\n",
      "\tbc := &BackendConn{addr: addr, config: config, database: database}\n",
      "\tbc.input = make(chan *Request, 1024)\n",
      "\tbc.retry.delay = &DelayExp2{Min: 50, Max: 5000, Unit: time.Millisecond}\n",
      "\tgo bc.run()\n",
      "\treturn bc\n",
      "}\n",
      "func (s *Sentinel) monitorGroupsCommand(client *Client, sentniel string, config *MonitorConfig, groups map[int]*net.TCPAddr) error {\n",
      "\tdefer func() {\n",
      "\t\tif !client.isRecyclable() {\n",
      "\t\t\tclient.Close()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tvar names []string\n",
      "\tfor gid := range groups {\n",
      "\t\tnames = append(names, s.NodeName(gid))\n",
      "\t}\n",
      "\tif err := s.removeCommand(client, names); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tgo func() {\n",
      "\t\tfor gid, tcpAddr := range groups {\n",
      "\t\t\tvar ip, port = tcpAddr.IP.String(), tcpAddr.Port\n",
      "\t\t\tclient.Send(\"SENTINEL\", \"monitor\", s.NodeName(gid), ip, port, config.Quorum)\n",
      "\t\t}\n",
      "\t\tif len(groups) != 0 {\n",
      "\t\t\tclient.Flush()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tfor range groups {\n",
      "\t\t_, err := client.Receive()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Trace(err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tgo func() {\n",
      "\t\tfor gid := range groups {\n",
      "\t\t\tvar args = []interface{}{\"set\", s.NodeName(gid)}\n",
      "\t\t\tif config.ParallelSyncs != 0 {\n",
      "\t\t\t\targs = append(args, \"parallel-syncs\", config.ParallelSyncs)\n",
      "\t\t\t}\n",
      "\t\t\tif config.DownAfter != 0 {\n",
      "\t\t\t\targs = append(args, \"down-after-milliseconds\", int(config.DownAfter/time.Millisecond))\n",
      "\t\t\t}\n",
      "\t\t\tif config.FailoverTimeout != 0 {\n",
      "\t\t\t\targs = append(args, \"failover-timeout\", int(config.FailoverTimeout/time.Millisecond))\n",
      "\t\t\t}\n",
      "\t\t\tif s.Auth != \"\" {\n",
      "\t\t\t\targs = append(args, \"auth-pass\", s.Auth)\n",
      "\t\t\t}\n",
      "\t\t\tif config.NotificationScript != \"\" {\n",
      "\t\t\t\targs = append(args, \"notification-script\", config.NotificationScript)\n",
      "\t\t\t}\n",
      "\t\t\tif config.ClientReconfigScript != \"\" {\n",
      "\t\t\t\targs = append(args, \"client-reconfig-script\", config.ClientReconfigScript)\n",
      "\t\t\t}\n",
      "\t\t\tclient.Send(\"SENTINEL\", args...)\n",
      "\t\t}\n",
      "\t\tif len(groups) != 0 {\n",
      "\t\t\tclient.Flush()\n",
      "\t\t}\n",
      "\t}()\n",
      "\tfor range groups {\n",
      "\t\t_, err := client.Receive()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Trace(err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func New(client models.Client, config *Config) (*Topom, error) {\n",
      "\tif err := config.Validate(); err != nil {\n",
      "\t\treturn nil, errors.Trace(err)\n",
      "\t}\n",
      "\tif err := models.ValidateProduct(config.ProductName); err != nil {\n",
      "\t\treturn nil, errors.Trace(err)\n",
      "\t}\n",
      "\ts := &Topom{}\n",
      "\ts.config = config\n",
      "\ts.exit.C = make(chan struct{})\n",
      "\ts.action.redisp = redis.NewPool(config.ProductAuth, config.MigrationTimeout.Duration())\n",
      "\ts.action.progress.status.Store(\"\")\n",
      "\ts.ha.redisp = redis.NewPool(\"\", time.Second*5)\n",
      "\ts.model = &models.Topom{StartTime: time.Now().String()}\n",
      "\ts.model.ProductName = config.ProductName\n",
      "\ts.model.Pid = os.Getpid()\n",
      "\ts.model.Pwd, _ = os.Getwd()\n",
      "\tif b, err := exec.Command(\"uname\", \"-a\").Output(); err != nil {\n",
      "\t\tlog.WarnErrorf(err, \"run command uname failed\")\n",
      "\t} else {\n",
      "\t\ts.model.Sys = strings.TrimSpace(string(b))\n",
      "\t}\n",
      "\ts.store = models.NewStore(client, config.ProductName)\n",
      "\ts.stats.redisp = redis.NewPool(config.ProductAuth, time.Second*5)\n",
      "\ts.stats.servers = make(map[string]*RedisStats)\n",
      "\ts.stats.proxies = make(map[string]*ProxyStats)\n",
      "\tif err := s.setup(config); err != nil {\n",
      "\t\ts.Close()\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tlog.Warnf(\"create new topom:\\n%s\", s.model.Encode())\n",
      "\tgo s.serveAdmin()\n",
      "\treturn s, nil\n",
      "}\n",
      "func (t *cmdAdmin) handleConfigRestore(d map[string]interface{}) {\n",
      "\tstore := t.newTopomStore(d)\n",
      "\tdefer store.Close()\n",
      "\tconfig := t.loadJsonConfigV3(utils.ArgumentMust(d, \"--config-restore\"))\n",
      "\tif !d[\"--confirm\"].(bool) {\n",
      "\t\tb, err := json.MarshalIndent(config, \"\", \"    \")\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"json marshal failed\")\n",
      "\t\t}\n",
      "\t\tfmt.Println(string(b))\n",
      "\t\treturn\n",
      "\t}\n",
      "\tproxy, err := store.ListProxy()\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"list proxy failed\")\n",
      "\t}\n",
      "\tgroup, err := store.ListGroup()\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"list group failed\")\n",
      "\t}\n",
      "\tif len(group) != 0 || len(proxy) != 0 {\n",
      "\t\tlog.Panicf(\"product %s is not empty\", t.product)\n",
      "\t}\n",
      "\tfor _, s := range config.Slots {\n",
      "\t\tif err := store.UpdateSlotMapping(s); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"restore slot-%04d failed\", s.Id)\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor _, g := range config.Group {\n",
      "\t\tif err := store.UpdateGroup(g); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"restore group-%04d failed\", g.Id)\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor _, p := range config.Proxy {\n",
      "\t\tif err := store.UpdateProxy(p); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"restore proxy-%s failed\", p.Token)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (s *Topom) ResyncSentinels() error {\n",
      "\ts.mu.Lock()\n",
      "\tdefer s.mu.Unlock()\n",
      "\tctx, err := s.newContext()\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tdefer s.dirtySentinelCache()\n",
      "\tp := ctx.sentinel\n",
      "\tp.OutOfSync = true\n",
      "\tif err := s.storeUpdateSentinel(p); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tconfig := &redis.MonitorConfig{Quorum: s.config.SentinelQuorum, ParallelSyncs: s.config.SentinelParallelSyncs, DownAfter: s.config.SentinelDownAfter.Duration(), FailoverTimeout: s.config.SentinelFailoverTimeout.Duration(), NotificationScript: s.config.SentinelNotificationScript, ClientReconfigScript: s.config.SentinelClientReconfigScript}\n",
      "\tsentinel := redis.NewSentinel(s.config.ProductName, s.config.ProductAuth)\n",
      "\tif err := sentinel.RemoveGroupsAll(p.Servers, s.config.SentinelClientTimeout.Duration()); err != nil {\n",
      "\t\tlog.WarnErrorf(err, \"remove sentinels failed\")\n",
      "\t}\n",
      "\tif err := sentinel.MonitorGroups(p.Servers, s.config.SentinelClientTimeout.Duration(), config, ctx.getGroupMasters()); err != nil {\n",
      "\t\tlog.WarnErrorf(err, \"resync sentinels failed\")\n",
      "\t\treturn err\n",
      "\t}\n",
      "\ts.rewatchSentinels(p.Servers)\n",
      "\tvar fut sync2.Future\n",
      "\tfor _, p := range ctx.proxy {\n",
      "\t\tfut.Add()\n",
      "\t\tgo func(p *models.Proxy) {\n",
      "\t\t\terr := s.newProxyClient(p).SetSentinels(ctx.sentinel)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlog.ErrorErrorf(err, \"proxy-[%s] resync sentinel failed\", p.Token)\n",
      "\t\t\t}\n",
      "\t\t\tfut.Done(p.Token, err)\n",
      "\t\t}(p)\n",
      "\t}\n",
      "\tfor t, v := range fut.Wait() {\n",
      "\t\tswitch err := v.(type) {\n",
      "\t\tcase error:\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn errors.Errorf(\"proxy-[%s] sentinel failed\", t)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tp.OutOfSync = false\n",
      "\treturn s.storeUpdateSentinel(p)\n",
      "}\n",
      "func main() {\n",
      "\tconst usage = `\n",
      "Usage:\n",
      "\tcodis-dashboard [--ncpu=N] [--config=CONF] [--log=FILE] [--log-level=LEVEL] [--host-admin=ADDR] [--pidfile=FILE] [--zookeeper=ADDR|--etcd=ADDR|--filesystem=ROOT] [--product_name=NAME] [--product_auth=AUTH] [--remove-lock]\n",
      "\tcodis-dashboard  --default-config\n",
      "\tcodis-dashboard  --version\n",
      "\n",
      "Options:\n",
      "\t--ncpu=N                    set runtime.GOMAXPROCS to N, default is runtime.NumCPU().\n",
      "\t-c CONF, --config=CONF      run with the specific configuration.\n",
      "\t-l FILE, --log=FILE         set path/name of daliy rotated log file.\n",
      "\t--log-level=LEVEL           set the log-level, should be INFO,WARN,DEBUG or ERROR, default is INFO.\n",
      "`\n",
      "\td, err := docopt.Parse(usage, nil, true, \"\", false)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicError(err, \"parse arguments failed\")\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase d[\"--default-config\"]:\n",
      "\t\tfmt.Println(topom.DefaultConfig)\n",
      "\t\treturn\n",
      "\tcase d[\"--version\"].(bool):\n",
      "\t\tfmt.Println(\"version:\", utils.Version)\n",
      "\t\tfmt.Println(\"compile:\", utils.Compile)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--log\"); ok {\n",
      "\t\tw, err := log.NewRollingFile(s, log.DailyRolling)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"open log file %s failed\", s)\n",
      "\t\t} else {\n",
      "\t\t\tlog.StdLog = log.New(w, \"\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tlog.SetLevel(log.LevelInfo)\n",
      "\tif s, ok := utils.Argument(d, \"--log-level\"); ok {\n",
      "\t\tif !log.SetLevelString(s) {\n",
      "\t\t\tlog.Panicf(\"option --log-level = %s\", s)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif n, ok := utils.ArgumentInteger(d, \"--ncpu\"); ok {\n",
      "\t\truntime.GOMAXPROCS(n)\n",
      "\t} else {\n",
      "\t\truntime.GOMAXPROCS(runtime.NumCPU())\n",
      "\t}\n",
      "\tlog.Warnf(\"set ncpu = %d\", runtime.GOMAXPROCS(0))\n",
      "\tconfig := topom.NewDefaultConfig()\n",
      "\tif s, ok := utils.Argument(d, \"--config\"); ok {\n",
      "\t\tif err := config.LoadFromFile(s); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"load config %s failed\", s)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--host-admin\"); ok {\n",
      "\t\tconfig.HostAdmin = s\n",
      "\t\tlog.Warnf(\"option --host-admin = %s\", s)\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase d[\"--zookeeper\"] != nil:\n",
      "\t\tconfig.CoordinatorName = \"zookeeper\"\n",
      "\t\tconfig.CoordinatorAddr = utils.ArgumentMust(d, \"--zookeeper\")\n",
      "\t\tlog.Warnf(\"option --zookeeper = %s\", config.CoordinatorAddr)\n",
      "\tcase d[\"--etcd\"] != nil:\n",
      "\t\tconfig.CoordinatorName = \"etcd\"\n",
      "\t\tconfig.CoordinatorAddr = utils.ArgumentMust(d, \"--etcd\")\n",
      "\t\tlog.Warnf(\"option --etcd = %s\", config.CoordinatorAddr)\n",
      "\tcase d[\"--filesystem\"] != nil:\n",
      "\t\tconfig.CoordinatorName = \"filesystem\"\n",
      "\t\tconfig.CoordinatorAddr = utils.ArgumentMust(d, \"--filesystem\")\n",
      "\t\tlog.Warnf(\"option --filesystem = %s\", config.CoordinatorAddr)\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--product_name\"); ok {\n",
      "\t\tconfig.ProductName = s\n",
      "\t\tlog.Warnf(\"option --product_name = %s\", s)\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--product_auth\"); ok {\n",
      "\t\tconfig.ProductAuth = s\n",
      "\t\tlog.Warnf(\"option --product_auth = %s\", s)\n",
      "\t}\n",
      "\tclient, err := models.NewClient(config.CoordinatorName, config.CoordinatorAddr, config.CoordinatorAuth, time.Minute)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"create '%s' client to '%s' failed\", config.CoordinatorName, config.CoordinatorAddr)\n",
      "\t}\n",
      "\tdefer client.Close()\n",
      "\tif d[\"--remove-lock\"].(bool) {\n",
      "\t\tstore := models.NewStore(client, config.ProductName)\n",
      "\t\tdefer store.Close()\n",
      "\t\tlog.Warnf(\"force remove-lock\")\n",
      "\t\tif err := store.Release(); err != nil {\n",
      "\t\t\tlog.WarnErrorf(err, \"force remove-lock failed\")\n",
      "\t\t} else {\n",
      "\t\t\tlog.Warnf(\"force remove-lock OK\")\n",
      "\t\t}\n",
      "\t}\n",
      "\ts, err := topom.New(client, config)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"create topom with config file failed\\n%s\", config)\n",
      "\t}\n",
      "\tdefer s.Close()\n",
      "\tlog.Warnf(\"create topom with config\\n%s\", config)\n",
      "\tif s, ok := utils.Argument(d, \"--pidfile\"); ok {\n",
      "\t\tif pidfile, err := filepath.Abs(s); err != nil {\n",
      "\t\t\tlog.WarnErrorf(err, \"parse pidfile = '%s' failed\", s)\n",
      "\t\t} else if err := ioutil.WriteFile(pidfile, []byte(strconv.Itoa(os.Getpid())), 0644); err != nil {\n",
      "\t\t\tlog.WarnErrorf(err, \"write pidfile = '%s' failed\", pidfile)\n",
      "\t\t} else {\n",
      "\t\t\tdefer func() {\n",
      "\t\t\t\tif err := os.Remove(pidfile); err != nil {\n",
      "\t\t\t\t\tlog.WarnErrorf(err, \"remove pidfile = '%s' failed\", pidfile)\n",
      "\t\t\t\t}\n",
      "\t\t\t}()\n",
      "\t\t\tlog.Warnf(\"option --pidfile = %s\", pidfile)\n",
      "\t\t}\n",
      "\t}\n",
      "\tgo func() {\n",
      "\t\tdefer s.Close()\n",
      "\t\tc := make(chan os.Signal, 1)\n",
      "\t\tsignal.Notify(c, syscall.SIGINT, syscall.SIGKILL, syscall.SIGTERM)\n",
      "\t\tsig := <-c\n",
      "\t\tlog.Warnf(\"[%p] dashboard receive signal = '%v'\", s, sig)\n",
      "\t}()\n",
      "\tfor i := 0; !s.IsClosed() && !s.IsOnline(); i++ {\n",
      "\t\tif err := s.Start(true); err != nil {\n",
      "\t\t\tif i <= 15 {\n",
      "\t\t\t\tlog.Warnf(\"[%p] dashboard online failed [%d]\", s, i)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tlog.Panicf(\"dashboard online failed, give up & abort :'(\")\n",
      "\t\t\t}\n",
      "\t\t\ttime.Sleep(time.Second * 2)\n",
      "\t\t}\n",
      "\t}\n",
      "\tlog.Warnf(\"[%p] dashboard is working ...\", s)\n",
      "\tfor !s.IsClosed() {\n",
      "\t\ttime.Sleep(time.Second)\n",
      "\t}\n",
      "\tlog.Warnf(\"[%p] dashboard is exiting ...\", s)\n",
      "}\n",
      "func (t *cmdAdmin) loadJsonConfigV3(file string) *ConfigV3 {\n",
      "\tb, err := ioutil.ReadFile(file)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"read file '%s' failed\", file)\n",
      "\t}\n",
      "\tconfig := &ConfigV3{}\n",
      "\tif err := json.Unmarshal(b, config); err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"json unmarshal failed\")\n",
      "\t}\n",
      "\tvar proxy = make(map[string]*models.Proxy)\n",
      "\tfor _, p := range config.Proxy {\n",
      "\t\tif proxy[p.Token] != nil {\n",
      "\t\t\tlog.Panicf(\"proxy-%s already exists\", p.Token)\n",
      "\t\t}\n",
      "\t\tproxy[p.Token] = p\n",
      "\t}\n",
      "\tvar group = make(map[int]*models.Group)\n",
      "\tvar maddr = make(map[string]bool)\n",
      "\tfor _, g := range config.Group {\n",
      "\t\tif g.Id <= 0 || g.Id > models.MaxGroupId {\n",
      "\t\t\tlog.Panicf(\"invalid group id = %d\", g.Id)\n",
      "\t\t}\n",
      "\t\tif group[g.Id] != nil {\n",
      "\t\t\tlog.Panicf(\"group-%04d already exists\", g.Id)\n",
      "\t\t}\n",
      "\t\tif g.Promoting.State != models.ActionNothing {\n",
      "\t\t\tlog.Panicf(\"gorup-%04d is promoting\", g.Id)\n",
      "\t\t}\n",
      "\t\tfor _, x := range g.Servers {\n",
      "\t\t\taddr := x.Addr\n",
      "\t\t\tif maddr[addr] {\n",
      "\t\t\t\tlog.Panicf(\"server %s already exists\", addr)\n",
      "\t\t\t}\n",
      "\t\t\tmaddr[addr] = true\n",
      "\t\t}\n",
      "\t\tgroup[g.Id] = g\n",
      "\t}\n",
      "\tvar slots = make(map[int]*models.SlotMapping)\n",
      "\tfor _, s := range config.Slots {\n",
      "\t\tif s.Id < 0 || s.Id >= models.MaxSlotNum {\n",
      "\t\t\tlog.Panicf(\"invalid slot id = %d\", s.Id)\n",
      "\t\t}\n",
      "\t\tif slots[s.Id] != nil {\n",
      "\t\t\tlog.Panicf(\"slot-%04d already exists\", s.Id)\n",
      "\t\t}\n",
      "\t\tif s.Action.State != models.ActionNothing {\n",
      "\t\t\tlog.Panicf(\"slot-%04d action is not empty\", s.Id)\n",
      "\t\t}\n",
      "\t\tif g := group[s.GroupId]; g == nil || len(g.Servers) == 0 {\n",
      "\t\t\tlog.Panicf(\"slot-%04d with group-%04d doesn't exist or empty\", s.Id, s.GroupId)\n",
      "\t\t}\n",
      "\t\tslots[s.Id] = s\n",
      "\t}\n",
      "\treturn config\n",
      "}\n",
      "func (s *Sentinel) MonitorGroups(sentinels []string, timeout time.Duration, config *MonitorConfig, groups map[int]string) error {\n",
      "\tcntx, cancel := context.WithTimeout(s.Context, timeout)\n",
      "\tdefer cancel()\n",
      "\tresolve := make(map[int]*net.TCPAddr)\n",
      "\tvar exit = make(chan error, 1)\n",
      "\tgo func() (err error) {\n",
      "\t\tdefer func() {\n",
      "\t\t\texit <- err\n",
      "\t\t}()\n",
      "\t\tfor gid, addr := range groups {\n",
      "\t\t\tif err := cntx.Err(); err != nil {\n",
      "\t\t\t\treturn errors.Trace(err)\n",
      "\t\t\t}\n",
      "\t\t\ttcpAddr, err := net.ResolveTCPAddr(\"tcp\", addr)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\ts.printf(\"sentinel monitor resolve tcp address of %s failed, %s\", addr, err)\n",
      "\t\t\t\treturn errors.Trace(err)\n",
      "\t\t\t}\n",
      "\t\t\tresolve[gid] = tcpAddr\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}()\n",
      "\tselect {\n",
      "\tcase <-cntx.Done():\n",
      "\t\tif cntx.Err() != context.DeadlineExceeded {\n",
      "\t\t\ts.printf(\"sentinel monitor canceled (%v)\", cntx.Err())\n",
      "\t\t} else {\n",
      "\t\t\ts.printf(\"sentinel montior resolve tcp address (%v)\", cntx.Err())\n",
      "\t\t}\n",
      "\t\treturn errors.Trace(cntx.Err())\n",
      "\tcase err := <-exit:\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\ttimeout += time.Second * 5\n",
      "\tresults := make(chan error, len(sentinels))\n",
      "\tfor i := range sentinels {\n",
      "\t\tgo func(sentinel string) {\n",
      "\t\t\terr := s.monitorGroupsDispatch(cntx, sentinel, timeout, config, resolve)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\ts.errorf(err, \"sentinel-[%s] monitor failed\", sentinel)\n",
      "\t\t\t}\n",
      "\t\t\tresults <- err\n",
      "\t\t}(sentinels[i])\n",
      "\t}\n",
      "\tvar last error\n",
      "\tfor range sentinels {\n",
      "\t\tselect {\n",
      "\t\tcase <-cntx.Done():\n",
      "\t\t\tif last != nil {\n",
      "\t\t\t\treturn last\n",
      "\t\t\t}\n",
      "\t\t\treturn errors.Trace(cntx.Err())\n",
      "\t\tcase err := <-results:\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tlast = err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn last\n",
      "}\n",
      "func (s *Session) handleRequest(r *Request, d *Router) error {\n",
      "\topstr, flag, err := getOpInfo(r.Multi)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tr.OpStr = opstr\n",
      "\tr.OpFlag = flag\n",
      "\tr.Broken = &s.broken\n",
      "\tif flag.IsNotAllowed() {\n",
      "\t\treturn fmt.Errorf(\"command '%s' is not allowed\", opstr)\n",
      "\t}\n",
      "\tswitch opstr {\n",
      "\tcase \"QUIT\":\n",
      "\t\treturn s.handleQuit(r)\n",
      "\tcase \"AUTH\":\n",
      "\t\treturn s.handleAuth(r)\n",
      "\t}\n",
      "\tif !s.authorized {\n",
      "\t\tif s.config.SessionAuth != \"\" {\n",
      "\t\t\tr.Resp = redis.NewErrorf(\"NOAUTH Authentication required\")\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t\ts.authorized = true\n",
      "\t}\n",
      "\tswitch opstr {\n",
      "\tcase \"SELECT\":\n",
      "\t\treturn s.handleSelect(r)\n",
      "\tcase \"PING\":\n",
      "\t\treturn s.handleRequestPing(r, d)\n",
      "\tcase \"INFO\":\n",
      "\t\treturn s.handleRequestInfo(r, d)\n",
      "\tcase \"MGET\":\n",
      "\t\treturn s.handleRequestMGet(r, d)\n",
      "\tcase \"MSET\":\n",
      "\t\treturn s.handleRequestMSet(r, d)\n",
      "\tcase \"DEL\":\n",
      "\t\treturn s.handleRequestDel(r, d)\n",
      "\tcase \"EXISTS\":\n",
      "\t\treturn s.handleRequestExists(r, d)\n",
      "\tcase \"SLOTSINFO\":\n",
      "\t\treturn s.handleRequestSlotsInfo(r, d)\n",
      "\tcase \"SLOTSSCAN\":\n",
      "\t\treturn s.handleRequestSlotsScan(r, d)\n",
      "\tcase \"SLOTSMAPPING\":\n",
      "\t\treturn s.handleRequestSlotsMapping(r, d)\n",
      "\tdefault:\n",
      "\t\treturn d.dispatch(r)\n",
      "\t}\n",
      "}\n",
      "func (t *cmdAdmin) handleConfigConvert(d map[string]interface{}) {\n",
      "\tdefer func() {\n",
      "\t\tif x := recover(); x != nil {\n",
      "\t\t\tlog.Panicf(\"convert config failed: %+v\", x)\n",
      "\t\t}\n",
      "\t}()\n",
      "\tcfg1 := t.loadJsonConfigV1(utils.ArgumentMust(d, \"--config-convert\"))\n",
      "\tcfg2 := &ConfigV3{}\n",
      "\tif slots := cfg1[\"slots\"]; slots != nil {\n",
      "\t\ttemp := make(map[int]*models.SlotMapping)\n",
      "\t\tfor _, v := range slots.(map[string]interface{}) {\n",
      "\t\t\tt.convertSlotsV1(temp, v)\n",
      "\t\t}\n",
      "\t\tfor i := 0; i < models.MaxSlotNum; i++ {\n",
      "\t\t\tif temp[i] == nil {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tcfg2.Slots = append(cfg2.Slots, temp[i])\n",
      "\t\t}\n",
      "\t}\n",
      "\tif servers := cfg1[\"servers\"]; servers != nil {\n",
      "\t\tgroup := make(map[int]*models.Group)\n",
      "\t\tfor _, g := range servers.(map[string]interface{}) {\n",
      "\t\t\tfor _, v := range g.(map[string]interface{}) {\n",
      "\t\t\t\tt.convertGroupV1(group, v)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tcfg2.Group = models.SortGroup(group)\n",
      "\t}\n",
      "\tb, err := json.MarshalIndent(cfg2, \"\", \"    \")\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"json marshal failed\")\n",
      "\t}\n",
      "\tfmt.Println(string(b))\n",
      "}\n",
      "func NewDefaultConfig() *Config {\n",
      "\tc := &Config{}\n",
      "\tif _, err := toml.Decode(DefaultConfig, c); err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"decode toml failed\")\n",
      "\t}\n",
      "\tif err := c.Validate(); err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"validate config failed\")\n",
      "\t}\n",
      "\treturn c\n",
      "}\n",
      "func New(config *Config) (*Proxy, error) {\n",
      "\tif err := config.Validate(); err != nil {\n",
      "\t\treturn nil, errors.Trace(err)\n",
      "\t}\n",
      "\tif err := models.ValidateProduct(config.ProductName); err != nil {\n",
      "\t\treturn nil, errors.Trace(err)\n",
      "\t}\n",
      "\ts := &Proxy{}\n",
      "\ts.config = config\n",
      "\ts.exit.C = make(chan struct{})\n",
      "\ts.router = NewRouter(config)\n",
      "\ts.ignore = make([]byte, config.ProxyHeapPlaceholder.Int64())\n",
      "\ts.model = &models.Proxy{StartTime: time.Now().String()}\n",
      "\ts.model.ProductName = config.ProductName\n",
      "\ts.model.DataCenter = config.ProxyDataCenter\n",
      "\ts.model.Pid = os.Getpid()\n",
      "\ts.model.Pwd, _ = os.Getwd()\n",
      "\tif b, err := exec.Command(\"uname\", \"-a\").Output(); err != nil {\n",
      "\t\tlog.WarnErrorf(err, \"run command uname failed\")\n",
      "\t} else {\n",
      "\t\ts.model.Sys = strings.TrimSpace(string(b))\n",
      "\t}\n",
      "\ts.model.Hostname = utils.Hostname\n",
      "\tif err := s.setup(config); err != nil {\n",
      "\t\ts.Close()\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tlog.Warnf(\"[%p] create new proxy:\\n%s\", s, s.model.Encode())\n",
      "\tunsafe2.SetMaxOffheapBytes(config.ProxyMaxOffheapBytes.Int64())\n",
      "\tgo s.serveAdmin()\n",
      "\tgo s.serveProxy()\n",
      "\ts.startMetricsJson()\n",
      "\ts.startMetricsInfluxdb()\n",
      "\ts.startMetricsStatsd()\n",
      "\treturn s, nil\n",
      "}\n",
      "func main() {\n",
      "\tconst usage = `\n",
      "Usage:\n",
      "\tcodis-proxy [--ncpu=N [--max-ncpu=MAX]] [--config=CONF] [--log=FILE] [--log-level=LEVEL] [--host-admin=ADDR] [--host-proxy=ADDR] [--dashboard=ADDR|--zookeeper=ADDR [--zookeeper-auth=USR:PWD]|--etcd=ADDR [--etcd-auth=USR:PWD]|--filesystem=ROOT|--fillslots=FILE] [--ulimit=NLIMIT] [--pidfile=FILE] [--product_name=NAME] [--product_auth=AUTH] [--session_auth=AUTH]\n",
      "\tcodis-proxy  --default-config\n",
      "\tcodis-proxy  --version\n",
      "\n",
      "Options:\n",
      "\t--ncpu=N                    set runtime.GOMAXPROCS to N, default is runtime.NumCPU().\n",
      "\t-c CONF, --config=CONF      run with the specific configuration.\n",
      "\t-l FILE, --log=FILE         set path/name of daliy rotated log file.\n",
      "\t--log-level=LEVEL           set the log-level, should be INFO,WARN,DEBUG or ERROR, default is INFO.\n",
      "\t--ulimit=NLIMIT             run 'ulimit -n' to check the maximum number of open file descriptors.\n",
      "`\n",
      "\td, err := docopt.Parse(usage, nil, true, \"\", false)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicError(err, \"parse arguments failed\")\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase d[\"--default-config\"]:\n",
      "\t\tfmt.Println(proxy.DefaultConfig)\n",
      "\t\treturn\n",
      "\tcase d[\"--version\"].(bool):\n",
      "\t\tfmt.Println(\"version:\", utils.Version)\n",
      "\t\tfmt.Println(\"compile:\", utils.Compile)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--log\"); ok {\n",
      "\t\tw, err := log.NewRollingFile(s, log.DailyRolling)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"open log file %s failed\", s)\n",
      "\t\t} else {\n",
      "\t\t\tlog.StdLog = log.New(w, \"\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tlog.SetLevel(log.LevelInfo)\n",
      "\tif s, ok := utils.Argument(d, \"--log-level\"); ok {\n",
      "\t\tif !log.SetLevelString(s) {\n",
      "\t\t\tlog.Panicf(\"option --log-level = %s\", s)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif n, ok := utils.ArgumentInteger(d, \"--ulimit\"); ok {\n",
      "\t\tb, err := exec.Command(\"/bin/sh\", \"-c\", \"ulimit -n\").Output()\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"run ulimit -n failed\")\n",
      "\t\t}\n",
      "\t\tif v, err := strconv.Atoi(strings.TrimSpace(string(b))); err != nil || v < n {\n",
      "\t\t\tlog.PanicErrorf(err, \"ulimit too small: %d, should be at least %d\", v, n)\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar ncpu int\n",
      "\tif n, ok := utils.ArgumentInteger(d, \"--ncpu\"); ok {\n",
      "\t\tncpu = n\n",
      "\t} else {\n",
      "\t\tncpu = 4\n",
      "\t}\n",
      "\truntime.GOMAXPROCS(ncpu)\n",
      "\tvar maxncpu int\n",
      "\tif n, ok := utils.ArgumentInteger(d, \"--max-ncpu\"); ok {\n",
      "\t\tmaxncpu = math2.MaxInt(ncpu, n)\n",
      "\t} else {\n",
      "\t\tmaxncpu = math2.MaxInt(ncpu, runtime.NumCPU())\n",
      "\t}\n",
      "\tlog.Warnf(\"set ncpu = %d, max-ncpu = %d\", ncpu, maxncpu)\n",
      "\tif ncpu < maxncpu {\n",
      "\t\tgo AutoGOMAXPROCS(ncpu, maxncpu)\n",
      "\t}\n",
      "\tconfig := proxy.NewDefaultConfig()\n",
      "\tif s, ok := utils.Argument(d, \"--config\"); ok {\n",
      "\t\tif err := config.LoadFromFile(s); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"load config %s failed\", s)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--host-admin\"); ok {\n",
      "\t\tconfig.HostAdmin = s\n",
      "\t\tlog.Warnf(\"option --host-admin = %s\", s)\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--host-proxy\"); ok {\n",
      "\t\tconfig.HostProxy = s\n",
      "\t\tlog.Warnf(\"option --host-proxy = %s\", s)\n",
      "\t}\n",
      "\tvar dashboard string\n",
      "\tif s, ok := utils.Argument(d, \"--dashboard\"); ok {\n",
      "\t\tdashboard = s\n",
      "\t\tlog.Warnf(\"option --dashboard = %s\", s)\n",
      "\t}\n",
      "\tvar coordinator struct {\n",
      "\t\tname\tstring\n",
      "\t\taddr\tstring\n",
      "\t\tauth\tstring\n",
      "\t}\n",
      "\tswitch {\n",
      "\tcase d[\"--zookeeper\"] != nil:\n",
      "\t\tcoordinator.name = \"zookeeper\"\n",
      "\t\tcoordinator.addr = utils.ArgumentMust(d, \"--zookeeper\")\n",
      "\t\tif d[\"--zookeeper-auth\"] != nil {\n",
      "\t\t\tcoordinator.auth = utils.ArgumentMust(d, \"--zookeeper-auth\")\n",
      "\t\t}\n",
      "\tcase d[\"--etcd\"] != nil:\n",
      "\t\tcoordinator.name = \"etcd\"\n",
      "\t\tcoordinator.addr = utils.ArgumentMust(d, \"--etcd\")\n",
      "\t\tif d[\"--etcd-auth\"] != nil {\n",
      "\t\t\tcoordinator.auth = utils.ArgumentMust(d, \"--etcd-auth\")\n",
      "\t\t}\n",
      "\tcase d[\"--filesystem\"] != nil:\n",
      "\t\tcoordinator.name = \"filesystem\"\n",
      "\t\tcoordinator.addr = utils.ArgumentMust(d, \"--filesystem\")\n",
      "\t}\n",
      "\tif coordinator.name != \"\" {\n",
      "\t\tlog.Warnf(\"option --%s = %s\", coordinator.name, coordinator.addr)\n",
      "\t}\n",
      "\tvar slots []*models.Slot\n",
      "\tif s, ok := utils.Argument(d, \"--fillslots\"); ok {\n",
      "\t\tb, err := ioutil.ReadFile(s)\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"load slots from file failed\")\n",
      "\t\t}\n",
      "\t\tif err := json.Unmarshal(b, &slots); err != nil {\n",
      "\t\t\tlog.PanicErrorf(err, \"decode slots from json failed\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--product_name\"); ok {\n",
      "\t\tconfig.ProductName = s\n",
      "\t\tlog.Warnf(\"option --product_name = %s\", s)\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--product_auth\"); ok {\n",
      "\t\tconfig.ProductAuth = s\n",
      "\t\tlog.Warnf(\"option --product_auth = %s\", s)\n",
      "\t}\n",
      "\tif s, ok := utils.Argument(d, \"--session_auth\"); ok {\n",
      "\t\tconfig.SessionAuth = s\n",
      "\t\tlog.Warnf(\"option --session_auth = %s\", s)\n",
      "\t}\n",
      "\ts, err := proxy.New(config)\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"create proxy with config file failed\\n%s\", config)\n",
      "\t}\n",
      "\tdefer s.Close()\n",
      "\tlog.Warnf(\"create proxy with config\\n%s\", config)\n",
      "\tif s, ok := utils.Argument(d, \"--pidfile\"); ok {\n",
      "\t\tif pidfile, err := filepath.Abs(s); err != nil {\n",
      "\t\t\tlog.WarnErrorf(err, \"parse pidfile = '%s' failed\", s)\n",
      "\t\t} else if err := ioutil.WriteFile(pidfile, []byte(strconv.Itoa(os.Getpid())), 0644); err != nil {\n",
      "\t\t\tlog.WarnErrorf(err, \"write pidfile = '%s' failed\", pidfile)\n",
      "\t\t} else {\n",
      "\t\t\tdefer func() {\n",
      "\t\t\t\tif err := os.Remove(pidfile); err != nil {\n",
      "\t\t\t\t\tlog.WarnErrorf(err, \"remove pidfile = '%s' failed\", pidfile)\n",
      "\t\t\t\t}\n",
      "\t\t\t}()\n",
      "\t\t\tlog.Warnf(\"option --pidfile = %s\", pidfile)\n",
      "\t\t}\n",
      "\t}\n",
      "\tgo func() {\n",
      "\t\tdefer s.Close()\n",
      "\t\tc := make(chan os.Signal, 1)\n",
      "\t\tsignal.Notify(c, syscall.SIGINT, syscall.SIGKILL, syscall.SIGTERM)\n",
      "\t\tsig := <-c\n",
      "\t\tlog.Warnf(\"[%p] proxy receive signal = '%v'\", s, sig)\n",
      "\t}()\n",
      "\tswitch {\n",
      "\tcase dashboard != \"\":\n",
      "\t\tgo AutoOnlineWithDashboard(s, dashboard)\n",
      "\tcase coordinator.name != \"\":\n",
      "\t\tgo AutoOnlineWithCoordinator(s, coordinator.name, coordinator.addr, coordinator.auth)\n",
      "\tcase slots != nil:\n",
      "\t\tgo AutoOnlineWithFillSlots(s, slots)\n",
      "\t}\n",
      "\tfor !s.IsClosed() && !s.IsOnline() {\n",
      "\t\tlog.Warnf(\"[%p] proxy waiting online ...\", s)\n",
      "\t\ttime.Sleep(time.Second)\n",
      "\t}\n",
      "\tlog.Warnf(\"[%p] proxy is working ...\", s)\n",
      "\tfor !s.IsClosed() {\n",
      "\t\ttime.Sleep(time.Second)\n",
      "\t}\n",
      "\tlog.Warnf(\"[%p] proxy is exiting ...\", s)\n",
      "}\n",
      "func NewDefaultConfig() *Config {\n",
      "\tc := &Config{}\n",
      "\tif _, err := toml.Decode(DefaultConfig, c); err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"decode toml failed\")\n",
      "\t}\n",
      "\tif err := c.Validate(); err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"validate config failed\")\n",
      "\t}\n",
      "\treturn c\n",
      "}\n",
      "func (t *cmdAdmin) dumpConfigV1(d map[string]interface{}) {\n",
      "\tclient := t.newTopomClient(d)\n",
      "\tdefer client.Close()\n",
      "\tprefix := filepath.Join(\"/zk/codis\", fmt.Sprintf(\"db_%s\", t.product))\n",
      "\tconfig := t.dumpConfigV1Recursively(client, prefix)\n",
      "\tif m, ok := config.(map[string]interface{}); !ok || m == nil {\n",
      "\t\tlog.Panicf(\"cann't find product = %s [v1]\", t.product)\n",
      "\t}\n",
      "\tb, err := json.MarshalIndent(config, \"\", \"    \")\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"json marshal failed\")\n",
      "\t}\n",
      "\tfmt.Println(string(b))\n",
      "}\n",
      "func (s *Sentinel) monitorGroupsDispatch(ctx context.Context, sentinel string, timeout time.Duration, config *MonitorConfig, groups map[int]*net.TCPAddr) error {\n",
      "\tvar err = s.dispatch(ctx, sentinel, timeout, func(c *Client) error {\n",
      "\t\treturn s.monitorGroupsCommand(c, sentinel, config, groups)\n",
      "\t})\n",
      "\tif err != nil {\n",
      "\t\tswitch errors.Cause(err) {\n",
      "\t\tcase context.Canceled:\n",
      "\t\t\treturn nil\n",
      "\t\tdefault:\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (bc *BackendConn) newBackendReader(round int, config *Config) (*redis.Conn, chan<- *Request, error) {\n",
      "\tc, err := redis.DialTimeout(bc.addr, time.Second*5, config.BackendRecvBufsize.AsInt(), config.BackendSendBufsize.AsInt())\n",
      "\tif err != nil {\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tc.ReaderTimeout = config.BackendRecvTimeout.Duration()\n",
      "\tc.WriterTimeout = config.BackendSendTimeout.Duration()\n",
      "\tc.SetKeepAlivePeriod(config.BackendKeepAlivePeriod.Duration())\n",
      "\tif err := bc.verifyAuth(c, config.ProductAuth); err != nil {\n",
      "\t\tc.Close()\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\tif err := bc.selectDatabase(c, bc.database); err != nil {\n",
      "\t\tc.Close()\n",
      "\t\treturn nil, nil, err\n",
      "\t}\n",
      "\ttasks := make(chan *Request, config.BackendMaxPipeline)\n",
      "\tgo bc.loopReader(tasks, c, round)\n",
      "\treturn c, tasks, nil\n",
      "}\n",
      "func NewSession(sock net.Conn, config *Config) *Session {\n",
      "\tc := redis.NewConn(sock, config.SessionRecvBufsize.AsInt(), config.SessionSendBufsize.AsInt())\n",
      "\tc.ReaderTimeout = config.SessionRecvTimeout.Duration()\n",
      "\tc.WriterTimeout = config.SessionSendTimeout.Duration()\n",
      "\tc.SetKeepAlivePeriod(config.SessionKeepAlivePeriod.Duration())\n",
      "\ts := &Session{Conn: c, config: config, CreateUnix: time.Now().Unix()}\n",
      "\ts.stats.opmap = make(map[string]*opStats, 16)\n",
      "\tlog.Infof(\"session [%p] create: %s\", s, s)\n",
      "\treturn s\n",
      "}\n",
      "func (t *cmdAdmin) dumpConfigV3(d map[string]interface{}) {\n",
      "\tstore := t.newTopomStore(d)\n",
      "\tdefer store.Close()\n",
      "\tgroup, err := store.ListGroup()\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"list group failed\")\n",
      "\t}\n",
      "\tproxy, err := store.ListProxy()\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"list proxy failed\")\n",
      "\t}\n",
      "\tif len(group) == 0 && len(proxy) == 0 {\n",
      "\t\tlog.Panicf(\"cann't find product = %s [v3]\", t.product)\n",
      "\t}\n",
      "\tslots, err := store.SlotMappings()\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"list slots failed\")\n",
      "\t}\n",
      "\tconfig := &ConfigV3{Slots: slots, Group: models.SortGroup(group), Proxy: models.SortProxy(proxy)}\n",
      "\tb, err := json.MarshalIndent(config, \"\", \"    \")\n",
      "\tif err != nil {\n",
      "\t\tlog.PanicErrorf(err, \"json marshal failed\")\n",
      "\t}\n",
      "\tfmt.Println(string(b))\n",
      "}\n",
      "func (c *Client) create(conn *zk.Conn, path string, data []byte, flag int32) (string, error) {\n",
      "\tif err := c.mkdir(conn, filepath.Dir(path)); err != nil {\n",
      "\t\treturn \"\", err\n",
      "\t}\n",
      "\tp, err := conn.Create(path, data, flag, func() []zk.ACL {\n",
      "\t\tconst perm = zk.PermAdmin | zk.PermRead | zk.PermWrite\n",
      "\t\tif c.username != \"\" {\n",
      "\t\t\treturn zk.DigestACL(perm, c.username, c.password)\n",
      "\t\t}\n",
      "\t\treturn zk.WorldACL(perm)\n",
      "\t}())\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", errors.Trace(err)\n",
      "\t}\n",
      "\treturn p, nil\n",
      "}\n",
      "func New(addrlist string, auth string, timeout time.Duration) (*Client, error) {\n",
      "\tendpoints := strings.Split(addrlist, \",\")\n",
      "\tfor i, s := range endpoints {\n",
      "\t\tif s != \"\" && !strings.HasPrefix(s, \"http://\") {\n",
      "\t\t\tendpoints[i] = \"http://\" + s\n",
      "\t\t}\n",
      "\t}\n",
      "\tif timeout <= 0 {\n",
      "\t\ttimeout = time.Second * 5\n",
      "\t}\n",
      "\tconfig := client.Config{Endpoints: endpoints, Transport: client.DefaultTransport, HeaderTimeoutPerRequest: time.Second * 5}\n",
      "\tif auth != \"\" {\n",
      "\t\tsplit := strings.SplitN(auth, \":\", 2)\n",
      "\t\tif len(split) != 2 || split[0] == \"\" {\n",
      "\t\t\treturn nil, errors.Errorf(\"invalid auth\")\n",
      "\t\t}\n",
      "\t\tconfig.Username = split[0]\n",
      "\t\tconfig.Password = split[1]\n",
      "\t}\n",
      "\tc, err := client.New(config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, errors.Trace(err)\n",
      "\t}\n",
      "\tclient := &Client{kapi: client.NewKeysAPI(c), timeout: timeout}\n",
      "\tclient.context, client.cancel = context.WithCancel(context.Background())\n",
      "\treturn client, nil\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "topic_3 10\n",
      "gohugoio/hugo 6 71281\n",
      "6\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "syncthing/syncthing 11 58080\n",
      "11\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func archiveAndSaveConfig(cfg config.Wrapper, originalVersion int) error {\n",
      "\tarchivePath := cfg.ConfigPath() + fmt.Sprintf(\".v%d\", originalVersion)\n",
      "\tl.Infoln(\"Archiving a copy of old config file format at:\", archivePath)\n",
      "\tif err := copyFile(cfg.ConfigPath(), archivePath); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\treturn cfg.Save()\n",
      "}\n",
      "func LoadConfigAtStartup(path string, cert tls.Certificate, evLogger events.Logger, allowNewerConfig, noDefaultFolder, skipPortProbing bool) (config.Wrapper, error) {\n",
      "\tmyID := protocol.NewDeviceID(cert.Certificate[0])\n",
      "\tcfg, originalVersion, err := config.Load(path, myID, evLogger)\n",
      "\tif fs.IsNotExist(err) {\n",
      "\t\tcfg, err = DefaultConfig(path, myID, evLogger, noDefaultFolder, skipPortProbing)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to generate default config: %w\", err)\n",
      "\t\t}\n",
      "\t\terr = cfg.Save()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"failed to save default config: %w\", err)\n",
      "\t\t}\n",
      "\t\tl.Infof(\"Default config saved. Edit %s to taste (with Syncthing stopped) or use the GUI\", cfg.ConfigPath())\n",
      "\t} else if err == io.EOF {\n",
      "\t\treturn nil, errors.New(\"failed to load config: unexpected end of file. Truncated or empty configuration?\")\n",
      "\t} else if err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"failed to load config: %w\", err)\n",
      "\t}\n",
      "\tif originalVersion != config.CurrentVersion {\n",
      "\t\tif originalVersion == config.CurrentVersion+1101 {\n",
      "\t\t\tl.Infof(\"Now, THAT's what we call a config from the future! Don't worry. As long as you hit that wire with the connecting hook at precisely eighty-eight miles per hour the instant the lightning strikes the tower... everything will be fine.\")\n",
      "\t\t}\n",
      "\t\tif originalVersion > config.CurrentVersion && !allowNewerConfig {\n",
      "\t\t\treturn nil, fmt.Errorf(\"config file version (%d) is newer than supported version (%d). If this is expected, use --allow-newer-config to override.\", originalVersion, config.CurrentVersion)\n",
      "\t\t}\n",
      "\t\terr = archiveAndSaveConfig(cfg, originalVersion)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"config archive: %w\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn cfg, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "etcd-io/etcd 15 45720\n",
      "15\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func GetLogger() *zap.Logger {\n",
      "\tconfig := logutil.DefaultZapLoggerConfig\n",
      "\tconfig.Encoding = \"console\"\n",
      "\tconfig.EncoderConfig.EncodeTime = zapcore.RFC3339TimeEncoder\n",
      "\tlg, err := config.Build()\n",
      "\tif err != nil {\n",
      "\t\tcobrautl.ExitWithError(cobrautl.ExitBadArgs, err)\n",
      "\t}\n",
      "\treturn lg\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func IsVerificationEnabled(verification VerificationType) bool {\n",
      "\tenv := getEnvVerify()\n",
      "\treturn env == string(ENV_VERIFY_VALUE_ALL) || env == strings.ToLower(string(verification))\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "gogs/gogs 3 43778\n",
      "3\n",
      "======================CLASS=======================\n",
      "func cleanUpMigrateGitConfig(configPath string) error {\n",
      "\tcfg, err := ini.Load(configPath)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"open config file: %v\", err)\n",
      "\t}\n",
      "\tcfg.DeleteSection(\"remote \\\"origin\\\"\")\n",
      "\tif err = cfg.SaveToIndent(configPath, \"\\t\"); err != nil {\n",
      "\t\treturn fmt.Errorf(\"save config file: %v\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func CreateHook(c *context.APIContext, form api.CreateHookOption) {\n",
      "\tif !database.IsValidHookTaskType(form.Type) {\n",
      "\t\tc.ErrorStatus(http.StatusUnprocessableEntity, errors.New(\"Invalid hook type.\"))\n",
      "\t\treturn\n",
      "\t}\n",
      "\tfor _, name := range []string{\"url\", \"content_type\"} {\n",
      "\t\tif _, ok := form.Config[name]; !ok {\n",
      "\t\t\tc.ErrorStatus(http.StatusUnprocessableEntity, errors.New(\"Missing config option: \"+name))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !database.IsValidHookContentType(form.Config[\"content_type\"]) {\n",
      "\t\tc.ErrorStatus(http.StatusUnprocessableEntity, errors.New(\"Invalid content type.\"))\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif len(form.Events) == 0 {\n",
      "\t\tform.Events = []string{\"push\"}\n",
      "\t}\n",
      "\tw := &database.Webhook{RepoID: c.Repo.Repository.ID, URL: form.Config[\"url\"], ContentType: database.ToHookContentType(form.Config[\"content_type\"]), Secret: form.Config[\"secret\"], HookEvent: &database.HookEvent{ChooseEvents: true, HookEvents: database.HookEvents{Create: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_CREATE)), Delete: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_DELETE)), Fork: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_FORK)), Push: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_PUSH)), Issues: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_ISSUES)), IssueComment: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_ISSUE_COMMENT)), PullRequest: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_PULL_REQUEST)), Release: com.IsSliceContainsStr(form.Events, string(database.HOOK_EVENT_RELEASE))}}, IsActive: form.Active, HookTaskType: database.ToHookTaskType(form.Type)}\n",
      "\tif w.HookTaskType == database.SLACK {\n",
      "\t\tchannel, ok := form.Config[\"channel\"]\n",
      "\t\tif !ok {\n",
      "\t\t\tc.ErrorStatus(http.StatusUnprocessableEntity, errors.New(\"Missing config option: channel\"))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tmeta, err := jsoniter.Marshal(&database.SlackMeta{Channel: channel, Username: form.Config[\"username\"], IconURL: form.Config[\"icon_url\"], Color: form.Config[\"color\"]})\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Errorf(err, \"marshal JSON\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tw.Meta = string(meta)\n",
      "\t}\n",
      "\tif err := w.UpdateEvent(); err != nil {\n",
      "\t\tc.Errorf(err, \"update event\")\n",
      "\t\treturn\n",
      "\t} else if err := database.CreateWebhook(w); err != nil {\n",
      "\t\tc.Errorf(err, \"create webhook\")\n",
      "\t\treturn\n",
      "\t}\n",
      "\tc.JSON(http.StatusCreated, convert.ToHook(c.Repo.RepoLink, w))\n",
      "}\n",
      "func InitLogging(hookMode bool) {\n",
      "\tlogConf, hasConsole, err := initLogConf(File, hookMode)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to init logging configuration: %v\", err)\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\tLog = logConf\n",
      "\t}()\n",
      "\tif hookMode {\n",
      "\t\treturn\n",
      "\t}\n",
      "\terr = os.MkdirAll(logConf.RootPath, os.ModePerm)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to create log directory: %v\", err)\n",
      "\t}\n",
      "\tfor i, mode := range logConf.Modes {\n",
      "\t\tc := logConf.Configs[i]\n",
      "\t\tvar err error\n",
      "\t\tvar level log.Level\n",
      "\t\tswitch mode {\n",
      "\t\tcase log.DefaultConsoleName:\n",
      "\t\t\tlevel = c.Config.(log.ConsoleConfig).Level\n",
      "\t\t\terr = log.NewConsole(c.Buffer, c.Config)\n",
      "\t\tcase log.DefaultFileName:\n",
      "\t\t\tlevel = c.Config.(log.FileConfig).Level\n",
      "\t\t\terr = log.NewFile(c.Buffer, c.Config)\n",
      "\t\tcase log.DefaultSlackName:\n",
      "\t\t\tlevel = c.Config.(log.SlackConfig).Level\n",
      "\t\t\terr = log.NewSlack(c.Buffer, c.Config)\n",
      "\t\tcase log.DefaultDiscordName:\n",
      "\t\t\tlevel = c.Config.(log.DiscordConfig).Level\n",
      "\t\t\terr = log.NewDiscord(c.Buffer, c.Config)\n",
      "\t\tdefault:\n",
      "\t\t\tpanic(\"unreachable\")\n",
      "\t\t}\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Fatal(\"Failed to init %s logger: %v\", mode, err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Log mode: %s (%s)\", strings.Title(mode), strings.Title(strings.ToLower(level.String())))\n",
      "\t}\n",
      "\tif !hasConsole {\n",
      "\t\tlog.Remove(log.DefaultConsoleName)\n",
      "\t}\n",
      "}\n",
      "func runRestore(c *cli.Context) error {\n",
      "\tzip.Verbose = c.Bool(\"verbose\")\n",
      "\ttmpDir := c.String(\"tempdir\")\n",
      "\tif !osutil.IsDir(tmpDir) {\n",
      "\t\tlog.Fatal(\"'--tempdir' does not exist: %s\", tmpDir)\n",
      "\t}\n",
      "\tarchivePath := path.Join(tmpDir, archiveRootDir)\n",
      "\terr := os.RemoveAll(archivePath)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to clean up previous leftover in %q: %v\", archivePath, err)\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\t_ = os.RemoveAll(archivePath)\n",
      "\t}()\n",
      "\tlog.Info(\"Restoring backup from: %s\", c.String(\"from\"))\n",
      "\terr = zip.ExtractTo(c.String(\"from\"), tmpDir)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to extract backup archive: %v\", err)\n",
      "\t}\n",
      "\tmetaFile := filepath.Join(archivePath, \"metadata.ini\")\n",
      "\tif !osutil.IsFile(metaFile) {\n",
      "\t\tlog.Fatal(\"File 'metadata.ini' is missing\")\n",
      "\t}\n",
      "\tmetadata, err := ini.Load(metaFile)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to load metadata '%s': %v\", metaFile, err)\n",
      "\t}\n",
      "\tbackupVersion := metadata.Section(\"\").Key(\"GOGS_VERSION\").MustString(\"999.0\")\n",
      "\tif semverutil.Compare(conf.App.Version, \"<\", backupVersion) {\n",
      "\t\tlog.Fatal(\"Current Gogs version is lower than backup version: %s < %s\", conf.App.Version, backupVersion)\n",
      "\t}\n",
      "\tformatVersion := metadata.Section(\"\").Key(\"VERSION\").MustInt()\n",
      "\tif formatVersion == 0 {\n",
      "\t\tlog.Fatal(\"Failed to determine the backup format version from metadata '%s': %s\", metaFile, \"VERSION is not presented\")\n",
      "\t}\n",
      "\tif formatVersion != currentBackupFormatVersion {\n",
      "\t\tlog.Fatal(\"Backup format version found is %d but this binary only supports %d\\nThe last known version that is able to import your backup is %s\", formatVersion, currentBackupFormatVersion, lastSupportedVersionOfFormat[formatVersion])\n",
      "\t}\n",
      "\tconfigFile := filepath.Join(archivePath, \"custom\", \"conf\", \"app.ini\")\n",
      "\tvar customConf string\n",
      "\tif c.IsSet(\"config\") {\n",
      "\t\tcustomConf = c.String(\"config\")\n",
      "\t} else if !osutil.IsFile(configFile) {\n",
      "\t\tlog.Fatal(\"'--config' is not specified and custom config file is not found in backup\")\n",
      "\t} else {\n",
      "\t\tcustomConf = configFile\n",
      "\t}\n",
      "\terr = conf.Init(customConf)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"init configuration\")\n",
      "\t}\n",
      "\tconf.InitLogging(true)\n",
      "\tconn, err := database.SetEngine()\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, \"set engine\")\n",
      "\t}\n",
      "\tdbDir := path.Join(archivePath, \"db\")\n",
      "\tif err = database.ImportDatabase(context.Background(), conn, dbDir, c.Bool(\"verbose\")); err != nil {\n",
      "\t\tlog.Fatal(\"Failed to import database: %v\", err)\n",
      "\t}\n",
      "\tif !c.Bool(\"database-only\") {\n",
      "\t\tif osutil.IsDir(conf.CustomDir()) {\n",
      "\t\t\tif err = os.Rename(conf.CustomDir(), conf.CustomDir()+\".bak\"); err != nil {\n",
      "\t\t\t\tlog.Fatal(\"Failed to backup current 'custom': %v\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err = os.Rename(filepath.Join(archivePath, \"custom\"), conf.CustomDir()); err != nil {\n",
      "\t\t\tlog.Fatal(\"Failed to import 'custom': %v\", err)\n",
      "\t\t}\n",
      "\t\t_ = os.MkdirAll(conf.Server.AppDataPath, os.ModePerm)\n",
      "\t\tfor _, dir := range []string{\"attachments\", \"avatars\", \"repo-avatars\"} {\n",
      "\t\t\tsrcPath := filepath.Join(archivePath, \"data\", dir)\n",
      "\t\t\tif !osutil.IsDir(srcPath) {\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tdirPath := filepath.Join(conf.Server.AppDataPath, dir)\n",
      "\t\t\tif osutil.IsDir(dirPath) {\n",
      "\t\t\t\tif err = os.Rename(dirPath, dirPath+\".bak\"); err != nil {\n",
      "\t\t\t\t\tlog.Fatal(\"Failed to backup current 'data': %v\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tif err = os.Rename(srcPath, dirPath); err != nil {\n",
      "\t\t\t\tlog.Fatal(\"Failed to import 'data': %v\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treposPath := filepath.Join(archivePath, \"repositories.zip\")\n",
      "\tif !c.Bool(\"exclude-repos\") && !c.Bool(\"database-only\") && osutil.IsFile(reposPath) {\n",
      "\t\tif err := zip.ExtractTo(reposPath, filepath.Dir(conf.Repository.Root)); err != nil {\n",
      "\t\t\tlog.Fatal(\"Failed to extract 'repositories.zip': %v\", err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tlog.Info(\"Restore succeed!\")\n",
      "\tlog.Stop()\n",
      "\treturn nil\n",
      "}\n",
      "func Config(c *context.Context) {\n",
      "\tc.Title(\"admin.config\")\n",
      "\tc.PageIs(\"Admin\")\n",
      "\tc.PageIs(\"AdminConfig\")\n",
      "\tc.Data[\"App\"] = conf.App\n",
      "\tc.Data[\"Server\"] = conf.Server\n",
      "\tc.Data[\"SSH\"] = conf.SSH\n",
      "\tc.Data[\"Repository\"] = conf.Repository\n",
      "\tc.Data[\"Database\"] = conf.Database\n",
      "\tc.Data[\"Security\"] = conf.Security\n",
      "\tc.Data[\"Email\"] = conf.Email\n",
      "\tc.Data[\"Auth\"] = conf.Auth\n",
      "\tc.Data[\"User\"] = conf.User\n",
      "\tc.Data[\"Session\"] = conf.Session\n",
      "\tc.Data[\"Cache\"] = conf.Cache\n",
      "\tc.Data[\"Attachment\"] = conf.Attachment\n",
      "\tc.Data[\"Release\"] = conf.Release\n",
      "\tc.Data[\"Picture\"] = conf.Picture\n",
      "\tc.Data[\"HTTP\"] = conf.HTTP\n",
      "\tc.Data[\"Mirror\"] = conf.Mirror\n",
      "\tc.Data[\"Webhook\"] = conf.Webhook\n",
      "\tc.Data[\"Git\"] = conf.Git\n",
      "\tc.Data[\"LFS\"] = conf.LFS\n",
      "\tc.Data[\"LogRootPath\"] = conf.Log.RootPath\n",
      "\ttype logger struct{ Mode, Config string }\n",
      "\tloggers := make([]*logger, len(conf.Log.Modes))\n",
      "\tfor i := range conf.Log.Modes {\n",
      "\t\tloggers[i] = &logger{Mode: strings.Title(conf.Log.Modes[i])}\n",
      "\t\tresult, _ := jsoniter.MarshalIndent(conf.Log.Configs[i], \"\", \"  \")\n",
      "\t\tloggers[i].Config = string(result)\n",
      "\t}\n",
      "\tc.Data[\"Loggers\"] = loggers\n",
      "\tc.Success(tmplConfig)\n",
      "}\n",
      "func handleServerConn(keyID string, chans <-chan ssh.NewChannel) {\n",
      "\tfor newChan := range chans {\n",
      "\t\tif newChan.ChannelType() != \"session\" {\n",
      "\t\t\t_ = newChan.Reject(ssh.UnknownChannelType, \"unknown channel type\")\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tch, reqs, err := newChan.Accept()\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(\"Error accepting channel: %v\", err)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tgo func(in <-chan *ssh.Request) {\n",
      "\t\t\tdefer func() {\n",
      "\t\t\t\t_ = ch.Close()\n",
      "\t\t\t}()\n",
      "\t\t\tfor req := range in {\n",
      "\t\t\t\tpayload := cleanCommand(string(req.Payload))\n",
      "\t\t\t\tswitch req.Type {\n",
      "\t\t\t\tcase \"env\":\n",
      "\t\t\t\t\tvar env struct {\n",
      "\t\t\t\t\t\tName\tstring\n",
      "\t\t\t\t\t\tValue\tstring\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif err := ssh.Unmarshal(req.Payload, &env); err != nil {\n",
      "\t\t\t\t\t\tlog.Warn(\"SSH: Invalid env payload %q: %v\", req.Payload, err)\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif env.Name == \"\" || env.Value == \"\" {\n",
      "\t\t\t\t\t\tlog.Warn(\"SSH: Invalid env arguments: %+v\", env)\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\t_, stderr, err := com.ExecCmd(\"env\", fmt.Sprintf(\"%s=%s\", env.Name, env.Value))\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"env: %v - %s\", err, stderr)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\tcase \"exec\":\n",
      "\t\t\t\t\tcmdName := strings.TrimLeft(payload, \"'()\")\n",
      "\t\t\t\t\tlog.Trace(\"SSH: Payload: %v\", cmdName)\n",
      "\t\t\t\t\targs := []string{\"serv\", \"key-\" + keyID, \"--config=\" + conf.CustomConf}\n",
      "\t\t\t\t\tlog.Trace(\"SSH: Arguments: %v\", args)\n",
      "\t\t\t\t\tcmd := exec.Command(conf.AppPath(), args...)\n",
      "\t\t\t\t\tcmd.Env = append(os.Environ(), \"SSH_ORIGINAL_COMMAND=\"+cmdName)\n",
      "\t\t\t\t\tstdout, err := cmd.StdoutPipe()\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"SSH: StdoutPipe: %v\", err)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tstderr, err := cmd.StderrPipe()\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"SSH: StderrPipe: %v\", err)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tinput, err := cmd.StdinPipe()\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"SSH: StdinPipe: %v\", err)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif err = cmd.Start(); err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"SSH: Start: %v\", err)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\t_ = req.Reply(true, nil)\n",
      "\t\t\t\t\tgo func() {\n",
      "\t\t\t\t\t\t_, _ = io.Copy(input, ch)\n",
      "\t\t\t\t\t}()\n",
      "\t\t\t\t\t_, _ = io.Copy(ch, stdout)\n",
      "\t\t\t\t\t_, _ = io.Copy(ch.Stderr(), stderr)\n",
      "\t\t\t\t\tif err = cmd.Wait(); err != nil {\n",
      "\t\t\t\t\t\tlog.Error(\"SSH: Wait: %v\", err)\n",
      "\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\t_, _ = ch.SendRequest(\"exit-status\", false, []byte{0, 0, 0, 0})\n",
      "\t\t\t\t\treturn\n",
      "\t\t\t\tdefault:\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}(reqs)\n",
      "\t}\n",
      "}\n",
      "func ToHook(repoLink string, w *database.Webhook) *api.Hook {\n",
      "\tconfig := map[string]string{\"url\": w.URL, \"content_type\": w.ContentType.Name()}\n",
      "\tif w.HookTaskType == database.SLACK {\n",
      "\t\ts := w.SlackMeta()\n",
      "\t\tconfig[\"channel\"] = s.Channel\n",
      "\t\tconfig[\"username\"] = s.Username\n",
      "\t\tconfig[\"icon_url\"] = s.IconURL\n",
      "\t\tconfig[\"color\"] = s.Color\n",
      "\t}\n",
      "\treturn &api.Hook{ID: w.ID, Type: w.HookTaskType.Name(), URL: fmt.Sprintf(\"%s/settings/hooks/%d\", repoLink, w.ID), Active: w.IsActive, Config: config, Events: w.EventsArray(), Updated: w.Updated, Created: w.Created}\n",
      "}\n",
      "func (r *Request) SetTLSClientConfig(config *tls.Config) *Request {\n",
      "\tr.setting.TlsClientConfig = config\n",
      "\treturn r\n",
      "}\n",
      "func Listen(opts conf.SSHOpts, appDataPath string) {\n",
      "\tconfig := &ssh.ServerConfig{Config: ssh.Config{Ciphers: opts.ServerCiphers, MACs: opts.ServerMACs}, PublicKeyCallback: func(conn ssh.ConnMetadata, key ssh.PublicKey) (*ssh.Permissions, error) {\n",
      "\t\tpkey, err := database.SearchPublicKeyByContent(strings.TrimSpace(string(ssh.MarshalAuthorizedKey(key))))\n",
      "\t\tif err != nil {\n",
      "\t\t\tlog.Error(\"SearchPublicKeyByContent: %v\", err)\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\treturn &ssh.Permissions{Extensions: map[string]string{\"key-id\": com.ToStr(pkey.ID)}}, nil\n",
      "\t}}\n",
      "\tkeys, err := setupHostKeys(appDataPath, opts.ServerAlgorithms)\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"SSH: Failed to setup host keys: %v\", err)\n",
      "\t}\n",
      "\tfor _, key := range keys {\n",
      "\t\tconfig.AddHostKey(key)\n",
      "\t}\n",
      "\tgo listen(config, opts.ListenHost, opts.ListenPort)\n",
      "}\n",
      "func SettingsPost(c *context.Context, f form.RepoSetting) {\n",
      "\tc.Title(\"repo.settings\")\n",
      "\tc.PageIs(\"SettingsOptions\")\n",
      "\tc.RequireAutosize()\n",
      "\trepo := c.Repo.Repository\n",
      "\tswitch c.Query(\"action\") {\n",
      "\tcase \"update\":\n",
      "\t\tif c.HasError() {\n",
      "\t\t\tc.Success(SETTINGS_OPTIONS)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tisNameChanged := false\n",
      "\t\toldRepoName := repo.Name\n",
      "\t\tnewRepoName := f.RepoName\n",
      "\t\tif repo.LowerName != strings.ToLower(newRepoName) {\n",
      "\t\t\tisNameChanged = true\n",
      "\t\t\tif err := database.ChangeRepositoryName(c.Repo.Owner, repo.Name, newRepoName); err != nil {\n",
      "\t\t\t\tc.FormErr(\"RepoName\")\n",
      "\t\t\t\tswitch {\n",
      "\t\t\t\tcase database.IsErrRepoAlreadyExist(err):\n",
      "\t\t\t\t\tc.RenderWithErr(c.Tr(\"form.repo_name_been_taken\"), SETTINGS_OPTIONS, &f)\n",
      "\t\t\t\tcase database.IsErrNameNotAllowed(err):\n",
      "\t\t\t\t\tc.RenderWithErr(c.Tr(\"repo.form.name_not_allowed\", err.(database.ErrNameNotAllowed).Value()), SETTINGS_OPTIONS, &f)\n",
      "\t\t\t\tdefault:\n",
      "\t\t\t\t\tc.Error(err, \"change repository name\")\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t\tlog.Trace(\"Repository name changed: %s/%s -> %s\", c.Repo.Owner.Name, repo.Name, newRepoName)\n",
      "\t\t}\n",
      "\t\trepo.Name = newRepoName\n",
      "\t\trepo.LowerName = strings.ToLower(newRepoName)\n",
      "\t\trepo.Description = f.Description\n",
      "\t\trepo.Website = f.Website\n",
      "\t\tif repo.IsFork {\n",
      "\t\t\tf.Private = repo.BaseRepo.IsPrivate\n",
      "\t\t\tf.Unlisted = repo.BaseRepo.IsUnlisted\n",
      "\t\t}\n",
      "\t\tvisibilityChanged := repo.IsPrivate != f.Private || repo.IsUnlisted != f.Unlisted\n",
      "\t\trepo.IsPrivate = f.Private\n",
      "\t\trepo.IsUnlisted = f.Unlisted\n",
      "\t\tif err := database.UpdateRepository(repo, visibilityChanged); err != nil {\n",
      "\t\t\tc.Error(err, \"update repository\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Repository basic settings updated: %s/%s\", c.Repo.Owner.Name, repo.Name)\n",
      "\t\tif isNameChanged {\n",
      "\t\t\tif err := database.Actions.RenameRepo(c.Req.Context(), c.User, repo.MustOwner(), oldRepoName, repo); err != nil {\n",
      "\t\t\t\tlog.Error(\"create rename repository action: %v\", err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.update_settings_success\"))\n",
      "\t\tc.Redirect(repo.Link() + \"/settings\")\n",
      "\tcase \"mirror\":\n",
      "\t\tif !repo.IsMirror {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif f.Interval > 0 {\n",
      "\t\t\tc.Repo.Mirror.EnablePrune = f.EnablePrune\n",
      "\t\t\tc.Repo.Mirror.Interval = f.Interval\n",
      "\t\t\tc.Repo.Mirror.NextSync = time.Now().Add(time.Duration(f.Interval) * time.Hour)\n",
      "\t\t\tif err := database.UpdateMirror(c.Repo.Mirror); err != nil {\n",
      "\t\t\t\tc.Error(err, \"update mirror\")\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err := c.Repo.Mirror.SaveAddress(f.MirrorAddress); err != nil {\n",
      "\t\t\tc.Error(err, \"save address\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.update_settings_success\"))\n",
      "\t\tc.Redirect(repo.Link() + \"/settings\")\n",
      "\tcase \"mirror-sync\":\n",
      "\t\tif !repo.IsMirror {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tgo database.MirrorQueue.Add(repo.ID)\n",
      "\t\tc.Flash.Info(c.Tr(\"repo.settings.mirror_sync_in_progress\"))\n",
      "\t\tc.Redirect(repo.Link() + \"/settings\")\n",
      "\tcase \"advanced\":\n",
      "\t\trepo.EnableWiki = f.EnableWiki\n",
      "\t\trepo.AllowPublicWiki = f.AllowPublicWiki\n",
      "\t\trepo.EnableExternalWiki = f.EnableExternalWiki\n",
      "\t\trepo.ExternalWikiURL = f.ExternalWikiURL\n",
      "\t\trepo.EnableIssues = f.EnableIssues\n",
      "\t\trepo.AllowPublicIssues = f.AllowPublicIssues\n",
      "\t\trepo.EnableExternalTracker = f.EnableExternalTracker\n",
      "\t\trepo.ExternalTrackerURL = f.ExternalTrackerURL\n",
      "\t\trepo.ExternalTrackerFormat = f.TrackerURLFormat\n",
      "\t\trepo.ExternalTrackerStyle = f.TrackerIssueStyle\n",
      "\t\trepo.EnablePulls = f.EnablePulls\n",
      "\t\trepo.PullsIgnoreWhitespace = f.PullsIgnoreWhitespace\n",
      "\t\trepo.PullsAllowRebase = f.PullsAllowRebase\n",
      "\t\tif !repo.EnableWiki || repo.EnableExternalWiki {\n",
      "\t\t\trepo.AllowPublicWiki = false\n",
      "\t\t}\n",
      "\t\tif !repo.EnableIssues || repo.EnableExternalTracker {\n",
      "\t\t\trepo.AllowPublicIssues = false\n",
      "\t\t}\n",
      "\t\tif err := database.UpdateRepository(repo, false); err != nil {\n",
      "\t\t\tc.Error(err, \"update repository\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Repository advanced settings updated: %s/%s\", c.Repo.Owner.Name, repo.Name)\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.update_settings_success\"))\n",
      "\t\tc.Redirect(c.Repo.RepoLink + \"/settings\")\n",
      "\tcase \"convert\":\n",
      "\t\tif !c.Repo.IsOwner() {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif repo.Name != f.RepoName {\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"form.enterred_invalid_repo_name\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif c.Repo.Owner.IsOrganization() {\n",
      "\t\t\tif !c.Repo.Owner.IsOwnedBy(c.User.ID) {\n",
      "\t\t\t\tc.NotFound()\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !repo.IsMirror {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\trepo.IsMirror = false\n",
      "\t\tif _, err := database.CleanUpMigrateInfo(repo); err != nil {\n",
      "\t\t\tc.Error(err, \"clean up migrate info\")\n",
      "\t\t\treturn\n",
      "\t\t} else if err = database.DeleteMirrorByRepoID(c.Repo.Repository.ID); err != nil {\n",
      "\t\t\tc.Error(err, \"delete mirror by repository ID\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Repository converted from mirror to regular: %s/%s\", c.Repo.Owner.Name, repo.Name)\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.convert_succeed\"))\n",
      "\t\tc.Redirect(conf.Server.Subpath + \"/\" + c.Repo.Owner.Name + \"/\" + repo.Name)\n",
      "\tcase \"transfer\":\n",
      "\t\tif !c.Repo.IsOwner() {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif repo.Name != f.RepoName {\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"form.enterred_invalid_repo_name\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif c.Repo.Owner.IsOrganization() && !c.User.IsAdmin {\n",
      "\t\t\tif !c.Repo.Owner.IsOwnedBy(c.User.ID) {\n",
      "\t\t\t\tc.NotFound()\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tnewOwner := c.Query(\"new_owner_name\")\n",
      "\t\tif !database.Users.IsUsernameUsed(c.Req.Context(), newOwner, c.Repo.Owner.ID) {\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"form.enterred_invalid_owner_name\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif err := database.TransferOwnership(c.User, newOwner, repo); err != nil {\n",
      "\t\t\tif database.IsErrRepoAlreadyExist(err) {\n",
      "\t\t\t\tc.RenderWithErr(c.Tr(\"repo.settings.new_owner_has_same_repo\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tc.Error(err, \"transfer ownership\")\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Repository transferred: %s/%s -> %s\", c.Repo.Owner.Name, repo.Name, newOwner)\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.transfer_succeed\"))\n",
      "\t\tc.Redirect(conf.Server.Subpath + \"/\" + newOwner + \"/\" + repo.Name)\n",
      "\tcase \"delete\":\n",
      "\t\tif !c.Repo.IsOwner() {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif repo.Name != f.RepoName {\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"form.enterred_invalid_repo_name\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif c.Repo.Owner.IsOrganization() && !c.User.IsAdmin {\n",
      "\t\t\tif !c.Repo.Owner.IsOwnedBy(c.User.ID) {\n",
      "\t\t\t\tc.NotFound()\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif err := database.DeleteRepository(c.Repo.Owner.ID, repo.ID); err != nil {\n",
      "\t\t\tc.Error(err, \"delete repository\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"Repository deleted: %s/%s\", c.Repo.Owner.Name, repo.Name)\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.deletion_success\"))\n",
      "\t\tc.Redirect(userutil.DashboardURLPath(c.Repo.Owner.Name, c.Repo.Owner.IsOrganization()))\n",
      "\tcase \"delete-wiki\":\n",
      "\t\tif !c.Repo.IsOwner() {\n",
      "\t\t\tc.NotFound()\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif repo.Name != f.RepoName {\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"form.enterred_invalid_repo_name\"), SETTINGS_OPTIONS, nil)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif c.Repo.Owner.IsOrganization() && !c.User.IsAdmin {\n",
      "\t\t\tif !c.Repo.Owner.IsOwnedBy(c.User.ID) {\n",
      "\t\t\t\tc.NotFound()\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\trepo.DeleteWiki()\n",
      "\t\tlog.Trace(\"Repository wiki deleted: %s/%s\", c.Repo.Owner.Name, repo.Name)\n",
      "\t\trepo.EnableWiki = false\n",
      "\t\tif err := database.UpdateRepository(repo, false); err != nil {\n",
      "\t\t\tc.Error(err, \"update repository\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tc.Flash.Success(c.Tr(\"repo.settings.wiki_deletion_success\"))\n",
      "\t\tc.Redirect(c.Repo.RepoLink + \"/settings\")\n",
      "\tdefault:\n",
      "\t\tc.NotFound()\n",
      "\t}\n",
      "}\n",
      "func NewAuthSourcePost(c *context.Context, f form.Authentication) {\n",
      "\tc.Title(\"admin.auths.new\")\n",
      "\tc.PageIs(\"Admin\")\n",
      "\tc.PageIs(\"AdminAuthentications\")\n",
      "\tc.Data[\"CurrentTypeName\"] = auth.Name(auth.Type(f.Type))\n",
      "\tc.Data[\"CurrentSecurityProtocol\"] = ldap.SecurityProtocolName(ldap.SecurityProtocol(f.SecurityProtocol))\n",
      "\tc.Data[\"AuthSources\"] = authSources\n",
      "\tc.Data[\"SecurityProtocols\"] = securityProtocols\n",
      "\tc.Data[\"SMTPAuths\"] = smtp.AuthTypes\n",
      "\thasTLS := false\n",
      "\tvar config any\n",
      "\tswitch auth.Type(f.Type) {\n",
      "\tcase auth.LDAP, auth.DLDAP:\n",
      "\t\tconfig = parseLDAPConfig(f)\n",
      "\t\thasTLS = ldap.SecurityProtocol(f.SecurityProtocol) > ldap.SecurityProtocolUnencrypted\n",
      "\tcase auth.SMTP:\n",
      "\t\tconfig = parseSMTPConfig(f)\n",
      "\t\thasTLS = true\n",
      "\tcase auth.PAM:\n",
      "\t\tconfig = &pam.Config{ServiceName: f.PAMServiceName}\n",
      "\tcase auth.GitHub:\n",
      "\t\tconfig = &github.Config{APIEndpoint: strings.TrimSuffix(f.GitHubAPIEndpoint, \"/\") + \"/\", SkipVerify: f.SkipVerify}\n",
      "\t\thasTLS = true\n",
      "\tdefault:\n",
      "\t\tc.Status(http.StatusBadRequest)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tc.Data[\"HasTLS\"] = hasTLS\n",
      "\tif c.HasError() {\n",
      "\t\tc.Success(AUTH_NEW)\n",
      "\t\treturn\n",
      "\t}\n",
      "\tsource, err := database.LoginSources.Create(c.Req.Context(), database.CreateLoginSourceOptions{Type: auth.Type(f.Type), Name: f.Name, Activated: f.IsActive, Default: f.IsDefault, Config: config})\n",
      "\tif err != nil {\n",
      "\t\tif database.IsErrLoginSourceAlreadyExist(err) {\n",
      "\t\t\tc.FormErr(\"Name\")\n",
      "\t\t\tc.RenderWithErr(c.Tr(\"admin.auths.login_source_exist\", f.Name), AUTH_NEW, f)\n",
      "\t\t} else {\n",
      "\t\t\tc.Error(err, \"create login source\")\n",
      "\t\t}\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif source.IsDefault {\n",
      "\t\terr = database.LoginSources.ResetNonDefault(c.Req.Context(), source)\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Error(err, \"reset non-default login sources\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\tlog.Trace(\"Authentication created by admin(%s): %s\", c.User.Name, f.Name)\n",
      "\tc.Flash.Success(c.Tr(\"admin.auths.new_success\", f.Name))\n",
      "\tc.Redirect(conf.Server.Subpath + \"/admin/auths\")\n",
      "}\n",
      "func Init(customConf string) error {\n",
      "\tdata, err := conf.Files.ReadFile(\"app.ini\")\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, `read default \"app.ini\"`)\n",
      "\t}\n",
      "\tFile, err = ini.LoadSources(ini.LoadOptions{IgnoreInlineComment: true}, data)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrap(err, `parse \"app.ini\"`)\n",
      "\t}\n",
      "\tFile.NameMapper = ini.SnackCase\n",
      "\tif customConf == \"\" {\n",
      "\t\tcustomConf = filepath.Join(CustomDir(), \"conf\", \"app.ini\")\n",
      "\t} else {\n",
      "\t\tcustomConf, err = filepath.Abs(customConf)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Wrap(err, \"get absolute path\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tCustomConf = customConf\n",
      "\tif osutil.IsFile(customConf) {\n",
      "\t\tif err = File.Append(customConf); err != nil {\n",
      "\t\t\treturn errors.Wrapf(err, \"append %q\", customConf)\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tlog.Warn(\"Custom config %q not found. Ignore this warning if you're running for the first time\", customConf)\n",
      "\t}\n",
      "\tif err = File.Section(ini.DefaultSection).MapTo(&App); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping default section\")\n",
      "\t}\n",
      "\tif err = File.Section(\"server\").MapTo(&Server); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [server] section\")\n",
      "\t}\n",
      "\tServer.AppDataPath = ensureAbs(Server.AppDataPath)\n",
      "\tif !strings.HasSuffix(Server.ExternalURL, \"/\") {\n",
      "\t\tServer.ExternalURL += \"/\"\n",
      "\t}\n",
      "\tServer.URL, err = url.Parse(Server.ExternalURL)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"parse '[server] EXTERNAL_URL' %q\", err)\n",
      "\t}\n",
      "\tServer.Subpath = strings.TrimRight(Server.URL.Path, \"/\")\n",
      "\tServer.SubpathDepth = strings.Count(Server.Subpath, \"/\")\n",
      "\tunixSocketMode, err := strconv.ParseUint(Server.UnixSocketPermission, 8, 32)\n",
      "\tif err != nil {\n",
      "\t\treturn errors.Wrapf(err, \"parse '[server] UNIX_SOCKET_PERMISSION' %q\", Server.UnixSocketPermission)\n",
      "\t}\n",
      "\tif unixSocketMode > 0777 {\n",
      "\t\tunixSocketMode = 0666\n",
      "\t}\n",
      "\tServer.UnixSocketMode = os.FileMode(unixSocketMode)\n",
      "\tSSH.RootPath = filepath.Join(HomeDir(), \".ssh\")\n",
      "\tSSH.KeyTestPath = os.TempDir()\n",
      "\tif err = File.Section(\"server\").MapTo(&SSH); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping SSH settings from [server] section\")\n",
      "\t}\n",
      "\tSSH.RootPath = ensureAbs(SSH.RootPath)\n",
      "\tSSH.KeyTestPath = ensureAbs(SSH.KeyTestPath)\n",
      "\tif !SSH.Disabled {\n",
      "\t\tif !SSH.StartBuiltinServer {\n",
      "\t\t\tif err := os.MkdirAll(SSH.RootPath, 0700); err != nil {\n",
      "\t\t\t\treturn errors.Wrap(err, \"create SSH root directory\")\n",
      "\t\t\t} else if err = os.MkdirAll(SSH.KeyTestPath, 0644); err != nil {\n",
      "\t\t\t\treturn errors.Wrap(err, \"create SSH key test directory\")\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tSSH.RewriteAuthorizedKeysAtStart = false\n",
      "\t\t}\n",
      "\t\tif SSH.MinimumKeySizeCheck {\n",
      "\t\t\tsshVersion, err := openSSHVersion()\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn errors.Wrap(err, \"get OpenSSH version\")\n",
      "\t\t\t}\n",
      "\t\t\tif IsWindowsRuntime() || semverutil.Compare(sshVersion, \"<\", \"5.1\") {\n",
      "\t\t\t\tlog.Warn(`SSH minimum key size check is forced to be disabled because server is not eligible:\n",
      "\t1. Windows server\n",
      "\t2. OpenSSH version is lower than 5.1`)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tSSH.MinimumKeySizes = map[string]int{}\n",
      "\t\t\t\tfor _, key := range File.Section(\"ssh.minimum_key_sizes\").Keys() {\n",
      "\t\t\t\t\tif key.MustInt() != -1 {\n",
      "\t\t\t\t\t\tSSH.MinimumKeySizes[strings.ToLower(key.Name())] = key.MustInt()\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tRepository.Root = filepath.Join(HomeDir(), \"gogs-repositories\")\n",
      "\tif err = File.Section(\"repository\").MapTo(&Repository); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [repository] section\")\n",
      "\t}\n",
      "\tRepository.Root = ensureAbs(Repository.Root)\n",
      "\tRepository.Upload.TempPath = ensureAbs(Repository.Upload.TempPath)\n",
      "\tif err = File.Section(\"database\").MapTo(&Database); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [database] section\")\n",
      "\t}\n",
      "\tDatabase.Path = ensureAbs(Database.Path)\n",
      "\tif err = File.Section(\"security\").MapTo(&Security); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [security] section\")\n",
      "\t}\n",
      "\tif Security.InstallLock {\n",
      "\t\tcurrentUser, match := CheckRunUser(App.RunUser)\n",
      "\t\tif !match {\n",
      "\t\t\treturn fmt.Errorf(\"user configured to run Gogs is %q, but the current user is %q\", App.RunUser, currentUser)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err = File.Section(\"email\").MapTo(&Email); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [email] section\")\n",
      "\t}\n",
      "\tif Email.Enabled {\n",
      "\t\tif Email.From == \"\" {\n",
      "\t\t\tEmail.From = Email.User\n",
      "\t\t}\n",
      "\t\tparsed, err := mail.ParseAddress(Email.From)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Wrapf(err, \"parse mail address %q\", Email.From)\n",
      "\t\t}\n",
      "\t\tEmail.FromEmail = parsed.Address\n",
      "\t}\n",
      "\tif err = File.Section(\"auth\").MapTo(&Auth); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [auth] section\")\n",
      "\t}\n",
      "\tif err = File.Section(\"user\").MapTo(&User); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [user] section\")\n",
      "\t}\n",
      "\tif err = File.Section(\"session\").MapTo(&Session); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [session] section\")\n",
      "\t}\n",
      "\tif err = File.Section(\"attachment\").MapTo(&Attachment); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [attachment] section\")\n",
      "\t}\n",
      "\tAttachment.Path = ensureAbs(Attachment.Path)\n",
      "\tif err = File.Section(\"time\").MapTo(&Time); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [time] section\")\n",
      "\t}\n",
      "\tTime.FormatLayout = map[string]string{\"ANSIC\": time.ANSIC, \"UnixDate\": time.UnixDate, \"RubyDate\": time.RubyDate, \"RFC822\": time.RFC822, \"RFC822Z\": time.RFC822Z, \"RFC850\": time.RFC850, \"RFC1123\": time.RFC1123, \"RFC1123Z\": time.RFC1123Z, \"RFC3339\": time.RFC3339, \"RFC3339Nano\": time.RFC3339Nano, \"Kitchen\": time.Kitchen, \"Stamp\": time.Stamp, \"StampMilli\": time.StampMilli, \"StampMicro\": time.StampMicro, \"StampNano\": time.StampNano}[Time.Format]\n",
      "\tif Time.FormatLayout == \"\" {\n",
      "\t\tTime.FormatLayout = time.RFC3339\n",
      "\t}\n",
      "\tif err = File.Section(\"picture\").MapTo(&Picture); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [picture] section\")\n",
      "\t}\n",
      "\tPicture.AvatarUploadPath = ensureAbs(Picture.AvatarUploadPath)\n",
      "\tPicture.RepositoryAvatarUploadPath = ensureAbs(Picture.RepositoryAvatarUploadPath)\n",
      "\tswitch Picture.GravatarSource {\n",
      "\tcase \"gravatar\":\n",
      "\t\tPicture.GravatarSource = \"https://secure.gravatar.com/avatar/\"\n",
      "\tcase \"libravatar\":\n",
      "\t\tPicture.GravatarSource = \"https://seccdn.libravatar.org/avatar/\"\n",
      "\t}\n",
      "\tif Server.OfflineMode {\n",
      "\t\tPicture.DisableGravatar = true\n",
      "\t\tPicture.EnableFederatedAvatar = false\n",
      "\t}\n",
      "\tif Picture.DisableGravatar {\n",
      "\t\tPicture.EnableFederatedAvatar = false\n",
      "\t}\n",
      "\tif Picture.EnableFederatedAvatar {\n",
      "\t\tgravatarURL, err := url.Parse(Picture.GravatarSource)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn errors.Wrapf(err, \"parse Gravatar source %q\", Picture.GravatarSource)\n",
      "\t\t}\n",
      "\t\tPicture.LibravatarService = libravatar.New()\n",
      "\t\tif gravatarURL.Scheme == \"https\" {\n",
      "\t\t\tPicture.LibravatarService.SetUseHTTPS(true)\n",
      "\t\t\tPicture.LibravatarService.SetSecureFallbackHost(gravatarURL.Host)\n",
      "\t\t} else {\n",
      "\t\t\tPicture.LibravatarService.SetUseHTTPS(false)\n",
      "\t\t\tPicture.LibravatarService.SetFallbackHost(gravatarURL.Host)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err = File.Section(\"mirror\").MapTo(&Mirror); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [mirror] section\")\n",
      "\t}\n",
      "\tif Mirror.DefaultInterval <= 0 {\n",
      "\t\tMirror.DefaultInterval = 8\n",
      "\t}\n",
      "\tI18n = new(i18nConf)\n",
      "\tif err = File.Section(\"i18n\").MapTo(I18n); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [i18n] section\")\n",
      "\t}\n",
      "\tI18n.dateLangs = File.Section(\"i18n.datelang\").KeysHash()\n",
      "\tif err = File.Section(\"lfs\").MapTo(&LFS); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [lfs] section\")\n",
      "\t}\n",
      "\tLFS.ObjectsPath = ensureAbs(LFS.ObjectsPath)\n",
      "\thandleDeprecated()\n",
      "\tif err = File.Section(\"cache\").MapTo(&Cache); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [cache] section\")\n",
      "\t} else if err = File.Section(\"http\").MapTo(&HTTP); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [http] section\")\n",
      "\t} else if err = File.Section(\"release\").MapTo(&Release); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [release] section\")\n",
      "\t} else if err = File.Section(\"webhook\").MapTo(&Webhook); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [webhook] section\")\n",
      "\t} else if err = File.Section(\"markdown\").MapTo(&Markdown); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [markdown] section\")\n",
      "\t} else if err = File.Section(\"smartypants\").MapTo(&Smartypants); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [smartypants] section\")\n",
      "\t} else if err = File.Section(\"admin\").MapTo(&Admin); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [admin] section\")\n",
      "\t} else if err = File.Section(\"cron\").MapTo(&Cron); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [cron] section\")\n",
      "\t} else if err = File.Section(\"git\").MapTo(&Git); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [git] section\")\n",
      "\t} else if err = File.Section(\"api\").MapTo(&API); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [api] section\")\n",
      "\t} else if err = File.Section(\"ui\").MapTo(&UI); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [ui] section\")\n",
      "\t} else if err = File.Section(\"prometheus\").MapTo(&Prometheus); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [prometheus] section\")\n",
      "\t} else if err = File.Section(\"other\").MapTo(&Other); err != nil {\n",
      "\t\treturn errors.Wrap(err, \"mapping [other] section\")\n",
      "\t}\n",
      "\tHasRobotsTxt = osutil.IsFile(filepath.Join(CustomDir(), \"robots.txt\"))\n",
      "\treturn nil\n",
      "}\n",
      "func HTTPContexter(store Store) macaron.Handler {\n",
      "\treturn func(c *macaron.Context) {\n",
      "\t\tif len(conf.HTTP.AccessControlAllowOrigin) > 0 {\n",
      "\t\t\tc.Header().Set(\"Access-Control-Allow-Origin\", conf.HTTP.AccessControlAllowOrigin)\n",
      "\t\t\tc.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Authorization, User-Agent\")\n",
      "\t\t\tif c.Req.Method == \"OPTIONS\" {\n",
      "\t\t\t\tc.Status(http.StatusOK)\n",
      "\t\t\t\treturn\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\townerName := c.Params(\":username\")\n",
      "\t\trepoName := strings.TrimSuffix(c.Params(\":reponame\"), \".git\")\n",
      "\t\trepoName = strings.TrimSuffix(repoName, \".wiki\")\n",
      "\t\tisPull := c.Query(\"service\") == \"git-upload-pack\" || strings.HasSuffix(c.Req.URL.Path, \"git-upload-pack\") || c.Req.Method == \"GET\"\n",
      "\t\towner, err := database.Users.GetByUsername(c.Req.Context(), ownerName)\n",
      "\t\tif err != nil {\n",
      "\t\t\tif database.IsErrUserNotExist(err) {\n",
      "\t\t\t\tc.Status(http.StatusNotFound)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tc.Status(http.StatusInternalServerError)\n",
      "\t\t\t\tlog.Error(\"Failed to get user [name: %s]: %v\", ownerName, err)\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\trepo, err := database.Repos.GetByName(c.Req.Context(), owner.ID, repoName)\n",
      "\t\tif err != nil {\n",
      "\t\t\tif database.IsErrRepoNotExist(err) {\n",
      "\t\t\t\tc.Status(http.StatusNotFound)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tc.Status(http.StatusInternalServerError)\n",
      "\t\t\t\tlog.Error(\"Failed to get repository [owner_id: %d, name: %s]: %v\", owner.ID, repoName, err)\n",
      "\t\t\t}\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif isPull && !repo.IsPrivate && !conf.Auth.RequireSigninView {\n",
      "\t\t\tc.Map(&HTTPContext{Context: c})\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\taction := c.Params(\"*\")\n",
      "\t\tif !strings.Contains(action, \"git-\") && !strings.Contains(action, \"info/\") && !strings.Contains(action, \"HEAD\") && !strings.Contains(action, \"objects/\") {\n",
      "\t\t\tc.Error(http.StatusBadRequest, fmt.Sprintf(\"Unrecognized action %q\", action))\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tauthHead := c.Req.Header.Get(\"Authorization\")\n",
      "\t\tif authHead == \"\" {\n",
      "\t\t\taskCredentials(c, http.StatusUnauthorized, \"\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tauths := strings.Fields(authHead)\n",
      "\t\tif len(auths) != 2 || auths[0] != \"Basic\" {\n",
      "\t\t\taskCredentials(c, http.StatusUnauthorized, \"\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tauthUsername, authPassword, err := tool.BasicAuthDecode(auths[1])\n",
      "\t\tif err != nil {\n",
      "\t\t\taskCredentials(c, http.StatusUnauthorized, \"\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tauthUser, err := database.Users.Authenticate(c.Req.Context(), authUsername, authPassword, -1)\n",
      "\t\tif err != nil && !auth.IsErrBadCredentials(err) {\n",
      "\t\t\tc.Status(http.StatusInternalServerError)\n",
      "\t\t\tlog.Error(\"Failed to authenticate user [name: %s]: %v\", authUsername, err)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif authUser == nil {\n",
      "\t\t\tauthUser, err = context.AuthenticateByToken(store, c.Req.Context(), authUsername)\n",
      "\t\t\tif err != nil && !database.IsErrAccessTokenNotExist(err) {\n",
      "\t\t\t\tc.Status(http.StatusInternalServerError)\n",
      "\t\t\t\tlog.Error(\"Failed to authenticate by access token via username: %v\", err)\n",
      "\t\t\t\treturn\n",
      "\t\t\t} else if database.IsErrAccessTokenNotExist(err) {\n",
      "\t\t\t\tauthUser, err = context.AuthenticateByToken(store, c.Req.Context(), authPassword)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tif database.IsErrAccessTokenNotExist(err) {\n",
      "\t\t\t\t\t\taskCredentials(c, http.StatusUnauthorized, \"\")\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tc.Status(http.StatusInternalServerError)\n",
      "\t\t\t\t\t\tlog.Error(\"Failed to authenticate by access token via password: %v\", err)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\treturn\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t} else if database.TwoFactors.IsEnabled(c.Req.Context(), authUser.ID) {\n",
      "\t\t\taskCredentials(c, http.StatusUnauthorized, `User with two-factor authentication enabled cannot perform HTTP/HTTPS operations via plain username and password\n",
      "Please create and use personal access token on user settings page`)\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tlog.Trace(\"[Git] Authenticated user: %s\", authUser.Name)\n",
      "\t\tmode := database.AccessModeWrite\n",
      "\t\tif isPull {\n",
      "\t\t\tmode = database.AccessModeRead\n",
      "\t\t}\n",
      "\t\tif !database.Perms.Authorize(c.Req.Context(), authUser.ID, repo.ID, mode, database.AccessModeOptions{OwnerID: repo.OwnerID, Private: repo.IsPrivate}) {\n",
      "\t\t\taskCredentials(c, http.StatusForbidden, \"User permission denied\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tif !isPull && repo.IsMirror {\n",
      "\t\t\tc.Error(http.StatusForbidden, \"Mirror repository is read-only\")\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t\tc.Map(&HTTPContext{Context: c, OwnerName: ownerName, OwnerSalt: owner.Salt, RepoID: repo.ID, RepoName: repoName, AuthUser: authUser})\n",
      "\t}\n",
      "}\n",
      "func setup(c *cli.Context, logFile string, connectDB bool) {\n",
      "\tconf.HookMode = true\n",
      "\tvar customConf string\n",
      "\tif c.IsSet(\"config\") {\n",
      "\t\tcustomConf = c.String(\"config\")\n",
      "\t} else if c.GlobalIsSet(\"config\") {\n",
      "\t\tcustomConf = c.GlobalString(\"config\")\n",
      "\t}\n",
      "\terr := conf.Init(customConf)\n",
      "\tif err != nil {\n",
      "\t\tfail(\"Internal error\", \"Failed to init configuration: %v\", err)\n",
      "\t}\n",
      "\tconf.InitLogging(true)\n",
      "\tlevel := log.LevelTrace\n",
      "\tif conf.IsProdMode() {\n",
      "\t\tlevel = log.LevelError\n",
      "\t}\n",
      "\terr = log.NewFile(log.FileConfig{Level: level, Filename: filepath.Join(conf.Log.RootPath, \"hooks\", logFile), FileRotationConfig: log.FileRotationConfig{Rotate: true, Daily: true, MaxDays: 3}})\n",
      "\tif err != nil {\n",
      "\t\tfail(\"Internal error\", \"Failed to init file logger: %v\", err)\n",
      "\t}\n",
      "\tlog.Remove(log.DefaultConsoleName)\n",
      "\tif !connectDB {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tif conf.UseSQLite3 {\n",
      "\t\t_ = os.Chdir(conf.WorkDir())\n",
      "\t}\n",
      "\tif _, err := database.SetEngine(); err != nil {\n",
      "\t\tfail(\"Internal error\", \"Failed to set database engine: %v\", err)\n",
      "\t}\n",
      "}\n",
      "func NewRepoContext() {\n",
      "\tzip.Verbose = false\n",
      "\tif _, err := exec.LookPath(\"git\"); err != nil {\n",
      "\t\tlog.Fatal(\"Failed to test 'git' command: %v (forgotten install?)\", err)\n",
      "\t}\n",
      "\tvar err error\n",
      "\tconf.Git.Version, err = git.BinVersion()\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatal(\"Failed to get Git version: %v\", err)\n",
      "\t}\n",
      "\tlog.Trace(\"Git version: %s\", conf.Git.Version)\n",
      "\tif semverutil.Compare(conf.Git.Version, \"<\", \"1.8.3\") {\n",
      "\t\tlog.Fatal(\"Gogs requires Git version greater or equal to 1.8.3\")\n",
      "\t}\n",
      "\tfor configKey, defaultValue := range map[string]string{\"user.name\": \"Gogs\", \"user.email\": \"gogs@fake.local\"} {\n",
      "\t\tif stdout, stderr, err := process.Exec(\"NewRepoContext(get setting)\", \"git\", \"config\", \"--get\", configKey); err != nil || strings.TrimSpace(stdout) == \"\" {\n",
      "\t\t\tif _, ok := err.(*exec.ExitError); ok || strings.TrimSpace(stdout) == \"\" {\n",
      "\t\t\t\tif _, stderr, gerr := process.Exec(\"NewRepoContext(set \"+configKey+\")\", \"git\", \"config\", \"--global\", configKey, defaultValue); gerr != nil {\n",
      "\t\t\t\t\tlog.Fatal(\"Failed to set git %s(%s): %s\", configKey, gerr, stderr)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tlog.Info(\"Git config %s set to %s\", configKey, defaultValue)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tlog.Fatal(\"Failed to get git %s(%s): %s\", configKey, err, stderr)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif _, stderr, err := process.Exec(\"NewRepoContext(git config --global core.quotepath false)\", \"git\", \"config\", \"--global\", \"core.quotepath\", \"false\"); err != nil {\n",
      "\t\tlog.Fatal(\"Failed to execute 'git config --global core.quotepath false': %v - %s\", err, stderr)\n",
      "\t}\n",
      "\tRemoveAllWithNotice(\"Clean up repository temporary data\", filepath.Join(conf.Server.AppDataPath, \"tmp\"))\n",
      "}\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "astaxie/build-web-application-with-golang 13 42697\n",
      "13\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "spf13/cobra 1 35174\n",
      "1\n",
      "======================CLASS=======================\n",
      "func (c *Command) RegisterFlagCompletionFunc(flagName string, f func(cmd *Command, args []string, toComplete string) ([]string, ShellCompDirective)) error {\n",
      "\tflag := c.Flag(flagName)\n",
      "\tif flag == nil {\n",
      "\t\treturn fmt.Errorf(\"RegisterFlagCompletionFunc: flag '%s' does not exist\", flagName)\n",
      "\t}\n",
      "\tflagCompletionMutex.Lock()\n",
      "\tdefer flagCompletionMutex.Unlock()\n",
      "\tif _, exists := flagCompletionFunctions[flag]; exists {\n",
      "\t\treturn fmt.Errorf(\"RegisterFlagCompletionFunc: flag '%s' already registered\", flagName)\n",
      "\t}\n",
      "\tflagCompletionFunctions[flag] = f\n",
      "\treturn nil\n",
      "}\n",
      "func hasNoOptDefVal(name string, fs *flag.FlagSet) bool {\n",
      "\tflag := fs.Lookup(name)\n",
      "\tif flag == nil {\n",
      "\t\treturn false\n",
      "\t}\n",
      "\treturn flag.NoOptDefVal != \"\"\n",
      "}\n",
      "func (e *flagCompError) Error() string {\n",
      "\treturn \"Subcommand '\" + e.subCommand + \"' does not support flag '\" + e.flagName + \"'\"\n",
      "}\n",
      "func genPowerShellComp(buf io.StringWriter, name string, includeDesc bool) {\n",
      "\tnameForVar := name\n",
      "\tnameForVar = strings.Replace(nameForVar, \"-\", \"_\", -1)\n",
      "\tnameForVar = strings.Replace(nameForVar, \":\", \"_\", -1)\n",
      "\tcompCmd := ShellCompRequestCmd\n",
      "\tif !includeDesc {\n",
      "\t\tcompCmd = ShellCompNoDescRequestCmd\n",
      "\t}\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(`# powershell completion for %-36[1]s -*- shell-script -*-\n",
      "\n",
      "function __%[1]s_debug {\n",
      "    if ($env:BASH_COMP_DEBUG_FILE) {\n",
      "        \"$args\" | Out-File -Append -FilePath \"$env:BASH_COMP_DEBUG_FILE\"\n",
      "    }\n",
      "}\n",
      "\n",
      "filter __%[1]s_escapeStringWithSpecialChars {\n",
      "`+\"    $_ -replace '\\\\s|#|@|\\\\$|;|,|''|\\\\{|\\\\}|\\\\(|\\\\)|\\\"|`|\\\\||<|>|&','`$&'\"+`\n",
      "}\n",
      "\n",
      "[scriptblock]${__%[2]sCompleterBlock} = {\n",
      "    param(\n",
      "            $WordToComplete,\n",
      "            $CommandAst,\n",
      "            $CursorPosition\n",
      "        )\n",
      "\n",
      "    # Get the current command line and convert into a string\n",
      "    $Command = $CommandAst.CommandElements\n",
      "    $Command = \"$Command\"\n",
      "\n",
      "    __%[1]s_debug \"\"\n",
      "    __%[1]s_debug \"========= starting completion logic ==========\"\n",
      "    __%[1]s_debug \"WordToComplete: $WordToComplete Command: $Command CursorPosition: $CursorPosition\"\n",
      "\n",
      "    # The user could have moved the cursor backwards on the command-line.\n",
      "    # We need to trigger completion from the $CursorPosition location, so we need\n",
      "    # to truncate the command-line ($Command) up to the $CursorPosition location.\n",
      "    # Make sure the $Command is longer then the $CursorPosition before we truncate.\n",
      "    # This happens because the $Command does not include the last space.\n",
      "    if ($Command.Length -gt $CursorPosition) {\n",
      "        $Command=$Command.Substring(0,$CursorPosition)\n",
      "    }\n",
      "    __%[1]s_debug \"Truncated command: $Command\"\n",
      "\n",
      "    $ShellCompDirectiveError=%[4]d\n",
      "    $ShellCompDirectiveNoSpace=%[5]d\n",
      "    $ShellCompDirectiveNoFileComp=%[6]d\n",
      "    $ShellCompDirectiveFilterFileExt=%[7]d\n",
      "    $ShellCompDirectiveFilterDirs=%[8]d\n",
      "    $ShellCompDirectiveKeepOrder=%[9]d\n",
      "\n",
      "    # Prepare the command to request completions for the program.\n",
      "    # Split the command at the first space to separate the program and arguments.\n",
      "    $Program,$Arguments = $Command.Split(\" \",2)\n",
      "\n",
      "    $RequestComp=\"$Program %[3]s $Arguments\"\n",
      "    __%[1]s_debug \"RequestComp: $RequestComp\"\n",
      "\n",
      "    # we cannot use $WordToComplete because it\n",
      "    # has the wrong values if the cursor was moved\n",
      "    # so use the last argument\n",
      "    if ($WordToComplete -ne \"\" ) {\n",
      "        $WordToComplete = $Arguments.Split(\" \")[-1]\n",
      "    }\n",
      "    __%[1]s_debug \"New WordToComplete: $WordToComplete\"\n",
      "\n",
      "\n",
      "    # Check for flag with equal sign\n",
      "    $IsEqualFlag = ($WordToComplete -Like \"--*=*\" )\n",
      "    if ( $IsEqualFlag ) {\n",
      "        __%[1]s_debug \"Completing equal sign flag\"\n",
      "        # Remove the flag part\n",
      "        $Flag,$WordToComplete = $WordToComplete.Split(\"=\",2)\n",
      "    }\n",
      "\n",
      "    if ( $WordToComplete -eq \"\" -And ( -Not $IsEqualFlag )) {\n",
      "        # If the last parameter is complete (there is a space following it)\n",
      "        # We add an extra empty parameter so we can indicate this to the go method.\n",
      "        __%[1]s_debug \"Adding extra empty parameter\"\n",
      "        # PowerShell 7.2+ changed the way how the arguments are passed to executables,\n",
      "        # so for pre-7.2 or when Legacy argument passing is enabled we need to use\n",
      "`+\"        # `\\\"`\\\" to pass an empty argument, a \\\"\\\" or '' does not work!!!\"+`\n",
      "        if ($PSVersionTable.PsVersion -lt [version]'7.2.0' -or\n",
      "            ($PSVersionTable.PsVersion -lt [version]'7.3.0' -and -not [ExperimentalFeature]::IsEnabled(\"PSNativeCommandArgumentPassing\")) -or\n",
      "            (($PSVersionTable.PsVersion -ge [version]'7.3.0' -or [ExperimentalFeature]::IsEnabled(\"PSNativeCommandArgumentPassing\")) -and\n",
      "              $PSNativeCommandArgumentPassing -eq 'Legacy')) {\n",
      "`+\"             $RequestComp=\\\"$RequestComp\\\" + ' `\\\"`\\\"'\"+`\n",
      "        } else {\n",
      "             $RequestComp=\"$RequestComp\" + ' \"\"'\n",
      "        }\n",
      "    }\n",
      "\n",
      "    __%[1]s_debug \"Calling $RequestComp\"\n",
      "    # First disable ActiveHelp which is not supported for Powershell\n",
      "    ${env:%[10]s}=0\n",
      "\n",
      "    #call the command store the output in $out and redirect stderr and stdout to null\n",
      "    # $Out is an array contains each line per element\n",
      "    Invoke-Expression -OutVariable out \"$RequestComp\" 2>&1 | Out-Null\n",
      "\n",
      "    # get directive from last line\n",
      "    [int]$Directive = $Out[-1].TrimStart(':')\n",
      "    if ($Directive -eq \"\") {\n",
      "        # There is no directive specified\n",
      "        $Directive = 0\n",
      "    }\n",
      "    __%[1]s_debug \"The completion directive is: $Directive\"\n",
      "\n",
      "    # remove directive (last element) from out\n",
      "    $Out = $Out | Where-Object { $_ -ne $Out[-1] }\n",
      "    __%[1]s_debug \"The completions are: $Out\"\n",
      "\n",
      "    if (($Directive -band $ShellCompDirectiveError) -ne 0 ) {\n",
      "        # Error code.  No completion.\n",
      "        __%[1]s_debug \"Received error from custom completion go code\"\n",
      "        return\n",
      "    }\n",
      "\n",
      "    $Longest = 0\n",
      "    [Array]$Values = $Out | ForEach-Object {\n",
      "        #Split the output in name and description\n",
      "`+\"        $Name, $Description = $_.Split(\\\"`t\\\",2)\"+`\n",
      "        __%[1]s_debug \"Name: $Name Description: $Description\"\n",
      "\n",
      "        # Look for the longest completion so that we can format things nicely\n",
      "        if ($Longest -lt $Name.Length) {\n",
      "            $Longest = $Name.Length\n",
      "        }\n",
      "\n",
      "        # Set the description to a one space string if there is none set.\n",
      "        # This is needed because the CompletionResult does not accept an empty string as argument\n",
      "        if (-Not $Description) {\n",
      "            $Description = \" \"\n",
      "        }\n",
      "        @{Name=\"$Name\";Description=\"$Description\"}\n",
      "    }\n",
      "\n",
      "\n",
      "    $Space = \" \"\n",
      "    if (($Directive -band $ShellCompDirectiveNoSpace) -ne 0 ) {\n",
      "        # remove the space here\n",
      "        __%[1]s_debug \"ShellCompDirectiveNoSpace is called\"\n",
      "        $Space = \"\"\n",
      "    }\n",
      "\n",
      "    if ((($Directive -band $ShellCompDirectiveFilterFileExt) -ne 0 ) -or\n",
      "       (($Directive -band $ShellCompDirectiveFilterDirs) -ne 0 ))  {\n",
      "        __%[1]s_debug \"ShellCompDirectiveFilterFileExt ShellCompDirectiveFilterDirs are not supported\"\n",
      "\n",
      "        # return here to prevent the completion of the extensions\n",
      "        return\n",
      "    }\n",
      "\n",
      "    $Values = $Values | Where-Object {\n",
      "        # filter the result\n",
      "        $_.Name -like \"$WordToComplete*\"\n",
      "\n",
      "        # Join the flag back if we have an equal sign flag\n",
      "        if ( $IsEqualFlag ) {\n",
      "            __%[1]s_debug \"Join the equal sign flag back to the completion value\"\n",
      "            $_.Name = $Flag + \"=\" + $_.Name\n",
      "        }\n",
      "    }\n",
      "\n",
      "    # we sort the values in ascending order by name if keep order isn't passed\n",
      "    if (($Directive -band $ShellCompDirectiveKeepOrder) -eq 0 ) {\n",
      "        $Values = $Values | Sort-Object -Property Name\n",
      "    }\n",
      "\n",
      "    if (($Directive -band $ShellCompDirectiveNoFileComp) -ne 0 ) {\n",
      "        __%[1]s_debug \"ShellCompDirectiveNoFileComp is called\"\n",
      "\n",
      "        if ($Values.Length -eq 0) {\n",
      "            # Just print an empty string here so the\n",
      "            # shell does not start to complete paths.\n",
      "            # We cannot use CompletionResult here because\n",
      "            # it does not accept an empty string as argument.\n",
      "            \"\"\n",
      "            return\n",
      "        }\n",
      "    }\n",
      "\n",
      "    # Get the current mode\n",
      "    $Mode = (Get-PSReadLineKeyHandler | Where-Object {$_.Key -eq \"Tab\" }).Function\n",
      "    __%[1]s_debug \"Mode: $Mode\"\n",
      "\n",
      "    $Values | ForEach-Object {\n",
      "\n",
      "        # store temporary because switch will overwrite $_\n",
      "        $comp = $_\n",
      "\n",
      "        # PowerShell supports three different completion modes\n",
      "        # - TabCompleteNext (default windows style - on each key press the next option is displayed)\n",
      "        # - Complete (works like bash)\n",
      "        # - MenuComplete (works like zsh)\n",
      "        # You set the mode with Set-PSReadLineKeyHandler -Key Tab -Function <mode>\n",
      "\n",
      "        # CompletionResult Arguments:\n",
      "        # 1) CompletionText text to be used as the auto completion result\n",
      "        # 2) ListItemText   text to be displayed in the suggestion list\n",
      "        # 3) ResultType     type of completion result\n",
      "        # 4) ToolTip        text for the tooltip with details about the object\n",
      "\n",
      "        switch ($Mode) {\n",
      "\n",
      "            # bash like\n",
      "            \"Complete\" {\n",
      "\n",
      "                if ($Values.Length -eq 1) {\n",
      "                    __%[1]s_debug \"Only one completion left\"\n",
      "\n",
      "                    # insert space after value\n",
      "                    [System.Management.Automation.CompletionResult]::new($($comp.Name | __%[1]s_escapeStringWithSpecialChars) + $Space, \"$($comp.Name)\", 'ParameterValue', \"$($comp.Description)\")\n",
      "\n",
      "                } else {\n",
      "                    # Add the proper number of spaces to align the descriptions\n",
      "                    while($comp.Name.Length -lt $Longest) {\n",
      "                        $comp.Name = $comp.Name + \" \"\n",
      "                    }\n",
      "\n",
      "                    # Check for empty description and only add parentheses if needed\n",
      "                    if ($($comp.Description) -eq \" \" ) {\n",
      "                        $Description = \"\"\n",
      "                    } else {\n",
      "                        $Description = \"  ($($comp.Description))\"\n",
      "                    }\n",
      "\n",
      "                    [System.Management.Automation.CompletionResult]::new(\"$($comp.Name)$Description\", \"$($comp.Name)$Description\", 'ParameterValue', \"$($comp.Description)\")\n",
      "                }\n",
      "             }\n",
      "\n",
      "            # zsh like\n",
      "            \"MenuComplete\" {\n",
      "                # insert space after value\n",
      "                # MenuComplete will automatically show the ToolTip of\n",
      "                # the highlighted value at the bottom of the suggestions.\n",
      "                [System.Management.Automation.CompletionResult]::new($($comp.Name | __%[1]s_escapeStringWithSpecialChars) + $Space, \"$($comp.Name)\", 'ParameterValue', \"$($comp.Description)\")\n",
      "            }\n",
      "\n",
      "            # TabCompleteNext and in case we get something unknown\n",
      "            Default {\n",
      "                # Like MenuComplete but we don't want to add a space here because\n",
      "                # the user need to press space anyway to get the completion.\n",
      "                # Description will not be shown because that's not possible with TabCompleteNext\n",
      "                [System.Management.Automation.CompletionResult]::new($($comp.Name | __%[1]s_escapeStringWithSpecialChars), \"$($comp.Name)\", 'ParameterValue', \"$($comp.Description)\")\n",
      "            }\n",
      "        }\n",
      "\n",
      "    }\n",
      "}\n",
      "\n",
      "Register-ArgumentCompleter -CommandName '%[1]s' -ScriptBlock ${__%[2]sCompleterBlock}\n",
      "`, name, nameForVar, compCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, ShellCompDirectiveKeepOrder, activeHelpEnvVar(name)))\n",
      "}\n",
      "func shortHasNoOptDefVal(name string, fs *flag.FlagSet) bool {\n",
      "\tif len(name) == 0 {\n",
      "\t\treturn false\n",
      "\t}\n",
      "\tflag := fs.ShorthandLookup(name[:1])\n",
      "\tif flag == nil {\n",
      "\t\treturn false\n",
      "\t}\n",
      "\treturn flag.NoOptDefVal != \"\"\n",
      "}\n",
      "func writeFlag(buf io.StringWriter, flag *pflag.Flag, cmd *Command) {\n",
      "\tname := flag.Name\n",
      "\tformat := \"    flags+=(\\\"--%s\"\n",
      "\tif len(flag.NoOptDefVal) == 0 {\n",
      "\t\tformat += \"=\"\n",
      "\t}\n",
      "\tformat += cbn\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(format, name))\n",
      "\tif len(flag.NoOptDefVal) == 0 {\n",
      "\t\tformat = \"    two_word_flags+=(\\\"--%s\" + cbn\n",
      "\t\tWriteStringAndCheck(buf, fmt.Sprintf(format, name))\n",
      "\t}\n",
      "\twriteFlagHandler(buf, \"--\"+name, flag.Annotations, cmd)\n",
      "}\n",
      "func writePreamble(buf io.StringWriter, name string) {\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(\"# bash completion for %-36s -*- shell-script -*-\\n\", name))\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(`\n",
      "__%[1]s_debug()\n",
      "{\n",
      "    if [[ -n ${BASH_COMP_DEBUG_FILE:-} ]]; then\n",
      "        echo \"$*\" >> \"${BASH_COMP_DEBUG_FILE}\"\n",
      "    fi\n",
      "}\n",
      "\n",
      "# Homebrew on Macs have version 1.3 of bash-completion which doesn't include\n",
      "# _init_completion. This is a very minimal version of that function.\n",
      "__%[1]s_init_completion()\n",
      "{\n",
      "    COMPREPLY=()\n",
      "    _get_comp_words_by_ref \"$@\" cur prev words cword\n",
      "}\n",
      "\n",
      "__%[1]s_index_of_word()\n",
      "{\n",
      "    local w word=$1\n",
      "    shift\n",
      "    index=0\n",
      "    for w in \"$@\"; do\n",
      "        [[ $w = \"$word\" ]] && return\n",
      "        index=$((index+1))\n",
      "    done\n",
      "    index=-1\n",
      "}\n",
      "\n",
      "__%[1]s_contains_word()\n",
      "{\n",
      "    local w word=$1; shift\n",
      "    for w in \"$@\"; do\n",
      "        [[ $w = \"$word\" ]] && return\n",
      "    done\n",
      "    return 1\n",
      "}\n",
      "\n",
      "__%[1]s_handle_go_custom_completion()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: cur is ${cur}, words[*] is ${words[*]}, #words[@] is ${#words[@]}\"\n",
      "\n",
      "    local shellCompDirectiveError=%[3]d\n",
      "    local shellCompDirectiveNoSpace=%[4]d\n",
      "    local shellCompDirectiveNoFileComp=%[5]d\n",
      "    local shellCompDirectiveFilterFileExt=%[6]d\n",
      "    local shellCompDirectiveFilterDirs=%[7]d\n",
      "\n",
      "    local out requestComp lastParam lastChar comp directive args\n",
      "\n",
      "    # Prepare the command to request completions for the program.\n",
      "    # Calling ${words[0]} instead of directly %[1]s allows handling aliases\n",
      "    args=(\"${words[@]:1}\")\n",
      "    # Disable ActiveHelp which is not supported for bash completion v1\n",
      "    requestComp=\"%[8]s=0 ${words[0]} %[2]s ${args[*]}\"\n",
      "\n",
      "    lastParam=${words[$((${#words[@]}-1))]}\n",
      "    lastChar=${lastParam:$((${#lastParam}-1)):1}\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: lastParam ${lastParam}, lastChar ${lastChar}\"\n",
      "\n",
      "    if [ -z \"${cur}\" ] && [ \"${lastChar}\" != \"=\" ]; then\n",
      "        # If the last parameter is complete (there is a space following it)\n",
      "        # We add an extra empty parameter so we can indicate this to the go method.\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: Adding extra empty parameter\"\n",
      "        requestComp=\"${requestComp} \\\"\\\"\"\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: calling ${requestComp}\"\n",
      "    # Use eval to handle any environment variables and such\n",
      "    out=$(eval \"${requestComp}\" 2>/dev/null)\n",
      "\n",
      "    # Extract the directive integer at the very end of the output following a colon (:)\n",
      "    directive=${out##*:}\n",
      "    # Remove the directive\n",
      "    out=${out%%:*}\n",
      "    if [ \"${directive}\" = \"${out}\" ]; then\n",
      "        # There is not directive specified\n",
      "        directive=0\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: the completion directive is: ${directive}\"\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: the completions are: ${out}\"\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveError)) -ne 0 ]; then\n",
      "        # Error code.  No completion.\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: received error from custom completion go code\"\n",
      "        return\n",
      "    else\n",
      "        if [ $((directive & shellCompDirectiveNoSpace)) -ne 0 ]; then\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                __%[1]s_debug \"${FUNCNAME[0]}: activating no space\"\n",
      "                compopt -o nospace\n",
      "            fi\n",
      "        fi\n",
      "        if [ $((directive & shellCompDirectiveNoFileComp)) -ne 0 ]; then\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                __%[1]s_debug \"${FUNCNAME[0]}: activating no file completion\"\n",
      "                compopt +o default\n",
      "            fi\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveFilterFileExt)) -ne 0 ]; then\n",
      "        # File extension filtering\n",
      "        local fullFilter filter filteringCmd\n",
      "        # Do not use quotes around the $out variable or else newline\n",
      "        # characters will be kept.\n",
      "        for filter in ${out}; do\n",
      "            fullFilter+=\"$filter|\"\n",
      "        done\n",
      "\n",
      "        filteringCmd=\"_filedir $fullFilter\"\n",
      "        __%[1]s_debug \"File filtering command: $filteringCmd\"\n",
      "        $filteringCmd\n",
      "    elif [ $((directive & shellCompDirectiveFilterDirs)) -ne 0 ]; then\n",
      "        # File completion for directories only\n",
      "        local subdir\n",
      "        # Use printf to strip any trailing newline\n",
      "        subdir=$(printf \"%%s\" \"${out}\")\n",
      "        if [ -n \"$subdir\" ]; then\n",
      "            __%[1]s_debug \"Listing directories in $subdir\"\n",
      "            __%[1]s_handle_subdirs_in_dir_flag \"$subdir\"\n",
      "        else\n",
      "            __%[1]s_debug \"Listing directories in .\"\n",
      "            _filedir -d\n",
      "        fi\n",
      "    else\n",
      "        while IFS='' read -r comp; do\n",
      "            COMPREPLY+=(\"$comp\")\n",
      "        done < <(compgen -W \"${out}\" -- \"$cur\")\n",
      "    fi\n",
      "}\n",
      "\n",
      "__%[1]s_handle_reply()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}\"\n",
      "    local comp\n",
      "    case $cur in\n",
      "        -*)\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                compopt -o nospace\n",
      "            fi\n",
      "            local allflags\n",
      "            if [ ${#must_have_one_flag[@]} -ne 0 ]; then\n",
      "                allflags=(\"${must_have_one_flag[@]}\")\n",
      "            else\n",
      "                allflags=(\"${flags[*]} ${two_word_flags[*]}\")\n",
      "            fi\n",
      "            while IFS='' read -r comp; do\n",
      "                COMPREPLY+=(\"$comp\")\n",
      "            done < <(compgen -W \"${allflags[*]}\" -- \"$cur\")\n",
      "            if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                [[ \"${COMPREPLY[0]}\" == *= ]] || compopt +o nospace\n",
      "            fi\n",
      "\n",
      "            # complete after --flag=abc\n",
      "            if [[ $cur == *=* ]]; then\n",
      "                if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "                    compopt +o nospace\n",
      "                fi\n",
      "\n",
      "                local index flag\n",
      "                flag=\"${cur%%=*}\"\n",
      "                __%[1]s_index_of_word \"${flag}\" \"${flags_with_completion[@]}\"\n",
      "                COMPREPLY=()\n",
      "                if [[ ${index} -ge 0 ]]; then\n",
      "                    PREFIX=\"\"\n",
      "                    cur=\"${cur#*=}\"\n",
      "                    ${flags_completion[${index}]}\n",
      "                    if [ -n \"${ZSH_VERSION:-}\" ]; then\n",
      "                        # zsh completion needs --flag= prefix\n",
      "                        eval \"COMPREPLY=( \\\"\\${COMPREPLY[@]/#/${flag}=}\\\" )\"\n",
      "                    fi\n",
      "                fi\n",
      "            fi\n",
      "\n",
      "            if [[ -z \"${flag_parsing_disabled}\" ]]; then\n",
      "                # If flag parsing is enabled, we have completed the flags and can return.\n",
      "                # If flag parsing is disabled, we may not know all (or any) of the flags, so we fallthrough\n",
      "                # to possibly call handle_go_custom_completion.\n",
      "                return 0;\n",
      "            fi\n",
      "            ;;\n",
      "    esac\n",
      "\n",
      "    # check if we are handling a flag with special work handling\n",
      "    local index\n",
      "    __%[1]s_index_of_word \"${prev}\" \"${flags_with_completion[@]}\"\n",
      "    if [[ ${index} -ge 0 ]]; then\n",
      "        ${flags_completion[${index}]}\n",
      "        return\n",
      "    fi\n",
      "\n",
      "    # we are parsing a flag and don't have a special handler, no completion\n",
      "    if [[ ${cur} != \"${words[cword]}\" ]]; then\n",
      "        return\n",
      "    fi\n",
      "\n",
      "    local completions\n",
      "    completions=(\"${commands[@]}\")\n",
      "    if [[ ${#must_have_one_noun[@]} -ne 0 ]]; then\n",
      "        completions+=(\"${must_have_one_noun[@]}\")\n",
      "    elif [[ -n \"${has_completion_function}\" ]]; then\n",
      "        # if a go completion function is provided, defer to that function\n",
      "        __%[1]s_handle_go_custom_completion\n",
      "    fi\n",
      "    if [[ ${#must_have_one_flag[@]} -ne 0 ]]; then\n",
      "        completions+=(\"${must_have_one_flag[@]}\")\n",
      "    fi\n",
      "    while IFS='' read -r comp; do\n",
      "        COMPREPLY+=(\"$comp\")\n",
      "    done < <(compgen -W \"${completions[*]}\" -- \"$cur\")\n",
      "\n",
      "    if [[ ${#COMPREPLY[@]} -eq 0 && ${#noun_aliases[@]} -gt 0 && ${#must_have_one_noun[@]} -ne 0 ]]; then\n",
      "        while IFS='' read -r comp; do\n",
      "            COMPREPLY+=(\"$comp\")\n",
      "        done < <(compgen -W \"${noun_aliases[*]}\" -- \"$cur\")\n",
      "    fi\n",
      "\n",
      "    if [[ ${#COMPREPLY[@]} -eq 0 ]]; then\n",
      "        if declare -F __%[1]s_custom_func >/dev/null; then\n",
      "            # try command name qualified custom func\n",
      "            __%[1]s_custom_func\n",
      "        else\n",
      "            # otherwise fall back to unqualified for compatibility\n",
      "            declare -F __custom_func >/dev/null && __custom_func\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    # available in bash-completion >= 2, not always present on macOS\n",
      "    if declare -F __ltrim_colon_completions >/dev/null; then\n",
      "        __ltrim_colon_completions \"$cur\"\n",
      "    fi\n",
      "\n",
      "    # If there is only 1 completion and it is a flag with an = it will be completed\n",
      "    # but we don't want a space after the =\n",
      "    if [[ \"${#COMPREPLY[@]}\" -eq \"1\" ]] && [[ $(type -t compopt) = \"builtin\" ]] && [[ \"${COMPREPLY[0]}\" == --*= ]]; then\n",
      "       compopt -o nospace\n",
      "    fi\n",
      "}\n",
      "\n",
      "# The arguments should be in the form \"ext1|ext2|extn\"\n",
      "__%[1]s_handle_filename_extension_flag()\n",
      "{\n",
      "    local ext=\"$1\"\n",
      "    _filedir \"@(${ext})\"\n",
      "}\n",
      "\n",
      "__%[1]s_handle_subdirs_in_dir_flag()\n",
      "{\n",
      "    local dir=\"$1\"\n",
      "    pushd \"${dir}\" >/dev/null 2>&1 && _filedir -d && popd >/dev/null 2>&1 || return\n",
      "}\n",
      "\n",
      "__%[1]s_handle_flag()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    # if a command required a flag, and we found it, unset must_have_one_flag()\n",
      "    local flagname=${words[c]}\n",
      "    local flagvalue=\"\"\n",
      "    # if the word contained an =\n",
      "    if [[ ${words[c]} == *\"=\"* ]]; then\n",
      "        flagvalue=${flagname#*=} # take in as flagvalue after the =\n",
      "        flagname=${flagname%%=*} # strip everything after the =\n",
      "        flagname=\"${flagname}=\" # but put the = back\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: looking for ${flagname}\"\n",
      "    if __%[1]s_contains_word \"${flagname}\" \"${must_have_one_flag[@]}\"; then\n",
      "        must_have_one_flag=()\n",
      "    fi\n",
      "\n",
      "    # if you set a flag which only applies to this command, don't show subcommands\n",
      "    if __%[1]s_contains_word \"${flagname}\" \"${local_nonpersistent_flags[@]}\"; then\n",
      "      commands=()\n",
      "    fi\n",
      "\n",
      "    # keep flag value with flagname as flaghash\n",
      "    # flaghash variable is an associative array which is only supported in bash > 3.\n",
      "    if [[ -z \"${BASH_VERSION:-}\" || \"${BASH_VERSINFO[0]:-}\" -gt 3 ]]; then\n",
      "        if [ -n \"${flagvalue}\" ] ; then\n",
      "            flaghash[${flagname}]=${flagvalue}\n",
      "        elif [ -n \"${words[ $((c+1)) ]}\" ] ; then\n",
      "            flaghash[${flagname}]=${words[ $((c+1)) ]}\n",
      "        else\n",
      "            flaghash[${flagname}]=\"true\" # pad \"true\" for bool flag\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    # skip the argument to a two word flag\n",
      "    if [[ ${words[c]} != *\"=\"* ]] && __%[1]s_contains_word \"${words[c]}\" \"${two_word_flags[@]}\"; then\n",
      "        __%[1]s_debug \"${FUNCNAME[0]}: found a flag ${words[c]}, skip the next argument\"\n",
      "        c=$((c+1))\n",
      "        # if we are looking for a flags value, don't show commands\n",
      "        if [[ $c -eq $cword ]]; then\n",
      "            commands=()\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    c=$((c+1))\n",
      "\n",
      "}\n",
      "\n",
      "__%[1]s_handle_noun()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    if __%[1]s_contains_word \"${words[c]}\" \"${must_have_one_noun[@]}\"; then\n",
      "        must_have_one_noun=()\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${noun_aliases[@]}\"; then\n",
      "        must_have_one_noun=()\n",
      "    fi\n",
      "\n",
      "    nouns+=(\"${words[c]}\")\n",
      "    c=$((c+1))\n",
      "}\n",
      "\n",
      "__%[1]s_handle_command()\n",
      "{\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "\n",
      "    local next_command\n",
      "    if [[ -n ${last_command} ]]; then\n",
      "        next_command=\"_${last_command}_${words[c]//:/__}\"\n",
      "    else\n",
      "        if [[ $c -eq 0 ]]; then\n",
      "            next_command=\"_%[1]s_root_command\"\n",
      "        else\n",
      "            next_command=\"_${words[c]//:/__}\"\n",
      "        fi\n",
      "    fi\n",
      "    c=$((c+1))\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: looking for ${next_command}\"\n",
      "    declare -F \"$next_command\" >/dev/null && $next_command\n",
      "}\n",
      "\n",
      "__%[1]s_handle_word()\n",
      "{\n",
      "    if [[ $c -ge $cword ]]; then\n",
      "        __%[1]s_handle_reply\n",
      "        return\n",
      "    fi\n",
      "    __%[1]s_debug \"${FUNCNAME[0]}: c is $c words[c] is ${words[c]}\"\n",
      "    if [[ \"${words[c]}\" == -* ]]; then\n",
      "        __%[1]s_handle_flag\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${commands[@]}\"; then\n",
      "        __%[1]s_handle_command\n",
      "    elif [[ $c -eq 0 ]]; then\n",
      "        __%[1]s_handle_command\n",
      "    elif __%[1]s_contains_word \"${words[c]}\" \"${command_aliases[@]}\"; then\n",
      "        # aliashash variable is an associative array which is only supported in bash > 3.\n",
      "        if [[ -z \"${BASH_VERSION:-}\" || \"${BASH_VERSINFO[0]:-}\" -gt 3 ]]; then\n",
      "            words[c]=${aliashash[${words[c]}]}\n",
      "            __%[1]s_handle_command\n",
      "        else\n",
      "            __%[1]s_handle_noun\n",
      "        fi\n",
      "    else\n",
      "        __%[1]s_handle_noun\n",
      "    fi\n",
      "    __%[1]s_handle_word\n",
      "}\n",
      "\n",
      "`, name, ShellCompNoDescRequestCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, activeHelpEnvVar(name)))\n",
      "}\n",
      "func writeShortFlag(buf io.StringWriter, flag *pflag.Flag, cmd *Command) {\n",
      "\tname := flag.Shorthand\n",
      "\tformat := \"    \"\n",
      "\tif len(flag.NoOptDefVal) == 0 {\n",
      "\t\tformat += \"two_word_\"\n",
      "\t}\n",
      "\tformat += \"flags+=(\\\"-%s\" + cbn\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(format, name))\n",
      "\twriteFlagHandler(buf, \"-\"+name, flag.Annotations, cmd)\n",
      "}\n",
      "func writeLocalNonPersistentFlag(buf io.StringWriter, flag *pflag.Flag) {\n",
      "\tname := flag.Name\n",
      "\tformat := \"    local_nonpersistent_flags+=(\\\"--%[1]s\" + cbn\n",
      "\tif len(flag.NoOptDefVal) == 0 {\n",
      "\t\tformat += \"    local_nonpersistent_flags+=(\\\"--%[1]s=\" + cbn\n",
      "\t}\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(format, name))\n",
      "\tif len(flag.Shorthand) > 0 {\n",
      "\t\tWriteStringAndCheck(buf, fmt.Sprintf(\"    local_nonpersistent_flags+=(\\\"-%s\\\")\\n\", flag.Shorthand))\n",
      "\t}\n",
      "}\n",
      "func (c *Command) GetFlagCompletionFunc(flagName string) (func(*Command, []string, string) ([]string, ShellCompDirective), bool) {\n",
      "\tflag := c.Flag(flagName)\n",
      "\tif flag == nil {\n",
      "\t\treturn nil, false\n",
      "\t}\n",
      "\tflagCompletionMutex.RLock()\n",
      "\tdefer flagCompletionMutex.RUnlock()\n",
      "\tcompletionFunc, exists := flagCompletionFunctions[flag]\n",
      "\treturn completionFunc, exists\n",
      "}\n",
      "func (c *Command) MarkFlagsRequiredTogether(flagNames ...string) {\n",
      "\tc.mergePersistentFlags()\n",
      "\tfor _, v := range flagNames {\n",
      "\t\tf := c.Flags().Lookup(v)\n",
      "\t\tif f == nil {\n",
      "\t\t\tpanic(fmt.Sprintf(\"Failed to find flag %q and mark it as being required in a flag group\", v))\n",
      "\t\t}\n",
      "\t\tif err := c.Flags().SetAnnotation(v, requiredAsGroup, append(f.Annotations[requiredAsGroup], strings.Join(flagNames, \" \"))); err != nil {\n",
      "\t\t\tpanic(err)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (c *Command) getCompletions(args []string) (*Command, []string, ShellCompDirective, error) {\n",
      "\ttoComplete := args[len(args)-1]\n",
      "\ttrimmedArgs := args[:len(args)-1]\n",
      "\tvar finalCmd *Command\n",
      "\tvar finalArgs []string\n",
      "\tvar err error\n",
      "\tif c.Root().TraverseChildren {\n",
      "\t\tfinalCmd, finalArgs, err = c.Root().Traverse(trimmedArgs)\n",
      "\t} else {\n",
      "\t\trootCmd := c.Root()\n",
      "\t\tif len(rootCmd.Commands()) == 1 {\n",
      "\t\t\trootCmd.RemoveCommand(c)\n",
      "\t\t}\n",
      "\t\tfinalCmd, finalArgs, err = rootCmd.Find(trimmedArgs)\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\treturn c, []string{}, ShellCompDirectiveDefault, fmt.Errorf(\"Unable to find a command for arguments: %v\", trimmedArgs)\n",
      "\t}\n",
      "\tfinalCmd.ctx = c.ctx\n",
      "\tif !finalCmd.DisableFlagParsing {\n",
      "\t\tfinalCmd.InitDefaultHelpFlag()\n",
      "\t\tfinalCmd.InitDefaultVersionFlag()\n",
      "\t}\n",
      "\tflag, finalArgs, toComplete, flagErr := checkIfFlagCompletion(finalCmd, finalArgs, toComplete)\n",
      "\tflagCompletion := true\n",
      "\t_ = finalCmd.ParseFlags(append(finalArgs, \"--\"))\n",
      "\tnewArgCount := finalCmd.Flags().NArg()\n",
      "\tif err = finalCmd.ParseFlags(finalArgs); err != nil {\n",
      "\t\treturn finalCmd, []string{}, ShellCompDirectiveDefault, fmt.Errorf(\"Error while parsing flags from args %v: %s\", finalArgs, err.Error())\n",
      "\t}\n",
      "\trealArgCount := finalCmd.Flags().NArg()\n",
      "\tif newArgCount > realArgCount {\n",
      "\t\tflagCompletion = false\n",
      "\t}\n",
      "\tif flagErr != nil {\n",
      "\t\tif _, ok := flagErr.(*flagCompError); !(ok && !flagCompletion) {\n",
      "\t\t\treturn finalCmd, []string{}, ShellCompDirectiveDefault, flagErr\n",
      "\t\t}\n",
      "\t}\n",
      "\tif helpOrVersionFlagPresent(finalCmd) {\n",
      "\t\treturn finalCmd, []string{}, ShellCompDirectiveNoFileComp, nil\n",
      "\t}\n",
      "\tif !finalCmd.DisableFlagParsing {\n",
      "\t\tfinalArgs = finalCmd.Flags().Args()\n",
      "\t}\n",
      "\tif flag != nil && flagCompletion {\n",
      "\t\tif validExts, present := flag.Annotations[BashCompFilenameExt]; present {\n",
      "\t\t\tif len(validExts) != 0 {\n",
      "\t\t\t\treturn finalCmd, validExts, ShellCompDirectiveFilterFileExt, nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif subDir, present := flag.Annotations[BashCompSubdirsInDir]; present {\n",
      "\t\t\tif len(subDir) == 1 {\n",
      "\t\t\t\treturn finalCmd, subDir, ShellCompDirectiveFilterDirs, nil\n",
      "\t\t\t}\n",
      "\t\t\treturn finalCmd, []string{}, ShellCompDirectiveFilterDirs, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar completions []string\n",
      "\tvar directive ShellCompDirective\n",
      "\tfinalCmd.enforceFlagGroupsForCompletion()\n",
      "\tif flag == nil && len(toComplete) > 0 && toComplete[0] == '-' && !strings.Contains(toComplete, \"=\") && flagCompletion {\n",
      "\t\tcompletions = completeRequireFlags(finalCmd, toComplete)\n",
      "\t\tif len(completions) == 0 {\n",
      "\t\t\tdoCompleteFlags := func(flag *pflag.Flag) {\n",
      "\t\t\t\tif !flag.Changed || strings.Contains(flag.Value.Type(), \"Slice\") || strings.Contains(flag.Value.Type(), \"Array\") {\n",
      "\t\t\t\t\tcompletions = append(completions, getFlagNameCompletions(flag, toComplete)...)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tfinalCmd.InheritedFlags().VisitAll(func(flag *pflag.Flag) {\n",
      "\t\t\t\tdoCompleteFlags(flag)\n",
      "\t\t\t})\n",
      "\t\t\tfinalCmd.NonInheritedFlags().VisitAll(func(flag *pflag.Flag) {\n",
      "\t\t\t\tdoCompleteFlags(flag)\n",
      "\t\t\t})\n",
      "\t\t}\n",
      "\t\tdirective = ShellCompDirectiveNoFileComp\n",
      "\t\tif len(completions) == 1 && strings.HasSuffix(completions[0], \"=\") {\n",
      "\t\t\tdirective = ShellCompDirectiveNoSpace\n",
      "\t\t}\n",
      "\t\tif !finalCmd.DisableFlagParsing {\n",
      "\t\t\treturn finalCmd, completions, directive, nil\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tdirective = ShellCompDirectiveDefault\n",
      "\t\tif flag == nil {\n",
      "\t\t\tfoundLocalNonPersistentFlag := false\n",
      "\t\t\tif !finalCmd.Root().TraverseChildren {\n",
      "\t\t\t\tlocalNonPersistentFlags := finalCmd.LocalNonPersistentFlags()\n",
      "\t\t\t\tfinalCmd.NonInheritedFlags().VisitAll(func(flag *pflag.Flag) {\n",
      "\t\t\t\t\tif localNonPersistentFlags.Lookup(flag.Name) != nil && flag.Changed {\n",
      "\t\t\t\t\t\tfoundLocalNonPersistentFlag = true\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t})\n",
      "\t\t\t}\n",
      "\t\t\tif len(finalArgs) == 0 && !foundLocalNonPersistentFlag {\n",
      "\t\t\t\tfor _, subCmd := range finalCmd.Commands() {\n",
      "\t\t\t\t\tif subCmd.IsAvailableCommand() || subCmd == finalCmd.helpCommand {\n",
      "\t\t\t\t\t\tif strings.HasPrefix(subCmd.Name(), toComplete) {\n",
      "\t\t\t\t\t\t\tcompletions = append(completions, fmt.Sprintf(\"%s\\t%s\", subCmd.Name(), subCmd.Short))\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tdirective = ShellCompDirectiveNoFileComp\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tcompletions = append(completions, completeRequireFlags(finalCmd, toComplete)...)\n",
      "\t\t\tif len(finalCmd.ValidArgs) > 0 {\n",
      "\t\t\t\tif len(finalArgs) == 0 {\n",
      "\t\t\t\t\tfor _, validArg := range finalCmd.ValidArgs {\n",
      "\t\t\t\t\t\tif strings.HasPrefix(validArg, toComplete) {\n",
      "\t\t\t\t\t\t\tcompletions = append(completions, validArg)\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tdirective = ShellCompDirectiveNoFileComp\n",
      "\t\t\t\t\tif len(completions) == 0 {\n",
      "\t\t\t\t\t\tfor _, argAlias := range finalCmd.ArgAliases {\n",
      "\t\t\t\t\t\t\tif strings.HasPrefix(argAlias, toComplete) {\n",
      "\t\t\t\t\t\t\t\tcompletions = append(completions, argAlias)\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\treturn finalCmd, completions, directive, nil\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar completionFn func(cmd *Command, args []string, toComplete string) ([]string, ShellCompDirective)\n",
      "\tif flag != nil && flagCompletion {\n",
      "\t\tflagCompletionMutex.RLock()\n",
      "\t\tcompletionFn = flagCompletionFunctions[flag]\n",
      "\t\tflagCompletionMutex.RUnlock()\n",
      "\t} else {\n",
      "\t\tcompletionFn = finalCmd.ValidArgsFunction\n",
      "\t}\n",
      "\tif completionFn != nil {\n",
      "\t\tvar comps []string\n",
      "\t\tcomps, directive = completionFn(finalCmd, finalArgs, toComplete)\n",
      "\t\tcompletions = append(completions, comps...)\n",
      "\t}\n",
      "\treturn finalCmd, completions, directive, nil\n",
      "}\n",
      "func genBashComp(buf io.StringWriter, name string, includeDesc bool) {\n",
      "\tcompCmd := ShellCompRequestCmd\n",
      "\tif !includeDesc {\n",
      "\t\tcompCmd = ShellCompNoDescRequestCmd\n",
      "\t}\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(`# bash completion V2 for %-36[1]s -*- shell-script -*-\n",
      "\n",
      "__%[1]s_debug()\n",
      "{\n",
      "    if [[ -n ${BASH_COMP_DEBUG_FILE-} ]]; then\n",
      "        echo \"$*\" >> \"${BASH_COMP_DEBUG_FILE}\"\n",
      "    fi\n",
      "}\n",
      "\n",
      "# Macs have bash3 for which the bash-completion package doesn't include\n",
      "# _init_completion. This is a minimal version of that function.\n",
      "__%[1]s_init_completion()\n",
      "{\n",
      "    COMPREPLY=()\n",
      "    _get_comp_words_by_ref \"$@\" cur prev words cword\n",
      "}\n",
      "\n",
      "# This function calls the %[1]s program to obtain the completion\n",
      "# results and the directive.  It fills the 'out' and 'directive' vars.\n",
      "__%[1]s_get_completion_results() {\n",
      "    local requestComp lastParam lastChar args\n",
      "\n",
      "    # Prepare the command to request completions for the program.\n",
      "    # Calling ${words[0]} instead of directly %[1]s allows handling aliases\n",
      "    args=(\"${words[@]:1}\")\n",
      "    requestComp=\"${words[0]} %[2]s ${args[*]}\"\n",
      "\n",
      "    lastParam=${words[$((${#words[@]}-1))]}\n",
      "    lastChar=${lastParam:$((${#lastParam}-1)):1}\n",
      "    __%[1]s_debug \"lastParam ${lastParam}, lastChar ${lastChar}\"\n",
      "\n",
      "    if [[ -z ${cur} && ${lastChar} != = ]]; then\n",
      "        # If the last parameter is complete (there is a space following it)\n",
      "        # We add an extra empty parameter so we can indicate this to the go method.\n",
      "        __%[1]s_debug \"Adding extra empty parameter\"\n",
      "        requestComp=\"${requestComp} ''\"\n",
      "    fi\n",
      "\n",
      "    # When completing a flag with an = (e.g., %[1]s -n=<TAB>)\n",
      "    # bash focuses on the part after the =, so we need to remove\n",
      "    # the flag part from $cur\n",
      "    if [[ ${cur} == -*=* ]]; then\n",
      "        cur=\"${cur#*=}\"\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug \"Calling ${requestComp}\"\n",
      "    # Use eval to handle any environment variables and such\n",
      "    out=$(eval \"${requestComp}\" 2>/dev/null)\n",
      "\n",
      "    # Extract the directive integer at the very end of the output following a colon (:)\n",
      "    directive=${out##*:}\n",
      "    # Remove the directive\n",
      "    out=${out%%:*}\n",
      "    if [[ ${directive} == \"${out}\" ]]; then\n",
      "        # There is not directive specified\n",
      "        directive=0\n",
      "    fi\n",
      "    __%[1]s_debug \"The completion directive is: ${directive}\"\n",
      "    __%[1]s_debug \"The completions are: ${out}\"\n",
      "}\n",
      "\n",
      "__%[1]s_process_completion_results() {\n",
      "    local shellCompDirectiveError=%[3]d\n",
      "    local shellCompDirectiveNoSpace=%[4]d\n",
      "    local shellCompDirectiveNoFileComp=%[5]d\n",
      "    local shellCompDirectiveFilterFileExt=%[6]d\n",
      "    local shellCompDirectiveFilterDirs=%[7]d\n",
      "    local shellCompDirectiveKeepOrder=%[8]d\n",
      "\n",
      "    if (((directive & shellCompDirectiveError) != 0)); then\n",
      "        # Error code.  No completion.\n",
      "        __%[1]s_debug \"Received error from custom completion go code\"\n",
      "        return\n",
      "    else\n",
      "        if (((directive & shellCompDirectiveNoSpace) != 0)); then\n",
      "            if [[ $(type -t compopt) == builtin ]]; then\n",
      "                __%[1]s_debug \"Activating no space\"\n",
      "                compopt -o nospace\n",
      "            else\n",
      "                __%[1]s_debug \"No space directive not supported in this version of bash\"\n",
      "            fi\n",
      "        fi\n",
      "        if (((directive & shellCompDirectiveKeepOrder) != 0)); then\n",
      "            if [[ $(type -t compopt) == builtin ]]; then\n",
      "                # no sort isn't supported for bash less than < 4.4\n",
      "                if [[ ${BASH_VERSINFO[0]} -lt 4 || ( ${BASH_VERSINFO[0]} -eq 4 && ${BASH_VERSINFO[1]} -lt 4 ) ]]; then\n",
      "                    __%[1]s_debug \"No sort directive not supported in this version of bash\"\n",
      "                else\n",
      "                    __%[1]s_debug \"Activating keep order\"\n",
      "                    compopt -o nosort\n",
      "                fi\n",
      "            else\n",
      "                __%[1]s_debug \"No sort directive not supported in this version of bash\"\n",
      "            fi\n",
      "        fi\n",
      "        if (((directive & shellCompDirectiveNoFileComp) != 0)); then\n",
      "            if [[ $(type -t compopt) == builtin ]]; then\n",
      "                __%[1]s_debug \"Activating no file completion\"\n",
      "                compopt +o default\n",
      "            else\n",
      "                __%[1]s_debug \"No file completion directive not supported in this version of bash\"\n",
      "            fi\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    # Separate activeHelp from normal completions\n",
      "    local completions=()\n",
      "    local activeHelp=()\n",
      "    __%[1]s_extract_activeHelp\n",
      "\n",
      "    if (((directive & shellCompDirectiveFilterFileExt) != 0)); then\n",
      "        # File extension filtering\n",
      "        local fullFilter filter filteringCmd\n",
      "\n",
      "        # Do not use quotes around the $completions variable or else newline\n",
      "        # characters will be kept.\n",
      "        for filter in ${completions[*]}; do\n",
      "            fullFilter+=\"$filter|\"\n",
      "        done\n",
      "\n",
      "        filteringCmd=\"_filedir $fullFilter\"\n",
      "        __%[1]s_debug \"File filtering command: $filteringCmd\"\n",
      "        $filteringCmd\n",
      "    elif (((directive & shellCompDirectiveFilterDirs) != 0)); then\n",
      "        # File completion for directories only\n",
      "\n",
      "        local subdir\n",
      "        subdir=${completions[0]}\n",
      "        if [[ -n $subdir ]]; then\n",
      "            __%[1]s_debug \"Listing directories in $subdir\"\n",
      "            pushd \"$subdir\" >/dev/null 2>&1 && _filedir -d && popd >/dev/null 2>&1 || return\n",
      "        else\n",
      "            __%[1]s_debug \"Listing directories in .\"\n",
      "            _filedir -d\n",
      "        fi\n",
      "    else\n",
      "        __%[1]s_handle_completion_types\n",
      "    fi\n",
      "\n",
      "    __%[1]s_handle_special_char \"$cur\" :\n",
      "    __%[1]s_handle_special_char \"$cur\" =\n",
      "\n",
      "    # Print the activeHelp statements before we finish\n",
      "    if ((${#activeHelp[*]} != 0)); then\n",
      "        printf \"\\n\";\n",
      "        printf \"%%s\\n\" \"${activeHelp[@]}\"\n",
      "        printf \"\\n\"\n",
      "\n",
      "        # The prompt format is only available from bash 4.4.\n",
      "        # We test if it is available before using it.\n",
      "        if (x=${PS1@P}) 2> /dev/null; then\n",
      "            printf \"%%s\" \"${PS1@P}${COMP_LINE[@]}\"\n",
      "        else\n",
      "            # Can't print the prompt.  Just print the\n",
      "            # text the user had typed, it is workable enough.\n",
      "            printf \"%%s\" \"${COMP_LINE[@]}\"\n",
      "        fi\n",
      "    fi\n",
      "}\n",
      "\n",
      "# Separate activeHelp lines from real completions.\n",
      "# Fills the $activeHelp and $completions arrays.\n",
      "__%[1]s_extract_activeHelp() {\n",
      "    local activeHelpMarker=\"%[9]s\"\n",
      "    local endIndex=${#activeHelpMarker}\n",
      "\n",
      "    while IFS='' read -r comp; do\n",
      "        if [[ ${comp:0:endIndex} == $activeHelpMarker ]]; then\n",
      "            comp=${comp:endIndex}\n",
      "            __%[1]s_debug \"ActiveHelp found: $comp\"\n",
      "            if [[ -n $comp ]]; then\n",
      "                activeHelp+=(\"$comp\")\n",
      "            fi\n",
      "        else\n",
      "            # Not an activeHelp line but a normal completion\n",
      "            completions+=(\"$comp\")\n",
      "        fi\n",
      "    done <<<\"${out}\"\n",
      "}\n",
      "\n",
      "__%[1]s_handle_completion_types() {\n",
      "    __%[1]s_debug \"__%[1]s_handle_completion_types: COMP_TYPE is $COMP_TYPE\"\n",
      "\n",
      "    case $COMP_TYPE in\n",
      "    37|42)\n",
      "        # Type: menu-complete/menu-complete-backward and insert-completions\n",
      "        # If the user requested inserting one completion at a time, or all\n",
      "        # completions at once on the command-line we must remove the descriptions.\n",
      "        # https://github.com/spf13/cobra/issues/1508\n",
      "        local tab=$'\\t' comp\n",
      "        while IFS='' read -r comp; do\n",
      "            [[ -z $comp ]] && continue\n",
      "            # Strip any description\n",
      "            comp=${comp%%%%$tab*}\n",
      "            # Only consider the completions that match\n",
      "            if [[ $comp == \"$cur\"* ]]; then\n",
      "                COMPREPLY+=(\"$comp\")\n",
      "            fi\n",
      "        done < <(printf \"%%s\\n\" \"${completions[@]}\")\n",
      "        ;;\n",
      "\n",
      "    *)\n",
      "        # Type: complete (normal completion)\n",
      "        __%[1]s_handle_standard_completion_case\n",
      "        ;;\n",
      "    esac\n",
      "}\n",
      "\n",
      "__%[1]s_handle_standard_completion_case() {\n",
      "    local tab=$'\\t' comp\n",
      "\n",
      "    # Short circuit to optimize if we don't have descriptions\n",
      "    if [[ \"${completions[*]}\" != *$tab* ]]; then\n",
      "        IFS=$'\\n' read -ra COMPREPLY -d '' < <(compgen -W \"${completions[*]}\" -- \"$cur\")\n",
      "        return 0\n",
      "    fi\n",
      "\n",
      "    local longest=0\n",
      "    local compline\n",
      "    # Look for the longest completion so that we can format things nicely\n",
      "    while IFS='' read -r compline; do\n",
      "        [[ -z $compline ]] && continue\n",
      "        # Strip any description before checking the length\n",
      "        comp=${compline%%%%$tab*}\n",
      "        # Only consider the completions that match\n",
      "        [[ $comp == \"$cur\"* ]] || continue\n",
      "        COMPREPLY+=(\"$compline\")\n",
      "        if ((${#comp}>longest)); then\n",
      "            longest=${#comp}\n",
      "        fi\n",
      "    done < <(printf \"%%s\\n\" \"${completions[@]}\")\n",
      "\n",
      "    # If there is a single completion left, remove the description text\n",
      "    if ((${#COMPREPLY[*]} == 1)); then\n",
      "        __%[1]s_debug \"COMPREPLY[0]: ${COMPREPLY[0]}\"\n",
      "        comp=\"${COMPREPLY[0]%%%%$tab*}\"\n",
      "        __%[1]s_debug \"Removed description from single completion, which is now: ${comp}\"\n",
      "        COMPREPLY[0]=$comp\n",
      "    else # Format the descriptions\n",
      "        __%[1]s_format_comp_descriptions $longest\n",
      "    fi\n",
      "}\n",
      "\n",
      "__%[1]s_handle_special_char()\n",
      "{\n",
      "    local comp=\"$1\"\n",
      "    local char=$2\n",
      "    if [[ \"$comp\" == *${char}* && \"$COMP_WORDBREAKS\" == *${char}* ]]; then\n",
      "        local word=${comp%%\"${comp##*${char}}\"}\n",
      "        local idx=${#COMPREPLY[*]}\n",
      "        while ((--idx >= 0)); do\n",
      "            COMPREPLY[idx]=${COMPREPLY[idx]#\"$word\"}\n",
      "        done\n",
      "    fi\n",
      "}\n",
      "\n",
      "__%[1]s_format_comp_descriptions()\n",
      "{\n",
      "    local tab=$'\\t'\n",
      "    local comp desc maxdesclength\n",
      "    local longest=$1\n",
      "\n",
      "    local i ci\n",
      "    for ci in ${!COMPREPLY[*]}; do\n",
      "        comp=${COMPREPLY[ci]}\n",
      "        # Properly format the description string which follows a tab character if there is one\n",
      "        if [[ \"$comp\" == *$tab* ]]; then\n",
      "            __%[1]s_debug \"Original comp: $comp\"\n",
      "            desc=${comp#*$tab}\n",
      "            comp=${comp%%%%$tab*}\n",
      "\n",
      "            # $COLUMNS stores the current shell width.\n",
      "            # Remove an extra 4 because we add 2 spaces and 2 parentheses.\n",
      "            maxdesclength=$(( COLUMNS - longest - 4 ))\n",
      "\n",
      "            # Make sure we can fit a description of at least 8 characters\n",
      "            # if we are to align the descriptions.\n",
      "            if ((maxdesclength > 8)); then\n",
      "                # Add the proper number of spaces to align the descriptions\n",
      "                for ((i = ${#comp} ; i < longest ; i++)); do\n",
      "                    comp+=\" \"\n",
      "                done\n",
      "            else\n",
      "                # Don't pad the descriptions so we can fit more text after the completion\n",
      "                maxdesclength=$(( COLUMNS - ${#comp} - 4 ))\n",
      "            fi\n",
      "\n",
      "            # If there is enough space for any description text,\n",
      "            # truncate the descriptions that are too long for the shell width\n",
      "            if ((maxdesclength > 0)); then\n",
      "                if ((${#desc} > maxdesclength)); then\n",
      "                    desc=${desc:0:$(( maxdesclength - 1 ))}\n",
      "                    desc+=\"\"\n",
      "                fi\n",
      "                comp+=\"  ($desc)\"\n",
      "            fi\n",
      "            COMPREPLY[ci]=$comp\n",
      "            __%[1]s_debug \"Final comp: $comp\"\n",
      "        fi\n",
      "    done\n",
      "}\n",
      "\n",
      "__start_%[1]s()\n",
      "{\n",
      "    local cur prev words cword split\n",
      "\n",
      "    COMPREPLY=()\n",
      "\n",
      "    # Call _init_completion from the bash-completion package\n",
      "    # to prepare the arguments properly\n",
      "    if declare -F _init_completion >/dev/null 2>&1; then\n",
      "        _init_completion -n =: || return\n",
      "    else\n",
      "        __%[1]s_init_completion -n =: || return\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug\n",
      "    __%[1]s_debug \"========= starting completion logic ==========\"\n",
      "    __%[1]s_debug \"cur is ${cur}, words[*] is ${words[*]}, #words[@] is ${#words[@]}, cword is $cword\"\n",
      "\n",
      "    # The user could have moved the cursor backwards on the command-line.\n",
      "    # We need to trigger completion from the $cword location, so we need\n",
      "    # to truncate the command-line ($words) up to the $cword location.\n",
      "    words=(\"${words[@]:0:$cword+1}\")\n",
      "    __%[1]s_debug \"Truncated words[*]: ${words[*]},\"\n",
      "\n",
      "    local out directive\n",
      "    __%[1]s_get_completion_results\n",
      "    __%[1]s_process_completion_results\n",
      "}\n",
      "\n",
      "if [[ $(type -t compopt) = \"builtin\" ]]; then\n",
      "    complete -o default -F __start_%[1]s %[1]s\n",
      "else\n",
      "    complete -o default -o nospace -F __start_%[1]s %[1]s\n",
      "fi\n",
      "\n",
      "# ex: ts=4 sw=4 et filetype=sh\n",
      "`, name, compCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, ShellCompDirectiveKeepOrder, activeHelpMarker))\n",
      "}\n",
      "func (c *Command) MarkFlagsMutuallyExclusive(flagNames ...string) {\n",
      "\tc.mergePersistentFlags()\n",
      "\tfor _, v := range flagNames {\n",
      "\t\tf := c.Flags().Lookup(v)\n",
      "\t\tif f == nil {\n",
      "\t\t\tpanic(fmt.Sprintf(\"Failed to find flag %q and mark it as being in a mutually exclusive flag group\", v))\n",
      "\t\t}\n",
      "\t\tif err := c.Flags().SetAnnotation(v, mutuallyExclusive, append(f.Annotations[mutuallyExclusive], strings.Join(flagNames, \" \"))); err != nil {\n",
      "\t\t\tpanic(err)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func (c *Command) Flag(name string) (flag *flag.Flag) {\n",
      "\tflag = c.Flags().Lookup(name)\n",
      "\tif flag == nil {\n",
      "\t\tflag = c.persistentFlag(name)\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func prepareCustomAnnotationsForFlags(cmd *Command) {\n",
      "\tflagCompletionMutex.RLock()\n",
      "\tdefer flagCompletionMutex.RUnlock()\n",
      "\tfor flag := range flagCompletionFunctions {\n",
      "\t\tif flag.Annotations == nil {\n",
      "\t\t\tflag.Annotations = map[string][]string{}\n",
      "\t\t}\n",
      "\t\tflag.Annotations[BashCompCustom] = []string{fmt.Sprintf(\"__%[1]s_handle_go_custom_completion\", cmd.Root().Name())}\n",
      "\t}\n",
      "}\n",
      "func (c *Command) enforceFlagGroupsForCompletion() {\n",
      "\tif c.DisableFlagParsing {\n",
      "\t\treturn\n",
      "\t}\n",
      "\tflags := c.Flags()\n",
      "\tgroupStatus := map[string]map[string]bool{}\n",
      "\toneRequiredGroupStatus := map[string]map[string]bool{}\n",
      "\tmutuallyExclusiveGroupStatus := map[string]map[string]bool{}\n",
      "\tc.Flags().VisitAll(func(pflag *flag.Flag) {\n",
      "\t\tprocessFlagForGroupAnnotation(flags, pflag, requiredAsGroup, groupStatus)\n",
      "\t\tprocessFlagForGroupAnnotation(flags, pflag, oneRequired, oneRequiredGroupStatus)\n",
      "\t\tprocessFlagForGroupAnnotation(flags, pflag, mutuallyExclusive, mutuallyExclusiveGroupStatus)\n",
      "\t})\n",
      "\tfor flagList, flagnameAndStatus := range groupStatus {\n",
      "\t\tfor _, isSet := range flagnameAndStatus {\n",
      "\t\t\tif isSet {\n",
      "\t\t\t\tfor _, fName := range strings.Split(flagList, \" \") {\n",
      "\t\t\t\t\t_ = c.MarkFlagRequired(fName)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor flagList, flagnameAndStatus := range oneRequiredGroupStatus {\n",
      "\t\tisSet := false\n",
      "\t\tfor _, isSet = range flagnameAndStatus {\n",
      "\t\t\tif isSet {\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !isSet {\n",
      "\t\t\tfor _, fName := range strings.Split(flagList, \" \") {\n",
      "\t\t\t\t_ = c.MarkFlagRequired(fName)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor flagList, flagnameAndStatus := range mutuallyExclusiveGroupStatus {\n",
      "\t\tfor flagName, isSet := range flagnameAndStatus {\n",
      "\t\t\tif isSet {\n",
      "\t\t\t\tfor _, fName := range strings.Split(flagList, \" \") {\n",
      "\t\t\t\t\tif fName != flagName {\n",
      "\t\t\t\t\t\tflag := c.Flags().Lookup(fName)\n",
      "\t\t\t\t\t\tflag.Hidden = true\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func genZshComp(buf io.StringWriter, name string, includeDesc bool) {\n",
      "\tcompCmd := ShellCompRequestCmd\n",
      "\tif !includeDesc {\n",
      "\t\tcompCmd = ShellCompNoDescRequestCmd\n",
      "\t}\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(`#compdef %[1]s\n",
      "compdef _%[1]s %[1]s\n",
      "\n",
      "# zsh completion for %-36[1]s -*- shell-script -*-\n",
      "\n",
      "__%[1]s_debug()\n",
      "{\n",
      "    local file=\"$BASH_COMP_DEBUG_FILE\"\n",
      "    if [[ -n ${file} ]]; then\n",
      "        echo \"$*\" >> \"${file}\"\n",
      "    fi\n",
      "}\n",
      "\n",
      "_%[1]s()\n",
      "{\n",
      "    local shellCompDirectiveError=%[3]d\n",
      "    local shellCompDirectiveNoSpace=%[4]d\n",
      "    local shellCompDirectiveNoFileComp=%[5]d\n",
      "    local shellCompDirectiveFilterFileExt=%[6]d\n",
      "    local shellCompDirectiveFilterDirs=%[7]d\n",
      "    local shellCompDirectiveKeepOrder=%[8]d\n",
      "\n",
      "    local lastParam lastChar flagPrefix requestComp out directive comp lastComp noSpace keepOrder\n",
      "    local -a completions\n",
      "\n",
      "    __%[1]s_debug \"\\n========= starting completion logic ==========\"\n",
      "    __%[1]s_debug \"CURRENT: ${CURRENT}, words[*]: ${words[*]}\"\n",
      "\n",
      "    # The user could have moved the cursor backwards on the command-line.\n",
      "    # We need to trigger completion from the $CURRENT location, so we need\n",
      "    # to truncate the command-line ($words) up to the $CURRENT location.\n",
      "    # (We cannot use $CURSOR as its value does not work when a command is an alias.)\n",
      "    words=(\"${=words[1,CURRENT]}\")\n",
      "    __%[1]s_debug \"Truncated words[*]: ${words[*]},\"\n",
      "\n",
      "    lastParam=${words[-1]}\n",
      "    lastChar=${lastParam[-1]}\n",
      "    __%[1]s_debug \"lastParam: ${lastParam}, lastChar: ${lastChar}\"\n",
      "\n",
      "    # For zsh, when completing a flag with an = (e.g., %[1]s -n=<TAB>)\n",
      "    # completions must be prefixed with the flag\n",
      "    setopt local_options BASH_REMATCH\n",
      "    if [[ \"${lastParam}\" =~ '-.*=' ]]; then\n",
      "        # We are dealing with a flag with an =\n",
      "        flagPrefix=\"-P ${BASH_REMATCH}\"\n",
      "    fi\n",
      "\n",
      "    # Prepare the command to obtain completions\n",
      "    requestComp=\"${words[1]} %[2]s ${words[2,-1]}\"\n",
      "    if [ \"${lastChar}\" = \"\" ]; then\n",
      "        # If the last parameter is complete (there is a space following it)\n",
      "        # We add an extra empty parameter so we can indicate this to the go completion code.\n",
      "        __%[1]s_debug \"Adding extra empty parameter\"\n",
      "        requestComp=\"${requestComp} \\\"\\\"\"\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug \"About to call: eval ${requestComp}\"\n",
      "\n",
      "    # Use eval to handle any environment variables and such\n",
      "    out=$(eval ${requestComp} 2>/dev/null)\n",
      "    __%[1]s_debug \"completion output: ${out}\"\n",
      "\n",
      "    # Extract the directive integer following a : from the last line\n",
      "    local lastLine\n",
      "    while IFS='\\n' read -r line; do\n",
      "        lastLine=${line}\n",
      "    done < <(printf \"%%s\\n\" \"${out[@]}\")\n",
      "    __%[1]s_debug \"last line: ${lastLine}\"\n",
      "\n",
      "    if [ \"${lastLine[1]}\" = : ]; then\n",
      "        directive=${lastLine[2,-1]}\n",
      "        # Remove the directive including the : and the newline\n",
      "        local suffix\n",
      "        (( suffix=${#lastLine}+2))\n",
      "        out=${out[1,-$suffix]}\n",
      "    else\n",
      "        # There is no directive specified.  Leave $out as is.\n",
      "        __%[1]s_debug \"No directive found.  Setting do default\"\n",
      "        directive=0\n",
      "    fi\n",
      "\n",
      "    __%[1]s_debug \"directive: ${directive}\"\n",
      "    __%[1]s_debug \"completions: ${out}\"\n",
      "    __%[1]s_debug \"flagPrefix: ${flagPrefix}\"\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveError)) -ne 0 ]; then\n",
      "        __%[1]s_debug \"Completion received error. Ignoring completions.\"\n",
      "        return\n",
      "    fi\n",
      "\n",
      "    local activeHelpMarker=\"%[9]s\"\n",
      "    local endIndex=${#activeHelpMarker}\n",
      "    local startIndex=$((${#activeHelpMarker}+1))\n",
      "    local hasActiveHelp=0\n",
      "    while IFS='\\n' read -r comp; do\n",
      "        # Check if this is an activeHelp statement (i.e., prefixed with $activeHelpMarker)\n",
      "        if [ \"${comp[1,$endIndex]}\" = \"$activeHelpMarker\" ];then\n",
      "            __%[1]s_debug \"ActiveHelp found: $comp\"\n",
      "            comp=\"${comp[$startIndex,-1]}\"\n",
      "            if [ -n \"$comp\" ]; then\n",
      "                compadd -x \"${comp}\"\n",
      "                __%[1]s_debug \"ActiveHelp will need delimiter\"\n",
      "                hasActiveHelp=1\n",
      "            fi\n",
      "\n",
      "            continue\n",
      "        fi\n",
      "\n",
      "        if [ -n \"$comp\" ]; then\n",
      "            # If requested, completions are returned with a description.\n",
      "            # The description is preceded by a TAB character.\n",
      "            # For zsh's _describe, we need to use a : instead of a TAB.\n",
      "            # We first need to escape any : as part of the completion itself.\n",
      "            comp=${comp//:/\\\\:}\n",
      "\n",
      "            local tab=\"$(printf '\\t')\"\n",
      "            comp=${comp//$tab/:}\n",
      "\n",
      "            __%[1]s_debug \"Adding completion: ${comp}\"\n",
      "            completions+=${comp}\n",
      "            lastComp=$comp\n",
      "        fi\n",
      "    done < <(printf \"%%s\\n\" \"${out[@]}\")\n",
      "\n",
      "    # Add a delimiter after the activeHelp statements, but only if:\n",
      "    # - there are completions following the activeHelp statements, or\n",
      "    # - file completion will be performed (so there will be choices after the activeHelp)\n",
      "    if [ $hasActiveHelp -eq 1 ]; then\n",
      "        if [ ${#completions} -ne 0 ] || [ $((directive & shellCompDirectiveNoFileComp)) -eq 0 ]; then\n",
      "            __%[1]s_debug \"Adding activeHelp delimiter\"\n",
      "            compadd -x \"--\"\n",
      "            hasActiveHelp=0\n",
      "        fi\n",
      "    fi\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveNoSpace)) -ne 0 ]; then\n",
      "        __%[1]s_debug \"Activating nospace.\"\n",
      "        noSpace=\"-S ''\"\n",
      "    fi\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveKeepOrder)) -ne 0 ]; then\n",
      "        __%[1]s_debug \"Activating keep order.\"\n",
      "        keepOrder=\"-V\"\n",
      "    fi\n",
      "\n",
      "    if [ $((directive & shellCompDirectiveFilterFileExt)) -ne 0 ]; then\n",
      "        # File extension filtering\n",
      "        local filteringCmd\n",
      "        filteringCmd='_files'\n",
      "        for filter in ${completions[@]}; do\n",
      "            if [ ${filter[1]} != '*' ]; then\n",
      "                # zsh requires a glob pattern to do file filtering\n",
      "                filter=\"\\*.$filter\"\n",
      "            fi\n",
      "            filteringCmd+=\" -g $filter\"\n",
      "        done\n",
      "        filteringCmd+=\" ${flagPrefix}\"\n",
      "\n",
      "        __%[1]s_debug \"File filtering command: $filteringCmd\"\n",
      "        _arguments '*:filename:'\"$filteringCmd\"\n",
      "    elif [ $((directive & shellCompDirectiveFilterDirs)) -ne 0 ]; then\n",
      "        # File completion for directories only\n",
      "        local subdir\n",
      "        subdir=\"${completions[1]}\"\n",
      "        if [ -n \"$subdir\" ]; then\n",
      "            __%[1]s_debug \"Listing directories in $subdir\"\n",
      "            pushd \"${subdir}\" >/dev/null 2>&1\n",
      "        else\n",
      "            __%[1]s_debug \"Listing directories in .\"\n",
      "        fi\n",
      "\n",
      "        local result\n",
      "        _arguments '*:dirname:_files -/'\" ${flagPrefix}\"\n",
      "        result=$?\n",
      "        if [ -n \"$subdir\" ]; then\n",
      "            popd >/dev/null 2>&1\n",
      "        fi\n",
      "        return $result\n",
      "    else\n",
      "        __%[1]s_debug \"Calling _describe\"\n",
      "        if eval _describe $keepOrder \"completions\" completions $flagPrefix $noSpace; then\n",
      "            __%[1]s_debug \"_describe found some completions\"\n",
      "\n",
      "            # Return the success of having called _describe\n",
      "            return 0\n",
      "        else\n",
      "            __%[1]s_debug \"_describe did not find completions.\"\n",
      "            __%[1]s_debug \"Checking if we should do file completion.\"\n",
      "            if [ $((directive & shellCompDirectiveNoFileComp)) -ne 0 ]; then\n",
      "                __%[1]s_debug \"deactivating file completion\"\n",
      "\n",
      "                # We must return an error code here to let zsh know that there were no\n",
      "                # completions found by _describe; this is what will trigger other\n",
      "                # matching algorithms to attempt to find completions.\n",
      "                # For example zsh can match letters in the middle of words.\n",
      "                return 1\n",
      "            else\n",
      "                # Perform file completion\n",
      "                __%[1]s_debug \"Activating file completion\"\n",
      "\n",
      "                # We must return the result of this command, so it must be the\n",
      "                # last command, or else we must store its result to return it.\n",
      "                _arguments '*:filename:_files'\" ${flagPrefix}\"\n",
      "            fi\n",
      "        fi\n",
      "    fi\n",
      "}\n",
      "\n",
      "# don't run the completion function when being source-ed or eval-ed\n",
      "if [ \"$funcstack[1]\" = \"_%[1]s\" ]; then\n",
      "    _%[1]s\n",
      "fi\n",
      "`, name, compCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, ShellCompDirectiveKeepOrder, activeHelpMarker))\n",
      "}\n",
      "func (c *Command) execute(a []string) (err error) {\n",
      "\tif c == nil {\n",
      "\t\treturn fmt.Errorf(\"Called Execute() on a nil Command\")\n",
      "\t}\n",
      "\tif len(c.Deprecated) > 0 {\n",
      "\t\tc.Printf(\"Command %q is deprecated, %s\\n\", c.Name(), c.Deprecated)\n",
      "\t}\n",
      "\tc.InitDefaultHelpFlag()\n",
      "\tc.InitDefaultVersionFlag()\n",
      "\terr = c.ParseFlags(a)\n",
      "\tif err != nil {\n",
      "\t\treturn c.FlagErrorFunc()(c, err)\n",
      "\t}\n",
      "\thelpVal, err := c.Flags().GetBool(\"help\")\n",
      "\tif err != nil {\n",
      "\t\tc.Println(\"\\\"help\\\" flag declared as non-bool. Please correct your code\")\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif helpVal {\n",
      "\t\treturn flag.ErrHelp\n",
      "\t}\n",
      "\tif c.Version != \"\" {\n",
      "\t\tversionVal, err := c.Flags().GetBool(\"version\")\n",
      "\t\tif err != nil {\n",
      "\t\t\tc.Println(\"\\\"version\\\" flag declared as non-bool. Please correct your code\")\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif versionVal {\n",
      "\t\t\terr := tmpl(c.OutOrStdout(), c.VersionTemplate(), c)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tc.Println(err)\n",
      "\t\t\t}\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\tif !c.Runnable() {\n",
      "\t\treturn flag.ErrHelp\n",
      "\t}\n",
      "\tc.preRun()\n",
      "\tdefer c.postRun()\n",
      "\targWoFlags := c.Flags().Args()\n",
      "\tif c.DisableFlagParsing {\n",
      "\t\targWoFlags = a\n",
      "\t}\n",
      "\tif err := c.ValidateArgs(argWoFlags); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tparents := make([]*Command, 0, 5)\n",
      "\tfor p := c; p != nil; p = p.Parent() {\n",
      "\t\tif EnableTraverseRunHooks {\n",
      "\t\t\tparents = append([]*Command{p}, parents...)\n",
      "\t\t} else {\n",
      "\t\t\tparents = append(parents, p)\n",
      "\t\t}\n",
      "\t}\n",
      "\tfor _, p := range parents {\n",
      "\t\tif p.PersistentPreRunE != nil {\n",
      "\t\t\tif err := p.PersistentPreRunE(c, argWoFlags); err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tif !EnableTraverseRunHooks {\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t} else if p.PersistentPreRun != nil {\n",
      "\t\t\tp.PersistentPreRun(c, argWoFlags)\n",
      "\t\t\tif !EnableTraverseRunHooks {\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif c.PreRunE != nil {\n",
      "\t\tif err := c.PreRunE(c, argWoFlags); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t} else if c.PreRun != nil {\n",
      "\t\tc.PreRun(c, argWoFlags)\n",
      "\t}\n",
      "\tif err := c.ValidateRequiredFlags(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := c.ValidateFlagGroups(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif c.RunE != nil {\n",
      "\t\tif err := c.RunE(c, argWoFlags); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tc.Run(c, argWoFlags)\n",
      "\t}\n",
      "\tif c.PostRunE != nil {\n",
      "\t\tif err := c.PostRunE(c, argWoFlags); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t} else if c.PostRun != nil {\n",
      "\t\tc.PostRun(c, argWoFlags)\n",
      "\t}\n",
      "\tfor p := c; p != nil; p = p.Parent() {\n",
      "\t\tif p.PersistentPostRunE != nil {\n",
      "\t\t\tif err := p.PersistentPostRunE(c, argWoFlags); err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tif !EnableTraverseRunHooks {\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t} else if p.PersistentPostRun != nil {\n",
      "\t\t\tp.PersistentPostRun(c, argWoFlags)\n",
      "\t\t\tif !EnableTraverseRunHooks {\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (c *Command) persistentFlag(name string) (flag *flag.Flag) {\n",
      "\tif c.HasPersistentFlags() {\n",
      "\t\tflag = c.PersistentFlags().Lookup(name)\n",
      "\t}\n",
      "\tif flag == nil {\n",
      "\t\tc.updateParentsPflags()\n",
      "\t\tflag = c.parentsPflags.Lookup(name)\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func (c *Command) MarkFlagsOneRequired(flagNames ...string) {\n",
      "\tc.mergePersistentFlags()\n",
      "\tfor _, v := range flagNames {\n",
      "\t\tf := c.Flags().Lookup(v)\n",
      "\t\tif f == nil {\n",
      "\t\t\tpanic(fmt.Sprintf(\"Failed to find flag %q and mark it as being in a one-required flag group\", v))\n",
      "\t\t}\n",
      "\t\tif err := c.Flags().SetAnnotation(v, oneRequired, append(f.Annotations[oneRequired], strings.Join(flagNames, \" \"))); err != nil {\n",
      "\t\t\tpanic(err)\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "func genFishComp(buf io.StringWriter, name string, includeDesc bool) {\n",
      "\tnameForVar := name\n",
      "\tnameForVar = strings.ReplaceAll(nameForVar, \"-\", \"_\")\n",
      "\tnameForVar = strings.ReplaceAll(nameForVar, \":\", \"_\")\n",
      "\tcompCmd := ShellCompRequestCmd\n",
      "\tif !includeDesc {\n",
      "\t\tcompCmd = ShellCompNoDescRequestCmd\n",
      "\t}\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(\"# fish completion for %-36s -*- shell-script -*-\\n\", name))\n",
      "\tWriteStringAndCheck(buf, fmt.Sprintf(`\n",
      "function __%[1]s_debug\n",
      "    set -l file \"$BASH_COMP_DEBUG_FILE\"\n",
      "    if test -n \"$file\"\n",
      "        echo \"$argv\" >> $file\n",
      "    end\n",
      "end\n",
      "\n",
      "function __%[1]s_perform_completion\n",
      "    __%[1]s_debug \"Starting __%[1]s_perform_completion\"\n",
      "\n",
      "    # Extract all args except the last one\n",
      "    set -l args (commandline -opc)\n",
      "    # Extract the last arg and escape it in case it is a space\n",
      "    set -l lastArg (string escape -- (commandline -ct))\n",
      "\n",
      "    __%[1]s_debug \"args: $args\"\n",
      "    __%[1]s_debug \"last arg: $lastArg\"\n",
      "\n",
      "    # Disable ActiveHelp which is not supported for fish shell\n",
      "    set -l requestComp \"%[10]s=0 $args[1] %[3]s $args[2..-1] $lastArg\"\n",
      "\n",
      "    __%[1]s_debug \"Calling $requestComp\"\n",
      "    set -l results (eval $requestComp 2> /dev/null)\n",
      "\n",
      "    # Some programs may output extra empty lines after the directive.\n",
      "    # Let's ignore them or else it will break completion.\n",
      "    # Ref: https://github.com/spf13/cobra/issues/1279\n",
      "    for line in $results[-1..1]\n",
      "        if test (string trim -- $line) = \"\"\n",
      "            # Found an empty line, remove it\n",
      "            set results $results[1..-2]\n",
      "        else\n",
      "            # Found non-empty line, we have our proper output\n",
      "            break\n",
      "        end\n",
      "    end\n",
      "\n",
      "    set -l comps $results[1..-2]\n",
      "    set -l directiveLine $results[-1]\n",
      "\n",
      "    # For Fish, when completing a flag with an = (e.g., <program> -n=<TAB>)\n",
      "    # completions must be prefixed with the flag\n",
      "    set -l flagPrefix (string match -r -- '-.*=' \"$lastArg\")\n",
      "\n",
      "    __%[1]s_debug \"Comps: $comps\"\n",
      "    __%[1]s_debug \"DirectiveLine: $directiveLine\"\n",
      "    __%[1]s_debug \"flagPrefix: $flagPrefix\"\n",
      "\n",
      "    for comp in $comps\n",
      "        printf \"%%s%%s\\n\" \"$flagPrefix\" \"$comp\"\n",
      "    end\n",
      "\n",
      "    printf \"%%s\\n\" \"$directiveLine\"\n",
      "end\n",
      "\n",
      "# this function limits calls to __%[1]s_perform_completion, by caching the result behind $__%[1]s_perform_completion_once_result\n",
      "function __%[1]s_perform_completion_once\n",
      "    __%[1]s_debug \"Starting __%[1]s_perform_completion_once\"\n",
      "\n",
      "    if test -n \"$__%[1]s_perform_completion_once_result\"\n",
      "        __%[1]s_debug \"Seems like a valid result already exists, skipping __%[1]s_perform_completion\"\n",
      "        return 0\n",
      "    end\n",
      "\n",
      "    set --global __%[1]s_perform_completion_once_result (__%[1]s_perform_completion)\n",
      "    if test -z \"$__%[1]s_perform_completion_once_result\"\n",
      "        __%[1]s_debug \"No completions, probably due to a failure\"\n",
      "        return 1\n",
      "    end\n",
      "\n",
      "    __%[1]s_debug \"Performed completions and set __%[1]s_perform_completion_once_result\"\n",
      "    return 0\n",
      "end\n",
      "\n",
      "# this function is used to clear the $__%[1]s_perform_completion_once_result variable after completions are run\n",
      "function __%[1]s_clear_perform_completion_once_result\n",
      "    __%[1]s_debug \"\"\n",
      "    __%[1]s_debug \"========= clearing previously set __%[1]s_perform_completion_once_result variable ==========\"\n",
      "    set --erase __%[1]s_perform_completion_once_result\n",
      "    __%[1]s_debug \"Successfully erased the variable __%[1]s_perform_completion_once_result\"\n",
      "end\n",
      "\n",
      "function __%[1]s_requires_order_preservation\n",
      "    __%[1]s_debug \"\"\n",
      "    __%[1]s_debug \"========= checking if order preservation is required ==========\"\n",
      "\n",
      "    __%[1]s_perform_completion_once\n",
      "    if test -z \"$__%[1]s_perform_completion_once_result\"\n",
      "        __%[1]s_debug \"Error determining if order preservation is required\"\n",
      "        return 1\n",
      "    end\n",
      "\n",
      "    set -l directive (string sub --start 2 $__%[1]s_perform_completion_once_result[-1])\n",
      "    __%[1]s_debug \"Directive is: $directive\"\n",
      "\n",
      "    set -l shellCompDirectiveKeepOrder %[9]d\n",
      "    set -l keeporder (math (math --scale 0 $directive / $shellCompDirectiveKeepOrder) %% 2)\n",
      "    __%[1]s_debug \"Keeporder is: $keeporder\"\n",
      "\n",
      "    if test $keeporder -ne 0\n",
      "        __%[1]s_debug \"This does require order preservation\"\n",
      "        return 0\n",
      "    end\n",
      "\n",
      "    __%[1]s_debug \"This doesn't require order preservation\"\n",
      "    return 1\n",
      "end\n",
      "\n",
      "\n",
      "# This function does two things:\n",
      "# - Obtain the completions and store them in the global __%[1]s_comp_results\n",
      "# - Return false if file completion should be performed\n",
      "function __%[1]s_prepare_completions\n",
      "    __%[1]s_debug \"\"\n",
      "    __%[1]s_debug \"========= starting completion logic ==========\"\n",
      "\n",
      "    # Start fresh\n",
      "    set --erase __%[1]s_comp_results\n",
      "\n",
      "    __%[1]s_perform_completion_once\n",
      "    __%[1]s_debug \"Completion results: $__%[1]s_perform_completion_once_result\"\n",
      "\n",
      "    if test -z \"$__%[1]s_perform_completion_once_result\"\n",
      "        __%[1]s_debug \"No completion, probably due to a failure\"\n",
      "        # Might as well do file completion, in case it helps\n",
      "        return 1\n",
      "    end\n",
      "\n",
      "    set -l directive (string sub --start 2 $__%[1]s_perform_completion_once_result[-1])\n",
      "    set --global __%[1]s_comp_results $__%[1]s_perform_completion_once_result[1..-2]\n",
      "\n",
      "    __%[1]s_debug \"Completions are: $__%[1]s_comp_results\"\n",
      "    __%[1]s_debug \"Directive is: $directive\"\n",
      "\n",
      "    set -l shellCompDirectiveError %[4]d\n",
      "    set -l shellCompDirectiveNoSpace %[5]d\n",
      "    set -l shellCompDirectiveNoFileComp %[6]d\n",
      "    set -l shellCompDirectiveFilterFileExt %[7]d\n",
      "    set -l shellCompDirectiveFilterDirs %[8]d\n",
      "\n",
      "    if test -z \"$directive\"\n",
      "        set directive 0\n",
      "    end\n",
      "\n",
      "    set -l compErr (math (math --scale 0 $directive / $shellCompDirectiveError) %% 2)\n",
      "    if test $compErr -eq 1\n",
      "        __%[1]s_debug \"Received error directive: aborting.\"\n",
      "        # Might as well do file completion, in case it helps\n",
      "        return 1\n",
      "    end\n",
      "\n",
      "    set -l filefilter (math (math --scale 0 $directive / $shellCompDirectiveFilterFileExt) %% 2)\n",
      "    set -l dirfilter (math (math --scale 0 $directive / $shellCompDirectiveFilterDirs) %% 2)\n",
      "    if test $filefilter -eq 1; or test $dirfilter -eq 1\n",
      "        __%[1]s_debug \"File extension filtering or directory filtering not supported\"\n",
      "        # Do full file completion instead\n",
      "        return 1\n",
      "    end\n",
      "\n",
      "    set -l nospace (math (math --scale 0 $directive / $shellCompDirectiveNoSpace) %% 2)\n",
      "    set -l nofiles (math (math --scale 0 $directive / $shellCompDirectiveNoFileComp) %% 2)\n",
      "\n",
      "    __%[1]s_debug \"nospace: $nospace, nofiles: $nofiles\"\n",
      "\n",
      "    # If we want to prevent a space, or if file completion is NOT disabled,\n",
      "    # we need to count the number of valid completions.\n",
      "    # To do so, we will filter on prefix as the completions we have received\n",
      "    # may not already be filtered so as to allow fish to match on different\n",
      "    # criteria than the prefix.\n",
      "    if test $nospace -ne 0; or test $nofiles -eq 0\n",
      "        set -l prefix (commandline -t | string escape --style=regex)\n",
      "        __%[1]s_debug \"prefix: $prefix\"\n",
      "\n",
      "        set -l completions (string match -r -- \"^$prefix.*\" $__%[1]s_comp_results)\n",
      "        set --global __%[1]s_comp_results $completions\n",
      "        __%[1]s_debug \"Filtered completions are: $__%[1]s_comp_results\"\n",
      "\n",
      "        # Important not to quote the variable for count to work\n",
      "        set -l numComps (count $__%[1]s_comp_results)\n",
      "        __%[1]s_debug \"numComps: $numComps\"\n",
      "\n",
      "        if test $numComps -eq 1; and test $nospace -ne 0\n",
      "            # We must first split on \\t to get rid of the descriptions to be\n",
      "            # able to check what the actual completion will be.\n",
      "            # We don't need descriptions anyway since there is only a single\n",
      "            # real completion which the shell will expand immediately.\n",
      "            set -l split (string split --max 1 \\t $__%[1]s_comp_results[1])\n",
      "\n",
      "            # Fish won't add a space if the completion ends with any\n",
      "            # of the following characters: @=/:.,\n",
      "            set -l lastChar (string sub -s -1 -- $split)\n",
      "            if not string match -r -q \"[@=/:.,]\" -- \"$lastChar\"\n",
      "                # In other cases, to support the \"nospace\" directive we trick the shell\n",
      "                # by outputting an extra, longer completion.\n",
      "                __%[1]s_debug \"Adding second completion to perform nospace directive\"\n",
      "                set --global __%[1]s_comp_results $split[1] $split[1].\n",
      "                __%[1]s_debug \"Completions are now: $__%[1]s_comp_results\"\n",
      "            end\n",
      "        end\n",
      "\n",
      "        if test $numComps -eq 0; and test $nofiles -eq 0\n",
      "            # To be consistent with bash and zsh, we only trigger file\n",
      "            # completion when there are no other completions\n",
      "            __%[1]s_debug \"Requesting file completion\"\n",
      "            return 1\n",
      "        end\n",
      "    end\n",
      "\n",
      "    return 0\n",
      "end\n",
      "\n",
      "# Since Fish completions are only loaded once the user triggers them, we trigger them ourselves\n",
      "# so we can properly delete any completions provided by another script.\n",
      "# Only do this if the program can be found, or else fish may print some errors; besides,\n",
      "# the existing completions will only be loaded if the program can be found.\n",
      "if type -q \"%[2]s\"\n",
      "    # The space after the program name is essential to trigger completion for the program\n",
      "    # and not completion of the program name itself.\n",
      "    # Also, we use '> /dev/null 2>&1' since '&>' is not supported in older versions of fish.\n",
      "    complete --do-complete \"%[2]s \" > /dev/null 2>&1\n",
      "end\n",
      "\n",
      "# Remove any pre-existing completions for the program since we will be handling all of them.\n",
      "complete -c %[2]s -e\n",
      "\n",
      "# this will get called after the two calls below and clear the $__%[1]s_perform_completion_once_result global\n",
      "complete -c %[2]s -n '__%[1]s_clear_perform_completion_once_result'\n",
      "# The call to __%[1]s_prepare_completions will setup __%[1]s_comp_results\n",
      "# which provides the program's completion choices.\n",
      "# If this doesn't require order preservation, we don't use the -k flag\n",
      "complete -c %[2]s -n 'not __%[1]s_requires_order_preservation && __%[1]s_prepare_completions' -f -a '$__%[1]s_comp_results'\n",
      "# otherwise we use the -k flag\n",
      "complete -k -c %[2]s -n '__%[1]s_requires_order_preservation && __%[1]s_prepare_completions' -f -a '$__%[1]s_comp_results'\n",
      "`, nameForVar, name, compCmd, ShellCompDirectiveError, ShellCompDirectiveNoSpace, ShellCompDirectiveNoFileComp, ShellCompDirectiveFilterFileExt, ShellCompDirectiveFilterDirs, ShellCompDirectiveKeepOrder, activeHelpEnvVar(name)))\n",
      "}\n",
      "func checkIfFlagCompletion(finalCmd *Command, args []string, lastArg string) (*pflag.Flag, []string, string, error) {\n",
      "\tif finalCmd.DisableFlagParsing {\n",
      "\t\treturn nil, args, lastArg, nil\n",
      "\t}\n",
      "\tvar flagName string\n",
      "\ttrimmedArgs := args\n",
      "\tflagWithEqual := false\n",
      "\torgLastArg := lastArg\n",
      "\tif len(lastArg) > 0 && lastArg[0] == '-' {\n",
      "\t\tif index := strings.Index(lastArg, \"=\"); index >= 0 {\n",
      "\t\t\tif strings.HasPrefix(lastArg[:index], \"--\") {\n",
      "\t\t\t\tflagName = lastArg[2:index]\n",
      "\t\t\t} else {\n",
      "\t\t\t\tflagName = lastArg[index-1 : index]\n",
      "\t\t\t}\n",
      "\t\t\tlastArg = lastArg[index+1:]\n",
      "\t\t\tflagWithEqual = true\n",
      "\t\t} else {\n",
      "\t\t\treturn nil, args, lastArg, nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(flagName) == 0 {\n",
      "\t\tif len(args) > 0 {\n",
      "\t\t\tprevArg := args[len(args)-1]\n",
      "\t\t\tif isFlagArg(prevArg) {\n",
      "\t\t\t\tif index := strings.Index(prevArg, \"=\"); index < 0 {\n",
      "\t\t\t\t\tif strings.HasPrefix(prevArg, \"--\") {\n",
      "\t\t\t\t\t\tflagName = prevArg[2:]\n",
      "\t\t\t\t\t} else {\n",
      "\t\t\t\t\t\tflagName = prevArg[len(prevArg)-1:]\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\ttrimmedArgs = args[:len(args)-1]\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(flagName) == 0 {\n",
      "\t\treturn nil, trimmedArgs, lastArg, nil\n",
      "\t}\n",
      "\tflag := findFlag(finalCmd, flagName)\n",
      "\tif flag == nil {\n",
      "\t\treturn nil, args, orgLastArg, &flagCompError{subCommand: finalCmd.Name(), flagName: flagName}\n",
      "\t}\n",
      "\tif !flagWithEqual {\n",
      "\t\tif len(flag.NoOptDefVal) != 0 {\n",
      "\t\t\ttrimmedArgs = args\n",
      "\t\t\tflag = nil\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn flag, trimmedArgs, lastArg, nil\n",
      "}\n",
      "go-gorm/gorm 1 34799\n",
      "1\n",
      "======================CLASS=======================\n",
      "func ParseTagSetting(str string, sep string) map[string]string {\n",
      "\tsettings := map[string]string{}\n",
      "\tnames := strings.Split(str, sep)\n",
      "\tfor i := 0; i < len(names); i++ {\n",
      "\t\tj := i\n",
      "\t\tif len(names[j]) > 0 {\n",
      "\t\t\tfor {\n",
      "\t\t\t\tif names[j][len(names[j])-1] == '\\\\' {\n",
      "\t\t\t\t\ti++\n",
      "\t\t\t\t\tnames[j] = names[j][0:len(names[j])-1] + sep + names[i]\n",
      "\t\t\t\t\tnames[i] = \"\"\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tvalues := strings.Split(names[j], \":\")\n",
      "\t\tk := strings.TrimSpace(strings.ToUpper(values[0]))\n",
      "\t\tif len(values) >= 2 {\n",
      "\t\t\tsettings[k] = strings.Join(values[1:], \":\")\n",
      "\t\t} else if k != \"\" {\n",
      "\t\t\tsettings[k] = k\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn settings\n",
      "}\n",
      "func Open(dialector Dialector, opts ...Option) (db *DB, err error) {\n",
      "\tconfig := &Config{}\n",
      "\tsort.Slice(opts, func(i, j int) bool {\n",
      "\t\t_, isConfig := opts[i].(*Config)\n",
      "\t\t_, isConfig2 := opts[j].(*Config)\n",
      "\t\treturn isConfig && !isConfig2\n",
      "\t})\n",
      "\tfor _, opt := range opts {\n",
      "\t\tif opt != nil {\n",
      "\t\t\tif applyErr := opt.Apply(config); applyErr != nil {\n",
      "\t\t\t\treturn nil, applyErr\n",
      "\t\t\t}\n",
      "\t\t\tdefer func(opt Option) {\n",
      "\t\t\t\tif errr := opt.AfterInitialize(db); errr != nil {\n",
      "\t\t\t\t\terr = errr\n",
      "\t\t\t\t}\n",
      "\t\t\t}(opt)\n",
      "\t\t}\n",
      "\t}\n",
      "\tif d, ok := dialector.(interface{ Apply(*Config) error }); ok {\n",
      "\t\tif err = d.Apply(config); err != nil {\n",
      "\t\t\treturn\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.NamingStrategy == nil {\n",
      "\t\tconfig.NamingStrategy = schema.NamingStrategy{IdentifierMaxLength: 64}\n",
      "\t}\n",
      "\tif config.Logger == nil {\n",
      "\t\tconfig.Logger = logger.Default\n",
      "\t}\n",
      "\tif config.NowFunc == nil {\n",
      "\t\tconfig.NowFunc = func() time.Time {\n",
      "\t\t\treturn time.Now().Local()\n",
      "\t\t}\n",
      "\t}\n",
      "\tif dialector != nil {\n",
      "\t\tconfig.Dialector = dialector\n",
      "\t}\n",
      "\tif config.Plugins == nil {\n",
      "\t\tconfig.Plugins = map[string]Plugin{}\n",
      "\t}\n",
      "\tif config.cacheStore == nil {\n",
      "\t\tconfig.cacheStore = &sync.Map{}\n",
      "\t}\n",
      "\tdb = &DB{Config: config, clone: 1}\n",
      "\tdb.callbacks = initializeCallbacks(db)\n",
      "\tif config.ClauseBuilders == nil {\n",
      "\t\tconfig.ClauseBuilders = map[string]clause.ClauseBuilder{}\n",
      "\t}\n",
      "\tif config.Dialector != nil {\n",
      "\t\terr = config.Dialector.Initialize(db)\n",
      "\t\tif err != nil {\n",
      "\t\t\tif db, _ := db.DB(); db != nil {\n",
      "\t\t\t\t_ = db.Close()\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tif config.PrepareStmt {\n",
      "\t\tpreparedStmt := NewPreparedStmtDB(db.ConnPool)\n",
      "\t\tdb.cacheStore.Store(preparedStmtDBKey, preparedStmt)\n",
      "\t\tdb.ConnPool = preparedStmt\n",
      "\t}\n",
      "\tdb.Statement = &Statement{DB: db, ConnPool: db.ConnPool, Context: context.Background(), Clauses: map[string]clause.Clause{}}\n",
      "\tif err == nil && !config.DisableAutomaticPing {\n",
      "\t\tif pinger, ok := db.ConnPool.(interface{ Ping() error }); ok {\n",
      "\t\t\terr = pinger.Ping()\n",
      "\t\t}\n",
      "\t}\n",
      "\tif err != nil {\n",
      "\t\tconfig.Logger.Error(context.Background(), \"failed to initialize database, got error %v\", err)\n",
      "\t}\n",
      "\treturn\n",
      "}\n",
      "func RegisterDefaultCallbacks(db *gorm.DB, config *Config) {\n",
      "\tenableTransaction := func(db *gorm.DB) bool {\n",
      "\t\treturn !db.SkipDefaultTransaction\n",
      "\t}\n",
      "\tif len(config.CreateClauses) == 0 {\n",
      "\t\tconfig.CreateClauses = createClauses\n",
      "\t}\n",
      "\tif len(config.QueryClauses) == 0 {\n",
      "\t\tconfig.QueryClauses = queryClauses\n",
      "\t}\n",
      "\tif len(config.DeleteClauses) == 0 {\n",
      "\t\tconfig.DeleteClauses = deleteClauses\n",
      "\t}\n",
      "\tif len(config.UpdateClauses) == 0 {\n",
      "\t\tconfig.UpdateClauses = updateClauses\n",
      "\t}\n",
      "\tcreateCallback := db.Callback().Create()\n",
      "\tcreateCallback.Match(enableTransaction).Register(\"gorm:begin_transaction\", BeginTransaction)\n",
      "\tcreateCallback.Register(\"gorm:before_create\", BeforeCreate)\n",
      "\tcreateCallback.Register(\"gorm:save_before_associations\", SaveBeforeAssociations(true))\n",
      "\tcreateCallback.Register(\"gorm:create\", Create(config))\n",
      "\tcreateCallback.Register(\"gorm:save_after_associations\", SaveAfterAssociations(true))\n",
      "\tcreateCallback.Register(\"gorm:after_create\", AfterCreate)\n",
      "\tcreateCallback.Match(enableTransaction).Register(\"gorm:commit_or_rollback_transaction\", CommitOrRollbackTransaction)\n",
      "\tcreateCallback.Clauses = config.CreateClauses\n",
      "\tqueryCallback := db.Callback().Query()\n",
      "\tqueryCallback.Register(\"gorm:query\", Query)\n",
      "\tqueryCallback.Register(\"gorm:preload\", Preload)\n",
      "\tqueryCallback.Register(\"gorm:after_query\", AfterQuery)\n",
      "\tqueryCallback.Clauses = config.QueryClauses\n",
      "\tdeleteCallback := db.Callback().Delete()\n",
      "\tdeleteCallback.Match(enableTransaction).Register(\"gorm:begin_transaction\", BeginTransaction)\n",
      "\tdeleteCallback.Register(\"gorm:before_delete\", BeforeDelete)\n",
      "\tdeleteCallback.Register(\"gorm:delete_before_associations\", DeleteBeforeAssociations)\n",
      "\tdeleteCallback.Register(\"gorm:delete\", Delete(config))\n",
      "\tdeleteCallback.Register(\"gorm:after_delete\", AfterDelete)\n",
      "\tdeleteCallback.Match(enableTransaction).Register(\"gorm:commit_or_rollback_transaction\", CommitOrRollbackTransaction)\n",
      "\tdeleteCallback.Clauses = config.DeleteClauses\n",
      "\tupdateCallback := db.Callback().Update()\n",
      "\tupdateCallback.Match(enableTransaction).Register(\"gorm:begin_transaction\", BeginTransaction)\n",
      "\tupdateCallback.Register(\"gorm:setup_reflect_value\", SetupUpdateReflectValue)\n",
      "\tupdateCallback.Register(\"gorm:before_update\", BeforeUpdate)\n",
      "\tupdateCallback.Register(\"gorm:save_before_associations\", SaveBeforeAssociations(false))\n",
      "\tupdateCallback.Register(\"gorm:update\", Update(config))\n",
      "\tupdateCallback.Register(\"gorm:save_after_associations\", SaveAfterAssociations(false))\n",
      "\tupdateCallback.Register(\"gorm:after_update\", AfterUpdate)\n",
      "\tupdateCallback.Match(enableTransaction).Register(\"gorm:commit_or_rollback_transaction\", CommitOrRollbackTransaction)\n",
      "\tupdateCallback.Clauses = config.UpdateClauses\n",
      "\trowCallback := db.Callback().Row()\n",
      "\trowCallback.Register(\"gorm:row\", RowQuery)\n",
      "\trowCallback.Clauses = config.QueryClauses\n",
      "\trawCallback := db.Callback().Raw()\n",
      "\trawCallback.Register(\"gorm:raw\", RawExec)\n",
      "\trawCallback.Clauses = config.QueryClauses\n",
      "}\n",
      "func New(writer Writer, config Config) Interface {\n",
      "\tvar (\n",
      "\t\tinfoStr\t\t= \"%s\\n[info] \"\n",
      "\t\twarnStr\t\t= \"%s\\n[warn] \"\n",
      "\t\terrStr\t\t= \"%s\\n[error] \"\n",
      "\t\ttraceStr\t= \"%s\\n[%.3fms] [rows:%v] %s\"\n",
      "\t\ttraceWarnStr\t= \"%s %s\\n[%.3fms] [rows:%v] %s\"\n",
      "\t\ttraceErrStr\t= \"%s %s\\n[%.3fms] [rows:%v] %s\"\n",
      "\t)\n",
      "\tif config.Colorful {\n",
      "\t\tinfoStr = Green + \"%s\\n\" + Reset + Green + \"[info] \" + Reset\n",
      "\t\twarnStr = BlueBold + \"%s\\n\" + Reset + Magenta + \"[warn] \" + Reset\n",
      "\t\terrStr = Magenta + \"%s\\n\" + Reset + Red + \"[error] \" + Reset\n",
      "\t\ttraceStr = Green + \"%s\\n\" + Reset + Yellow + \"[%.3fms] \" + BlueBold + \"[rows:%v]\" + Reset + \" %s\"\n",
      "\t\ttraceWarnStr = Green + \"%s \" + Yellow + \"%s\\n\" + Reset + RedBold + \"[%.3fms] \" + Yellow + \"[rows:%v]\" + Magenta + \" %s\" + Reset\n",
      "\t\ttraceErrStr = RedBold + \"%s \" + MagentaBold + \"%s\\n\" + Reset + Yellow + \"[%.3fms] \" + BlueBold + \"[rows:%v]\" + Reset + \" %s\"\n",
      "\t}\n",
      "\treturn &logger{Writer: writer, Config: config, infoStr: infoStr, warnStr: warnStr, errStr: errStr, traceStr: traceStr, traceWarnStr: traceWarnStr, traceErrStr: traceErrStr}\n",
      "}\n",
      "func parseFieldIndexes(field *Field) (indexes []Index, err error) {\n",
      "\tfor _, value := range strings.Split(field.Tag.Get(\"gorm\"), \";\") {\n",
      "\t\tif value != \"\" {\n",
      "\t\t\tv := strings.Split(value, \":\")\n",
      "\t\t\tk := strings.TrimSpace(strings.ToUpper(v[0]))\n",
      "\t\t\tif k == \"INDEX\" || k == \"UNIQUEINDEX\" {\n",
      "\t\t\t\tvar (\n",
      "\t\t\t\t\tname\t\tstring\n",
      "\t\t\t\t\ttag\t\t= strings.Join(v[1:], \":\")\n",
      "\t\t\t\t\tidx\t\t= strings.Index(tag, \",\")\n",
      "\t\t\t\t\ttagSetting\t= strings.Join(strings.Split(tag, \",\")[1:], \",\")\n",
      "\t\t\t\t\tsettings\t= ParseTagSetting(tagSetting, \",\")\n",
      "\t\t\t\t\tlength, _\t= strconv.Atoi(settings[\"LENGTH\"])\n",
      "\t\t\t\t)\n",
      "\t\t\t\tif idx == -1 {\n",
      "\t\t\t\t\tidx = len(tag)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif idx != -1 {\n",
      "\t\t\t\t\tname = tag[0:idx]\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif name == \"\" {\n",
      "\t\t\t\t\tsubName := field.Name\n",
      "\t\t\t\t\tconst key = \"COMPOSITE\"\n",
      "\t\t\t\t\tif composite, found := settings[key]; found {\n",
      "\t\t\t\t\t\tif len(composite) == 0 || composite == key {\n",
      "\t\t\t\t\t\t\terr = fmt.Errorf(\"The composite tag of %s.%s cannot be empty\", field.Schema.Name, field.Name)\n",
      "\t\t\t\t\t\t\treturn\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tsubName = composite\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tname = field.Schema.namer.IndexName(field.Schema.Table, subName)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif (k == \"UNIQUEINDEX\") || settings[\"UNIQUE\"] != \"\" {\n",
      "\t\t\t\t\tsettings[\"CLASS\"] = \"UNIQUE\"\n",
      "\t\t\t\t}\n",
      "\t\t\t\tpriority, err := strconv.Atoi(settings[\"PRIORITY\"])\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tpriority = 10\n",
      "\t\t\t\t}\n",
      "\t\t\t\tindexes = append(indexes, Index{Name: name, Class: settings[\"CLASS\"], Type: settings[\"TYPE\"], Where: settings[\"WHERE\"], Comment: settings[\"COMMENT\"], Option: settings[\"OPTION\"], Fields: []IndexOption{{Field: field, Expression: settings[\"EXPRESSION\"], Sort: settings[\"SORT\"], Collate: settings[\"COLLATE\"], Length: length, priority: priority}}})\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\terr = nil\n",
      "\treturn\n",
      "}\n",
      "func (rel *Relationship) ParseConstraint() *Constraint {\n",
      "\tstr := rel.Field.TagSettings[\"CONSTRAINT\"]\n",
      "\tif str == \"-\" {\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tif rel.Type == BelongsTo {\n",
      "\t\tfor _, r := range rel.FieldSchema.Relationships.Relations {\n",
      "\t\t\tif r != rel && r.FieldSchema == rel.Schema && len(rel.References) == len(r.References) {\n",
      "\t\t\t\tmatched := true\n",
      "\t\t\t\tfor idx, ref := range r.References {\n",
      "\t\t\t\t\tif !(rel.References[idx].PrimaryKey == ref.PrimaryKey && rel.References[idx].ForeignKey == ref.ForeignKey && rel.References[idx].PrimaryValue == ref.PrimaryValue) {\n",
      "\t\t\t\t\t\tmatched = false\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif matched {\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\tvar (\n",
      "\t\tname\t\tstring\n",
      "\t\tidx\t\t= strings.Index(str, \",\")\n",
      "\t\tsettings\t= ParseTagSetting(str, \",\")\n",
      "\t)\n",
      "\tif idx != -1 && regEnLetterAndMidline.MatchString(str[0:idx]) {\n",
      "\t\tname = str[0:idx]\n",
      "\t} else {\n",
      "\t\tname = rel.Schema.namer.RelationshipFKName(*rel)\n",
      "\t}\n",
      "\tconstraint := Constraint{Name: name, Field: rel.Field, OnUpdate: settings[\"ONUPDATE\"], OnDelete: settings[\"ONDELETE\"]}\n",
      "\tfor _, ref := range rel.References {\n",
      "\t\tif ref.PrimaryKey != nil && (rel.JoinTable == nil || ref.OwnPrimaryKey) {\n",
      "\t\t\tconstraint.ForeignKeys = append(constraint.ForeignKeys, ref.ForeignKey)\n",
      "\t\t\tconstraint.References = append(constraint.References, ref.PrimaryKey)\n",
      "\t\t\tif ref.OwnPrimaryKey {\n",
      "\t\t\t\tconstraint.Schema = ref.ForeignKey.Schema\n",
      "\t\t\t\tconstraint.ReferenceSchema = rel.Schema\n",
      "\t\t\t} else {\n",
      "\t\t\t\tconstraint.Schema = rel.Schema\n",
      "\t\t\t\tconstraint.ReferenceSchema = ref.PrimaryKey.Schema\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn &constraint\n",
      "}\n",
      "func (db *DB) Scan(dest interface{}) (tx *DB) {\n",
      "\tconfig := *db.Config\n",
      "\tcurrentLogger, newLogger := config.Logger, logger.Recorder.New()\n",
      "\tconfig.Logger = newLogger\n",
      "\ttx = db.getInstance()\n",
      "\ttx.Config = &config\n",
      "\tif rows, err := tx.Rows(); err == nil {\n",
      "\t\tif rows.Next() {\n",
      "\t\t\ttx.ScanRows(rows, dest)\n",
      "\t\t} else {\n",
      "\t\t\ttx.RowsAffected = 0\n",
      "\t\t\ttx.AddError(rows.Err())\n",
      "\t\t}\n",
      "\t\ttx.AddError(rows.Close())\n",
      "\t}\n",
      "\tcurrentLogger.Trace(tx.Statement.Context, newLogger.BeginAt, func() (string, int64) {\n",
      "\t\treturn newLogger.SQL, tx.RowsAffected\n",
      "\t}, tx.Error)\n",
      "\ttx.Logger = currentLogger\n",
      "\treturn\n",
      "}\n",
      "unknwon/the-way-to-go_ZH_CN 8 33963\n",
      "8\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "docker/compose 1 31817\n",
      "1\n",
      "======================CLASS=======================\n",
      "func (s *composeService) Watch(ctx context.Context, project *types.Project, services []string, options api.WatchOptions) error {\n",
      "\tvar err error\n",
      "\tif project, err = project.WithSelectedServices(services); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tsyncer, err := s.getSyncImplementation(project)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\teg, ctx := errgroup.WithContext(ctx)\n",
      "\twatching := false\n",
      "\toptions.LogTo.Register(api.WatchLogger)\n",
      "\tfor i := range project.Services {\n",
      "\t\tservice := project.Services[i]\n",
      "\t\tconfig, err := loadDevelopmentConfig(service, project)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tif service.Develop != nil {\n",
      "\t\t\tconfig = service.Develop\n",
      "\t\t}\n",
      "\t\tif config == nil {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tfor _, trigger := range config.Watch {\n",
      "\t\t\tif trigger.Action == types.WatchActionRebuild {\n",
      "\t\t\t\tif service.Build == nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"can't watch service %q with action %s without a build context\", service.Name, types.WatchActionRebuild)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tif options.Build == nil {\n",
      "\t\t\t\t\treturn fmt.Errorf(\"--no-build is incompatible with watch action %s in service %s\", types.WatchActionRebuild, service.Name)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif len(services) > 0 && service.Build == nil {\n",
      "\t\t\treturn fmt.Errorf(\"can't watch service %q without a build context\", service.Name)\n",
      "\t\t}\n",
      "\t\tif len(services) == 0 && service.Build == nil {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tservice.PullPolicy = types.PullPolicyBuild\n",
      "\t\tproject.Services[i] = service\n",
      "\t\tdockerIgnores, err := watch.LoadDockerIgnore(service.Build.Context)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tdotGitIgnore, err := watch.NewDockerPatternMatcher(\"/\", []string{\".git/\"})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tignore := watch.NewCompositeMatcher(dockerIgnores, watch.EphemeralPathMatcher(), dotGitIgnore)\n",
      "\t\tvar paths, pathLogs []string\n",
      "\t\tfor _, trigger := range config.Watch {\n",
      "\t\t\tif checkIfPathAlreadyBindMounted(trigger.Path, service.Volumes) {\n",
      "\t\t\t\tlogrus.Warnf(\"path '%s' also declared by a bind mount volume, this path won't be monitored!\\n\", trigger.Path)\n",
      "\t\t\t\tcontinue\n",
      "\t\t\t}\n",
      "\t\t\tpaths = append(paths, trigger.Path)\n",
      "\t\t\tpathLogs = append(pathLogs, fmt.Sprintf(\"Action %s for path %q\", trigger.Action, trigger.Path))\n",
      "\t\t}\n",
      "\t\twatcher, err := watch.NewWatcher(paths, ignore)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\tlogrus.Debugf(\"Watch configuration for service %q:%s\\n\", service.Name, strings.Join(append([]string{\"\"}, pathLogs...), \"\\n  - \"))\n",
      "\t\terr = watcher.Start()\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\twatching = true\n",
      "\t\teg.Go(func() error {\n",
      "\t\t\tdefer watcher.Close()\n",
      "\t\t\treturn s.watch(ctx, project, service.Name, options, watcher, syncer, config.Watch)\n",
      "\t\t})\n",
      "\t}\n",
      "\tif !watching {\n",
      "\t\treturn fmt.Errorf(\"none of the selected services is configured for watch, consider setting an 'develop' section\")\n",
      "\t}\n",
      "\toptions.LogTo.Log(api.WatchLogger, \"watch enabled\")\n",
      "\treturn eg.Wait()\n",
      "}\n",
      "func (d *DryRunClient) ConfigCreate(ctx context.Context, config swarm.ConfigSpec) (moby.ConfigCreateResponse, error) {\n",
      "\treturn d.apiClient.ConfigCreate(ctx, config)\n",
      "}\n",
      "func (d *DryRunClient) NetworkConnect(ctx context.Context, networkName, container string, config *network.EndpointSettings) error {\n",
      "\treturn nil\n",
      "}\n",
      "func osDependentRunDir() (string, error) {\n",
      "\tflags := []uint32{windows.KF_FLAG_DEFAULT, windows.KF_FLAG_DEFAULT_PATH}\n",
      "\tfor _, flag := range flags {\n",
      "\t\tp, _ := windows.KnownFolderPath(windows.FOLDERID_LocalAppData, flag|windows.KF_FLAG_DONT_VERIFY)\n",
      "\t\tif p != \"\" {\n",
      "\t\t\treturn filepath.Join(p, \"docker-compose\"), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tappData, ok := os.LookupEnv(\"LOCALAPPDATA\")\n",
      "\tif ok {\n",
      "\t\treturn filepath.Join(appData, \"docker-compose\"), nil\n",
      "\t}\n",
      "\thome, err := os.UserHomeDir()\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", err\n",
      "\t}\n",
      "\treturn filepath.Join(home, \"AppData\", \"Local\", \"docker-compose\"), nil\n",
      "}\n",
      "func (d *DryRunClient) ConfigUpdate(ctx context.Context, id string, version swarm.Version, config swarm.ConfigSpec) error {\n",
      "\treturn d.apiClient.ConfigUpdate(ctx, id, version, config)\n",
      "}\n",
      "func (d *DryRunClient) ContainerExecStart(ctx context.Context, execID string, config moby.ExecStartCheck) error {\n",
      "\tv, ok := d.execs.LoadAndDelete(execID)\n",
      "\tif !ok {\n",
      "\t\treturn fmt.Errorf(\"invalid exec ID %q\", execID)\n",
      "\t}\n",
      "\tdetails := v.(execDetails)\n",
      "\tfmt.Printf(\"%sExecuting command %q in %s (detached mode)\\n\", DRYRUN_PREFIX, details.command, details.container)\n",
      "\treturn nil\n",
      "}\n",
      "func createEndpointSettings(p *types.Project, service types.ServiceConfig, serviceIndex int, networkKey string, links []string, useNetworkAliases bool) *network.EndpointSettings {\n",
      "\tconfig := service.Networks[networkKey]\n",
      "\tvar ipam *network.EndpointIPAMConfig\n",
      "\tvar (\n",
      "\t\tipv4Address\tstring\n",
      "\t\tipv6Address\tstring\n",
      "\t\tmacAddress\tstring\n",
      "\t)\n",
      "\tif config != nil {\n",
      "\t\tipv4Address = config.Ipv4Address\n",
      "\t\tipv6Address = config.Ipv6Address\n",
      "\t\tipam = &network.EndpointIPAMConfig{IPv4Address: ipv4Address, IPv6Address: ipv6Address, LinkLocalIPs: config.LinkLocalIPs}\n",
      "\t\tmacAddress = config.MacAddress\n",
      "\t}\n",
      "\treturn &network.EndpointSettings{Aliases: getAliases(p, service, serviceIndex, networkKey, useNetworkAliases), Links: links, IPAddress: ipv4Address, IPv6Gateway: ipv6Address, IPAMConfig: ipam, MacAddress: macAddress}\n",
      "}\n",
      "func resolveImageDigests(ctx context.Context, dockerCli command.Cli, model map[string]any) (err error) {\n",
      "\tp := &types.Project{Services: types.Services{}}\n",
      "\tservices := model[\"services\"].(map[string]any)\n",
      "\tfor name, s := range services {\n",
      "\t\tservice := s.(map[string]any)\n",
      "\t\tif image, ok := service[\"image\"]; ok {\n",
      "\t\t\tp.Services[name] = types.ServiceConfig{Image: image.(string)}\n",
      "\t\t}\n",
      "\t}\n",
      "\tp, err = p.WithImagesResolved(compose.ImageDigestResolver(ctx, dockerCli.ConfigFile(), dockerCli.Client()))\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tfor name, s := range services {\n",
      "\t\tservice := s.(map[string]any)\n",
      "\t\tconfig := p.Services[name]\n",
      "\t\tif config.Image != \"\" {\n",
      "\t\t\tservice[\"image\"] = config.Image\n",
      "\t\t}\n",
      "\t\tservices[name] = service\n",
      "\t}\n",
      "\tmodel[\"services\"] = services\n",
      "\treturn nil\n",
      "}\n",
      "func (d *DryRunClient) ContainerExecCreate(ctx context.Context, container string, config moby.ExecConfig) (moby.IDResponse, error) {\n",
      "\tb := make([]byte, 32)\n",
      "\t_, _ = rand.Read(b)\n",
      "\tid := fmt.Sprintf(\"%x\", b)\n",
      "\td.execs.Store(id, execDetails{container: container, command: config.Cmd})\n",
      "\treturn moby.IDResponse{ID: id}, nil\n",
      "}\n",
      "func ToMobyEnv(environment compose.MappingWithEquals) []string {\n",
      "\tvar env []string\n",
      "\tfor k, v := range environment {\n",
      "\t\tif v == nil {\n",
      "\t\t\tenv = append(env, k)\n",
      "\t\t} else {\n",
      "\t\t\tenv = append(env, fmt.Sprintf(\"%s=%s\", k, *v))\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn env\n",
      "}\n",
      "func (s *composeService) resolveOrCreateNetwork(ctx context.Context, n *types.NetworkConfig) error {\n",
      "\texpectedNetworkLabel := n.Labels[api.NetworkLabel]\n",
      "\texpectedProjectLabel := n.Labels[api.ProjectLabel]\n",
      "\tinspect, err := s.apiClient().NetworkInspect(ctx, n.Name, moby.NetworkInspectOptions{})\n",
      "\tif err == nil {\n",
      "\t\tif inspect.Name == n.Name || inspect.ID == n.Name {\n",
      "\t\t\tp, ok := inspect.Labels[api.ProjectLabel]\n",
      "\t\t\tif !ok {\n",
      "\t\t\t\tlogrus.Warnf(\"a network with name %s exists but was not created by compose.\\n\"+\"Set `external: true` to use an existing network\", n.Name)\n",
      "\t\t\t} else if p != expectedProjectLabel {\n",
      "\t\t\t\tlogrus.Warnf(\"a network with name %s exists but was not created for project %q.\\n\"+\"Set `external: true` to use an existing network\", n.Name, expectedProjectLabel)\n",
      "\t\t\t}\n",
      "\t\t\tif inspect.Labels[api.NetworkLabel] != expectedNetworkLabel {\n",
      "\t\t\t\treturn fmt.Errorf(\"network %s was found but has incorrect label %s set to %q\", n.Name, api.NetworkLabel, inspect.Labels[api.NetworkLabel])\n",
      "\t\t\t}\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tnetworks, err := s.apiClient().NetworkList(ctx, moby.NetworkListOptions{Filters: filters.NewArgs(filters.Arg(\"name\", n.Name))})\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tnetworks = utils.Filter(networks, func(net moby.NetworkResource) bool {\n",
      "\t\treturn net.Name == n.Name\n",
      "\t})\n",
      "\tfor _, net := range networks {\n",
      "\t\tif net.Labels[api.ProjectLabel] == expectedProjectLabel && net.Labels[api.NetworkLabel] == expectedNetworkLabel {\n",
      "\t\t\treturn nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tif len(networks) > 0 {\n",
      "\t\tlogrus.Warnf(\"a network with name %s exists but was not created by compose.\\n\"+\"Set `external: true` to use an existing network\", n.Name)\n",
      "\t\treturn nil\n",
      "\t}\n",
      "\tvar ipam *network.IPAM\n",
      "\tif n.Ipam.Config != nil {\n",
      "\t\tvar config []network.IPAMConfig\n",
      "\t\tfor _, pool := range n.Ipam.Config {\n",
      "\t\t\tconfig = append(config, network.IPAMConfig{Subnet: pool.Subnet, IPRange: pool.IPRange, Gateway: pool.Gateway, AuxAddress: pool.AuxiliaryAddresses})\n",
      "\t\t}\n",
      "\t\tipam = &network.IPAM{Driver: n.Ipam.Driver, Config: config}\n",
      "\t}\n",
      "\tcreateOpts := moby.NetworkCreate{CheckDuplicate: true, Labels: n.Labels, Driver: n.Driver, Options: n.DriverOpts, Internal: n.Internal, Attachable: n.Attachable, IPAM: ipam, EnableIPv6: n.EnableIPv6}\n",
      "\tif n.Ipam.Driver != \"\" || len(n.Ipam.Config) > 0 {\n",
      "\t\tcreateOpts.IPAM = &network.IPAM{}\n",
      "\t}\n",
      "\tif n.Ipam.Driver != \"\" {\n",
      "\t\tcreateOpts.IPAM.Driver = n.Ipam.Driver\n",
      "\t}\n",
      "\tfor _, ipamConfig := range n.Ipam.Config {\n",
      "\t\tconfig := network.IPAMConfig{Subnet: ipamConfig.Subnet, IPRange: ipamConfig.IPRange, Gateway: ipamConfig.Gateway, AuxAddress: ipamConfig.AuxiliaryAddresses}\n",
      "\t\tcreateOpts.IPAM.Config = append(createOpts.IPAM.Config, config)\n",
      "\t}\n",
      "\tnetworkEventName := fmt.Sprintf(\"Network %s\", n.Name)\n",
      "\tw := progress.ContextWriter(ctx)\n",
      "\tw.Event(progress.CreatingEvent(networkEventName))\n",
      "\t_, err = s.apiClient().NetworkCreate(ctx, n.Name, createOpts)\n",
      "\tif err != nil {\n",
      "\t\tw.Event(progress.ErrorEvent(networkEventName))\n",
      "\t\treturn fmt.Errorf(\"failed to create network %s: %w\", n.Name, err)\n",
      "\t}\n",
      "\tw.Event(progress.CreatedEvent(networkEventName))\n",
      "\treturn nil\n",
      "}\n",
      "func (g gitRemoteLoader) gitCommandEnv() []string {\n",
      "\tenv := types.NewMapping(os.Environ())\n",
      "\tif env[\"GIT_TERMINAL_PROMPT\"] == \"\" {\n",
      "\t\tenv[\"GIT_TERMINAL_PROMPT\"] = \"0\"\n",
      "\t}\n",
      "\tif env[\"GIT_SSH\"] == \"\" && env[\"GIT_SSH_COMMAND\"] == \"\" {\n",
      "\t\tenv[\"GIT_SSH_COMMAND\"] = \"ssh -o ControlMaster=no -o BatchMode=yes\"\n",
      "\t}\n",
      "\tv := env.Values()\n",
      "\treturn v\n",
      "}\n",
      "func configCommand(p *ProjectOptions, dockerCli command.Cli) *cobra.Command {\n",
      "\topts := configOptions{ProjectOptions: p}\n",
      "\tcmd := &cobra.Command{Aliases: []string{\"convert\"}, Use: \"config [OPTIONS] [SERVICE...]\", Short: \"Parse, resolve and render compose file in canonical format\", PreRunE: Adapt(func(ctx context.Context, args []string) error {\n",
      "\t\tif opts.quiet {\n",
      "\t\t\tdevnull, err := os.Open(os.DevNull)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tos.Stdout = devnull\n",
      "\t\t}\n",
      "\t\tif p.Compatibility {\n",
      "\t\t\topts.noNormalize = true\n",
      "\t\t}\n",
      "\t\treturn nil\n",
      "\t}), RunE: Adapt(func(ctx context.Context, args []string) error {\n",
      "\t\tif opts.services {\n",
      "\t\t\treturn runServices(ctx, dockerCli, opts)\n",
      "\t\t}\n",
      "\t\tif opts.volumes {\n",
      "\t\t\treturn runVolumes(ctx, dockerCli, opts)\n",
      "\t\t}\n",
      "\t\tif opts.hash != \"\" {\n",
      "\t\t\treturn runHash(ctx, dockerCli, opts)\n",
      "\t\t}\n",
      "\t\tif opts.profiles {\n",
      "\t\t\treturn runProfiles(ctx, dockerCli, opts, args)\n",
      "\t\t}\n",
      "\t\tif opts.images {\n",
      "\t\t\treturn runConfigImages(ctx, dockerCli, opts, args)\n",
      "\t\t}\n",
      "\t\treturn runConfig(ctx, dockerCli, opts, args)\n",
      "\t}), ValidArgsFunction: completeServiceNames(dockerCli, p)}\n",
      "\tflags := cmd.Flags()\n",
      "\tflags.StringVar(&opts.Format, \"format\", \"yaml\", \"Format the output. Values: [yaml | json]\")\n",
      "\tflags.BoolVar(&opts.resolveImageDigests, \"resolve-image-digests\", false, \"Pin image tags to digests\")\n",
      "\tflags.BoolVarP(&opts.quiet, \"quiet\", \"q\", false, \"Only validate the configuration, don't print anything\")\n",
      "\tflags.BoolVar(&opts.noInterpolate, \"no-interpolate\", false, \"Don't interpolate environment variables\")\n",
      "\tflags.BoolVar(&opts.noNormalize, \"no-normalize\", false, \"Don't normalize compose model\")\n",
      "\tflags.BoolVar(&opts.noResolvePath, \"no-path-resolution\", false, \"Don't resolve file paths\")\n",
      "\tflags.BoolVar(&opts.noConsistency, \"no-consistency\", false, \"Don't check model consistency - warning: may produce invalid Compose output\")\n",
      "\tflags.BoolVar(&opts.services, \"services\", false, \"Print the service names, one per line\")\n",
      "\tflags.BoolVar(&opts.volumes, \"volumes\", false, \"Print the volume names, one per line\")\n",
      "\tflags.BoolVar(&opts.profiles, \"profiles\", false, \"Print the profile names, one per line\")\n",
      "\tflags.BoolVar(&opts.images, \"images\", false, \"Print the image names, one per line\")\n",
      "\tflags.StringVar(&opts.hash, \"hash\", \"\", \"Print the service config hash, one per line\")\n",
      "\tflags.StringVarP(&opts.Output, \"output\", \"o\", \"\", \"Save to file (default to stdout)\")\n",
      "\treturn cmd\n",
      "}\n",
      "func (s *composeService) injectSecrets(ctx context.Context, project *types.Project, service types.ServiceConfig, id string) error {\n",
      "\tfor _, config := range service.Secrets {\n",
      "\t\tfile := project.Secrets[config.Source]\n",
      "\t\tif file.Environment == \"\" {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif config.Target == \"\" {\n",
      "\t\t\tconfig.Target = \"/run/secrets/\" + config.Source\n",
      "\t\t} else if !isAbsTarget(config.Target) {\n",
      "\t\t\tconfig.Target = \"/run/secrets/\" + config.Target\n",
      "\t\t}\n",
      "\t\tenv, ok := project.Environment[file.Environment]\n",
      "\t\tif !ok {\n",
      "\t\t\treturn fmt.Errorf(\"environment variable %q required by file %q is not set\", file.Environment, file.Name)\n",
      "\t\t}\n",
      "\t\tb, err := createTar(env, types.FileReferenceConfig(config))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\terr = s.apiClient().CopyToContainer(ctx, id, \"/\", &b, moby.CopyToContainerOptions{CopyUIDGID: config.UID != \"\" || config.GID != \"\"})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func initializePlugins(t testing.TB, configDir string) {\n",
      "\tt.Helper()\n",
      "\tt.Cleanup(func() {\n",
      "\t\tif t.Failed() {\n",
      "\t\t\tif conf, err := os.ReadFile(filepath.Join(configDir, \"config.json\")); err == nil {\n",
      "\t\t\t\tt.Logf(\"Config: %s\\n\", string(conf))\n",
      "\t\t\t}\n",
      "\t\t\tt.Log(\"Contents of config dir:\")\n",
      "\t\t\tfor _, p := range dirContents(configDir) {\n",
      "\t\t\t\tt.Logf(\"  - %s\", p)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t})\n",
      "\trequire.NoError(t, os.MkdirAll(filepath.Join(configDir, \"cli-plugins\"), 0o755), \"Failed to create cli-plugins directory\")\n",
      "\tcomposePlugin, err := findExecutable(DockerComposeExecutableName)\n",
      "\tif errors.Is(err, fs.ErrNotExist) {\n",
      "\t\tt.Logf(\"WARNING: docker-compose cli-plugin not found\")\n",
      "\t}\n",
      "\tif err == nil {\n",
      "\t\tCopyFile(t, composePlugin, filepath.Join(configDir, \"cli-plugins\", DockerComposeExecutableName))\n",
      "\t\tbuildxPlugin, err := findPluginExecutable(DockerBuildxExecutableName)\n",
      "\t\tif err != nil {\n",
      "\t\t\tt.Logf(\"WARNING: docker-buildx cli-plugin not found, using default buildx installation.\")\n",
      "\t\t} else {\n",
      "\t\t\tCopyFile(t, buildxPlugin, filepath.Join(configDir, \"cli-plugins\", DockerBuildxExecutableName))\n",
      "\t\t}\n",
      "\t\tCopyFile(t, composePlugin, filepath.Join(configDir, \"cli-plugins\", DockerScanExecutableName))\n",
      "\t}\n",
      "}\n",
      "func loadDevelopmentConfig(service types.ServiceConfig, project *types.Project) (*types.DevelopConfig, error) {\n",
      "\tvar config types.DevelopConfig\n",
      "\ty, ok := service.Extensions[\"x-develop\"]\n",
      "\tif !ok {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tlogrus.Warnf(\"x-develop is DEPRECATED, please use the official `develop` attribute\")\n",
      "\terr := mapstructure.Decode(y, &config)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\tbaseDir, err := filepath.EvalSymlinks(project.WorkingDir)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"resolving symlink for %q: %w\", project.WorkingDir, err)\n",
      "\t}\n",
      "\tfor i, trigger := range config.Watch {\n",
      "\t\tif !filepath.IsAbs(trigger.Path) {\n",
      "\t\t\ttrigger.Path = filepath.Join(baseDir, trigger.Path)\n",
      "\t\t}\n",
      "\t\tif p, err := filepath.EvalSymlinks(trigger.Path); err == nil {\n",
      "\t\t\ttrigger.Path = p\n",
      "\t\t}\n",
      "\t\ttrigger.Path = filepath.Clean(trigger.Path)\n",
      "\t\tif trigger.Path == \"\" {\n",
      "\t\t\treturn nil, errors.New(\"watch rules MUST define a path\")\n",
      "\t\t}\n",
      "\t\tif trigger.Action == types.WatchActionRebuild && service.Build == nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"service %s doesn't have a build section, can't apply 'rebuild' on watch\", service.Name)\n",
      "\t\t}\n",
      "\t\tconfig.Watch[i] = trigger\n",
      "\t}\n",
      "\treturn &config, nil\n",
      "}\n",
      "func buildContainerConfigMounts(p types.Project, s types.ServiceConfig) ([]mount.Mount, error) {\n",
      "\tvar mounts = map[string]mount.Mount{}\n",
      "\tconfigsBaseDir := \"/\"\n",
      "\tfor _, config := range s.Configs {\n",
      "\t\ttarget := config.Target\n",
      "\t\tif config.Target == \"\" {\n",
      "\t\t\ttarget = configsBaseDir + config.Source\n",
      "\t\t} else if !isAbsTarget(config.Target) {\n",
      "\t\t\ttarget = configsBaseDir + config.Target\n",
      "\t\t}\n",
      "\t\tif config.UID != \"\" || config.GID != \"\" || config.Mode != nil {\n",
      "\t\t\tlogrus.Warn(\"config `uid`, `gid` and `mode` are not supported, they will be ignored\")\n",
      "\t\t}\n",
      "\t\tdefinedConfig := p.Configs[config.Source]\n",
      "\t\tif definedConfig.External {\n",
      "\t\t\treturn nil, fmt.Errorf(\"unsupported external config %s\", definedConfig.Name)\n",
      "\t\t}\n",
      "\t\tif definedConfig.Driver != \"\" {\n",
      "\t\t\treturn nil, errors.New(\"Docker Compose does not support configs.*.driver\")\n",
      "\t\t}\n",
      "\t\tif definedConfig.TemplateDriver != \"\" {\n",
      "\t\t\treturn nil, errors.New(\"Docker Compose does not support configs.*.template_driver\")\n",
      "\t\t}\n",
      "\t\tif definedConfig.Environment != \"\" || definedConfig.Content != \"\" {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tbindMount, err := buildMount(p, types.ServiceVolumeConfig{Type: types.VolumeTypeBind, Source: definedConfig.File, Target: target, ReadOnly: true})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn nil, err\n",
      "\t\t}\n",
      "\t\tmounts[target] = bindMount\n",
      "\t}\n",
      "\tvalues := make([]mount.Mount, 0, len(mounts))\n",
      "\tfor _, v := range mounts {\n",
      "\t\tvalues = append(values, v)\n",
      "\t}\n",
      "\treturn values, nil\n",
      "}\n",
      "func (c *CLI) BaseEnvironment() []string {\n",
      "\tenv := []string{\"HOME=\" + c.HomeDir, \"USER=\" + os.Getenv(\"USER\"), \"DOCKER_CONFIG=\" + c.ConfigDir, \"KUBECONFIG=invalid\", \"PATH=\" + os.Getenv(\"PATH\")}\n",
      "\tdockerContextEnv, ok := os.LookupEnv(\"DOCKER_CONTEXT\")\n",
      "\tif ok {\n",
      "\t\tenv = append(env, \"DOCKER_CONTEXT=\"+dockerContextEnv)\n",
      "\t}\n",
      "\tif coverdir, ok := os.LookupEnv(\"GOCOVERDIR\"); ok {\n",
      "\t\t_, filename, _, _ := runtime.Caller(0)\n",
      "\t\troot := filepath.Join(filepath.Dir(filename), \"..\", \"..\")\n",
      "\t\tcoverdir = filepath.Join(root, coverdir)\n",
      "\t\tenv = append(env, fmt.Sprintf(\"GOCOVERDIR=%s\", coverdir))\n",
      "\t}\n",
      "\treturn env\n",
      "}\n",
      "func osDependentCacheDir() (string, error) {\n",
      "\tflags := []uint32{windows.KF_FLAG_DEFAULT, windows.KF_FLAG_DEFAULT_PATH}\n",
      "\tfor _, flag := range flags {\n",
      "\t\tp, _ := windows.KnownFolderPath(windows.FOLDERID_LocalAppData, flag|windows.KF_FLAG_DONT_VERIFY)\n",
      "\t\tif p != \"\" {\n",
      "\t\t\treturn filepath.Join(p, \"cache\", \"docker-compose\"), nil\n",
      "\t\t}\n",
      "\t}\n",
      "\tappData, ok := os.LookupEnv(\"LOCALAPPDATA\")\n",
      "\tif ok {\n",
      "\t\treturn filepath.Join(appData, \"cache\", \"docker-compose\"), nil\n",
      "\t}\n",
      "\thome, err := os.UserHomeDir()\n",
      "\tif err != nil {\n",
      "\t\treturn \"\", err\n",
      "\t}\n",
      "\treturn filepath.Join(home, \"AppData\", \"Local\", \"cache\", \"docker-compose\"), nil\n",
      "}\n",
      "func (s *composeService) create(ctx context.Context, project *types.Project, options api.CreateOptions) error {\n",
      "\tif len(options.Services) == 0 {\n",
      "\t\toptions.Services = project.ServiceNames()\n",
      "\t}\n",
      "\tvar observedState Containers\n",
      "\tobservedState, err := s.getContainers(ctx, project.Name, oneOffInclude, true)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\terr = s.ensureImagesExists(ctx, project, options.Build, options.QuietPull)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tprepareNetworks(project)\n",
      "\tif err := s.ensureNetworks(ctx, project.Networks); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tif err := s.ensureProjectVolumes(ctx, project); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tallServiceNames := append(project.ServiceNames(), project.DisabledServiceNames()...)\n",
      "\torphans := observedState.filter(isNotService(allServiceNames...))\n",
      "\tif len(orphans) > 0 && !options.IgnoreOrphans {\n",
      "\t\tif options.RemoveOrphans {\n",
      "\t\t\terr := s.removeContainers(ctx, orphans, nil, false)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tlogrus.Warnf(\"Found orphan containers (%s) for this project. If \"+\"you removed or renamed this service in your compose \"+\"file, you can run this command with the \"+\"--remove-orphans flag to clean it up.\", orphans.names())\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn newConvergence(options.Services, observedState, s).apply(ctx, project, options)\n",
      "}\n",
      "func (s *composeService) copy(ctx context.Context, projectName string, options api.CopyOptions) error {\n",
      "\tprojectName = strings.ToLower(projectName)\n",
      "\tsrcService, srcPath := splitCpArg(options.Source)\n",
      "\tdestService, dstPath := splitCpArg(options.Destination)\n",
      "\tvar direction copyDirection\n",
      "\tvar serviceName string\n",
      "\tvar copyFunc func(ctx context.Context, containerID string, srcPath string, dstPath string, opts api.CopyOptions) error\n",
      "\tif srcService != \"\" {\n",
      "\t\tdirection |= fromService\n",
      "\t\tserviceName = srcService\n",
      "\t\tcopyFunc = s.copyFromContainer\n",
      "\t\tif options.All {\n",
      "\t\t\treturn errors.New(\"cannot use the --all flag when copying from a service\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tif destService != \"\" {\n",
      "\t\tdirection |= toService\n",
      "\t\tserviceName = destService\n",
      "\t\tcopyFunc = s.copyToContainer\n",
      "\t}\n",
      "\tif direction == acrossServices {\n",
      "\t\treturn errors.New(\"copying between services is not supported\")\n",
      "\t}\n",
      "\tif direction == 0 {\n",
      "\t\treturn errors.New(\"unknown copy direction\")\n",
      "\t}\n",
      "\tcontainers, err := s.listContainersTargetedForCopy(ctx, projectName, options.Index, direction, serviceName)\n",
      "\tif err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tw := progress.ContextWriter(ctx)\n",
      "\tg := errgroup.Group{}\n",
      "\tfor _, cont := range containers {\n",
      "\t\tcontainer := cont\n",
      "\t\tg.Go(func() error {\n",
      "\t\t\tname := getCanonicalContainerName(container)\n",
      "\t\t\tvar msg string\n",
      "\t\t\tif direction == fromService {\n",
      "\t\t\t\tmsg = fmt.Sprintf(\"copy %s:%s to %s\", name, srcPath, dstPath)\n",
      "\t\t\t} else {\n",
      "\t\t\t\tmsg = fmt.Sprintf(\"copy %s to %s:%s\", srcPath, name, dstPath)\n",
      "\t\t\t}\n",
      "\t\t\tw.Event(progress.Event{ID: name, Text: msg, Status: progress.Working, StatusText: \"Copying\"})\n",
      "\t\t\tif err := copyFunc(ctx, container.ID, srcPath, dstPath, options); err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t\tw.Event(progress.Event{ID: name, Text: msg, Status: progress.Done, StatusText: \"Copied\"})\n",
      "\t\t\treturn nil\n",
      "\t\t})\n",
      "\t}\n",
      "\treturn g.Wait()\n",
      "}\n",
      "func addSecretsConfig(project *types.Project, service types.ServiceConfig) (session.Attachable, error) {\n",
      "\tvar sources []secretsprovider.Source\n",
      "\tfor _, secret := range service.Build.Secrets {\n",
      "\t\tconfig := project.Secrets[secret.Source]\n",
      "\t\tid := secret.Source\n",
      "\t\tif secret.Target != \"\" {\n",
      "\t\t\tid = secret.Target\n",
      "\t\t}\n",
      "\t\tswitch {\n",
      "\t\tcase config.File != \"\":\n",
      "\t\t\tsources = append(sources, secretsprovider.Source{ID: id, FilePath: config.File})\n",
      "\t\tcase config.Environment != \"\":\n",
      "\t\t\tsources = append(sources, secretsprovider.Source{ID: id, Env: config.Environment})\n",
      "\t\tdefault:\n",
      "\t\t\treturn nil, fmt.Errorf(\"build.secrets only supports environment or file-based secrets: %q\", secret.Source)\n",
      "\t\t}\n",
      "\t\tif secret.UID != \"\" || secret.GID != \"\" || secret.Mode != nil {\n",
      "\t\t\tlogrus.Warn(\"secrets `uid`, `gid` and `mode` are not supported by BuildKit, they will be ignored\")\n",
      "\t\t}\n",
      "\t}\n",
      "\tstore, err := secretsprovider.NewStore(sources)\n",
      "\tif err != nil {\n",
      "\t\treturn nil, err\n",
      "\t}\n",
      "\treturn secretsprovider.NewSecretProvider(store), nil\n",
      "}\n",
      "func (d *DryRunClient) ContainerExecAttach(ctx context.Context, execID string, config moby.ExecStartCheck) (moby.HijackedResponse, error) {\n",
      "\treturn moby.HijackedResponse{}, errors.New(\"interactive exec is not supported in dry-run mode\")\n",
      "}\n",
      "func traceClientFromDockerContext(dockerCli command.Cli, otelEnv envMap) (otlptrace.Client, error) {\n",
      "\tcfg, err := ConfigFromDockerContext(dockerCli.ContextStore(), dockerCli.CurrentContext())\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"loading otel config from docker context metadata: %w\", err)\n",
      "\t}\n",
      "\tif cfg.Endpoint == \"\" {\n",
      "\t\treturn nil, nil\n",
      "\t}\n",
      "\tdefer func() {\n",
      "\t\tfor k, v := range otelEnv {\n",
      "\t\t\tif err := os.Setenv(k, v); err != nil {\n",
      "\t\t\t\tpanic(fmt.Errorf(\"restoring env for %q: %w\", k, err))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}()\n",
      "\tfor k := range otelEnv {\n",
      "\t\tif err := os.Unsetenv(k); err != nil {\n",
      "\t\t\treturn nil, fmt.Errorf(\"stashing env for %q: %w\", k, err)\n",
      "\t\t}\n",
      "\t}\n",
      "\tdialCtx, cancel := context.WithTimeout(context.Background(), 1*time.Second)\n",
      "\tdefer cancel()\n",
      "\tconn, err := grpc.DialContext(dialCtx, cfg.Endpoint, grpc.WithContextDialer(DialInMemory), grpc.WithTransportCredentials(insecure.NewCredentials()))\n",
      "\tif err != nil {\n",
      "\t\treturn nil, fmt.Errorf(\"initializing otel connection from docker context metadata: %w\", err)\n",
      "\t}\n",
      "\tclient := otlptracegrpc.NewClient(otlptracegrpc.WithGRPCConn(conn))\n",
      "\treturn client, nil\n",
      "}\n",
      "func (s *composeService) getCreateConfigs(ctx context.Context, p *types.Project, service types.ServiceConfig, number int, inherit *moby.Container, opts createOptions) (createConfigs, error) {\n",
      "\tlabels, err := s.prepareLabels(opts.Labels, service, number)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\tvar (\n",
      "\t\trunCmd\t\tstrslice.StrSlice\n",
      "\t\tentrypoint\tstrslice.StrSlice\n",
      "\t)\n",
      "\tif service.Command != nil {\n",
      "\t\trunCmd = strslice.StrSlice(service.Command)\n",
      "\t}\n",
      "\tif service.Entrypoint != nil {\n",
      "\t\tentrypoint = strslice.StrSlice(service.Entrypoint)\n",
      "\t}\n",
      "\tvar (\n",
      "\t\ttty\t\t= service.Tty\n",
      "\t\tstdinOpen\t= service.StdinOpen\n",
      "\t)\n",
      "\tproxyConfig := types.MappingWithEquals(s.configFile().ParseProxyConfig(s.apiClient().DaemonHost(), nil))\n",
      "\tenv := proxyConfig.OverrideBy(service.Environment)\n",
      "\tvar mainNwName string\n",
      "\tvar mainNw *types.ServiceNetworkConfig\n",
      "\tif len(service.Networks) > 0 {\n",
      "\t\tmainNwName = service.NetworksByPriority()[0]\n",
      "\t\tmainNw = service.Networks[mainNwName]\n",
      "\t}\n",
      "\tmacAddress, err := s.prepareContainerMACAddress(ctx, service, mainNw, mainNwName)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\thealthcheck, err := s.ToMobyHealthCheck(ctx, service.HealthCheck)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\tvar containerConfig = container.Config{Hostname: service.Hostname, Domainname: service.DomainName, User: service.User, ExposedPorts: buildContainerPorts(service), Tty: tty, OpenStdin: stdinOpen, StdinOnce: opts.AttachStdin && stdinOpen, AttachStdin: opts.AttachStdin, AttachStderr: true, AttachStdout: true, Cmd: runCmd, Image: api.GetImageNameOrDefault(service, p.Name), WorkingDir: service.WorkingDir, Entrypoint: entrypoint, NetworkDisabled: service.NetworkMode == \"disabled\", MacAddress: macAddress, Labels: labels, StopSignal: service.StopSignal, Env: ToMobyEnv(env), Healthcheck: healthcheck, StopTimeout: ToSeconds(service.StopGracePeriod)}\n",
      "\ttmpfs := map[string]string{}\n",
      "\tfor _, t := range service.Tmpfs {\n",
      "\t\tif arr := strings.SplitN(t, \":\", 2); len(arr) > 1 {\n",
      "\t\t\ttmpfs[arr[0]] = arr[1]\n",
      "\t\t} else {\n",
      "\t\t\ttmpfs[arr[0]] = \"\"\n",
      "\t\t}\n",
      "\t}\n",
      "\tbinds, mounts, err := s.buildContainerVolumes(ctx, *p, service, inherit)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\tlinks, err := s.getLinks(ctx, p.Name, service, number)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\tapiVersion, err := s.RuntimeVersion(ctx)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\tnetworkMode, networkingConfig := defaultNetworkSettings(p, service, number, links, opts.UseNetworkAliases, apiVersion)\n",
      "\tportBindings := buildContainerPortBindingOptions(service)\n",
      "\tresources := getDeployResources(service)\n",
      "\tvar logConfig container.LogConfig\n",
      "\tif service.Logging != nil {\n",
      "\t\tlogConfig = container.LogConfig{Type: service.Logging.Driver, Config: service.Logging.Options}\n",
      "\t}\n",
      "\tsecurityOpts, unconfined, err := parseSecurityOpts(p, service.SecurityOpt)\n",
      "\tif err != nil {\n",
      "\t\treturn createConfigs{}, err\n",
      "\t}\n",
      "\thostConfig := container.HostConfig{AutoRemove: opts.AutoRemove, Binds: binds, Mounts: mounts, CapAdd: strslice.StrSlice(service.CapAdd), CapDrop: strslice.StrSlice(service.CapDrop), NetworkMode: networkMode, Init: service.Init, IpcMode: container.IpcMode(service.Ipc), CgroupnsMode: container.CgroupnsMode(service.Cgroup), ReadonlyRootfs: service.ReadOnly, RestartPolicy: getRestartPolicy(service), ShmSize: int64(service.ShmSize), Sysctls: service.Sysctls, PortBindings: portBindings, Resources: resources, VolumeDriver: service.VolumeDriver, VolumesFrom: service.VolumesFrom, DNS: service.DNS, DNSSearch: service.DNSSearch, DNSOptions: service.DNSOpts, ExtraHosts: service.ExtraHosts.AsList(\":\"), SecurityOpt: securityOpts, StorageOpt: service.StorageOpt, UsernsMode: container.UsernsMode(service.UserNSMode), UTSMode: container.UTSMode(service.Uts), Privileged: service.Privileged, PidMode: container.PidMode(service.Pid), Tmpfs: tmpfs, Isolation: container.Isolation(service.Isolation), Runtime: service.Runtime, LogConfig: logConfig, GroupAdd: service.GroupAdd, Links: links, OomScoreAdj: int(service.OomScoreAdj)}\n",
      "\tif unconfined {\n",
      "\t\thostConfig.MaskedPaths = []string{}\n",
      "\t\thostConfig.ReadonlyPaths = []string{}\n",
      "\t}\n",
      "\tcfgs := createConfigs{Container: &containerConfig, Host: &hostConfig, Network: networkingConfig, Links: links}\n",
      "\treturn cfgs, nil\n",
      "}\n",
      "func (s *composeService) injectConfigs(ctx context.Context, project *types.Project, service types.ServiceConfig, id string) error {\n",
      "\tfor _, config := range service.Configs {\n",
      "\t\tfile := project.Configs[config.Source]\n",
      "\t\tcontent := file.Content\n",
      "\t\tif file.Environment != \"\" {\n",
      "\t\t\tenv, ok := project.Environment[file.Environment]\n",
      "\t\t\tif !ok {\n",
      "\t\t\t\treturn fmt.Errorf(\"environment variable %q required by file %q is not set\", file.Environment, file.Name)\n",
      "\t\t\t}\n",
      "\t\t\tcontent = env\n",
      "\t\t}\n",
      "\t\tif content == \"\" {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tif config.Target == \"\" {\n",
      "\t\t\tconfig.Target = \"/\" + config.Source\n",
      "\t\t}\n",
      "\t\tb, err := createTar(content, types.FileReferenceConfig(config))\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t\terr = s.apiClient().CopyToContainer(ctx, id, \"/\", &b, moby.CopyToContainerOptions{CopyUIDGID: config.UID != \"\" || config.GID != \"\"})\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func imageBuildOptions(dockerCli command.Cli, project *types.Project, service types.ServiceConfig, options api.BuildOptions) dockertypes.ImageBuildOptions {\n",
      "\tconfig := service.Build\n",
      "\treturn dockertypes.ImageBuildOptions{Version: dockertypes.BuilderV1, Tags: config.Tags, NoCache: config.NoCache, Remove: true, PullParent: config.Pull, BuildArgs: resolveAndMergeBuildArgs(dockerCli, project, service, options), Labels: config.Labels, NetworkMode: config.Network, ExtraHosts: config.ExtraHosts.AsList(\":\"), Target: config.Target, Isolation: container.Isolation(config.Isolation)}\n",
      "}\n",
      "func (d *DryRunClient) ContainerCreate(ctx context.Context, config *containerType.Config, hostConfig *containerType.HostConfig, networkingConfig *network.NetworkingConfig, platform *specs.Platform, containerName string) (containerType.CreateResponse, error) {\n",
      "\td.containers = append(d.containers, moby.Container{ID: containerName, Names: []string{containerName}, Labels: config.Labels, HostConfig: struct {\n",
      "\t\tNetworkMode string `json:\",omitempty\"`\n",
      "\t}{}})\n",
      "\treturn containerType.CreateResponse{ID: containerName}, nil\n",
      "}\n",
      "func createTar(env string, config types.FileReferenceConfig) (bytes.Buffer, error) {\n",
      "\tvalue := []byte(env)\n",
      "\tb := bytes.Buffer{}\n",
      "\ttarWriter := tar.NewWriter(&b)\n",
      "\tmode := uint32(0o444)\n",
      "\tif config.Mode != nil {\n",
      "\t\tmode = *config.Mode\n",
      "\t}\n",
      "\tvar uid, gid int\n",
      "\tif config.UID != \"\" {\n",
      "\t\tv, err := strconv.Atoi(config.UID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn b, err\n",
      "\t\t}\n",
      "\t\tuid = v\n",
      "\t}\n",
      "\tif config.GID != \"\" {\n",
      "\t\tv, err := strconv.Atoi(config.GID)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn b, err\n",
      "\t\t}\n",
      "\t\tgid = v\n",
      "\t}\n",
      "\theader := &tar.Header{Name: config.Target, Size: int64(len(value)), Mode: int64(mode), ModTime: time.Now(), Uid: uid, Gid: gid}\n",
      "\terr := tarWriter.WriteHeader(header)\n",
      "\tif err != nil {\n",
      "\t\treturn bytes.Buffer{}, err\n",
      "\t}\n",
      "\t_, err = tarWriter.Write(value)\n",
      "\tif err != nil {\n",
      "\t\treturn bytes.Buffer{}, err\n",
      "\t}\n",
      "\terr = tarWriter.Close()\n",
      "\treturn b, err\n",
      "}\n",
      "func (s *composeService) waitDependencies(ctx context.Context, project *types.Project, dependant string, dependencies types.DependsOnConfig, containers Containers) error {\n",
      "\teg, _ := errgroup.WithContext(ctx)\n",
      "\tw := progress.ContextWriter(ctx)\n",
      "\tfor dep, config := range dependencies {\n",
      "\t\tif shouldWait, err := shouldWaitForDependency(dep, config, project); err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t} else if !shouldWait {\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\twaitingFor := containers.filter(isService(dep))\n",
      "\t\tw.Events(containerEvents(waitingFor, progress.Waiting))\n",
      "\t\tif len(waitingFor) == 0 {\n",
      "\t\t\tif config.Required {\n",
      "\t\t\t\treturn fmt.Errorf(\"%s is missing dependency %s\", dependant, dep)\n",
      "\t\t\t}\n",
      "\t\t\tlogrus.Warnf(\"%s is missing dependency %s\", dependant, dep)\n",
      "\t\t\tcontinue\n",
      "\t\t}\n",
      "\t\tdep, config := dep, config\n",
      "\t\teg.Go(func() error {\n",
      "\t\t\tticker := time.NewTicker(500 * time.Millisecond)\n",
      "\t\t\tdefer ticker.Stop()\n",
      "\t\t\tfor {\n",
      "\t\t\t\tselect {\n",
      "\t\t\t\tcase <-ticker.C:\n",
      "\t\t\t\tcase <-ctx.Done():\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t\tswitch config.Condition {\n",
      "\t\t\t\tcase ServiceConditionRunningOrHealthy:\n",
      "\t\t\t\t\thealthy, err := s.isServiceHealthy(ctx, waitingFor, true)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tif !config.Required {\n",
      "\t\t\t\t\t\t\tw.Events(containerReasonEvents(waitingFor, progress.SkippedEvent, fmt.Sprintf(\"optional dependency %q is not running or is unhealthy\", dep)))\n",
      "\t\t\t\t\t\t\tlogrus.Warnf(\"optional dependency %q is not running or is unhealthy: %s\", dep, err.Error())\n",
      "\t\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\treturn err\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif healthy {\n",
      "\t\t\t\t\t\tw.Events(containerEvents(waitingFor, progress.Healthy))\n",
      "\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\tcase types.ServiceConditionHealthy:\n",
      "\t\t\t\t\thealthy, err := s.isServiceHealthy(ctx, waitingFor, false)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\tif !config.Required {\n",
      "\t\t\t\t\t\t\tw.Events(containerReasonEvents(waitingFor, progress.SkippedEvent, fmt.Sprintf(\"optional dependency %q failed to start\", dep)))\n",
      "\t\t\t\t\t\t\tlogrus.Warnf(\"optional dependency %q failed to start: %s\", dep, err.Error())\n",
      "\t\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tw.Events(containerEvents(waitingFor, progress.ErrorEvent))\n",
      "\t\t\t\t\t\treturn fmt.Errorf(\"dependency failed to start: %w\", err)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif healthy {\n",
      "\t\t\t\t\t\tw.Events(containerEvents(waitingFor, progress.Healthy))\n",
      "\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\tcase types.ServiceConditionCompletedSuccessfully:\n",
      "\t\t\t\t\texited, code, err := s.isServiceCompleted(ctx, waitingFor)\n",
      "\t\t\t\t\tif err != nil {\n",
      "\t\t\t\t\t\treturn err\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tif exited {\n",
      "\t\t\t\t\t\tif code == 0 {\n",
      "\t\t\t\t\t\t\tw.Events(containerEvents(waitingFor, progress.Exited))\n",
      "\t\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tmessageSuffix := fmt.Sprintf(\"%q didn't complete successfully: exit %d\", dep, code)\n",
      "\t\t\t\t\t\tif !config.Required {\n",
      "\t\t\t\t\t\t\tw.Events(containerReasonEvents(waitingFor, progress.SkippedEvent, fmt.Sprintf(\"optional dependency %s\", messageSuffix)))\n",
      "\t\t\t\t\t\t\tlogrus.Warnf(\"optional dependency %s\", messageSuffix)\n",
      "\t\t\t\t\t\t\treturn nil\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\tmsg := fmt.Sprintf(\"service %s\", messageSuffix)\n",
      "\t\t\t\t\t\tw.Events(containerReasonEvents(waitingFor, progress.ErrorMessageEvent, msg))\n",
      "\t\t\t\t\t\treturn errors.New(msg)\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\tdefault:\n",
      "\t\t\t\t\tlogrus.Warnf(\"unsupported depends_on condition: %s\", config.Condition)\n",
      "\t\t\t\t\treturn nil\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t})\n",
      "\t}\n",
      "\treturn eg.Wait()\n",
      "}\n",
      "harness/gitness 5 31162\n",
      "5\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (r *SharedRepo) push(ctx context.Context, sourceRef string, destinationRef string, force bool, env ...string) error {\n",
      "\tif err := r.adapter.Push(ctx, r.tmpPath, types.PushOptions{Remote: r.remoteRepoPath, Branch: sourceRef + \":\" + destinationRef, Env: env, Force: force}); err != nil {\n",
      "\t\treturn fmt.Errorf(\"unable to push back to repo from temporary repo: %w\", err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (r *SharedRepo) CommitTreeWithDate(ctx context.Context, parent string, author, committer *types.Identity, treeHash, message string, signoff bool, authorDate, committerDate time.Time) (string, error) {\n",
      "\tenv := []string{\"GIT_AUTHOR_NAME=\" + author.Name, \"GIT_AUTHOR_EMAIL=\" + author.Email, \"GIT_AUTHOR_DATE=\" + authorDate.Format(time.RFC3339), \"GIT_COMMITTER_NAME=\" + committer.Name, \"GIT_COMMITTER_EMAIL=\" + committer.Email, \"GIT_COMMITTER_DATE=\" + committerDate.Format(time.RFC3339)}\n",
      "\tmessageBytes := new(bytes.Buffer)\n",
      "\t_, _ = messageBytes.WriteString(message)\n",
      "\t_, _ = messageBytes.WriteString(\"\\n\")\n",
      "\tvar args []string\n",
      "\tif parent != \"\" {\n",
      "\t\targs = []string{\"commit-tree\", treeHash, \"-p\", parent}\n",
      "\t} else {\n",
      "\t\targs = []string{\"commit-tree\", treeHash}\n",
      "\t}\n",
      "\targs = append(args, \"--no-gpg-sign\")\n",
      "\tif signoff {\n",
      "\t\tgiteaSignature := &gitea.Signature{Name: committer.Name, Email: committer.Email, When: committerDate}\n",
      "\t\t_, _ = messageBytes.WriteString(\"\\n\")\n",
      "\t\t_, _ = messageBytes.WriteString(\"Signed-off-by: \")\n",
      "\t\t_, _ = messageBytes.WriteString(giteaSignature.String())\n",
      "\t}\n",
      "\tstdout := new(bytes.Buffer)\n",
      "\tstderr := new(bytes.Buffer)\n",
      "\tif err := gitea.NewCommand(ctx, args...).Run(&gitea.RunOpts{Env: env, Dir: r.tmpPath, Stdin: messageBytes, Stdout: stdout, Stderr: stderr}); err != nil {\n",
      "\t\treturn \"\", processGiteaErrorf(err, \"unable to commit-tree in temporary repo: %s Error: %v\\nStdout: %s\\nStderr: %s\", r.repoUID, err, stdout, stderr)\n",
      "\t}\n",
      "\treturn strings.TrimSpace(stdout.String()), nil\n",
      "}\n",
      "func (a Adapter) InfoRefs(ctx context.Context, repoPath string, service string, w io.Writer, env ...string) error {\n",
      "\tcmd := &bytes.Buffer{}\n",
      "\tif err := git.NewCommand(ctx, service, \"--stateless-rpc\", \"--advertise-refs\", \".\").Run(&git.RunOpts{Env: env, Dir: repoPath, Stdout: cmd}); err != nil {\n",
      "\t\treturn errors.Internal(err, \"InfoRefs service %s failed\", service)\n",
      "\t}\n",
      "\tif _, err := w.Write(packetWrite(\"# service=git-\" + service + \"\\n\")); err != nil {\n",
      "\t\treturn errors.Internal(err, \"failed to write pktLine in InfoRefs %s service\", service)\n",
      "\t}\n",
      "\tif _, err := w.Write([]byte(\"0000\")); err != nil {\n",
      "\t\treturn errors.Internal(err, \"failed to flush data in InfoRefs %s service\", service)\n",
      "\t}\n",
      "\tif _, err := io.Copy(w, cmd); err != nil {\n",
      "\t\treturn errors.Internal(err, \"streaming InfoRefs %s service failed\", service)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func commitAndSignNoAuthor(ctx context.Context, pr *types.PullRequest, message string, signArg string, tmpBasePath string, env []string) error {\n",
      "\tvar outbuf, errbuf strings.Builder\n",
      "\tif signArg == \"\" {\n",
      "\t\tif err := git.NewCommand(ctx, \"commit\", \"-m\", message).Run(&git.RunOpts{Env: env, Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\treturn processGiteaErrorf(err, \"git commit [%s -> %s]\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, outbuf.String(), errbuf.String())\n",
      "\t\t}\n",
      "\t} else {\n",
      "\t\tif err := git.NewCommand(ctx, \"commit\", signArg, \"-m\", message).Run(&git.RunOpts{Env: env, Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\treturn processGiteaErrorf(err, \"git commit [%s -> %s]\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, outbuf.String(), errbuf.String())\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func runMergeCommand(ctx context.Context, pr *types.PullRequest, mergeMethod enum.MergeMethod, cmd *git.Command, tmpBasePath string, env []string) (runMergeResult, error) {\n",
      "\tvar outbuf, errbuf strings.Builder\n",
      "\tif err := cmd.Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf, Env: env}); err != nil {\n",
      "\t\tif strings.Contains(errbuf.String(), \"refusing to merge unrelated histories\") {\n",
      "\t\t\treturn runMergeResult{}, &types.MergeUnrelatedHistoriesError{Method: mergeMethod, StdOut: outbuf.String(), StdErr: errbuf.String(), Err: err}\n",
      "\t\t}\n",
      "\t\tif _, statErr := os.Stat(filepath.Join(tmpBasePath, \".git\", \"MERGE_HEAD\")); statErr == nil {\n",
      "\t\t\tfiles, cferr := conflictFiles(ctx, pr, env, tmpBasePath)\n",
      "\t\t\tif cferr != nil {\n",
      "\t\t\t\treturn runMergeResult{}, cferr\n",
      "\t\t\t}\n",
      "\t\t\treturn runMergeResult{conflictFiles: files}, nil\n",
      "\t\t}\n",
      "\t\tgiteaErr := &giteaRunStdError{err: err, stderr: errbuf.String()}\n",
      "\t\treturn runMergeResult{}, processGiteaErrorf(giteaErr, \"git merge [%s -> %s]\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, outbuf.String(), errbuf.String())\n",
      "\t}\n",
      "\treturn runMergeResult{}, nil\n",
      "}\n",
      "func (r *SharedRepo) PushTag(ctx context.Context, tagName string, force bool, env ...string) error {\n",
      "\trefTag := GetReferenceFromTagName(tagName)\n",
      "\treturn r.push(ctx, refTag, refTag, force, env...)\n",
      "}\n",
      "func (a Adapter) Config(ctx context.Context, repoPath string, key string, value string) error {\n",
      "\tif repoPath == \"\" {\n",
      "\t\treturn ErrRepositoryPathEmpty\n",
      "\t}\n",
      "\tif key == \"\" {\n",
      "\t\treturn errors.InvalidArgument(\"key cannot be empty\")\n",
      "\t}\n",
      "\tvar outbuf, errbuf strings.Builder\n",
      "\tcmd := command.New(\"config\", command.WithFlag(\"--local\"), command.WithArg(key, value))\n",
      "\terr := cmd.Run(ctx, command.WithDir(repoPath), command.WithStdout(&outbuf), command.WithStderr(&errbuf))\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"git config [%s -> <%s> ]: %w\\n%s\\n%s\", key, value, err, outbuf.String(), errbuf.String())\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (r *SharedRepo) PushDeleteBranch(ctx context.Context, branch string, force bool, env ...string) error {\n",
      "\treturn r.push(ctx, \"\", GetReferenceFromBranchName(branch), force, env...)\n",
      "}\n",
      "func (s *Service) ServicePack(ctx context.Context, w io.Writer, params *ServicePackParams) error {\n",
      "\tif err := params.Validate(); err != nil {\n",
      "\t\treturn err\n",
      "\t}\n",
      "\tvar (\n",
      "\t\trepoPath\tstring\n",
      "\t\tenv\t\t[]string\n",
      "\t)\n",
      "\tswitch params.Service {\n",
      "\tcase \"upload-pack\":\n",
      "\t\tif err := params.ReadParams.Validate(); err != nil {\n",
      "\t\t\treturn errors.InvalidArgument(\"upload-pack requires ReadParams\")\n",
      "\t\t}\n",
      "\t\trepoPath = getFullPathForRepo(s.reposRoot, params.ReadParams.RepoUID)\n",
      "\tcase \"receive-pack\":\n",
      "\t\tif err := params.WriteParams.Validate(); err != nil {\n",
      "\t\t\treturn errors.InvalidArgument(\"receive-pack requires WriteParams\")\n",
      "\t\t}\n",
      "\t\tenv = CreateEnvironmentForPush(ctx, *params.WriteParams)\n",
      "\t\trepoPath = getFullPathForRepo(s.reposRoot, params.WriteParams.RepoUID)\n",
      "\tdefault:\n",
      "\t\treturn errors.InvalidArgument(\"unsupported service provided: %s\", params.Service)\n",
      "\t}\n",
      "\tif params.GitProtocol != \"\" && safeGitProtocolHeader.MatchString(params.GitProtocol) {\n",
      "\t\tenv = append(env, \"GIT_PROTOCOL=\"+params.GitProtocol)\n",
      "\t}\n",
      "\terr := s.adapter.ServicePack(ctx, repoPath, params.Service, params.Data, w, env...)\n",
      "\tif err != nil {\n",
      "\t\treturn fmt.Errorf(\"failed to execute git %s: %w\", params.Service, err)\n",
      "\t}\n",
      "\treturn nil\n",
      "}\n",
      "func (a Adapter) ServicePack(ctx context.Context, repoPath string, service string, stdin io.Reader, stdout io.Writer, env ...string) error {\n",
      "\tenv = append(env, \"SSH_ORIGINAL_COMMAND=\"+service)\n",
      "\tvar (\n",
      "\t\tstderr bytes.Buffer\n",
      "\t)\n",
      "\tcmd := git.NewCommand(ctx, service, \"--stateless-rpc\", repoPath)\n",
      "\tcmd.SetDescription(fmt.Sprintf(\"%s %s %s [repo_path: %s]\", git.GitExecutable, service, \"--stateless-rpc\", repoPath))\n",
      "\terr := cmd.Run(&git.RunOpts{Dir: repoPath, Env: env, Stdout: stdout, Stdin: stdin, Stderr: &stderr, UseContextTimeout: true})\n",
      "\tif err != nil && err.Error() != \"signal: killed\" {\n",
      "\t\tlog.Ctx(ctx).Err(err).Msgf(\"Fail to serve RPC(%s) in %s: %v - %s\", service, repoPath, err, stderr.String())\n",
      "\t}\n",
      "\treturn err\n",
      "}\n",
      "func conflictFiles(ctx context.Context, pr *types.PullRequest, env []string, repoPath string) (files []string, err error) {\n",
      "\tstdout, stderr, err := git.NewCommand(ctx, \"diff\", \"--name-only\", \"--diff-filter=U\", \"--relative\").RunStdString(&git.RunOpts{Env: env, Dir: repoPath})\n",
      "\tif err != nil {\n",
      "\t\treturn nil, processGiteaErrorf(err, \"failed to list conflict files [%s -> %s], stderr: %v, err: %v\", pr.HeadBranch, pr.BaseBranch, stderr, err)\n",
      "\t}\n",
      "\tif len(stdout) > 0 {\n",
      "\t\tfiles = strings.Split(stdout[:len(stdout)-1], \"\\n\")\n",
      "\t}\n",
      "\treturn files, nil\n",
      "}\n",
      "func ProvideScheduler(store Store, executor *Executor, mutexManager lock.MutexManager, pubsubService pubsub.PubSub, config Config) (*Scheduler, error) {\n",
      "\treturn NewScheduler(store, executor, mutexManager, pubsubService, config.InstanceID, config.BackgroundJobsMaxRunning, config.BackgroundJobsRetentionTime)\n",
      "}\n",
      "func (r *SharedRepo) PushBranch(ctx context.Context, sourceBranch string, branch string, force bool, env ...string) error {\n",
      "\treturn r.push(ctx, GetReferenceFromBranchName(sourceBranch), GetReferenceFromBranchName(branch), force, env...)\n",
      "}\n",
      "func (r *SharedRepo) PushDeleteTag(ctx context.Context, tagName string, force bool, env ...string) error {\n",
      "\trefTag := GetReferenceFromTagName(tagName)\n",
      "\treturn r.push(ctx, \"\", refTag, force, env...)\n",
      "}\n",
      "func (r *SharedRepo) PushCommitToBranch(ctx context.Context, commitSHA string, branch string, force bool, env ...string) error {\n",
      "\treturn r.push(ctx, commitSHA, GetReferenceFromBranchName(branch), force, env...)\n",
      "}\n",
      "func (a Adapter) Merge(ctx context.Context, pr *types.PullRequest, mergeMethod enum.MergeMethod, baseBranch string, trackingBranch string, tmpBasePath string, mergeMsg string, identity *types.Identity, env ...string) (types.MergeResult, error) {\n",
      "\tvar (\n",
      "\t\toutbuf, errbuf strings.Builder\n",
      "\t)\n",
      "\tif mergeMsg == \"\" {\n",
      "\t\tmergeMsg = \"Merge commit\"\n",
      "\t}\n",
      "\tstagingBranch := \"staging\"\n",
      "\tsignArg := \"--no-gpg-sign\"\n",
      "\tswitch mergeMethod {\n",
      "\tcase enum.MergeMethodMerge:\n",
      "\t\tcmd := git.NewCommand(ctx, \"merge\", \"--no-ff\", \"--no-commit\", trackingBranch)\n",
      "\t\tresult, err := runMergeCommand(ctx, pr, mergeMethod, cmd, tmpBasePath, env)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"unable to merge tracking into base: %w\", err)\n",
      "\t\t}\n",
      "\t\tif len(result.conflictFiles) > 0 {\n",
      "\t\t\treturn types.MergeResult{ConflictFiles: result.conflictFiles}, nil\n",
      "\t\t}\n",
      "\t\tif err := commitAndSignNoAuthor(ctx, pr, mergeMsg, signArg, tmpBasePath, env); err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"unable to make final commit: %w\", err)\n",
      "\t\t}\n",
      "\tcase enum.MergeMethodSquash:\n",
      "\t\tcmd := git.NewCommand(ctx, \"merge\", \"--squash\", trackingBranch)\n",
      "\t\tresult, err := runMergeCommand(ctx, pr, mergeMethod, cmd, tmpBasePath, env)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"unable to merge --squash tracking into base: %w\", err)\n",
      "\t\t}\n",
      "\t\tif len(result.conflictFiles) > 0 {\n",
      "\t\t\treturn types.MergeResult{ConflictFiles: result.conflictFiles}, nil\n",
      "\t\t}\n",
      "\t\tif signArg == \"\" {\n",
      "\t\t\tif err := git.NewCommand(ctx, \"commit\", fmt.Sprintf(\"--author='%s'\", identity.String()), \"-m\", mergeMsg).Run(&git.RunOpts{Env: env, Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\t\treturn types.MergeResult{}, processGiteaErrorf(err, \"git commit [%s -> %s]\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t} else {\n",
      "\t\t\tif err := git.NewCommand(ctx, \"commit\", signArg, fmt.Sprintf(\"--author='%s'\", identity.String()), \"-m\", mergeMsg).Run(&git.RunOpts{Env: env, Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\t\treturn types.MergeResult{}, processGiteaErrorf(err, \"git commit [%s -> %s]\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\tcase enum.MergeMethodRebase:\n",
      "\t\tif err := git.NewCommand(ctx, \"checkout\", \"-b\", stagingBranch, trackingBranch).Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"git checkout base prior to merge post staging rebase  [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t}\n",
      "\t\toutbuf.Reset()\n",
      "\t\terrbuf.Reset()\n",
      "\t\tvar conflicts bool\n",
      "\t\tif err := git.NewCommand(ctx, \"rebase\", baseBranch).Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\tif _, statErr := os.Stat(filepath.Join(tmpBasePath, \".git\", \"REBASE_HEAD\")); statErr == nil {\n",
      "\t\t\t\tconflicts = true\n",
      "\t\t\t} else {\n",
      "\t\t\t\treturn types.MergeResult{}, fmt.Errorf(\"git rebase staging on to base [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\toutbuf.Reset()\n",
      "\t\terrbuf.Reset()\n",
      "\t\tif conflicts {\n",
      "\t\t\tif err := git.NewCommand(ctx, \"rebase\", \"--abort\").Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\t\treturn types.MergeResult{}, fmt.Errorf(\"git abort rebase [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t\toutbuf.Reset()\n",
      "\t\t\terrbuf.Reset()\n",
      "\t\t\tif err := git.NewCommand(ctx, \"checkout\", baseBranch).Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\t\treturn types.MergeResult{}, fmt.Errorf(\"return to the base branch [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t\toutbuf.Reset()\n",
      "\t\t\terrbuf.Reset()\n",
      "\t\t\tcmd := git.NewCommand(ctx, \"merge\", \"--no-ff\", \"--no-commit\", trackingBranch)\n",
      "\t\t\tresult, err := runMergeCommand(ctx, pr, mergeMethod, cmd, tmpBasePath, env)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn types.MergeResult{}, fmt.Errorf(\"git abort rebase [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t\t}\n",
      "\t\t\tif len(result.conflictFiles) > 0 {\n",
      "\t\t\t\treturn types.MergeResult{ConflictFiles: result.conflictFiles}, nil\n",
      "\t\t\t}\n",
      "\t\t\treturn types.MergeResult{}, errors.New(\"rebase reported conflicts, but merge gave no conflict files\")\n",
      "\t\t}\n",
      "\t\tif err := git.NewCommand(ctx, \"checkout\", baseBranch).Run(&git.RunOpts{Dir: tmpBasePath, Stdout: &outbuf, Stderr: &errbuf}); err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"git checkout base prior to merge post staging rebase  [%s -> %s]: %w\\n%s\\n%s\", pr.HeadBranch, pr.BaseBranch, err, outbuf.String(), errbuf.String())\n",
      "\t\t}\n",
      "\t\toutbuf.Reset()\n",
      "\t\terrbuf.Reset()\n",
      "\t\tcmd := git.NewCommand(ctx, \"merge\", \"--ff-only\", stagingBranch)\n",
      "\t\tresult, err := runMergeCommand(ctx, pr, mergeMethod, cmd, tmpBasePath, env)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn types.MergeResult{}, fmt.Errorf(\"unable to ff-olny merge tracking into base: %w\", err)\n",
      "\t\t}\n",
      "\t\tif len(result.conflictFiles) > 0 {\n",
      "\t\t\treturn types.MergeResult{ConflictFiles: result.conflictFiles}, nil\n",
      "\t\t}\n",
      "\tdefault:\n",
      "\t\treturn types.MergeResult{}, fmt.Errorf(\"wrong merge method provided: %s\", mergeMethod)\n",
      "\t}\n",
      "\treturn types.MergeResult{}, nil\n",
      "}\n",
      "======================CLASS=======================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "topic_4 10\n",
      "avelino/awesome-go 1 116621\n",
      "1\n",
      "======================CLASS=======================\n",
      "gin-gonic/gin 2 74189\n",
      "2\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "func (c *Context) ClientIP() string {\n",
      "\tif c.engine.TrustedPlatform != \"\" {\n",
      "\t\tif addr := c.requestHeader(c.engine.TrustedPlatform); addr != \"\" {\n",
      "\t\t\treturn addr\n",
      "\t\t}\n",
      "\t}\n",
      "\tif c.engine.AppEngine {\n",
      "\t\tlog.Println(`The AppEngine flag is going to be deprecated. Please check issues #2723 and #2739 and use 'TrustedPlatform: gin.PlatformGoogleAppEngine' instead.`)\n",
      "\t\tif addr := c.requestHeader(\"X-Appengine-Remote-Addr\"); addr != \"\" {\n",
      "\t\t\treturn addr\n",
      "\t\t}\n",
      "\t}\n",
      "\tremoteIP := net.ParseIP(c.RemoteIP())\n",
      "\tif remoteIP == nil {\n",
      "\t\treturn \"\"\n",
      "\t}\n",
      "\ttrusted := c.engine.isTrustedProxy(remoteIP)\n",
      "\tif trusted && c.engine.ForwardedByClientIP && c.engine.RemoteIPHeaders != nil {\n",
      "\t\tfor _, headerName := range c.engine.RemoteIPHeaders {\n",
      "\t\t\tip, valid := c.engine.validateHeader(c.requestHeader(headerName))\n",
      "\t\t\tif valid {\n",
      "\t\t\t\treturn ip\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn remoteIP.String()\n",
      "}\n",
      "func (c *Context) Negotiate(code int, config Negotiate) {\n",
      "\tswitch c.NegotiateFormat(config.Offered...) {\n",
      "\tcase binding.MIMEJSON:\n",
      "\t\tdata := chooseData(config.JSONData, config.Data)\n",
      "\t\tc.JSON(code, data)\n",
      "\tcase binding.MIMEHTML:\n",
      "\t\tdata := chooseData(config.HTMLData, config.Data)\n",
      "\t\tc.HTML(code, config.HTMLName, data)\n",
      "\tcase binding.MIMEXML:\n",
      "\t\tdata := chooseData(config.XMLData, config.Data)\n",
      "\t\tc.XML(code, data)\n",
      "\tcase binding.MIMEYAML:\n",
      "\t\tdata := chooseData(config.YAMLData, config.Data)\n",
      "\t\tc.YAML(code, data)\n",
      "\tcase binding.MIMETOML:\n",
      "\t\tdata := chooseData(config.TOMLData, config.Data)\n",
      "\t\tc.TOML(code, data)\n",
      "\tdefault:\n",
      "\t\tc.AbortWithError(http.StatusNotAcceptable, errors.New(\"the accepted formats are not offered by the server\"))\n",
      "\t}\n",
      "}\n",
      "func chooseData(custom, wildcard any) any {\n",
      "\tif custom != nil {\n",
      "\t\treturn custom\n",
      "\t}\n",
      "\tif wildcard != nil {\n",
      "\t\treturn wildcard\n",
      "\t}\n",
      "\tpanic(\"negotiation config is invalid\")\n",
      "}\n",
      "sirupsen/logrus 1 23799\n",
      "1\n",
      "======================CLASS=======================\n",
      "charmbracelet/bubbletea 4 22583\n",
      "4\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "stretchr/testify 4 21538\n",
      "4\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "gorilla/mux 1 19872\n",
      "1\n",
      "======================CLASS=======================\n",
      "go-chi/chi 4 16555\n",
      "4\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "======================CLASS=======================\n",
      "julienschmidt/httprouter 1 16120\n",
      "1\n",
      "======================CLASS=======================\n",
      "go-playground/validator 1 15048\n",
      "1\n",
      "======================CLASS=======================\n",
      "jmoiron/sqlx 1 15043\n",
      "1\n",
      "======================CLASS=======================\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T00:56:21.900482Z",
     "start_time": "2024-11-29T00:56:04.356328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = open(\"codes.txt\", \"a\")\n",
    "for topic in repos_topic:\n",
    "  print(topic, len(repos_topic[topic]))\n",
    "  file.write(f\"TOPIC {topic}\\n\")\n",
    "  for repo in repos_topic[topic]:\n",
    "    print(repo['key'], len(repo['classes']), repo['stars'])\n",
    "    file.write(f\"REPO {repo['key']} {len(repo['classes'])}\\n\")\n",
    "    line = save_classes_code(repo['key'], repo['classes'])\n",
    "    file.write(line)\n",
    "  file.write(\"\\n\"*2)\n",
    "file.close()"
   ],
   "id": "8f708a3d5b0152b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 10\n",
      "junegunn/fzf 2 57530\n",
      "wagoodman/dive 2 42548\n",
      "coreybutler/nvm-windows 4 33303\n",
      "spf13/viper 3 25212\n",
      "tsenart/vegeta 5 22484\n",
      "projectdiscovery/nuclei 1 16418\n",
      "charmbracelet/gum 4 15909\n",
      "bcicen/ctop 6 14993\n",
      "FiloSottile/age 1 14855\n",
      "gitleaks/gitleaks 2 14713\n",
      "topic_1 10\n",
      "fatedier/frp 9 77144\n",
      "FiloSottile/mkcert 2 44662\n",
      "ehang-io/nps 3 28567\n",
      "schollz/croc 5 25745\n",
      "inconshreveable/ngrok 1 23632\n",
      "redis/go-redis 3 18715\n",
      "yudai/gotty 2 18326\n",
      "joewalnes/websocketd 6 17028\n",
      "rakyll/hey 2 16914\n",
      "XIU2/CloudflareSpeedTest 2 15319\n",
      "topic_2 10\n",
      "prometheus/prometheus 5 51732\n",
      "rclone/rclone 6 42712\n",
      "hashicorp/terraform 6 40408\n",
      "hashicorp/vault 703 29289\n",
      "hashicorp/consul 11 27562\n",
      "tmrts/go-patterns 1 23606\n",
      "hashicorp/packer 1 14780\n",
      "rqlite/rqlite 3 14605\n",
      "Netflix/chaosmonkey 3 14258\n",
      "CodisLabs/codis 5 13027\n",
      "topic_3 10\n",
      "gohugoio/hugo 6 71281\n",
      "syncthing/syncthing 11 58080\n",
      "etcd-io/etcd 15 45720\n",
      "gogs/gogs 3 43778\n",
      "astaxie/build-web-application-with-golang 13 42697\n",
      "spf13/cobra 1 35174\n",
      "go-gorm/gorm 1 34799\n",
      "unknwon/the-way-to-go_ZH_CN 8 33963\n",
      "docker/compose 1 31817\n",
      "harness/gitness 5 31162\n",
      "topic_4 10\n",
      "avelino/awesome-go 1 116621\n",
      "gin-gonic/gin 2 74189\n",
      "sirupsen/logrus 1 23799\n",
      "charmbracelet/bubbletea 4 22583\n",
      "stretchr/testify 4 21538\n",
      "gorilla/mux 1 19872\n",
      "go-chi/chi 4 16555\n",
      "julienschmidt/httprouter 1 16120\n",
      "go-playground/validator 1 15048\n",
      "jmoiron/sqlx 1 15043\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T01:53:03.259397Z",
     "start_time": "2024-11-29T01:52:43.934637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = open(\"codes.json\", \"a\")\n",
    "objs = []\n",
    "for topic in repos_topic:\n",
    "  for repo in repos_topic[topic]:\n",
    "    ob = {\n",
    "      'repository': repo['key'],\n",
    "      'topic': topic,\n",
    "      'total_classes': len(repo['classes']),\n",
    "      'classes': json_classes_code(repo['key'], repo['classes'])\n",
    "    }\n",
    "    objs.append(ob)\n",
    "file.write(json.dumps(objs)) \n",
    "file.close()"
   ],
   "id": "81573837acf5e3b3",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T00:20:35.112475Z",
     "start_time": "2024-11-29T00:20:35.100599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# average number of elements per class per topic\n",
    "for topic in repos_topic:\n",
    "  total = 0\n",
    "  for repo in repos_topic[topic]:\n",
    "    for klass in repo['classes']:\n",
    "      total += len(klass)\n",
    "  print(topic, total/len(repos_topic[topic]))\n",
    "    "
   ],
   "id": "6d838621bee74c45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 355.9\n",
      "topic_1 320.3\n",
      "topic_2 832.0\n",
      "topic_3 567.2\n",
      "topic_4 247.2\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T02:44:46.107501Z",
     "start_time": "2024-11-29T02:44:44.966773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "file_path = \"codes.json\"\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "categories = {\n",
    "    \"Concurrency\": [\"sync\", \"lock\", \"mutex\", \"parallel\", \"goroutine\", \"wait\", \"go\", \"waitgroup\", \"chan\", \"select\"],\n",
    "    \"Error Handling\": [\"error\", \"panic\", \"recover\", \"fail\"],\n",
    "    \"Mocking\": [\"mock\", \"stub\", \"fake\", \"spy\", \"testdouble\", \"mockservice\"],\n",
    "    \"Logging\": [\"log\", \"logger\", \"logging\"],\n",
    "    \"Autogenerated Code\": [\"auto\", \"generate\", \"template\"],\n",
    "    \"Utility Functions\": [\"util\", \"helper\", \"common\", \"tool\", \"contains\", \"prefix\"],\n",
    "    \"Rendering/Output\": [\"render\", \"print\", \"output\", \"display\", \"draw\"],\n",
    "    \"File/IO\": [\"file\", \"read\", \"write\", \"io\", \"stream\", \"open\", \"close\"],\n",
    "    \"Configuration\": [\"config\", \"env\", \"flag\", \"viper\", \"init\", \"settings\"],\n",
    "    \"Types\": [\"type\", \"switch\", \"case\"],\n",
    "}\n",
    "\n",
    "category_counts = Counter()\n",
    "\n",
    "for repo in data:\n",
    "    for func in repo.get(\"classes\", []):\n",
    "        function_body = \" \".join(func)\n",
    "        matched_categories = set()\n",
    "        \n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in function_body.lower() for keyword in keywords):\n",
    "                matched_categories.add(category)\n",
    "        \n",
    "        if not matched_categories:\n",
    "            matched_categories.add(\"Uncategorized\")\n",
    "        \n",
    "        for matched in matched_categories:\n",
    "            category_counts[matched] += 1\n",
    "\n",
    "category_counts"
   ],
   "id": "c06590c67bd46562",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Error Handling': 624,\n",
       "         'File/IO': 601,\n",
       "         'Logging': 407,\n",
       "         'Configuration': 393,\n",
       "         'Types': 372,\n",
       "         'Concurrency': 369,\n",
       "         'Utility Functions': 335,\n",
       "         'Rendering/Output': 246,\n",
       "         'Autogenerated Code': 200,\n",
       "         'Uncategorized': 55,\n",
       "         'Mocking': 28})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
